{
    "2020": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2020s.html",
            "conf_title": "50th DSN 2020: Valencia, Spain - Supplemental Volume",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/9146897/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00013",
                    "title": "Robustness Inside Out Testing",
                    "authors": "Deborah S. Katz, Milda Zizyte, Casidhe Hutchison, David Guttendorf, Patrick E. Lanigan, Eric M. Sample, Philip Koopman, Michael D. Wagner, Claire Le Goues",
                    "abstract": "Robustness testing is an important technique to reveal defects and vulnerabilities in software, especially software for Unmanned Autonomous Systems (UAS). We present Robustness Inside Out Testing (RIOT) as a technique directed at finding failures in autonomy systems that are able to be activated from external interfaces. The technique consists of four main steps: unit-level robustness testing, generalization, permeability analysis, and activation. Each of these steps yields a valuable deliverable in the testing process, and, when applied in succession, expands a unit-level bug to an external interface. RIOT has the following advantages over traditional robustness testing: it finds faults faster, it can find faults missed by traditional approaches, it identifies faults that can be triggered from inputs at an external interface, and it produces useful artifacts to aid in fault diagnosis and repair. In this paper, we outline each step of the RIOT process and provide an example of RIOT finding a bug on a real system that would not have been discovered using existing techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "健壮性测试是揭示软件缺陷和漏洞的重要技术，尤其是无人自主系统(UAS)的软件。我们将健壮性从里到外测试(RIOT)作为一种技术，旨在发现能够从外部接口激活的自治系统中的故障。该技术由四个主要步骤组成:单元级健壮性测试、泛化、渗透性分析和激活。这些步骤中的每一步都会在测试过程中产生有价值的可交付成果，并且当连续应用时，会将单元级别的错误扩展到外部接口。与传统的健壮性测试相比，RIOT具有以下优势:它可以更快地发现故障，可以发现传统方法遗漏的故障，可以识别外部接口输入触发的故障，并产生有用的工件来帮助故障诊断和修复。在本文中，我们概述了RIOT流程的每个步骤，并提供了一个RIOT在真实系统上发现一个使用现有技术无法发现的bug的示例。",
                    "title_zh": "由内向外测试的健壮性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00014",
                    "title": "Towards Host Intrusion Detection for Embedded Industrial Systems",
                    "authors": "Marine Kadar, Sergey Tverdyshev, Gerhard Fohler",
                    "abstract": "Original Equipment Manufacturers now embed hardware virtualization in car equipment to reduce costs and hardware complexity, while allowing more functionalities, such as connectivity. This evolution forces the cohabitation of distinct criticality domains on the same hardware, reaffirming the need for security. Because of the trade-off between performance and system overall complexity, deploying security becomes a challenging balancing act. Host Intrusion Detection Systems (HIDS) security protects the behavior of a program at run-time: it monitors the program execution flow to distinguish threats from benign activity. This paper presents a novel run-time security solution for embedded mixed-criticality systems, which integrates HIDS in a partitioned system based on Multiple Independent Levels of Security (MILS) architecture. Our HIDS monitors a program's execution by observing both hardware and software signals; there is to our knowledge no HIDS providing such precise representation of program execution.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/5851296/files/45.pdf"
                    },
                    "abstract_zh": "原始设备制造商现在将硬件虚拟化嵌入汽车设备，以降低成本和硬件复杂性，同时允许更多功能，如连接。这种发展迫使不同的关键域在同一硬件上共存，再次证实了对安全性的需求。由于性能和系统整体复杂性之间的权衡，部署安全性成为一项具有挑战性的平衡工作。主机入侵检测系统(HIDS)安全保护程序在运行时的行为:它监视程序执行流，以区分威胁和良性活动。提出了一种新的嵌入式混合关键度系统运行时安全解决方案，该方案基于多独立安全级别(MILS)架构将HIDS集成到一个分区系统中。我们的HIDS通过观察硬件和软件信号来监控程序的执行；据我们所知，没有HIDS提供如此精确的程序执行表示。",
                    "title_zh": "面向嵌入式工业系统的主机入侵检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00015",
                    "title": "The Monitor as Key Architecture Element for Safe Self-Driving Cars",
                    "authors": "Ayhan Mehmed, Moritz Antlanger, Wilfried Steiner",
                    "abstract": "While research in self-driving cars continuous to boom, research of their dependability aspects is only emerging. In particular, trade-off studies on fault-tolerant architectures for safe self-driving cars are largely missing, but desperately needed by the automotive industry. In this paper we give a brief overview of some possible architecture designs, and argue in favour of those architectures that implement a monitor element. We also formulate open research questions with respect to monitor construction and permissible interfaces from the monitor to other elements that constitute the architecture.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然对自动驾驶汽车的研究持续繁荣，但对其可靠性方面的研究才刚刚开始。特别是，关于安全自动驾驶汽车容错架构的权衡研究在很大程度上是缺失的，但却是汽车行业迫切需要的。在本文中，我们简要概述了一些可能的架构设计，并支持那些实现监视器元素的架构。我们还制定了关于监视器构造和从监视器到构成架构的其他元素的允许接口的开放研究问题。",
                    "title_zh": "监控器是安全自动驾驶汽车的关键架构元素"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00016",
                    "title": "Predicting Remediations for Hardware Failures in Large-Scale Datacenters",
                    "authors": "Fan Fred Lin, Antonio Davoli, Imran Akbar, Sukumar Kalmanje, Leandro Silva, John Stamford, Yanai Golany, Jim Piazza, Sriram Sankar",
                    "abstract": "Large-scale service environments rely on autonomous systems for remediating hardware failures efficiently. In production, the autonomous system diagnoses hardware failures based on the rules that the subject matter experts put in the system. This process is increasingly complex given new types of failures and the increasing complexity in the hardware and software configurations. In this paper, we present a machine learning framework that predicts the required remediations for undiagnosed failures, based on the similar repair tickets closed in the past. We explain the methodology in detail for setting up a machine learning model, deploying it in a production environment, and monitoring its performance with the necessary metrics. We also demonstrate the prediction performance on some of the repair actions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大规模服务环境依赖于自治系统来有效地修复硬件故障。在生产中，自治系统根据主题专家放入系统的规则来诊断硬件故障。鉴于新的故障类型以及硬件和软件配置的日益增加的复杂性，该过程变得日益复杂。在本文中，我们提出了一个机器学习框架，该框架基于过去关闭的类似维修单，预测未诊断故障所需的补救措施。我们详细解释了建立机器学习模型的方法，将其部署在生产环境中，并使用必要的指标监控其性能。我们还演示了一些修复动作的预测性能。",
                    "title_zh": "预测大规模数据中心硬件故障的补救措施"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00017",
                    "title": "ZTE-Predictor: Disk Failure Prediction System Based on LSTM",
                    "authors": "Hongzhang Yang, Zongzhao Li, Huiyuan Qiang, Zhongliang Li, Yaofeng Tu, Yahui Yang",
                    "abstract": "Disk failure prediction technology has become a hotspot in both academia and industry, which is of great significance to improve the reliability of data center. This paper studies ZTE's disk SMART (Self-Monitoring Analysis and Reporting Technology) data set, trying to predict whether the disk will fail within 5-7 days. In the model training stage, the disk state is classified as normal and failure within 5 days. Then the positive and negative samples are balanced by both over-sampling and under-sampling. Finally, the data set is trained by LSTM (Long Short-Term Memory) and the disk failure prediction model is obtained. In the experiment of ZTE historical data set, the best FDR (Fault Detection Rate) is 97.4% and FAR (False Alarm Rate) is 0.3%. After launching in ZTE data center for 7 months, the best FDR is 94.5%, and the FAR is 0.7%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "磁盘故障预测技术已经成为学术界和工业界的研究热点，对提高数据中心的可靠性具有重要意义。本文研究了中兴的disk SMART(自监测分析报告技术)数据集，试图预测磁盘是否会在5-7天内失效。在模型训练阶段，5天内将磁盘状态分类为正常和故障。然后通过过采样和欠采样来平衡正负样本。最后，利用LSTM对数据集进行训练，得到磁盘故障预测模型。在中兴历史数据集的实验中，最佳FDR(故障检测率)为97.4%，FAR(误报率)为0.3%。在中兴数据中心上线7个月，最好的FDR为94.5%，FAR为0.7%。",
                    "title_zh": "ZTE-Predictor:基于LSTM的磁盘故障预测系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00018",
                    "title": "Neuraltran: Optimal Data Transformation for Privacy-Preserving Machine Learning by Leveraging Neural Networks",
                    "authors": "Changchang Liu, Wei-Han Lee, Seraphin B. Calo",
                    "abstract": "In this work, we develop a new data transformation technique to mediate privacy-preserving access to data while achieving machine learning (ML) tasks. Specifically, we first leverage mutual information in information theory to quantify the utility-providing information (corresponding to any ML task) and the privacy information (could be arbitrary information specified by the users). We further convert the optimization of utility-privacy tradeoff into training a novel neural network (named as NeuralTran) which consists of three modules: transformation module, utility module and privacy module. NeuralTran can be leveraged to automatically transform the input data to ensure that only utility-providing information is kept while the private information is removed. Through extensive experiments on real world datasets, we show the effectiveness of NeuralTran in balancing utility and privacy as well as its advantages over previous approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在这项工作中，我们开发了一种新的数据转换技术，以调解隐私保护的数据访问，同时实现机器学习(ML)任务。具体来说，我们首先利用信息论中的互信息来量化效用提供信息(对应于任何ML任务)和隐私信息(可以是用户指定的任意信息)。我们进一步将效用-隐私折衷的优化转化为训练一个新的神经网络(命名为NeuralTran ),该网络由三个模块组成:转换模块、效用模块和隐私模块。可以利用NeuralTran自动转换输入数据，以确保只保留提供实用程序的信息，而删除私有信息。通过在真实数据集上的大量实验，我们展示了NeuralTran在平衡效用和隐私方面的有效性，以及它相对于以前方法的优势。",
                    "title_zh": "Neuraltran:利用神经网络进行隐私保护机器学习的最优数据转换"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00019",
                    "title": "Simulating Reliability of IoT Networks with RelIoT",
                    "authors": "Kazim Ergun, Xiaofan Yu, Nitish Nagesh, Ludmila Cherkasova, Pietro Mercati, Raid Ayoub, Tajana Rosing",
                    "abstract": "The Internet of Things (IoT) networks are expected to operate reliably for many years while meeting the needs of a growing range of applications. However, a dependable operation may not always be maintained due to the reliability degradation of IoT devices. From low-power sensors to multi-core platforms, IoT devices age and degrade, leading to failures that necessitate maintenance. Reliability-aware design and management were shown to delay failures and improve the lifetime of individual devices. Even though the IoT networks can also radically benefit from this, the unavailability of network simulators that provide reliability modeling makes it impossible to assess reliability-aware strategies. To bridge this gap and enable reliability analysis at an early design phase, we introduce an integrated reliability framework called RelIoT for IoT networks, implemented in the ns-3 simulator. The framework also includes modeling of power, performance, and temperature, which are required to model reliability. We validate the simulations done using our framework and demonstrate that RelIoT accurately captures the power, temperature, and reliability dynamics of real networked IoT devices.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "物联网(IoT)网络有望在满足日益增长的应用需求的同时可靠运行多年。然而，由于物联网设备的可靠性下降，可能不总是保持可靠的操作。从低功耗传感器到多核平台，物联网设备会老化和降级，导致需要维护的故障。具有可靠性意识的设计和管理被证明可以延迟故障并提高单个设备的寿命。尽管物联网网络也可以从这一点上受益，但提供可靠性建模的网络模拟器的不可用性使得评估可靠性感知策略变得不可能。为了弥合这一差距并在早期设计阶段实现可靠性分析，我们引入了一个名为RelIoT for IoT networks的集成可靠性框架，在ns-3模拟器中实施。该框架还包括建模可靠性所需的功耗、性能和温度模型。我们验证了使用我们的框架完成的模拟，并证明RelIoT准确地捕捉了真实联网物联网设备的功率、温度和可靠性动态。",
                    "title_zh": "用RelIoT模拟物联网网络的可靠性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00020",
                    "title": "Performance-Aware Wi-Fi Problem Diagnosis and Mitigation through Peer-to-Peer Data Sharing",
                    "authors": "Nathan D. Mickulicz, Priya Narasimhan",
                    "abstract": "Large-scale, high-density Wi-Fi networks use hundreds of access points to serve thousands of closely-packed users within a large physical space, such as within a stadium or arena. It is difficult to predict when and where problems will occur in these Wi-Fi networks, due to the constant movement of mobile devices within the network and the constantly-changing workload as users switch between applications. In this paper, we describe a unique approach to detecting, diagnosing, and mitigating problems in Wi-Fi networks using Wi-Fi performance data collected from mobile devices and shared between nearby peers. Our approach draws upon 3 years of production performance data that we have collected from 35 production mobile applications used in 25 professional and collegiate sports venues in the US. We also present an evaluation of the effectiveness of our diagnostic and mitigation approach in a real-world high-density Wi-Fi environment, showing that our approach outperforms standard driver-based problem detection and mitigation on several common Wi-Fi faults.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大规模、高密度的Wi-Fi网络使用数百个接入点来为大型物理空间(例如体育场或竞技场)内成千上万密集的用户提供服务。由于移动设备在网络中的不断移动以及用户在应用程序之间切换时不断变化的工作负载，很难预测这些Wi-Fi网络中何时何地会出现问题。在本文中，我们描述了一种独特的方法来检测、诊断和缓解Wi-Fi网络中的问题，该方法使用从移动设备收集的Wi-Fi性能数据，并在附近的对等设备之间共享。我们的方法利用了3年的生产性能数据，这些数据是我们从美国25个专业和大学体育场馆中使用的35个生产移动应用程序中收集的。我们还对我们的诊断和缓解方法在真实世界高密度Wi-Fi环境中的有效性进行了评估，表明我们的方法在几种常见Wi-Fi故障上优于标准的基于驱动程序的问题检测和缓解。",
                    "title_zh": "通过点对点数据共享进行性能感知的Wi-Fi问题诊断和缓解"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00021",
                    "title": "Fundamental Challenges of Cyber-Physical Systems Security Modeling",
                    "authors": "Georgios Bakirtzis, Garrett L. Ward, Christopher J. Deloglos, Carl R. Elks, Barry M. Horowitz, Cody H. Fleming",
                    "abstract": "Systems modeling practice lacks security analysis tools that can interface with modeling languages to facilitate security by design. Security by design is a necessity in the age of safety critical cyber-physical systems, where security violations can cause hazards. Currently, the overlap between security and safety is narrow. But deploying cyber-physical systems means that today's adversaries can intentionally trigger accidents. By implementing security assessment tools for modeling languages we are better able to address threats earlier in the system's lifecycle and, therefore, assure their safe and secure behavior in their eventual deployment. We posit that cyber-physical systems security modeling is practiced insufficiently because it is still addressed similarly to information technology systems.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2005.00043"
                    },
                    "abstract_zh": "系统建模实践缺乏安全分析工具，这些工具可以与建模语言交互以通过设计促进安全性。在安全至关重要的网络物理系统时代，安全设计是必要的，在这个时代，违反安全可能会导致危险。目前，安保和安全之间的重叠很少。但是部署网络物理系统意味着今天的对手可以故意引发事故。通过实现建模语言的安全评估工具，我们能够更好地在系统生命周期的早期解决威胁，从而确保它们在最终部署中的安全行为。我们假设，网络物理系统安全建模没有得到充分实施，因为它仍然以类似于信息技术系统的方式处理。",
                    "title_zh": "信息物理系统安全建模的基本挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00022",
                    "title": "Ontology Configuration Management for Knowledge-Centric Systems Engineering in Industry",
                    "authors": "Borja López, José María Álvarez Rodríguez, Eugenio Parra, Jose Luis de la Vara",
                    "abstract": "The engineering of safety-critical systems is a complex process whose cost-effectiveness is very important. Reuse of system artefacts is an activity that can contribute to improving quality and to saving costs during the process. Reuse must pay attention to artefact configuration management, as an artefact evolves through different versions and such an evolution must be properly managed. An artefact type that is used nowadays in industry for the engineering of safety-critical systems and can be reused is ontologies, which represent system domain information via knowledge representations. However, academic approaches for ontology reuse do not meet industrial needs for their application for systems engineering. As a solution, this paper presents an industrial approach to define and operate ontologies as libraries of knowledge to enable ontology configuration management. The approach supports the reuse and exploitation of domain knowledge through operations for mapping, alignment, and merge of ontology elements. The proposed approach, the current implementation, and validation activities are presented on top of the Knowledge Manager tool.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全关键系统的工程是一个复杂的过程，其成本效益非常重要。系统工件的重用是一种在过程中有助于提高质量和节约成本的活动。重用必须注意产品的配置管理，因为一个产品通过不同的版本进化，这样的进化必须被正确地管理。现今在工业中用于安全关键系统的工程并且可以重复使用的人工制品类型是本体，其通过知识表示来表示系统领域信息。然而，本体重用的学术方法不能满足系统工程应用的工业需求。作为一种解决方案，本文提出了一种工业方法来定义和操作作为知识库的本体，以实现本体配置管理。该方法通过本体元素的映射、对齐和合并操作来支持领域知识的重用和开发。建议的方法、当前的实现和验证活动在知识管理器工具之上呈现。",
                    "title_zh": "面向工业知识中心系统工程的本体配置管理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00023",
                    "title": "Secure Consensus Generation with Distributed DoH",
                    "authors": "Philipp Jeitner, Haya Shulman, Michael Waidner",
                    "abstract": "Many applications and protocols depend on the ability to generate a pool of servers to conduct majority-based consensus mechanisms and often this is done by doing plain DNS queries. A recent off-path attack [1] against NTP and security enhanced NTP with Chronos [2] showed that relying on DNS for generating the pool of NTP servers introduces a weak link. In this work, we propose a secure, backward-compatible address pool generation method using distributed DNS-over-HTTPS (DoH) resolvers which is aimed to prevent such attacks against server pool generation.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2010.09331"
                    },
                    "abstract_zh": "许多应用程序和协议依赖于生成服务器池的能力来执行基于多数的共识机制，这通常是通过执行简单的DNS查询来完成的。最近针对NTP和使用Chronos [2]的安全增强型NTP的路径外攻击[1]表明，依赖DNS来生成NTP服务器池会引入一个薄弱环节。在这篇文章中，我们提出了一种安全的、向后兼容的地址池生成方法，该方法使用分布式HTTPS域名解析器(DoH)来防止对服务器地址池生成的攻击。",
                    "title_zh": "使用分布式DoH的安全共识生成"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00024",
                    "title": "Design and Performance Analysis of Software Defined Networking Based Web Services Adopting Moving Target Defense",
                    "authors": "Dong Seong Kim, Minjune Kim, Jin-Hee Cho, Hyuk Lim, Terrence J. Moore, Frederica Free-Nelson",
                    "abstract": "Moving Target Defense (MTD) has been emerged as a promising countermeasure to defend systems against cyberattacks asymmetrically while working well with legacy security and defense mechanisms. MTD provides proactive security services by dynamically altering attack surfaces and increasing attack cost or complexity to prevent further escalation of the attack. However, one of the non-trivial hurdles in deploying MTD techniques is how to handle potential performance degradation (e.g., interruptions of service availability) and maintain acceptable quality-of-service (QoS) in an MTD-enabled system. In this paper, we derive the service performance metrics (e.g., an extent of failed jobs) to measure how much performance degradation is introduced due to MTD operations, and propose QoS-aware service strategies (i.e., drop and wait) to manage ongoing jobs with the minimum performance degradation even under MTD operations running. We evaluate the service performance of software-defined networking (SDN)-based web services (i.e., Apache web servers). Our experimental results prove that the MTD-enabled system can minimize performance degradation by using the proposed job management strategies. The proposed strategies aim to optimize a specific service configuration (e.g., types of jobs and request rates) and effectively minimize the adverse impact of deploying MTD in the system with acceptable QoS while retaining the security effect of IP shuffling-based MTD.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "移动目标防御(MTD)已经成为一种有前途的对抗措施，用于防御非对称的网络攻击，同时与传统的安全和防御机制配合良好。MTD通过动态改变攻击面和增加攻击成本或复杂性来提供主动安全服务，以防止攻击的进一步升级。然而，部署MTD技术的一个重要障碍是如何在启用MTD的系统中处理潜在的性能下降(例如，服务可用性的中断)并保持可接受的服务质量(QoS)。在本文中，我们推导了服务性能度量(例如，失败作业的程度)来测量由于MTD操作引入了多少性能降级，并提出了QoS感知的服务策略(即，丢弃和等待)来管理正在进行的作业，即使在MTD操作运行的情况下也具有最小的性能降级。我们评估了基于软件定义网络(SDN)的web服务(即Apache web服务器)的服务性能。我们的实验结果证明，MTD支持的系统可以通过使用所提出的作业管理策略来最小化性能下降。所提出的策略旨在优化特定的服务配置(例如，作业类型和请求速率)，并有效地最小化在具有可接受的QoS的系统中部署MTD的不利影响，同时保留基于IP改组的MTD的安全效果。",
                    "title_zh": "采用移动目标防御的软件定义网络Web服务的设计与性能分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00025",
                    "title": "Tomographic Measuring Sensors System for Analysis and Visualization of Technological Processes",
                    "authors": "Mariusz Mazurek, Tomasz Rymarczyk, Grzegorz Klosowski, Michal Maj, Przemyslaw Adamkiewicz",
                    "abstract": "The paper presents the results of research on the use of tomographic sensors to analyze industrial processes using dedicated measuring devices, image reconstruction algorithms and cyber-physical system (CPS). The work mainly focuses on ultrasound tomography and image reconstruction using determi-nistic methods and machine learning. The tests were carried out for synthetic data and laboratory measurements. The main advantage of the proposed system is the ability to analyze spatial data and their high processing speed. The presented research results indicate that ultrasonic process tomography gives the opportunity to analyze processes occurring inside the facility without disrupting production. The presented method enables the analysis and detection of obstacles, defects and various anomalies. Knowing the characteristics of the problem, the application allows you to choose the right method of image reconstruction.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了使用专用测量设备、图像重建算法和信息物理系统(CPS)使用层析成像传感器分析工业过程的研究结果。这项工作主要集中在使用确定性方法和机器学习的超声层析成像和图像重建。对合成数据和实验室测量进行了测试。所提议的系统的主要优点是分析空间数据的能力及其高处理速度。提出的研究结果表明，超声波过程层析成像提供了在不中断生产的情况下分析设施内部发生的过程的机会。所提出的方法能够分析和检测障碍物、缺陷和各种异常。了解了问题的特征，应用程序允许您选择正确的图像重建方法。",
                    "title_zh": "用于工艺过程分析和可视化的层析测量传感器系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00026",
                    "title": "MPC for Securing Internet Infrastructure",
                    "authors": "Kris Shrishak, Haya Shulman",
                    "abstract": "Secure multiparty computation (MPC) allows multiple entities to perform joint computation over their private inputs, revealing only the output. Although it was considered to be \"not efficient enough\" for many years, recent advances have shown that secure computation can be practical for specific applications. These applications have ranged from privacy-preserving auctions to private machine learning. In this work we explore the use of MPC for securing Internet infrastructure. We show that basic Internet systems, such as routing and DNS, rely on centralised authorities. Nevertheless, vulnerabilities as well as conflicting interests often make this requirement for trust not suitable for practical purposes. In this work, we set forth to explore replacement of trust in centralised authorities in Internet infrastructure with secure MPC.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全多方计算(MPC)允许多个实体对其私有输入执行联合计算，仅显示输出。尽管多年来人们一直认为安全计算“不够有效”，但最近的进展表明，安全计算对于特定的应用是切实可行的。这些应用包括从隐私保护拍卖到私人机器学习。在这项工作中，我们探索了使用MPC来保护互联网基础设施。我们表明，基本的互联网系统，如路由和域名系统，依赖于中央机构。然而，脆弱性以及利益冲突往往使这种信任要求不适用于实际目的。在这项工作中，我们开始探索在互联网基础设施中用安全的MPC取代对中央权威机构的信任。",
                    "title_zh": "保护互联网基础设施的MPC"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00027",
                    "title": "Pitfalls of Provably Secure Systems in Internet the Case of Chronos-NTP",
                    "authors": "Philipp Jeitner, Haya Shulman, Michael Waidner",
                    "abstract": "The critical role that Network Time Protocol (NTP) plays in the Internet led to multiple efforts to secure it against time-shifting attacks. A recent proposal for enhancing the security of NTP with Chronos against on-path attackers seems the most promising one and is on a standardisation track of the IETF. In this work we demonstrate off-path attacks against Chronos enhanced NTP clients. The weak link is a central security feature of Chronos: The server pool generation mechanism using DNS. We show that the insecurity of DNS allows to subvert the security of Chronos making the time-shifting attacks against Chronos-NTP even easier than attacks against plain NTP.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2010.08460"
                    },
                    "abstract_zh": "网络时间协议(NTP)在互联网中扮演的关键角色导致了多种努力来保护它免受时移攻击。最近提出的用Chronos增强NTP的安全性以抵御路径上的攻击者的建议似乎是最有希望的，并且是在IETF的标准化轨道上。在这项工作中，我们演示了针对Chronos增强型NTP客户端的路径外攻击。薄弱环节是Chronos的核心安全特性:使用DNS的服务器池生成机制。我们证明DNS的不安全性允许破坏Chronos的安全性，使得针对Chronos-NTP的时移攻击比针对普通NTP的攻击更容易。",
                    "title_zh": "互联网中可证明安全系统的缺陷——Chronos-NTP案例"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00028",
                    "title": "SIMBA: An Efficient Simulator for Blockchain Applications",
                    "authors": "Seyed Mehdi Fattahi, Adetokunbo Makanju, Amin Milani Fard",
                    "abstract": "Predicting the performance of a blockchain application during the design phase is difficult and evaluation after it is built could be expensive. The ability to simulate a blockchain network during the design stage in order to evaluate it is therefore a necessity. In this paper, we present a simulator for blockchain applications, called SIMBA (SIMulator for Blockchain Applications). SIMBA extends an existing simulator by adding the Merkle tree feature to blockchain nodes to improve efficiency and allowing more realistic evaluations not possible with the base tool to be performed. Results of our experiments show that the inclusion of Merkle trees has a high impact of up to 30 times reduction in the verification time of block transactions without an impact on block propagation delay. Since block verification is a critical part of the computational load of nodes on the network, this performance improvement significantly affects the overall performance of each node and consequently the entire network.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在设计阶段预测区块链应用程序的性能是很困难的，并且在构建之后进行评估也是非常昂贵的。因此，在设计阶段模拟区块链网络以对其进行评估的能力是必要的。在本文中，我们提出了一个用于区块链应用的模拟器，称为SIMBA(区块链应用模拟器)。SIMBA通过向区块链节点添加Merkle树功能来扩展现有的模拟器，以提高效率，并允许使用基本工具无法执行的更真实的评估。我们的实验结果表明，包含Merkle树对块事务的验证时间具有高达30倍的减少的高影响，而对块传播延迟没有影响。由于块验证是网络上节点的计算负载的关键部分，所以这种性能改进显著影响每个节点的整体性能，从而影响整个网络。",
                    "title_zh": "SIMBA:区块链应用的高效模拟器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00029",
                    "title": "Fault Tree Analysis: Identifying Maximum Probability Minimal Cut Sets with MaxSAT",
                    "authors": "Martín Barrère, Chris Hankin",
                    "abstract": "In this paper, we present a novel MaxSAT-based technique to compute Maximum Probability Minimal Cut Sets (MPMCSs) in fault trees. We model the MPMCS problem as a Weighted Partial MaxSAT problem and solve it using a parallel SAT-solving architecture. The results obtained with our open source tool indicate that the approach is effective and efficient.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2005.03003"
                    },
                    "abstract_zh": "本文提出了一种新的基于MaxSAT的技术来计算故障树中的最大概率最小割集。我们将MPMCS问题建模为加权部分最大SAT问题，并使用并行SAT求解架构来解决它。使用我们的开源工具获得的结果表明该方法是有效和高效的。",
                    "title_zh": "故障树分析:用MaxSAT确定最大概率最小割集"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00030",
                    "title": "Impact of Coding Styles on Behaviours of Static Analysis Tools for Web Applications",
                    "authors": "Ibéria Medeiros, Nuno Neves",
                    "abstract": "Web applications have become an essential resource to access the services of diverse subjects (e.g., financial, healthcare) available on the Internet. Despite the efforts that have been made on its security, namely on the investigation of better techniques to detect vulnerabilities on its source code, the number of vulnerabilities exploited has not decreased. Static analysis tools (SATs) are often used to test the security of applications since their outcomes can help developers in the correction of the bugs they found. The conducted investigation made over SATs stated they often generate errors (false positives (FP) and false negatives (FN)), whose cause is recurrently associated with very diverse coding styles, i.e., similar functionality is implemented in distinct manners, and programming practices that create ambiguity, such as the reuse and share of variables. Based on a common practice of using multiple forms in a same webpage and its processing in a single file, we defined a use case for user login and register with six coding styles scenarios for processing their data, and evaluated the behaviour of three SATs (phpSAFE, RIPS and WAP) with them to verify and understand why SATs produce FP and FN.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Web应用程序已经成为访问互联网上各种主题(如金融、医疗保健)服务的重要资源。尽管在安全方面已经做出了努力，即研究更好的技术来检测源代码中的漏洞，但是被利用的漏洞数量并没有减少。静态分析工具(sat)通常用于测试应用程序的安全性，因为它们的结果可以帮助开发人员纠正他们发现的错误。对sat进行的调查表明，它们经常产生错误(假阳性(FP)和假阴性(FN))，其原因经常与非常不同的编码风格有关，即类似的功能以不同的方式实现，以及产生模糊性的编程实践，如变量的重用和共享。基于在同一个网页中使用多个表单并在单个文件中处理表单的常见实践，我们定义了一个用户登录和注册用例，使用六种编码风格场景来处理他们的数据，并评估了三种sat(phpSAFE、RIPS和WAP)的行为，以验证和理解sat产生FP和FN的原因。",
                    "title_zh": "编码风格对Web应用静态分析工具行为的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00031",
                    "title": "A Novel Graphical Security Model for Evolving Cyber Attacks in Internet of Things",
                    "authors": "Dong Seong Kim, Kok Onn Chee, Mengmeng Ge",
                    "abstract": "Internet of Things (IoT) devices have become attack targets due to their weak security protections and could be maliciously exploited as bots controlled by attackers to launch further attacks (e.g., distributed denial of service attacks). In this work, we investigate infection behaviors of Mirai and its variants to explore malware spreading in IoT networks and propose a novel approach to model the spreading of malware via a graphical security model. We completed an initial analysis via an example of IoT network. Our results capture the spreading behavior of Mirai in the IoT network by showing different stages of an IoT node (i.e., healthy, infected and propagating).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于安全保护薄弱，物联网(IoT)设备已成为攻击目标，并可能被攻击者恶意利用为受控的机器人，以发起进一步的攻击(例如，分布式拒绝服务攻击)。在这项工作中，我们研究了Mirai未来组合及其变种的感染行为，以探索恶意软件在物联网网络中的传播，并提出了一种通过图形安全模型来模拟恶意软件传播的新方法。我们通过一个物联网网络的例子完成了初步的分析。我们的结果通过显示物联网节点的不同阶段(即健康、受感染和传播)来捕捉Mirai未来组合在物联网网络中的传播行为。",
                    "title_zh": "一种新的物联网网络攻击图形化安全模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00032",
                    "title": "The Effect of Motion on PPG Heart Rate Sensors",
                    "authors": "Daniel Hu, Calvin Henry, Saurabh Bagchi",
                    "abstract": "As smartwatches become more commonly used for keeping track of health data, their accuracy becomes more and more important. In this paper, we investigate the accuracy of smartwatch heart rate sensors and how it depends on the movement of the wearer. Some additional steps were taken in being able to predict whether a smart watch will report an accurate heart rate based on motion using a support vector machine.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着智能手表越来越普遍地用于跟踪健康数据，其准确性变得越来越重要。在本文中，我们研究了智能手表心率传感器的精度，以及它如何依赖于佩戴者的运动。为了能够使用支持向量机预测智能手表是否会基于运动报告准确的心率，还采取了一些额外的步骤。",
                    "title_zh": "运动对PPG心率传感器的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00033",
                    "title": "Reliability Analysis of Edge Scenarios Using Pedestrian Mobility",
                    "authors": "Kshitiz Goel, Abhishek Bhaumick, Deepika Kaushal, Saurabh Bagchi",
                    "abstract": "Edge computing is actively being adopted by various organizations and applications owing to its bandwidth saving and faster response times. However, this is accompanied by its own set of reliability issues and serves as an excellent target for optimizations and analysis. Our work analyzes the effect of mobile clients on task failure rates and proposes a low overhead location and network congestion aware optimization. In this paper, we discuss our motivations, provide details about the dataset, present some statistical analysis, and propose an improved mobile-side edge selection policy.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于节省带宽和更快的响应时间，边缘计算正被各种组织和应用积极采用。然而，这伴随着它自己的一系列可靠性问题，并且作为优化和分析的极好目标。我们的工作分析了移动客户端对任务失败率的影响，并提出了一种低开销的位置和网络拥塞感知优化。在本文中，我们讨论了我们的动机，提供了关于数据集的细节，提出了一些统计分析，并提出了一个改进的移动端边缘选择策略。",
                    "title_zh": "基于行人移动性的边缘场景可靠性分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00034",
                    "title": "Improving the Dependability of the ECG Signal for Classification of Heart Diseases",
                    "authors": "Bartosz Przysucha, Tomasz Rymarczyk, Dariusz Wójcik, Michal Wos, Andrés Véjar",
                    "abstract": "Electrocardiogram (ECG) signals are widely used to classify a spectrum of human diseases, given the functional importance of the heart in the overall body activity. For automated classification, the degree of membership of an instance of ECG data to a particular disease can be measured using an indicator function. We use online classification and therefore this membership score is affected by fluctuations in the input data. A deterioration in the classification task is perceived when strong noise input signals are acquired or when disruption events qualitatively affects the input signal. The present work implements a method for detecting disruption events and noise in the ECG signal. The purpose of this method is to improve the quality and the reliability of the classification task for real measurements. The indicator function for disease classification using ECG data is based in the k-means cluster analysis method.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "鉴于心脏在整个身体活动中的功能重要性，心电图(ECG)信号被广泛用于对人类疾病进行分类。对于自动分类，可以使用指示函数来测量ECG数据实例对特定疾病的隶属度。我们使用在线分类，因此该成员分数受输入数据波动的影响。当获取强噪声输入信号时，或者当干扰事件定性地影响输入信号时，分类任务的恶化被察觉。本工作实现了一种用于检测ECG信号中的中断事件和噪声的方法。该方法的目的是提高真实测量的分类任务的质量和可靠性。使用ECG数据进行疾病分类的指示函数基于k均值聚类分析方法。",
                    "title_zh": "提高心电信号在心脏病分类中的可靠性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00035",
                    "title": "Safeguarding Data Consistency at the Edge",
                    "authors": "Cláudio Correia",
                    "abstract": "We propose to design and implement a secure edge storage system. Edge computing is a paradigm that extends cloud computing with storage and processing capacity close to the edge of the network, supporting new applications that require low latency. It assumes the availability of fog nodes that are located close to the edge. However, fog nodes are likely to be vulnerable to tampering. A malicious fog node can manipulate, create or delete data from edge applications, leading this application into a fail state, impacting the quality of service. Therefore, it is important to secure the functions fog nodes provide. To achieve our goal we plan to leverage the use of secure hardware (e.g., Intel SGX) as a means to harden the implementation. However, as we discuss here, SGX alone is not enough to achieve the qualities we consider necessary to support edge applications, such as low latency, scalability, and multiple models of data consistency. In this work, we present the main challenges in the design of a secure edge storage system and point to the research directions that we plan to follow to address these challenges.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出设计和实现一个安全的边缘存储系统。边缘计算是一种将云计算的存储和处理能力扩展到网络边缘的模式，支持要求低延迟的新应用。它假设靠近边缘的雾节点可用。然而，雾节点很可能容易被篡改。恶意的fog节点可以操纵、创建或删除边缘应用程序中的数据，导致该应用程序进入故障状态，影响服务质量。因此，保护雾节点提供的功能非常重要。为了实现我们的目标，我们计划利用安全硬件(如英特尔SGX)来强化实施。然而，正如我们在这里讨论的，SGX本身不足以达到我们认为支持边缘应用所必需的质量，如低延迟、可扩展性和多种数据一致性模型。在这项工作中，我们提出了安全边缘存储系统设计中的主要挑战，并指出我们计划遵循的研究方向，以解决这些挑战。",
                    "title_zh": "在边缘保护数据一致性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00036",
                    "title": "Depending on HTTP/2 for Privacy? Good Luck!",
                    "authors": "Gargi Mitra",
                    "abstract": "HTTP/2 introduced multi-threaded server operation for performance improvement over HTTP/1.1. Recent works have discovered that multi-threaded operation results in multiplexed object transmission, that can also have an unanticipated positive effect on TLS/SSL privacy. In fact, these works go on to design privacy schemes that rely heavily on multiplexing to obfuscate the sizes of the objects based on which the attackers inferred sensitive information. Orthogonal to these works, we examine if the privacy offered by such schemes work in practice. In this work, we show that it is possible for a network adversary with modest capabilities to completely break the privacy offered by the schemes that leverage HTTP/2 multiplexing. Our adversary works based on the following intuition: restricting only one HTTP/2 object to be in the server queue at any point of time will eliminate multiplexing of that object and any privacy benefit thereof. In our scheme, we begin by studying if (1) packet delays, (2) network jitter, (3) bandwidth limitation, and (4) targeted packet drops have an impact on the number of HTTP/2 objects processed by the server at an instant of time. Based on these insights, we design our adversary that forces the server to serialize object transmissions, thereby completing the attack. Our adversary was able to break the privacy of a real-world HTTP/2 website 90% of the time, the code for which will be released. To the best of our knowledge, this is the first privacy attack on HTTP/2.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "HTTP/2引入了多线程服务器操作，以提高HTTP/1.1的性能。最近的研究发现，多线程操作会导致多路复用的对象传输，这也会对TLS/SSL隐私产生意想不到的积极影响。事实上，这些工作继续设计隐私方案，这些方案严重依赖于多路复用来混淆对象的大小，攻击者基于这些大小推断敏感信息。在这些工作的基础上，我们检验了这些方案提供的隐私在实践中是否有效。在这项工作中，我们表明，对于一个能力有限的网络对手来说，完全破坏利用HTTP/2多路复用的方案所提供的隐私是可能的。我们的对手基于以下直觉工作:在任何时间点限制服务器队列中只有一个HTTP/2对象将消除该对象的多路复用以及由此带来的任何隐私好处。在我们的方案中，我们首先研究(1)分组延迟，(2)网络抖动，(3)带宽限制，以及(4)目标分组丢弃是否对服务器在某一时刻处理的HTTP/2对象的数量有影响。基于这些认识，我们设计了我们的对手，迫使服务器序列化对象传输，从而完成攻击。我们的对手能够在90%的时间里破坏真实世界HTTP/2网站的隐私，其代码将被公布。据我们所知，这是对HTTP/2的第一次隐私攻击。",
                    "title_zh": "依靠HTTP/2实现隐私？祝你好运！"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00037",
                    "title": "Towards Practical Privacy-Preserving Collaborative Machine Learning at a Scale",
                    "authors": "Rania Talbi",
                    "abstract": "Collaborative machine learning allows multiple participants to get a global and valuable insight over their joint data. Nonetheless, in data-sensitive applications, it is crucial to maintain confidentiality across the end-to-end path the data follows from model training phase to the inference phase, preventing any form of information leakage about training data, the learned model, or the inference queries. In this paper, we present our approach to addressing this problem through PrivML, a framework for end-to-end outsourced privacy-preserving data classification over encrypted data. We provide some preliminary results comparing our proposal with state of the art solutions as well as some insight on our prospective research plan.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-02886063/file/Towards_Practical_Privacy_Preserving_Collaborative_Machine_Learning_at_a_Scale.pdf"
                    },
                    "abstract_zh": "协作机器学习允许多个参与者获得对他们的联合数据的全局和有价值的洞察。尽管如此，在数据敏感的应用程序中，保持数据从模型训练阶段到推理阶段的端到端路径的机密性是至关重要的，这可以防止任何形式的关于训练数据、学习模型或推理查询的信息泄漏。在本文中，我们提出了通过PrivML解决这一问题的方法，priv ml是一个对加密数据进行端到端外包隐私保护数据分类的框架。我们提供了一些初步结果，将我们的建议与最先进的解决方案进行了比较，并对我们的前瞻性研究计划提出了一些见解。",
                    "title_zh": "大规模实现实用的隐私保护协作机器学习"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00038",
                    "title": "What Exactly Determines the Type? Inferring Types with Context",
                    "authors": "Ligeng Chen",
                    "abstract": "Closed-source programs lack crucial information vital for code analysis because that information is stripped on compilation to achieve smaller executable size. Variable type information is fundamental in this process. In this paper, we implement a system called CATI (Context-Assisted Type Inference), which locates variables from stripped binaries and infers 19 types from variables. Experiments show that it infers variable type with 71.2% accuracy on unseen binaries.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "闭源程序缺乏对代码分析至关重要的关键信息，因为这些信息在编译时被剥离以获得更小的可执行文件。可变类型信息是这个过程中的基础。在本文中，我们实现了一个称为CATI(上下文辅助类型推断)的系统，该系统从剥离的二进制文件中定位变量，并从变量中推断出19种类型。实验表明，该算法对未知二进制文件的变量类型推断准确率达到71.2%。",
                    "title_zh": "到底是什么决定了类型？根据上下文推断类型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00039",
                    "title": "Impact of Geo-Distribution and Mining Pools on Blockchains: A Study of Ethereum - Practical Experience Report and Ongoing PhD Work",
                    "authors": "Paulo Silva",
                    "abstract": "Given the large adoption and economical impact of permissionless blockchains, the complexity of the underlying systems and the adversarial environment in which they operate, it is fundamental to properly study and understand the emergent behavior and properties of these systems. We describe our experience on a detailed, one-month study of the Ethereum network from several geographically dispersed observation points. We leverage multiple geographic vantage points to assess the key pillars of Ethereum, namely geographical dispersion, network efficiency, blockchain efficiency and security, and the impact of mining pools. Among other new findings, we identify previously undocumented forms of selfish behavior and show that the prevalence of powerful mining pools exacerbates the geographical impact on block propagation delays. Furthermore, we provide a set of open measurement and processing tools, as well as the data set of the collected measurements, in order to promote further research on understanding permissionless blockchains.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "鉴于无许可区块链的广泛采用和经济影响，潜在系统的复杂性及其运行的敌对环境，正确研究和理解这些系统的涌现行为和属性是至关重要的。我们描述了我们从几个地理上分散的观察点对以太坊网络进行的一个月的详细研究的经验。我们利用多个地理优势来评估以太坊的关键支柱，即地理分散性、网络效率、区块链效率和安全性，以及矿池的影响。在其他新发现中，我们确定了以前未记录的自私行为形式，并表明强大的矿池的流行加剧了地理对块传播延迟的影响。此外，我们提供了一套开放的测量和处理工具，以及收集的测量数据集，以促进对理解无许可区块链的进一步研究。",
                    "title_zh": "地理分布和采矿池对区块链的影响:以太坊研究-实践经验报告和正在进行的博士工作"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00040",
                    "title": "CanvasMirror: Secure Integration of Third-Party Libraries in a WebVR Environment",
                    "authors": "Jiyeon Lee",
                    "abstract": "Web technology has evolved to offer 360-degree immersive browsing experiences. This new technology, called WebVR, enables virtual reality by rendering a three-dimensional world on an HTML canvas. Unfortunately, there exists no browser-supported way of sharing this canvas between different parties. As a result, third-party library providers with ill intent (e.g., stealing sensitive information from end-users) can easily distort the entire WebVR site. To mitigate the new threats posed in WebVR, we propose CanvasMirror, which allows publishers to specify the behaviors of third-party libraries and enforce this specification. We show that CanvasMirror effectively separates the third-party context from the host origin by leveraging the privilege separation technique and safely integrates VR contents on a shared canvas.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络技术已经发展到提供360度沉浸式浏览体验。这项名为WebVR的新技术通过在HTML画布上渲染三维世界来实现虚拟现实。不幸的是，不存在浏览器支持的在不同方之间共享该画布的方式。因此，恶意的第三方库提供商(例如，从最终用户那里窃取敏感信息)可以很容易地歪曲整个WebVR站点。为了减轻WebVR带来的新威胁，我们提出了CanvasMirror，它允许出版商指定第三方库的行为并强制执行这一规范。我们表明CanvasMirror通过利用权限分离技术有效地将第三方上下文与主机源分离，并在共享画布上安全地集成VR内容。",
                    "title_zh": "CanvasMirror:web VR环境中第三方库的安全集成"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00041",
                    "title": "A Framework for Risk Assessment in Augmented Reality-Equipped Socio-Technical Systems",
                    "authors": "Soheila Sheikh Bahaei",
                    "abstract": "New technologies, such as augmented reality (AR) are used to enhance human capabilities and extend human functioning; nevertheless they may cause distraction and incorrect human functioning. Systems including socio entities (such as human) and technical entities (such as augmented reality) are called socio-technical systems. In order to do risk assessment in such systems, considering new dependability threats caused by augmented reality is essential, for example failure of an extended human function is a new type of dependability threat introduced to the system because of new technologies. In particular, it is required to identify these new dependability threats and extend modeling and analyzing techniques to be able to uncover their potential impacts. This research aims at providing a framework for risk assessment in AR-equipped socio-technical systems by identifying AR-extended human failures and AR-caused faults leading to human failures. Our work also extends modeling elements in an existing metamodel for modeling socio-technical systems, to enable AR-relevant dependability threats modeling. This extended metamodel is expected to be used for extending analysis techniques to analyze AR-equipped socio-technical systems.",
                    "files": {
                        "openAccessPdf": "http://mdh.diva-portal.org/smash/get/diva2:1432516/FULLTEXT02"
                    },
                    "abstract_zh": "诸如增强现实(AR)之类的新技术被用于增强人的能力和扩展人的功能；然而，他们可能会导致分心和不正确的人类功能。包括社会实体(如人类)和技术实体(如增强现实)的系统称为社会技术系统。为了在这种系统中进行风险评估，考虑由增强现实引起的新的可靠性威胁是必不可少的，例如，扩展的人类功能的故障是由于新技术而引入系统的新类型的可靠性威胁。特别是，需要识别这些新的可靠性威胁，并扩展建模和分析技术，以便能够发现它们的潜在影响。本研究旨在通过识别增强现实扩展的人为失误和导致人为失误的增强现实导致的失误，为配备增强现实的社会技术系统提供一个风险评估框架。我们的工作还扩展了现有社会技术系统建模元模型中的建模元素，以支持AR相关的可信性威胁建模。这个扩展的元模型有望用于扩展分析技术，以分析配备AR的社会技术系统。",
                    "title_zh": "增强现实社会技术系统中的风险评估框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00042",
                    "title": "Cross-Layer Soft-Error Resilience Analysis of Computing Systems",
                    "authors": "Alberto Bosio, Ramon Canal, Stefano Di Carlo, Dimitris Gizopoulos, Alessandro Savino",
                    "abstract": "In a world with computation at the epicenter of every activity, computing systems must be highly resilient to errors even if miniaturization makes the underlying hardware unreliable. Techniques able to guarantee high reliability are associated to high costs. Early resilience analysis has the potential to support informed design decisions to maximize system-level reliability while minimizing the associated costs. This tutorial focuses on early cross-layer (hardware and software) resilience analysis considering the full computing continuum (from IoT/CPS to HPC applications) with emphasis on soft errors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在一个一切活动都以计算为中心的世界里，即使小型化使得底层硬件不可靠，计算系统也必须对错误具有高度的弹性。能够保证高可靠性的技术与高成本相关联。早期弹性分析有可能支持明智的设计决策，以最大限度地提高系统级可靠性，同时最大限度地降低相关成本。本教程重点关注早期跨层(硬件和软件)弹性分析，考虑整个计算连续体(从IoT/CPS到HPC应用),重点关注软错误。",
                    "title_zh": "计算系统的跨层软错误弹性分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00043",
                    "title": "The InterPlanetary File System and the Filecoin Network",
                    "authors": "Yiannis Psaras, David Dias",
                    "abstract": "The InterPlanetary File System (IPFS) is a peer-to-peer content-addressable distributed file system that seeks to connect all computing devices with the same system of files. It is an open-source community-driven project, with reference implementations in Go and Javascript, and a global community of millions of users. IPFS and libp2p, which is the modular network stack of IPFS, are based on name-resolution based routing. The resolution system is based on Kademlia DHT and content is addressed by flat hash-based names. IPFS sees significant real-world usage, with over 250,000 daily active network nodes, millions of end users and wide adoption by several other projects in the Decentralised Web space, but not only. An adjacent project to IPFS, which was also masterminded and is also being developed within Protocol Labs (the umbrella company of IPFS and libp2p) is filecoin. Filecoin is a token protocol that supports a decentralised storage network. Storage miners are rewarded according to their contribution to the network and the mechanics of filecoin secure the network against malicious activity. The objective of this half-day tutorial is to make the audience familiar with IPFS and filecoin and able to use the tools provided by the project for research and development. The tutorial targets both developers and researchers, who may contribute to the project or use it as a tool.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "星际文件系统(IPFS)是一个对等的内容可寻址分布式文件系统，它试图用相同的文件系统连接所有的计算设备。这是一个开源社区驱动的项目，有Go和Javascript的参考实现，有数百万用户的全球社区。IPFS和IPFS的模块化网络堆栈libp2p都是基于基于名称解析的路由。解析系统基于Kademlia DHT，内容通过基于平面哈希的名称进行寻址。IPFS看到了重要的现实世界的使用，超过250，000个每日活跃的网络节点，数以百万计的最终用户和分散化网络空间中其他几个项目的广泛采用，但不是唯一的。与IPFS相邻的一个项目是filecoin，它也是由Protocol Labs(IPFS和libp2p的联合公司)策划和开发的。Filecoin是一种令牌协议，支持分散式存储网络。存储矿工根据他们对网络的贡献获得奖励，而filecoin的机制可以保护网络免受恶意活动的攻击。这个半天的教程的目的是让观众熟悉IPFS和filecoin，并能够使用项目提供的工具进行研究和开发。本教程面向开发人员和研究人员，他们可能会对项目做出贡献或将其用作工具。",
                    "title_zh": "星际文件系统和Filecoin网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00044",
                    "title": "Into the Unknown: Unsupervised Machine Learning Algorithms for Anomaly-Based Intrusion Detection",
                    "authors": "Tommaso Zoppi, Andrea Ceccarelli, Andrea Bondavalli",
                    "abstract": "Anomaly detection aims at identifying patterns in data that do not conform to the expected behavior, relying on machine-learning algorithms that are suited for binary classification. It has been arising as one of the most promising techniques to suspect intrusions, zero-day attacks and, under certain conditions, failures. This tutorial aims to instruct the attendees to the principles, application and evaluation of anomaly-based techniques for intrusion detection, with a focus on unsupervised algorithms, which are able to classify normal and anomalous behaviors without relying on input data with labeled attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "异常检测旨在识别数据中不符合预期行为的模式，依靠适合二进制分类的机器学习算法。它已经成为怀疑入侵、零日攻击以及某些情况下的故障的最有前途的技术之一。本教程旨在向与会者介绍基于异常的入侵检测技术的原理、应用和评估，重点是无监督算法，这种算法能够在不依赖带有标记攻击的输入数据的情况下对正常和异常行为进行分类。",
                    "title_zh": "未知领域:基于异常的入侵检测的无监督机器学习算法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00045",
                    "title": "Software-Only Triple Diverse Redundancy on GPUs for Autonomous Driving Platforms",
                    "authors": "Sergi Alcaide Portet, Leonidas Kosmidis, Carles Hernández, Jaume Abella",
                    "abstract": "Autonomous driving (AD) imposes the need for safe computations in high-performance computing (HPC) components such as GPUs, thus with capabilities to detect and recover from errors since a safe state may not exist anymore. This can be achieved with Triple Modular Redundancy (TMR) for computation components. Furthermore, error detection capabilities need to provide some form of diversity to avoid the case where a single fault leads all redundant executions lead to the same error, which would go undetected. In our past work, we assessed GPUs against dual modular redundancy (DMR) with diversity, showing their potential and limitations to provide diverse redundancy building on reset and restart for recovery. However, such recovery scheme may be too slow for some applications. This paper proposes a software-only solution to deliver diverse TMR on commercial off-the-shelf (COTS) GPUs. Our work details how staggered execution can be achieved and assesses the performance of TMR on COTS GPUs. Moreover, we identify those elements where diversity cannot be guaranteed and provide some discussion comparing the case of DMR and TMR for those elements.",
                    "files": {
                        "openAccessPdf": "https://upcommons.upc.edu/bitstream/2117/328869/1/Software_Only.pdf"
                    },
                    "abstract_zh": "自动驾驶(AD)对高性能计算(HPC)组件(如GPU)中的安全计算提出了要求，因此具有检测错误和从错误中恢复的能力，因为安全状态可能不再存在。这可以通过计算组件的三重模块化冗余(TMR)来实现。此外，错误检测功能需要提供某种形式的多样性，以避免单个错误导致所有冗余执行导致相同错误的情况，这种情况不会被检测到。在我们过去的工作中，我们针对具有多样性的双模冗余(DMR)评估了GPU，显示了它们在重置和重启以进行恢复时提供多样化冗余构建的潜力和局限性。然而，这种恢复方案对于某些应用来说可能太慢。本文提出了一种纯软件解决方案，用于在商用现货(COTS)GPU上提供多样化的TMR。我们的工作详细描述了如何实现交错执行，并评估了TMR在COTS GPUs上的性能。此外，我们确定了那些不能保证多样性的因素，并提供了一些讨论，比较DMR和德涅斯特河沿岸摩尔多瓦共和国的情况。",
                    "title_zh": "用于自动驾驶平台的GPU上的纯软件三重多样冗余"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00046",
                    "title": "A Machine Learning-Based Error Model of Voltage-Scaled Circuits",
                    "authors": "Dongning Ma, Xun Jiao",
                    "abstract": "Various approximation methods demonstrate the effectiveness of voltage scaling in digital circuits in order to explore the energy-error trade-off. An accurate error model is of critical importance for assessing the error behavior of voltage-scaled circuits and its effects on the application quality. However, existing error models of voltage-scaled circuits overlook the effects of input data and error rate disparity among different bits. To tackle this challenge, we propose a machine learning-based error model of voltage-scaled circuits that can predict the timing error rate for each output bit. We train this model using random forest methods with input features and output labels extracted from gate-level simulation. We evaluate the model accuracy on different circuits. Across all bit positions, voltage levels, and circuits, the model achieves on average a relative error of 1.06%. The model also achieves an average per-voltage Root Mean Square Error (RMSE) of 0.92% and per-bit RMSE of 1.02%. Exposing this error rate even up to the application level, the model can estimate the quality of an image processing application under voltage scaling with an average accuracy of 97.5%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "各种近似方法证明了数字电路中电压调整的有效性，以便探索能量误差权衡。精确的误差模型对于评估电压缩放电路的误差行为及其对应用质量的影响至关重要。然而，电压缩放电路的现有误差模型忽略了输入数据的影响和不同位之间的误差率差异。为了应对这一挑战，我们提出了一种基于机器学习的电压缩放电路误差模型，该模型可以预测每个输出位的时序误差率。我们使用随机森林方法训练该模型，输入特征和输出标签从门级模拟中提取。我们评估了不同电路的模型精度。在所有位位置、电压电平和电路上，该模型平均实现1.06%的相对误差。该模型还实现了0.92%的平均每电压均方根误差(RMSE)和1.02%的每比特RMSE。将这种误差率甚至暴露到应用级，该模型可以在电压缩放下以97.5%的平均精度估计图像处理应用的质量。",
                    "title_zh": "基于机器学习的电压缩放电路误差模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00047",
                    "title": "An Overview of the Risk Posed by Thermal Neutrons to the Reliability of Computing Devices",
                    "authors": "Daniel Oliveira, Sean Blanchard, Nathan DeBardeleben, Fermando Santos, Gabriel Piscoya Dávila, Philippe Olivier Alexandre Navaux, Stephen Wender, Carlo Cazzaniga, Christopher Frost, Robert C. Baumann, Paolo Rech",
                    "abstract": "The high performance, high efficiency, and low cost of Commercial Off-The-Shelf (COTS) devices make them attractive also for applications with strict reliability constraints. Today, COTS devices are adopted in HPC and safety-critical applications such as autonomous driving. Unfortunately, we cannot assume that COTS chips manufacturing process does not include the cheap natural Boron, that could makes them highly susceptible to thermal (low energy) neutrons. Through radiation beam experiments, using high-energy and low-energy neutrons, it has been shown that thermal neutrons are a significant threat to COTS device reliability. The evaluation includes AMD APU, three different NVIDIA GPUs, an Intel accelerator, and an FPGA executing a relevant set of algorithms. Besides the sensitivity of the devices to thermal neutrons it is also fundamental to consider the thermal neutron flux in different scenarios such as weather, concrete walls and floors, or even HPC liquid cooling systems. Correlating beam experiments and neutron detector data, it is shown that thermal neutrons FIT rate could be comparable or even higher than the high energy neutron FIT rate.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "商用现货(COTS)器件的高性能、高效率和低成本使其对可靠性要求严格的应用也很有吸引力。如今，高性能计算和自动驾驶等安全关键型应用都采用了COTS器件。不幸的是，我们不能假设COTS芯片制造过程中不包括廉价的天然硼，这可能使它们对热中子(低能量)高度敏感。通过使用高能和低能中子的辐射束实验，已经表明热中子是对COTS器件可靠性的重大威胁。评估包括AMD APU、三种不同的NVIDIA GPUs、一个英特尔加速器和一个执行一组相关算法的FPGA。除了设备对热中子的敏感性之外，还必须考虑不同场景下的热中子通量，例如天气、混凝土墙壁和地板，甚至HPC液体冷却系统。将束流实验和中子探测器数据相关联，表明热中子拟合率可以与高能中子拟合率相当甚至更高。",
                    "title_zh": "热中子对计算设备可靠性造成的风险概述"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2020w.html",
            "conf_title": "50th DSN 2020: Valencia, Spain - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/9145942/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00006",
                    "title": "Third International Workshop on Dependable and Secure Machine Learning - DSML 2020",
                    "authors": "Homa Alemzadeh, Rakesh Bobba, Varun Chandrasekaran, David E. Evans, Nicolas Papernot, Karthik Pattabiraman, Florian Tramèr",
                    "abstract": "On behalf of the Organizing Committee, it is our pleasure to welcome you to the third International Workshop on Dependable and Secure Machine Learning (DSML). This year, due to the COVID-19 situation, the DSML workshop will be held online, in conjunction with the 50th IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) on Monday, 29 June 2020.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9145942/9151459/09151470.pdf"
                    },
                    "abstract_zh": "代表组委会，我们很高兴欢迎你参加第三届可靠和安全机器学习国际研讨会(DSML)。今年，由于新冠肺炎的情况，DSML研讨会将在2020年6月29日(星期一)与第50届IEEE/IFIP可靠系统和网络国际会议(DSN)同时在线举行。",
                    "title_zh": "第三届可靠和安全机器学习国际研讨会- DSML 2020"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00008",
                    "title": "Workshop on High-performance Computing Platforms for Dependable Autonomous Systems",
                    "authors": "Carles Hernández, Jaume Abella, Mikel Azkarate-askasua, Roman Obermaisser",
                    "abstract": "A number of high-performance computing (HPC) commercial off-the-shelf (COTS) platforms offer the computation capabilities needed by autonomous systems in domains such as automotive, space, avionics, robotics and factory automation by means of multicores, GPUs and specialized accelerators. Unfortunately, the utilization of HPC platforms has been traditionally considered out of the reach for the safety-critical systems industry due to the difficulties or roadblocks these platforms bring to the certification process. This workshop focuses on the research towards the adoption of HPC hardware and software platforms in the context of safety- and security-critical applications. In particular, the scope of the workshop includes functional-safety and security requirements for HPC systems, including but not limited to non-functional aspects such as time-predictability and energy consumption.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9145942/9151459/09151601.pdf"
                    },
                    "abstract_zh": "许多高性能计算(HPC)商业现货(COTS)平台通过多核、GPU和专用加速器提供汽车、航天、航空电子、机器人和工厂自动化等领域的自主系统所需的计算能力。不幸的是，由于HPC平台给认证流程带来的困难或障碍，这些平台的利用一直被认为是安全关键系统行业无法企及的。本研讨会重点研究在安全和安保关键应用环境中采用HPC硬件和软件平台。特别是，研讨会的范围包括HPC系统的功能安全和安全性要求，包括但不限于非功能方面，如时间可预测性和能耗。",
                    "title_zh": "面向可靠自治系统的高性能计算平台研讨会"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00007",
                    "title": "Second International Workshop on Data-Centric Dependability and Security (DCDS)",
                    "authors": "Ibéria Medeiros, Ilir Gashi, Michael Kamp, Pedro Ferreira",
                    "abstract": "On behalf of the Organizing Committee, it is our pleasure to welcome you to the second International Workshop on Data- Centric Dependability and Security (DCDS), co-located with the 50th IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2020) in Valencia, Spain on Monday, 29 June 2020.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9145942/9151459/09151836.pdf"
                    },
                    "abstract_zh": "代表组委会，我们很高兴欢迎您参加第二届以数据为中心的可靠性和安全性国际研讨会(DCDS)，该研讨会将与2020年6月29日(星期一)在西班牙巴伦西亚举行的第50届IEEE/IFIP国际可靠系统和网络会议(DSN 2020)同期举办。",
                    "title_zh": "第二届以数据为中心的可靠性和安全性国际研讨会(DCDS)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00009",
                    "title": "6th International Workshop on Safety and Security of Intelligent Vehicles - SSIV 2020",
                    "authors": "João Carlos Cunha, Kalinka Branco, Michaël Lauer",
                    "abstract": "Mobile robot systems, like aerial and ground vehicles, have been receiving an increased number of electronic components, connected through wireless networks and running embedded software over the last years. This strong integration between dedicated computing devices, i.e., the physical environment, dedicated computing devices, and networking, composes a Cyber-Physical System (CPS). CPS have thus become part of common vehicles, accessible to everyone, such as automobiles or unmanned aerial vehicles (UAVs). Furthermore, as processing power increases and software becomes more sophisticated, these vehicles gain the ability to perform complex operations, becoming more autonomous, efficient, adaptable, comfortable, safe and usable. These are known as Intelligent Vehicles (IV).",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9145942/9151459/09151823.pdf"
                    },
                    "abstract_zh": "在过去的几年中，移动机器人系统，如空中和地面车辆，已经接收了越来越多的电子组件，通过无线网络连接并运行嵌入式软件。专用计算设备(即物理环境、专用计算设备和网络)之间的这种强集成构成了信息物理系统(CPS)。因此，CPS已经成为普通交通工具的一部分，每个人都可以使用，例如汽车或无人驾驶飞行器(UAV)。此外，随着处理能力的提高和软件变得更加复杂，这些车辆获得了执行复杂操作的能力，变得更加自主、高效、适应性强、舒适、安全和可用。这些被称为智能车辆(IV)。",
                    "title_zh": "第六届SSIV 2020智能车辆安全国际研讨会"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00011",
                    "title": "TAaMR: Targeted Adversarial Attack against Multimedia Recommender Systems",
                    "authors": "Tommaso Di Noia, Daniele Malitesta, Felice Antonio Merra",
                    "abstract": "Deep learning classifiers are hugely vulnerable to adversarial examples, and their existence raised cybersecurity concerns in many tasks with an emphasis on malware detection, computer vision, and speech recognition. While there is a considerable effort to investigate attacks and defense strategies in these tasks, only limited work explores the influence of targeted attacks on input data (e.g., images, textual descriptions, audio) used in multimedia recommender systems (MR). In this work, we examine the consequences of applying targeted adversarial attacks against the product images of a visual-based MR. We propose a novel adversarial attack approach, called Target Adversarial Attack against Multimedia Recommender Systems (TAaMR), to investigate the modification of MR behavior when the images of a category of low recommended products (e.g., socks) are perturbed to misclassify the deep neural classifier towards the class of more recommended products (e.g., running shoes) with human-level slight images alterations. We explore the TAaMR approach studying the effect of two targeted adversarial attacks (i.e., FGSM and PGD) against input pictures of two state-of-the-art MR (i.e., VBPR and AMR). Extensive experiments on two real-world recommender fashion datasets confirmed the effectiveness of TAaMR in terms of recommendation lists changing while keeping the original human judgment on the perturbed images.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "深度学习分类器非常容易受到敌对例子的攻击，它们的存在在许多任务中引发了网络安全问题，重点是恶意软件检测、计算机视觉和语音识别。虽然在这些任务中有相当多的努力来研究攻击和防御策略，但是只有有限的工作探索了目标攻击对多媒体推荐系统(MR)中使用的输入数据(例如，图像、文本描述、音频)的影响。在这项工作中，我们研究了对基于视觉的MR的产品图像应用目标对抗性攻击的后果。我们提出了一种新的对抗性攻击方法，称为针对多媒体推荐系统的目标对抗性攻击(TAaMR)，以研究当低推荐产品类别(例如袜子)的图像被扰乱以将深度神经分类器错误分类为具有人类级别轻微图像改变的更推荐产品类别(例如跑鞋)时MR行为的修改。我们探索了TAaMR方法，研究了针对两种最先进MR(即VBPR和aMR)的输入图片的两种有针对性的对抗性攻击(即FGSM和PGD)的效果。在两个真实推荐时尚数据集上的大量实验证实了TAaMR在推荐列表改变方面的有效性，同时保持了原始人类对扰动图像的判断。",
                    "title_zh": "TAaMR:针对多媒体推荐系统的针对性对抗攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00012",
                    "title": "On The Generation of Unrestricted Adversarial Examples",
                    "authors": "Mehrgan Khoshpasand, Ali A. Ghorbani",
                    "abstract": "Adversarial examples are inputs designed by an adversary with the goal of fooling the machine learning models. Most of the research about adversarial examples have focused on perturbing the natural inputs with the assumption that the true label remains unchanged. Even in this limited setting and despite extensive studies in recent years, there is no defence against adversarial examples for complex tasks (e.g., ImageNet). However, for simpler tasks like handwritten digit classification, a robust model seems to be within reach. Unlike perturbation-based adversarial examples, the adversary is not limited to small norm-based perturbations in unrestricted adversarial examples. Hence, defending against unrestricted adversarial examples is a more challenging task.In this paper, we show that previous methods for generating unrestricted adversarial examples ignored a large part of the adversarial subspace. In particular, we demonstrate the bias of previous methods towards generating samples that are far inside the decision boundaries of an auxiliary classifier. We also show the similarity of the decision boundaries of an auxiliary classifier and baseline CNNs. By putting these two evidence together, we explain why adversarial examples generated by the previous approaches lack the desired transferability. Additionally, we present an efficient technique to create adversarial examples using generative adversarial networks to address this issue. We demonstrate that even the state-of-the-art MNIST classifiers are vulnerable to the adversarial examples generated with this technique. Additionally, we show that examples generated with our method are transferable. Accordingly, we hope that new proposed defences use this attack to evaluate the robustness of their models against unrestricted attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对抗性例子是由对手设计的输入，目的是愚弄机器学习模型。大多数关于对立例子的研究都集中在干扰自然输入，假设真实标签保持不变。即使在这种有限的环境中，尽管近年来进行了广泛的研究，对于复杂任务的对抗性例子(如ImageNet)也没有防御。然而，对于更简单的任务，如手写数字分类，一个健壮的模型似乎触手可及。与基于扰动的对抗范例不同，在不受限制的对抗范例中，对手并不局限于小的基于规范的扰动。因此，防御不受限制的对抗性例子是一个更具挑战性的任务。在本文中，我们表明，以前的方法，产生无限制的对抗性例子忽略了大部分的对抗性子空间。特别是，我们证明了以前的方法偏向于生成远在辅助分类器的决策边界内的样本。我们还显示了辅助分类器和基线细胞神经网络的决策边界的相似性。通过把这两个证据放在一起，我们解释了为什么以前的方法产生的对立例子缺乏预期的可转移性。此外，我们提出了一个有效的技术来创建对抗性的例子使用生成对抗性网络来解决这个问题。我们证明，即使是最先进的MNIST分类器也容易受到这种技术产生的对立例子的影响。此外，我们证明了用我们的方法生成的例子是可移植的。因此，我们希望新提出的防御方法利用这种攻击来评估他们的模型对无限制攻击的鲁棒性。",
                    "title_zh": "论无限制对立范例的生成"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00013",
                    "title": "Blackbox Attacks on Reinforcement Learning Agents Using Approximated Temporal Information",
                    "authors": "Yiren Zhao, Ilia Shumailov, Han Cui, Xitong Gao, Robert D. Mullins, Ross J. Anderson",
                    "abstract": "Recent research on reinforcement learning (RL) has suggested that trained agents are vulnerable to maliciously-crafted adversarial samples. In this work, we show how such samples can be generalised from White-box and Grey-box attacks to a strong Black-box case, where the attacker has no knowledge of the agents, their training parameters or their training methods. We use sequence-to-sequence models to predict a single action or a sequence of future actions that a trained agent will make. First, we show that our approximation model, based on time-series information from the agent, consistently predicts RL agents’ future actions with high accuracy in a Black-box setup on a wide range of games and RL algorithms. Second, we find that although adversarial samples are transferable from the sequence-to-sequence model to our RL agents, they often outperform Random Gaussian Noise only marginally. Third, we propose a novel use for adversarial samples in Black-box attacks of RL agents: they can be used to trigger a trained agent to misbehave after a specific time delay. This potentially enables an attacker to use devices controlled by RL agents as time bombs.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1909.02918"
                    },
                    "abstract_zh": "最近关于强化学习(RL)的研究表明，训练有素的代理容易受到恶意制作的敌对样本的攻击。在这项工作中，我们展示了如何将这样的样本从白盒和灰盒攻击推广到强黑盒攻击，在这种情况下，攻击者对代理、它们的训练参数或它们的训练方法一无所知。我们使用序列对序列模型来预测一个训练有素的代理人将做出的单个动作或一系列未来动作。首先，我们表明，我们的近似模型，基于来自代理的时间序列信息，在广泛的游戏和RL算法的黑盒设置中，一致地预测RL代理的未来行为，具有高精度。第二，我们发现，尽管敌对样本可以从序列到序列模型转移到我们的RL代理，但它们通常仅略微优于随机高斯噪声。第三，我们提出了在RL代理的黑盒攻击中对抗性样本的一种新用途:它们可以用来触发一个训练有素的代理在特定的时间延迟后行为不端。这潜在地使得攻击者能够将由RL代理控制的设备用作定时炸弹。",
                    "title_zh": "利用近似时间信息对强化学习代理的黑盒攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00014",
                    "title": "PyTorchFI: A Runtime Perturbation Tool for DNNs",
                    "authors": "Abdulrahman Mahmoud, Neeraj Aggarwal, Alex Nobbe, Jose Rodrigo Sanchez Vicarte, Sarita V. Adve, Christopher W. Fletcher, Iuri Frosio, Siva Kumar Sastry Hari",
                    "abstract": "PyTorchFI is a runtime perturbation tool for deep neural networks (DNNs), implemented for the popular PyTorch deep learning platform. PyTorchFI enables users to perform perturbations on weights or neurons of DNNs at runtime. It is designed with the programmer in mind, providing a simple and easy-to-use API, requiring as little as three lines of code for use. It also provides an extensible interface, enabling researchers to choose from various perturbation models (or design their own custom models), which allows for the study of hardware error (or general perturbation) propagation to the software layer of the DNN output. Additionally, PyTorchFI is extremely versatile: we demonstrate how it can be applied to five different use cases for dependability and reliability research, including resiliency analysis of classification networks, resiliency analysis of object detection networks, analysis of models robust to adversarial attacks, training resilient models, and for DNN interpertability. This paper discusses the technical underpinnings and design decisions of PyTorchFI which make it an easy-to-use, extensible, fast, and versatile research tool. PyTorchFI is open-sourced and available for download via pip or github at: https://github.com/pytorchfi",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "PyTorchFI是一个用于深度神经网络(DNNs)的运行时扰动工具，为流行的PyTorch深度学习平台实现。PyTorchFI允许用户在运行时对DNNs的权重或神经元进行扰动。它是为程序员设计的，提供了一个简单易用的API，只需要三行代码就可以使用。它还提供了一个可扩展的接口，使研究人员能够从各种扰动模型中进行选择(或设计他们自己的定制模型)，这允许研究硬件误差(或一般扰动)传播到DNN输出的软件层。此外，PyTorchFI非常通用:我们展示了它如何应用于五个不同的可靠性和可靠性研究用例，包括分类网络的弹性分析、对象检测网络的弹性分析、对恶意攻击稳健的模型分析、训练弹性模型以及DNN可解释性。本文讨论PyTorchFI的技术基础和设计决策，这使它成为一个易于使用、可扩展、快速和多功能的研究工具。PyTorchFI是开源的，可以通过pip或github下载，网址是:https://github.com/pytorchfi",
                    "title_zh": "PyTorchFI:DNNs的运行时扰动工具"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00015",
                    "title": "Online Verification through Model Checking of Medical Critical Intelligent Systems",
                    "authors": "João Martins, Raul Barbosa, Nuno Lourenço, Jacques Robin, Henrique Madeira",
                    "abstract": "Software systems based on Artificial Intelligence (AI) and Machine Learning (ML) are being widely adopted in various scenarios, from online shopping to medical applications. When developing these systems, one needs to take into account that they should be verifiable to make sure that they are in accordance with their requirements. In this work we propose a framework to perform online verification of ML models, through the use of model checking. In order to validate the proposal, we apply it to the medical domain to help qualify medical risk. The results reveal that we can efficiently use the framework to determine if a patient is close to the multidimensional decision boundary of a risk score model. This is particularly relevant since patients in these circumstances are the ones more likely to be misclassified. As such, our framework can be used to help medical teams make better informed decisions.",
                    "files": {
                        "openAccessPdf": "https://hal-paris1.archives-ouvertes.fr/hal-03967999/file/_DSML_2020__Verification_through_model_checking.pdf"
                    },
                    "abstract_zh": "基于人工智能(AI)和机器学习(ML)的软件系统正在广泛应用于各种场景，从在线购物到医疗应用。在开发这些系统时，需要考虑到它们应该是可验证的，以确保它们符合要求。在这项工作中，我们提出了一个框架来执行在线验证的ML模型，通过使用模型检查。为了验证该提议，我们将其应用于医疗领域，以帮助确定医疗风险。结果表明，我们可以有效地使用该框架来确定患者是否接近风险评分模型的多维决策边界。这一点尤其重要，因为在这些情况下，患者更有可能被错误分类。因此，我们的框架可以用来帮助医疗团队做出更明智的决策。",
                    "title_zh": "通过医学关键智能系统的模型检查进行在线验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00016",
                    "title": "BlurNet: Defense by Filtering the Feature Maps",
                    "authors": "Ravi S. Raju, Mikko H. Lipasti",
                    "abstract": "Recently, the field of adversarial machine learning has been garnering attention by showing that state-of-the-art deep neural networks are vulnerable to adversarial examples, stemming from small perturbations being added to the input image. Adversarial examples are generated by a malicious adversary by obtaining access to the model parameters, such as gradient information, to alter the input or by attacking a substitute model and transferring those malicious examples over to attack the victim model. Specifically, one of these attack algorithms, Robust Physical Perturbations $(RP_{2})$, generates adversarial images of stop signs with black and white stickers to achieve high targeted misclassification rates against standard-architecture traffic sign classifiers. In this paper, we propose BlurNet, a defense against the RP2 attack. First, we motivate the defense with a frequency analysis of the first layer feature maps of the network on the LISA dataset, which shows that high frequency noise is introduced into the input image by the RP2 algorithm. To remove the high frequency noise, we introduce a depthwise convolution layer of standard blur kernels after the first layer. We perform a blackbox transfer attack to show that low-pass filtering the feature maps is more beneficial than filtering the input. We then present various regularization schemes to incorporate this low-pass filtering behavior into the training regime of the network and perform white-box attacks. We conclude with an adaptive attack evaluation to show that the success rate of the attack drops from 90% to 20% with total variation regularization, one of the proposed defenses.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1908.02256"
                    },
                    "abstract_zh": "最近，对抗性机器学习领域已经引起了人们的关注，因为它表明，最先进的深度神经网络容易受到对抗性例子的影响，这些例子来自于添加到输入图像的小扰动。恶意对手通过获得对模型参数(例如梯度信息)的访问权来改变输入，或者通过攻击替代模型并将那些恶意示例转移到攻击受害者模型，从而产生对抗性示例。具体来说，这些攻击算法之一Robust Physical Perturbations $(RP _ { 2 })$，生成带有黑白贴纸的停车标志的对立图像，以实现针对标准架构交通标志分类器的高目标误分类率。在本文中，我们提出了BlurNet，一种针对RP2攻击的防御方法。首先，我们通过在LISA数据集上对网络的第一层特征图进行频率分析来激发防御，这表明RP2算法将高频噪声引入了输入图像。为了去除高频噪声，我们在第一层之后引入标准模糊核的深度方向卷积层。我们进行了黑盒转移攻击，以表明对特征图进行低通滤波比对输入进行滤波更有益。然后，我们提出了各种正则化方案，将这种低通滤波行为纳入网络的训练机制，并执行白盒攻击。我们以一个适应性攻击评估来结束，以显示攻击的成功率从90%下降到20%。",
                    "title_zh": "BlurNet:通过过滤特征地图进行防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00017",
                    "title": "Association Rule Mining with Differential Privacy",
                    "authors": "Hao Zhen, Bo-Cheng Chiou, Yao-Tung Tsou, Sy-Yen Kuo, Pang-Chieh Wang",
                    "abstract": "Association analysis is an important task in data analysis to find all co-occurrence relationships (i.e., frequent itemsets or confident association rules) from the transactional dataset. An association rule can help people better discover patterns and develop corresponding strategies. The process of data analysis can be highly summarized as a set of queries, where each query is a real-valued function of the dataset. However, without any restriction and protection, accessing the dataset to answer the queries may lead to the disclosure of individual privacy. In this paper, we propose and implement the association rule mining with differential privacy algorithm, which uses multiple support thresholds to reduce the number of candidate itemsets while reflecting the real nature of the items, and uses random truncation and uniform partition to lower the dimensionality of the dataset. We also stabilize the noise scale by adaptively allocating the privacy budgets, and bound the overall privacy loss. In addition, we prove that the association rule mining with differential privacy algorithm satisfies ex post differential privacy, and verify the utility of our association rule mining with differential privacy algorithm through a series of experiments. To the best of our knowledge, our work is the first differentially private association rule mining algorithm under multiple support thresholds.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "关联分析是数据分析中的一项重要任务，用于从事务数据集中发现所有共现关系(即频繁项集或可信关联规则)。关联规则可以帮助人们更好地发现模式并制定相应的策略。数据分析的过程可以高度概括为一组查询，其中每个查询都是数据集的实值函数。然而，在没有任何限制和保护的情况下，访问数据集来回答查询可能会导致个人隐私的泄露。本文提出并实现了基于差分隐私算法的关联规则挖掘，该算法使用多个支持度阈值来减少候选项目集的数量，同时反映项目的真实性质，并使用随机截断和均匀划分来降低数据集的维数。我们还通过自适应分配隐私预算来稳定噪声规模，并限制整体隐私损失。此外，我们证明了基于差分隐私算法的关联规则挖掘满足事后差分隐私，并通过一系列实验验证了基于差分隐私算法的关联规则挖掘的实用性。据我们所知，我们的工作是第一个差分私人关联规则挖掘算法下的多支持度阈值。",
                    "title_zh": "具有差异隐私的关联规则挖掘"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00018",
                    "title": "Pelican: A Deep Residual Network for Network Intrusion Detection",
                    "authors": "Peilun Wu, Hui Guo, Nour Moustafa",
                    "abstract": "One challenge for building a secure network communication environment is how to effectively detect and prevent malicious network behaviours. The abnormal network activities threaten users’ privacy and potentially damage the function and infrastructure of the whole network. To address this problem, the network intrusion detection system (NIDS) has been used. By continuously monitoring network activities, the system can timely identify attacks and prompt counter-attack actions. NIDS has been evolving over years. The current-generation NIDS incorporates machine learning (ML) as the core technology in order to improve the detection performance on novel attacks. However, the high detection rate achieved by a traditional ML-based detection method is often accompanied by large false-alarms, which greatly affects its overall performance. In this paper, we propose a deep neural network, Pelican, that is built upon specially-designed residual blocks. We evaluated Pelican on two network traffic datasets, NSL-KDD and UNSW-NB15. Our experiments show that Pelican can achieve a high attack detection performance while keeping a much low false alarm rate when compared with a set of up-to-date machine learning based designs.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2001.08523"
                    },
                    "abstract_zh": "构建安全网络通信环境的一个挑战是如何有效地检测和防止恶意网络行为。异常的网络活动威胁着用户的隐私，并可能破坏整个网络的功能和基础设施。为了解决这个问题，使用了网络入侵检测系统(NIDS)。通过持续监控网络活动，系统可以及时识别攻击并提示反击行动。NIDS多年来一直在演变。当代NIDS将机器学习(ML)作为核心技术，以提高对新型攻击的检测性能。然而，由传统的基于最大似然的检测方法实现的高检测率经常伴随着大的虚警，这极大地影响了其整体性能。在本文中，我们提出了一个深度神经网络Pelican，它是建立在专门设计的残差块之上的。我们在NSL-KDD和UNSW-NB15两个网络流量数据集上评估了Pelican。我们的实验表明，与一组最新的基于机器学习的设计相比，Pelican可以实现高攻击检测性能，同时保持低得多的虚警率。",
                    "title_zh": "Pelican:用于网络入侵检测的深度残留网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00019",
                    "title": "Open Source Hardware: An Opportunity For Critical Systems",
                    "authors": "Jimmy Le Rhun, Sylvain Girbal, Daniel Gracia Pérez",
                    "abstract": "Dependable systems currently undergo a series of transformations, notably the shift to multi-core processors and the rise of concerns previously limited to the IT domain such as cybersecurity or cloud-like versatility. In this position paper we summarize the key challenges, and some promising solutions.In addition to software-based techniques devised for COTS multi-processors, emerging Open-Source processing platforms provide the ability to experiment domain-specific mitigation techniques that were previously deemed not economically feasible.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可靠系统目前正在经历一系列转型，特别是向多核处理器的转变，以及以前仅限于IT领域的担忧的增加，如网络安全或类似云的多功能性。在这份立场文件中，我们总结了主要挑战和一些有希望的解决方案。除了为COTS多处理器设计的基于软件的技术之外，新兴的开源处理平台提供了试验特定领域缓解技术的能力，这些技术以前被认为在经济上不可行。",
                    "title_zh": "开源硬件:关键系统的机会"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00020",
                    "title": "Development of a NOEL-V RISC-V SoC Targeting Space Applications",
                    "authors": "Jan Andersson",
                    "abstract": "This extended abstract describes the development of a RISC-V-based System-on-Chip design targeting space applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "这篇扩展摘要描述了以空间应用为目标的基于RISC-V的片上系统设计的发展。",
                    "title_zh": "面向空间应用的NOEL-V RISC-V SoC的开发"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00021",
                    "title": "Safe and secure software updates on high-performance embedded systems",
                    "authors": "Irune Agirre",
                    "abstract": "The next generation of dependable embedded systems feature autonomy and higher levels of interconnection. Autonomy is commonly achieved with the support of artificial intelligence algorithms that pose high computing demands on the hardware platform, reaching a high performance scale. This involves a dramatic increase in software and hardware complexity, fact that together with the novelty of the technology, raises serious concerns regarding system dependability. Traditional approaches for certification require to demonstrate that the system will be acceptably safe to operate before it is deployed into service. The nature of autonomous systems, with potentially infinite scenarios, configurations and unanticipated interactions, makes it increasingly difficult to support such claim at design time. In this context, the extended networking technologies can be exploited to collect post-deployment evidence that serve to oversee whether safety assumptions are preserved during operation and to continuously improve the system through regular software updates. These software updates are not only convenient for critical bug fixing but also necessary for keeping the interconnected system resilient against security threats. However, such approach requires a recondition of the traditional certification practices.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/4008919/files/DSN_W_U2D_ExtendedAbstract.pdf"
                    },
                    "abstract_zh": "下一代可靠的嵌入式系统具有自主性和更高级别的互连。自治通常是在人工智能算法的支持下实现的，这些算法对硬件平台提出了高计算要求，达到了高性能规模。这涉及到软件和硬件复杂性的急剧增加，加上技术的新颖性，引起了对系统可靠性的严重关注。传统的认证方法需要证明系统在投入使用前可以安全运行。自治系统的本质，具有潜在的无限场景、配置和无法预料的交互，使得在设计时支持这样的声明变得越来越困难。在这种情况下，可以利用扩展的网络技术来收集部署后的证据，这些证据用于监督在运行期间是否保持了安全假设，并通过定期的软件更新来持续改进系统。这些软件更新不仅便于修复关键的错误，而且对于保持互联系统抵御安全威胁也是必要的。然而，这种方法需要重新调整传统的认证做法。",
                    "title_zh": "高性能嵌入式系统上安全可靠的软件更新"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00022",
                    "title": "Approaching certification of complex systems",
                    "authors": "Nicholas Mc Guire, Imanol Allende",
                    "abstract": "Safety being a system property and not an element property means that novel systems need to be treated as ”oneof”. Only after we gained adequate experience in context of a few (probably dozen) such complex system will common ”baseline” argument emerge. Trying to build ”out-of-context” elements certainly is either not feasible at all or would, if feasible, not simplify anything, since all possible states would need to be considered. In the case of, for example, the Linux kernel, the sheer amount of such states would completely overstrain such an approach. Applying route 3S assessment of non-compliant development while managing the extensive tailoring of measures, techniques and processes, seems to us to be the most promising path towards for safe complex systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全是一个系统属性，而不是一个元素属性，这意味着新系统需要被视为“其中之一”。只有当我们在几个(可能十几个)这样的复杂系统中获得足够的经验后，常见的“基线”论点才会出现。试图构建“脱离上下文”的元素肯定是根本不可行的，或者即使可行，也不会简化任何事情，因为需要考虑所有可能的状态。例如，在Linux内核的情况下，这种状态的绝对数量将完全超过这种方法的负荷。在管理措施、技术和过程的大规模定制的同时，应用路线3S评估不合规开发，在我们看来是实现安全复杂系统的最有希望的途径。",
                    "title_zh": "复杂系统认证的探讨"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00023",
                    "title": "AI Safety Landscape From short-term specific system engineering to long-term artificial general intelligence",
                    "authors": "José Hernández-Orallo",
                    "abstract": "AI Safety is an emerging area that integrates very different perspectives from mainstream AI, critical system engineering, dependable autonomous systems, artificial general intelligence, and many other areas concerned and occupied with building AI systems that are safe. Because of this diversity, there is an important level of disagreement in the terminology, the ontologies and the priorities of the field. The Consortium on the Landscape of AI Safety (CLAIS) is an international initiative to create a worldwide, consensus-based and generally-accepted knowledge base (online, interactive and constantly evolving) of structured subareas in AI Safety, including terminology, technologies, research gaps and opportunities, resources, people and groups working in the area, and connection with other subareas and disciplines. In this note we summarise early discussions around the initiative, the associated workshops, its current state and activities, including the body of knowledge, and how to contribute. On a more technical side, I will cover a few spots in the landscape, from very specific and short-term safety engineering issues appearing in specialised systems, to more long-term hazards emerging from more general and powerful intelligent systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "人工智能安全是一个新兴领域，它整合了主流人工智能、关键系统工程、可靠的自治系统、人工通用智能以及许多其他与构建安全的人工智能系统有关的领域的不同观点。由于这种多样性，在该领域的术语、本体和优先次序方面存在着很大程度的分歧。人工智能安全领域联盟(CLAIS)是一项国际倡议，旨在创建人工智能安全领域结构化分区的全球、基于共识和普遍接受的知识库(在线、互动和不断发展)，包括术语、技术、研究差距和机会、资源、在该领域工作的人员和团体，以及与其他分区和学科的联系。在这篇笔记中，我们总结了早期围绕该计划的讨论，相关的研讨会，其当前状态和活动，包括知识体系，以及如何做出贡献。从更技术性的角度来看，我将涉及一些领域，从专业系统中出现的非常具体和短期的安全工程问题，到更普遍和强大的智能系统中出现的更长期的危险。",
                    "title_zh": "从短期特定系统工程到长期人工通用智能的AI安全格局"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00024",
                    "title": "AI and Reliability Trends in Safety-Critical Autonomous Systems on Ground and Air",
                    "authors": "Jyotika Athavale, Andrea Baldovin, Ralf Graefe, Michael Paulitsch, Rafael Rosales",
                    "abstract": "Safety-critical autonomous systems are becoming more powerful and more integrated to enable higher-level functionality. Modern multi-core SOCs are often the computing backbone in such systems for which safety and associated certification tasks are one of the key challenges, which can become more costly and difficult to achieve. Hence, modeling and assessment of these systems can be a formidable task. In addition, Artificial Intelligence (AI) is already being deployed in safety critical autonomous systems and Machine Learning (ML) enables the achievement of tasks in a cost-effective way.Compliance to Soft Error Rate (SER) requirements is an important element to be successful in these markets. When considering SER performance for functional safety, we need to focus on accurately modeling vulnerability factors for transient analysis based on AI and Deep Learning workloads. We also need to consider the reliability implications due to long mission times leading to high utilization factors for autonomous transport. The reliability risks due to these new use cases also need to be comprehended for modeling and mitigation and would directly impact the safety analysis for these systems. Finally, the need for telemetry for reliability, including capabilities for anomaly detection and prognostics techniques to minimize field failures is of paramount importance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全关键型自治系统正变得越来越强大，集成度越来越高，以支持更高级别的功能。现代多核SOC通常是此类系统的计算中枢，对于这些系统而言，安全性和相关认证任务是关键挑战之一，这可能会变得更加昂贵和难以实现。因此，这些系统的建模和评估可能是一项艰巨的任务。此外，人工智能(AI)已经被部署在安全关键的自主系统中，机器学习(ML)能够以经济高效的方式完成任务。符合软错误率(SER)要求是在这些市场取得成功的重要因素。当考虑功能安全的SER性能时，我们需要专注于基于AI和深度学习工作负载的瞬态分析的精确建模漏洞因素。我们还需要考虑由于长任务时间导致自主运输的高利用率而带来的可靠性问题。由于这些新用例而产生的可靠性风险也需要被理解用于建模和缓解，并将直接影响这些系统的安全分析。最后，对遥测可靠性的需求，包括异常检测能力和预测技术，以最大限度地减少现场故障，是至关重要的。",
                    "title_zh": "地面和空中安全关键自主系统的人工智能和可靠性趋势"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00025",
                    "title": "Reward Tuning for self-adaptive Policy in MDP based Distributed Decision-Making to ensure a Safe Mission Planning",
                    "authors": "Mohand Hamadouche, Catherine Dezan, Kalinka R. L. J. C. Branco",
                    "abstract": "Markov Decision Process (MDP) becomes a standard model for sequential decision making under uncertainty. This planning gives the appropriate sequence of actions to perform the goal of the mission in an efficient way. Often a single agent makes decisions and performs a single action. However, in several fields such as robotics several actions can be executed simultaneously. Moreover, with the increase of the complexity of missions, the decomposition of an MDP into several sub-MDPs becomes necessary. The decomposition involves parallel decisions between different agents, but the execution of concurrent actions can lead to conflicts. In addition, problems due to the system and to sensor failures may appear during the mission; these can lead to negative consequences (e.g. crash of a UAV caused by the drop in battery charge). In this article, we present a new method to prevent behavior conflicts that can appear within distributed decision-making and to emphasize the action selection if needed to ensure the safety and the various requirements of the system. This method takes into consideration the different constraints due to antagonist actions and wile additionally considering some thresholds on transition functions to promote specific actions that guarantee the safety of the system. Then it automatically computes the rewards of the different MDPs related to the mission in order to establish a safe planning. We validate this method on a case study of UAV mission such as a tracking mission. From the list of the constraints identified for the mission, the rewards of the MDPs are recomputed in order to avoid all potential conflicts and violation of constraints related to the safety of the system, thereby ensuring a safe specification of the mission.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "马尔可夫决策过程(MDP)成为不确定条件下顺序决策的标准模型。该计划给出了适当的行动顺序，以有效地实现任务目标。通常，单个代理做出决策并执行单个动作。然而，在一些领域，如机器人，几个行动可以同时执行。此外，随着任务复杂性的增加，有必要将一个MDP分解成若干个子MDP。分解涉及不同代理之间的并行决策，但是并发动作的执行会导致冲突。此外，由于系统和传感器故障引起的问题可能会在任务期间出现；这可能导致负面后果(例如，电池电量下降导致无人机坠毁)。在本文中，我们提出了一种新的方法来防止分布式决策中出现的行为冲突，并在需要时强调行动选择，以确保系统的安全性和各种需求。该方法考虑了由于对抗行为而产生的不同约束，并且额外考虑了一些关于转移函数的阈值，以促进保证系统安全的特定行为。然后，它会自动计算与任务相关的不同MDP的奖励，以便建立安全的计划。我们通过一个无人机任务(如跟踪任务)的实例研究验证了该方法。从为任务识别的约束列表中，重新计算MDP的回报，以避免所有潜在的冲突和违反与系统安全相关的约束，从而确保任务的安全规范。",
                    "title_zh": "基于MDP的分布式决策中自适应策略的奖励调整以确保安全的任务规划"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00026",
                    "title": "The Quantitative Risk Norm - A Proposed Tailoring of HARA for ADS",
                    "authors": "Fredrik Warg, Martin A. Skoglund, Anders Thorsén, Rolf Johansson, Mattias Brännström, Magnus Gyllenhammar, Martin Sanfridson",
                    "abstract": "One of the major challenges of automated driving systems (ADS) is showing that they drive safely. Key to ensuring safety is eliciting a complete set of top-level safety requirements (safety goals). This is typically done with an activity called hazard analysis and risk assessment (HARA). In this paper we argue that the HARA of ISO 26262:2018 is not directly suitable for an ADS, both because the number of relevant operational situations may be vast, and because the ability of the ADS to make decisions in order to reduce risks will affect the analysis of exposure and hazards. Instead we propose a tailoring using a quantitative risk norm (QRN) with consequence classes, where each class has a limit for the frequency within which the consequences may occur. Incident types are then defined and assigned to the consequence classes; the requirements prescribing the limits of these incident types are used as safety goals to fulfil in the implementation. The main benefits of the QRN approach are the ability to show completeness of safety goals, and make sure that the safety strategy is not limited by safety goals which are not formulated in a way suitable for an ADS.",
                    "files": {
                        "openAccessPdf": "http://ri.diva-portal.org/smash/get/diva2:1458651/FULLTEXT01"
                    },
                    "abstract_zh": "自动驾驶系统(ADS)的主要挑战之一是显示它们安全驾驶。确保安全的关键是引出一套完整的顶级安全要求(安全目标)。这通常是通过称为危害分析和风险评估(HARA)的活动来完成的。在本文中，我们认为ISO 26262:2018的HARA并不直接适合于ADS，因为相关操作情况的数量可能是巨大的，并且因为ADS做出决策以降低风险的能力将影响暴露和危害的分析。相反，我们建议使用定量风险标准(QRN)和后果等级进行剪裁，其中每个等级都有后果发生频率的限制。然后定义事故类型，并将其分配给后果类；规定这些事件类型限制的要求被用作实施中要实现的安全目标。QRN方法的主要优点是能够显示安全目标的完整性，并确保安全策略不受安全目标的限制，安全目标不是以适合于ADS的方式制定的。",
                    "title_zh": "定量风险标准——为广告量身定制HARA的建议"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00027",
                    "title": "Analysis of Cybersecurity Mechanisms with respect to Dependability and Security Attributes",
                    "authors": "Behrooz Sangchoolie, Peter Folkesson, Pierre Kleberger, Jonny Vinter",
                    "abstract": "Embedded electronic systems need to be equipped with different types of security mechanisms to protect themselves and to mitigate the effects of cybersecurity attacks. These mechanisms should be evaluated with respect to their impacts on dependability and security attributes such as availability, reliability, safety, etc. The evaluation is of great importance as, e.g., a security mechanism should never violate the system safety. Therefore, in this paper, we evaluate a comprehensive set of security mechanisms consisting of 17 different types of mechanisms with respect to their impact on dependability and security attributes. The results show that, in general, the use of these mechanisms have positive effect on system dependability and security. However, there are at least three mechanisms that could have negative impacts on system dependability by violating safety and availability requirements. The results support our claim that the analyses such as the ones conducted in this paper are necessary when selecting and implementing an optimal set of safety and security mechanisms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "嵌入式电子系统需要配备不同类型的安全机制来保护自己并减轻网络安全攻击的影响。应该评估这些机制对可靠性和安全性属性(如可用性、可靠性、安全性等)的影响。该评估非常重要，因为例如安全机制不应该违反系统安全性。因此，在本文中，我们评估了一套全面的安全机制，包括17种不同类型的机制对可靠性和安全属性的影响。结果表明，一般来说，这些机制的使用对系统的可靠性和安全性有积极的影响。然而，至少有三种机制会违反安全性和可用性要求，从而对系统的可靠性产生负面影响。这些结果支持了我们的主张，即在选择和实施一组最佳的安全和保障机制时，像本文中所进行的分析是必要的。",
                    "title_zh": "关于可信性和安全属性的网络安全机制分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00028",
                    "title": "Exploring Fault Parameter Space Using Reinforcement Learning-based Fault Injection",
                    "authors": "Mehrdad Moradi, Bentley James Oakes, Mustafa Saraoglu, Andrey Morozov, Klaus Janschek, Joachim Denil",
                    "abstract": "Assessing the safety of complex Cyber-Physical Systems (CPS) is a challenge in any industry. Fault Injection (FI) is a proven technique for safety analysis and is recommended by the automotive safety standard ISO 26262. Traditional FI methods require a considerable amount of effort and cost as FI is applied late in the development cycle and is driven by manual effort or random algorithms. In this paper, we propose a Reinforcement Learning (RL) approach to explore the fault space and find critical faults. During the learning process, the RL agent injects and parameterizes faults in the system to cause catastrophic behavior. The fault space is explored based on a reward function that evaluates previous simulation results such that the RL technique tries to predict improved fault timing and values. In this paper, we apply our technique on an Adaptive Cruise Controller with sensor fusion and compare the proposed method with Monte Carlo-based fault injection. The proposed technique is more efficient in terms of fault coverage and time to find the first critical fault.",
                    "files": {
                        "openAccessPdf": "https://figshare.com/articles/preprint/Exploring_Fault_Parameter_Space_Using_Reinforcement_Learning-based_Fault_Injection/12479888/1/files/23135735.pdf"
                    },
                    "abstract_zh": "评估复杂的网络物理系统(CPS)的安全性在任何行业都是一个挑战。故障注入(FI)是一种成熟的安全分析技术，由ISO 26262汽车安全标准推荐。传统的FI方法需要大量的工作和成本，因为FI是在开发周期的后期应用的，并且是由人工工作或随机算法驱动的。在本文中，我们提出了一种强化学习(RL)方法来探索故障空间和发现关键故障。在学习过程中，RL代理在系统中注入并参数化故障，以导致灾难性行为。基于评价先前仿真结果的回报函数来探索故障空间，使得RL技术试图预测改进的故障定时和值。在本文中，我们将我们的技术应用于一个具有传感器融合的自适应巡航控制器，并将所提出的方法与基于蒙特卡罗的故障注入进行了比较。所提出的技术在故障覆盖率和发现第一个关键故障的时间方面更有效。",
                    "title_zh": "基于强化学习的故障注入探索故障参数空间"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00029",
                    "title": "Flexible Deployment and Enforcement of Flight and Privacy Restrictions for Drone Applications",
                    "authors": "Nasos Grigoropoulos, Spyros Lalis",
                    "abstract": "As drones gradually become a key component of next-generation cyber-physical systems, it is important to manage them in a flexible and efficient way. At the same time, it is crucial to enforce certain restrictions, which may not only concern no-fly zones but may also limit the usage of specific sensors, especially in urban areas. To this end, we propose an open system that enables the flexible deployment and controlled execution of drone applications. On the one hand, applications come in the form of independently executable software bundles that can be deployed on whichever drones are available and satisfy the corresponding resource and flight requirements. On the other hand, suitable mechanisms are used to monitor the execution of the applications at runtime in order to check conformance to the restrictions posed by the authorities, as well as to handle related violations in an automated way. In this paper, we present the key elements of the proposed approach and describe a proof-of-concept implementation that supports most of the envisioned functionality. We also provide a validation of our system prototype using both a software-in-the-loop setup and a real drone in the open.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着无人机逐渐成为下一代网络物理系统的关键组成部分，以灵活高效的方式管理它们非常重要。与此同时，强制执行某些限制也至关重要，这些限制可能不仅涉及禁飞区，还可能限制特定传感器的使用，特别是在城市地区。为此，我们提出了一个开放系统，能够灵活部署和控制无人机应用程序的执行。一方面，应用程序以独立可执行软件包的形式出现，可以部署在任何可用的无人机上，并满足相应的资源和飞行要求。另一方面，合适的机制用于在运行时监控应用程序的执行，以便检查是否符合权威机构提出的限制，以及以自动方式处理相关的违反。在本文中，我们介绍了所提出方法的关键要素，并描述了一个支持大多数预期功能的概念验证实现。我们还使用软件在环设置和开放的真实无人机对我们的系统原型进行了验证。",
                    "title_zh": "无人机应用的飞行和隐私限制的灵活部署和实施"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00030",
                    "title": "Conceptual Design of Human-Drone Communication in Collaborative Environments",
                    "authors": "Hans Dermot Doran, Monika Reif, Marco Oehler, Curdin Stöhr, Pierluigi Capone",
                    "abstract": "Autonomous robots and drones will work collaboratively and cooperatively in tomorrow’s industry and agriculture. Before this becomes a reality, some form of standardised communication between man and machine must be established that specifically facilitates communication between autonomous machines and both trained and un-trained human actors in the working environment. We present preliminary results on a human-drone and a drone-human language situated in the agricultural industry where interactions with trained and untrained workers and visitors can be expected. We present basic visual indicators enhanced with flight patterns for drone-human interaction and human signaling based on aircraft marshalling for humane-drone interaction. We discuss preliminary results on image recognition and future work.",
                    "files": {
                        "openAccessPdf": "https://digitalcollection.zhaw.ch/bitstream/11475/20448/3/2020_Doran-etal_Conceptual-design-of-human-drone-communication_IEEE.pdf"
                    },
                    "abstract_zh": "自主机器人和无人机将在未来的工业和农业中协同工作。在这成为现实之前，必须在人和机器之间建立某种形式的标准化通信，特别是促进自主机器和工作环境中训练有素和未经训练的人类演员之间的通信。我们展示了农业行业中人-无人机和无人机-人类语言的初步结果，在农业行业中，可以预期与经过培训和未经培训的工人和访客进行交互。我们提出了基本的视觉指示器，增强了无人机-人交互的飞行模式和基于飞机编组的人-无人机交互的人信号。我们讨论了图像识别的初步结果和未来的工作。",
                    "title_zh": "协同环境中人机通信的概念设计"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W50199.2020.00031",
                    "title": "A hierarchical fault tolerant architecture for an autonomous robot",
                    "authors": "Anthony Favier, Antonin Messioux, Jérémie Guiochet, Jean-Charles Fabre, Charles Lesire",
                    "abstract": "This paper presents a generic approach to specify a fault tolerant robot controller, and its implementation and validation with ROS and Gazebo. The main idea is to implement a fault tolerance strategy using a fault tree and an ordered set of recovery modules. A fault injection campaign has been carried out with a mobile autonomous robot for airport inspection using simulation with Gazebo and ROS. This successful experiment implements a safety-first strategy.",
                    "files": {
                        "openAccessPdf": "https://hal.laas.fr/hal-02558604/file/PID6442955.pdf"
                    },
                    "abstract_zh": "本文提出了一种通用的方法来指定一个容错机器人控制器，并与ROS和Gazebo的实现和验证。主要思想是使用故障树和一组有序的恢复模块来实现容错策略。使用Gazebo和ROS进行仿真，对用于机场检查的移动自主机器人进行了故障注入活动。这个成功的实验实施了安全第一的策略。",
                    "title_zh": "自主机器人的分层容错体系结构"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2020.html",
            "conf_title": "50th DSN 2020: Valencia, Spain",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/9145511/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00021",
                    "title": "KShot: Live Kernel Patching with SMM and SGX",
                    "authors": "Lei Zhou, Fengwei Zhang, Jinghui Liao, Zhenyu Ning, Jidong Xiao, Kevin Leach, Westley Weimer, Guojun Wang",
                    "abstract": "Live kernel patching is an increasingly common trend in operating system distributions, enabling dynamic updates to include new features or to fix vulnerabilities without having to reboot the system. Patching the kernel at runtime lowers downtime and reduces the loss of useful state from running applications. However, existing kernel live patching techniques (1) rely on specific support from the target operating system, and (2) admit patch failures resulting from kernel faults. We present KSHOT, a kernel live patching mechanism based on x86 SMM and Intel SGX that focuses on patching Linux kernel security vulnerabilities. Our patching processes are protected by hardware-assisted Trusted Execution Environments. We demonstrate that our technique can successfully patch vulnerable kernel functions at the binary-level without support from the underlying OS and regardless of whether the kernel patching mechanism is compromised. We demonstrate the applicability of KSHOT by successfully patching 30 critical indicative kernel vulnerabilities.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "实时内核补丁是操作系统发行版中越来越普遍的趋势，允许动态更新以包括新功能或修复漏洞，而无需重启系统。在运行时修补内核可以减少停机时间，并减少运行应用程序时有用状态的丢失。然而，现有的内核实时修补技术(1)依赖于来自目标操作系统的特定支持，以及(2)允许由内核故障导致的修补失败。我们介绍了KSHOT，这是一种基于x86 SMM和英特尔SGX的内核实时补丁机制，专注于修补Linux内核安全漏洞。我们的修补流程受到硬件辅助的可信执行环境的保护。我们证明了我们的技术可以成功地在二进制级别上修补易受攻击的内核函数，而无需底层操作系统的支持，并且不管内核修补机制是否受到损害。我们通过成功修补30个关键的指示性内核漏洞来证明KSHOT的适用性。",
                    "title_zh": "KShot:SMM和SGX的实时内核补丁"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00022",
                    "title": "CDN Backfired: Amplification Attacks Based on HTTP Range Requests",
                    "authors": "Weizhong Li, Kaiwen Shen, Run Guo, Baojun Liu, Jia Zhang, Haixin Duan, Shuang Hao, Xiarun Chen, Yao Wang",
                    "abstract": "Content Delivery Networks (CDNs) aim to improve network performance and protect against web attack traffic for their hosting websites. And the HTTP range request mechanism is majorly designed to reduce unnecessary network transmission. However, we find the specifications failed to consider the security risks introduced when CDNs meet range requests. In this study, we present a novel class of HTTP amplification attack, Range-based Amplification (RangeAmp) Attacks. It allows attackers to massively exhaust not only the outgoing bandwidth of the origin servers deployed behind CDNs but also the bandwidth of CDN surrogate nodes. We examined the RangeAmp attacks on 13 popular CDNs to evaluate the feasibility and real-world impacts. Our experiment results show that all these CDNs are affected by the RangeAmp attacks. We also disclosed all security issues to affected CDN vendors and already received positive feedback from 12 vendors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内容交付网络(cdn)旨在提高网络性能并保护其托管网站免受网络攻击。HTTP范围请求机制主要是为了减少不必要的网络传输。然而，我们发现规范没有考虑当cdn满足范围要求时引入的安全风险。在这项研究中，我们提出了一种新的HTTP放大攻击，基于范围的放大(RangeAmp)攻击。它允许攻击者不仅大量耗尽部署在CDN后面的源服务器的输出带宽，而且耗尽CDN代理节点的带宽。我们研究了针对13个流行cdn的RangeAmp攻击，以评估其可行性和现实影响。我们的实验结果表明，所有这些cdn都受到RangeAmp攻击的影响。我们还向受影响的CDN供应商披露了所有安全问题，并且已经收到了12家供应商的积极反馈。",
                    "title_zh": "CDN事与愿违:基于HTTP范围请求的放大攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00023",
                    "title": "Online Payments by Merely Broadcasting Messages",
                    "authors": "Daniel Collins, Rachid Guerraoui, Jovan Komatovic, Petr Kuznetsov, Matteo Monti, Matej Pavlovic, Yvonne-Anne Pignolet, Dragos-Adrian Seredinschi, Andrei Tonkikh, Athanasios Xygkis",
                    "abstract": "We address the problem of online payments, where users can transfer funds among themselves. We introduce Astro, a system solving this problem efficiently in a decentralized, deterministic, and completely asynchronous manner. Astro builds on the insight that consensus is unnecessary to prevent double-spending. Instead of consensus, Astro relies on a weaker primitive---Byzantine reliable broadcast---enabling a simpler and more efficient implementation than consensus-based payment systems. In terms of efficiency, Astro executes a payment by merely broadcasting a message. The distinguishing feature of Astro is that it can maintain performance robustly, i.e., remain unaffected by a fraction of replicas being compromised or slowed down by an adversary. Our experiments on a public cloud network show that Astro can achieve near-linear scalability in a sharded setup, going from 10K payments/sec (2 shards) to 20K payments/sec (4 shards). In a nutshell, Astro can match VISA-level average payment throughput, and achieves a 5× improvement over a state-of-the-art consensus-based solution, while exhibiting sub-second 95^th percentile latency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们解决了在线支付的问题，用户可以在他们之间转移资金。我们引入Astro，一个以分散的、确定的和完全异步的方式有效解决这个问题的系统。Astro建立在共识是不必要的，以防止重复支出的洞察力。Astro依赖于一种较弱的原始方式——拜占庭式的可靠广播——而不是共识，从而实现了比基于共识的支付系统更简单、更高效的实现。就效率而言，Astro仅通过广播消息来执行支付。Astro与众不同的特点是，它可以稳健地保持性能，即不受一小部分副本被对手破坏或减慢的影响。我们在公共云网络上的实验表明，Astro可以在分片设置中实现接近线性的可扩展性，从10K支付/秒(2个分片)到20K支付/秒(4个分片)。简而言之，Astro可以匹配签证级别的平均支付吞吐量，并比最先进的基于共识的解决方案提高5倍，同时表现出亚秒级95^th百分位延迟。",
                    "title_zh": "仅通过广播信息进行在线支付"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00024",
                    "title": "Comprehensive Java Metadata Tracking for Attack Detection and Repair",
                    "authors": "Jeff H. Perkins, Jordan Eikenberry, Alessandro Coglio, Martin C. Rinard",
                    "abstract": "We present ClearTrack, a system that tracks meta-data for each primitive value in Java programs to detect and nullify a range of vulnerabilities such as integer overflow/underflow and SQL/command injection vulnerabilities. Contributions include new techniques for eliminating false positives associated with benign integer overflows and underflows, new metadata-aware techniques for detecting and nullifying SQL/command command injection attacks, and results from an independent evaluation team. These results show that 1) ClearTrack operates successfully on Java programs comprising hundreds of thousands of lines of code (including instrumented jar files and Java system libraries, the majority of the applications comprise over 3 million lines of code), 2) because of computations such as cryptography and hash table calculations, these applications perform millions of benign integer overflows and underflows, and 3) ClearTrack successfully detects and nullifies all tested integer overflow and underflow and SQL/command injection vulnerabilities in the benchmark applications.",
                    "files": {
                        "openAccessPdf": "https://dspace.mit.edu/bitstream/1721.1/137581/2/ClearTrack_mit_tech_report.pdf"
                    },
                    "abstract_zh": "我们提出了ClearTrack，这是一个跟踪Java程序中每个基元值的元数据的系统，用于检测和消除一系列漏洞，如整数溢出/下溢和SQL/命令注入漏洞。贡献包括用于消除与良性整数溢出和下溢相关的误报的新技术，用于检测和消除SQL/command命令注入攻击的新元数据感知技术，以及来自独立评估团队的结果。这些结果表明:1) ClearTrack在包含数十万行代码的Java程序上成功运行(包括检测的jar文件和Java系统库，大多数应用程序包含超过300万行代码)，2)由于加密和哈希表计算等计算，这些应用程序执行了数百万次良性整数溢出和下溢，3) ClearTrack成功检测并消除了基准应用程序中所有测试的整数溢出和下溢以及SQL/命令注入漏洞。",
                    "title_zh": "全面的Java元数据跟踪，用于攻击检测和修复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00025",
                    "title": "TraceSanitizer - Eliminating the Effects of Non-Determinism on Error Propagation Analysis",
                    "authors": "Habib Saissi, Stefan Winter, Oliver Schwahn, Karthik Pattabiraman, Neeraj Suri",
                    "abstract": "Modern computing systems typically relax execution determinism, for instance by allowing the CPU scheduler to inter- leave the execution of several threads. While beneficial for performance, execution non-determinism affects programs' execution traces and hampers the comparability of repeated executions. We present TraceSanitizer, a novel approach for execution trace comparison in Error Propagation Analyses (EPA) of multi-threaded programs. TraceSanitizer can identify and compensate for non- determinisms caused either by dynamic memory allocation or by non-deterministic scheduling. We formulate a condition under which TraceSanitizer is guaranteed to achieve a 0% false positive rate, and automate its verification using Satisfiability Modulo Theory (SMT) solving techniques. TraceSanitizer is comprehensively evaluated using execution traces from the PARSEC and Phoenix benchmarks. In contrast with other approaches, Trace- Sanitizer eliminates false positives without increasing the false negative rate (for a specific class of programs), with reasonable performance overheads.",
                    "files": {
                        "openAccessPdf": "https://eprints.lancs.ac.uk/id/eprint/154041/1/DSN_2020_paper_1_.pdf"
                    },
                    "abstract_zh": "现代计算系统通常放松执行确定性，例如通过允许CPU调度程序在几个线程之间执行。虽然对性能有益，但执行不确定性会影响程序的执行轨迹，并妨碍重复执行的可比性。我们提出了TraceSanitizer，一种在多线程程序的错误传播分析(EPA)中进行执行跟踪比较的新方法。TraceSanitizer可以识别和补偿由动态内存分配或非确定性调度引起的非确定性。我们制定了TraceSanitizer保证实现0%误报率的条件，并使用可满足性模理论(SMT)求解技术自动化其验证。TraceSanitizer使用来自PARSEC和Phoenix基准的执行跟踪进行全面评估。与其他方法相比，Trace- Sanitizer消除了误报，而没有增加误报率(对于特定类别的程序)，并且具有合理的性能开销。",
                    "title_zh": "trace sanitizer——消除不确定性对错误传播分析的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00026",
                    "title": "JSKernel: Fortifying JavaScript against Web Concurrency Attacks via a Kernel-Like Structure",
                    "authors": "Zhanhao Chen, Yinzhi Cao",
                    "abstract": "As portals to the Internet, web browsers constitute prominent targets for attacks. Existing defenses that redefine web APIs typically capture information related to a single JavaScript function. Thus, they fail to defend against the so-called web concurrency attacks that use multiple interleaved functions to trigger a browser vulnerability. In this paper, we propose JSKernel, the first generic framework that introduces a kernel concept into JavaScript to defend against web concurrency attacks. The JavaScript kernel, inspired from operating system concepts, enforces the execution order of JavaScript events and threads to fortify security. We implement a prototype of JSKernel deployable as add-on extensions to three widely used web browsers, namely Google Chrome, Mozilla Firefox, and Microsoft Edge. These open-source extensions are available at (https://github.com/jskernel2019/jskernel) along with a usability demo at (https://jskernel2019.github.io/). Our evaluation shows the prototype to be robust to web concurrency attacks, fast, and backward compatible with legacy websites.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为互联网的入口，web浏览器是攻击的主要目标。重新定义web APIs的现有防御措施通常会捕获与单个JavaScript函数相关的信息。因此，它们无法抵御所谓的web并发攻击，这种攻击使用多个交错的函数来触发浏览器漏洞。在本文中，我们提出了JSKernel，这是第一个将内核概念引入JavaScript以防御web并发攻击的通用框架。JavaScript内核受操作系统概念的启发，强制执行JavaScript事件和线程的执行顺序，以加强安全性。我们实现了一个JSKernel原型，可以作为三个广泛使用的web浏览器的附加扩展进行部署，这三个浏览器是Google Chrome、Mozilla Firefox和Microsoft Edge。这些开源扩展可在(https://github.com/jskernel2019/jskernel)获得，可用性演示可在(https://jskernel 2019 . github . io/)获得。我们的评估表明，该原型对web并发攻击是健壮的，快速的，并且向后兼容遗留网站。",
                    "title_zh": "JSKernel:通过一个类似内核的结构来增强JavaScript抵御Web并发攻击的能力"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00027",
                    "title": "Scarecrow: Deactivating Evasive Malware via Its Own Evasive Logic",
                    "authors": "Jialong Zhang, Zhongshu Gu, Jiyong Jang, Dhilung Kirat, Marc Ph. Stoecklin, Xiaokui Shu, Heqing Huang",
                    "abstract": "Security analysts widely use dynamic malware analysis environments to exercise malware samples and derive virus signatures. Unfortunately, malware authors are becoming more aware of such analysis environments. Therefore, many have embedded evasive logic into malware to probe execution environments before exposing malicious behaviors. Consequently, such analysis environments become useless and evasive malware can damage victim systems with unforeseen malicious activities. However, adopting evasive techniques to bypass dynamic malware analysis is a double-edged sword. While evasive techniques can avoid early detection through sandbox analysis, it also significantly constrains the spectrum of execution environments where the malware activates. In this paper, we exploit this dilemma and seek to reverse the challenge by camouflaging end-user execution environments into analysis-like environments using a lightweight deception engine called SCARECROW. We thoroughly evaluate SCARECROW with real evasive malware samples and demonstrate that we can successfully deactivate 89.56% of evasive malware samples and the variants of ransomware (e.g., WannaCry and Locky) with little or no impact on the most commonly used benign software. Our evaluation also shows that SCARECROW is able to steer state-of-the-art analysis environment fingerprinting techniques so that end-user execution environments with SCARECROW and malware analysis environments with SCARECROW become indistinguishable.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全分析师广泛使用动态恶意软件分析环境来测试恶意软件样本并获取病毒签名。不幸的是，恶意软件作者越来越了解这种分析环境。因此，许多人在恶意软件中嵌入规避逻辑，以在暴露恶意行为之前探测执行环境。因此，这种分析环境变得无用，并且逃避性恶意软件可以通过不可预见的恶意活动来损害受害者系统。然而，采用规避技术来绕过动态恶意软件分析是一把双刃剑。虽然规避技术可以通过沙盒分析避免早期检测，但它也极大地限制了恶意软件激活的执行环境的范围。在本文中，我们利用了这一困境，并试图通过使用名为稻草人的轻量级欺骗引擎将最终用户执行环境伪装成类似分析的环境来扭转这一挑战。我们使用真实的规避恶意软件样本对稻草人进行了全面评估，并证明我们可以成功停用89.56%的规避恶意软件样本和勒索软件的变体(例如WannaCry和Locky)，而对最常用的良性软件几乎没有影响。我们的评估还表明，稻草人能够驾驭最先进的分析环境指纹技术，从而使使用稻草人的最终用户执行环境和使用稻草人的恶意软件分析环境变得无法区分。",
                    "title_zh": "稻草人:通过自己的规避逻辑去激活规避恶意软件"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00028",
                    "title": "CATI: Context-Assisted Type Inference from Stripped Binaries",
                    "authors": "Ligeng Chen, Zhongling He, Bing Mao",
                    "abstract": "Code analysis is a powerful way to eliminate vulnerabilities. Closed-source programs lack crucial information vital for code analysis because that information is stripped on compilation to achieve smaller executable size. Restoration has always been a challenge for experts. Variable type information is fundamental in this process because it helps to provide a perspective on program semantic. In this paper, we present an efficient approach for inferring types, and we overcome the challenge of scattered information provided by static analysis on stripped binaries. We discover that neighboring instructions are likely to operate the same type of variables, which are leveraged to enrich the features that we rely on. Therefore, we implement a system called CATI, which locates variables from stripped binaries and infers 19 types from variables. Experiments show that it infers variable type with 71.2% accuracy on unseen binaries. Meanwhile, it takes approximately 6 seconds to process a typical binary.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "代码分析是消除漏洞的有力方法。闭源程序缺乏对代码分析至关重要的关键信息，因为这些信息在编译时被剥离以获得更小的可执行文件。修复对专家来说一直是个挑战。变量类型信息在这个过程中是基本的，因为它有助于提供对程序语义的透视。在本文中，我们提出了一种有效的推断类型的方法，并克服了静态分析剥离二进制提供的分散信息的挑战。我们发现相邻的指令很可能操作相同类型的变量，这些变量被用来丰富我们所依赖的特性。因此，我们实现了一个名为CATI的系统，它从剥离的二进制文件中定位变量，并从变量中推断出19种类型。实验表明，该算法对未知二进制文件的变量类型推断准确率达到71.2%。同时，处理一个典型的二进制文件大约需要6秒钟。",
                    "title_zh": "CATI:从剥离的二进制文件中进行上下文辅助的类型推理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00029",
                    "title": "PolygraphMR: Enhancing the Reliability and Dependability of CNNs",
                    "authors": "Salar Latifi, Babak Zamirai, Scott A. Mahlke",
                    "abstract": "Deep neural networks (DNNs) are now starting to emerge in mission critical applications including autonomous vehicles and precision medicine. An important question is the dependability of DNNs and trustworthiness of their predictions. Considering the irreparable damage that can be caused by mispredictions, assessment of their potential misbehavior is necessary for safe deployment. In this paper, we first show the deficiency of current confidence-based methods as reliability measurement, and assess the effectiveness of traditional architecture reliability methods such as modular redundancy (MR). Then, we propose PolygraphMR and show that the combination of input preprocessing, smarter decision policies, and inclusion of prediction confidences can substantially improve the effectiveness of MR for DNNs. Next, we show how to prohibit explosive growth in the cost of MR by the help of reduced-precision designs and staged activations. Across six benchmarks, PolygraphMR detects an average of 33.5% of the baseline mispredictions with less than 2x overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "深度神经网络(DNNs)现在开始出现在包括自动驾驶汽车和精确医疗在内的关键任务应用中。一个重要的问题是DNNs的可靠性和他们预测的可信度。考虑到预测失误可能造成的不可挽回的损失，评估其潜在的不当行为对于安全部署是必要的。本文首先指出了当前基于置信度的可靠性度量方法的不足，并评估了模块化冗余(MR)等传统体系结构可靠性方法的有效性。然后，我们提出了PolygraphMR，并证明了输入预处理、更智能的决策策略和包含预测置信度的组合可以显著提高DNNs的MR的有效性。接下来，我们展示了如何通过降低精度设计和分阶段激活的帮助来阻止MR成本的爆炸性增长。在六个基准测试中，PolygraphMR平均检测到33.5%的基线预测失误，而开销不到2倍。",
                    "title_zh": "增强CNN的可靠性和可信性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00030",
                    "title": "ML-Driven Malware that Targets AV Safety",
                    "authors": "Saurabh Jha, Shengkun Cui, Subho S. Banerjee, James Cyriac, Timothy Tsai, Zbigniew Kalbarczyk, Ravishankar K. Iyer",
                    "abstract": "Ensuring the safety of autonomous vehicles (AVs) is critical for their mass deployment and public adoption. However, security attacks that violate safety constraints and cause accidents are a significant deterrent to achieving public trust in AVs, and that hinders a vendor's ability to deploy AVs. Creating a security hazard that results in a severe safety compromise (for example, an accident) is compelling from an attacker's perspective. In this paper, we introduce an attack model, a method to deploy the attack in the form of smart malware, and an experimental evaluation of its impact on production-grade autonomous driving software. We find that determining the time interval during which to launch the attack is{ critically} important for causing safety hazards (such as collisions) with a high degree of success. For example, the smart malware caused 33X more forced emergency braking than random attacks did, and accidents in 52.6% of the driving simulations.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2004.13004"
                    },
                    "abstract_zh": "确保自动驾驶汽车(AVs)的安全对于其大规模部署和公众采用至关重要。然而，违反安全约束并导致事故的安全攻击是获得公众对AVs信任的重要障碍，并且阻碍了厂商部署AVs的能力。从攻击者的角度来看，制造导致严重安全危害(例如，事故)的安全隐患是令人信服的。在本文中，我们介绍了一种攻击模型，一种以智能恶意软件形式部署攻击的方法，以及一种对生产级自动驾驶软件影响的实验评估。我们发现，确定发动攻击的时间间隔对于高度成功地造成安全危害(如碰撞)是{至关重要的}。例如，智能恶意软件导致的紧急制动比随机攻击多33倍，在52.6%的驾驶模拟中发生事故。",
                    "title_zh": "以反病毒安全为目标的ML驱动型恶意软件"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00031",
                    "title": "Leaky DNN: Stealing Deep-Learning Model Secret with GPU Context-Switching Side-Channel",
                    "authors": "Junyi Wei, Yicheng Zhang, Zhe Zhou, Zhou Li, Mohammad Abdullah Al Faruque",
                    "abstract": "Machine learning has been attracting strong interests in recent years. Numerous companies have invested great efforts and resources to develop customized deep-learning models, which are their key intellectual properties. In this work, we investigate to what extent the secret of deep-learning models can be inferred by attackers. In particular, we focus on the scenario that a model developer and an adversary share the same GPU when training a Deep Neural Network (DNN) model. We exploit the GPU side-channel based on context-switching penalties. This side-channel allows us to extract the fine-grained structural secret of a DNN model, including its layer composition and hyper-parameters. Leveraging this side-channel, we developed an attack prototype named MosConS, which applies LSTM-based inference models to identify the structural secret. Our evaluation of MosConS shows the structural information can be accurately recovered. Therefore, we believe new defense mechanisms should be developed to protect training against the GPU side-channel.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，机器学习一直吸引着人们的浓厚兴趣。许多公司都投入了巨大的努力和资源来开发定制的深度学习模型，这是他们的关键知识产权。在这项工作中，我们调查了攻击者可以在多大程度上推断出深度学习模型的秘密。特别是，我们关注的场景是，当训练深度神经网络(DNN)模型时，模型开发人员和对手共享相同的GPU。我们利用基于上下文切换惩罚的GPU侧通道。这个旁门左道允许我们提取DNN模型的细粒度结构秘密，包括它的层组成和超参数。利用这个侧通道，我们开发了一个名为MosConS的攻击原型，它应用基于LSTM的推理模型来识别结构秘密。我们对MosConS的评估表明，结构信息可以准确恢复。因此，我们认为应该开发新的防御机制来保护GPU侧信道的训练。",
                    "title_zh": "漏DNN:用GPU上下文切换侧通道窃取深度学习模型秘密"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00032",
                    "title": "An Experimental Study of Reduced-Voltage Operation in Modern FPGAs for Neural Network Acceleration",
                    "authors": "Behzad Salami, Erhan Baturay Onural, Ismail Emir Yuksel, Fahrettin Koc, Oguz Ergin, Adrián Cristal Kestelman, Osman S. Unsal, Hamid Sarbazi-Azad, Onur Mutlu",
                    "abstract": "We empirically evaluate an undervolting technique, i.e., underscaling the circuit supply voltage below the nominal level, to improve the power-efficiency of Convolutional Neural Network (CNN) accelerators mapped to Field Programmable Gate Arrays (FPGAs). Undervolting below a safe voltage level can lead to timing faults due to excessive circuit latency increase. We evaluate the reliability-power trade-off for such accelerators. Specifically, we experimentally study the reduced-voltage operation of multiple components of real FPGAs, characterize the corresponding reliability behavior of CNN accelerators, propose techniques to minimize the drawbacks of reduced-voltage operation, and combine undervolting with architectural CNN optimization techniques, i.e., quantization and pruning. We investigate the effect ofenvironmental temperature on the reliability-power trade-off of such accelerators. We perform experiments on three identical samples of modern Xilinx ZCU102 FPGA platforms with five state-of-the-art image classification CNN benchmarks. This approach allows us to study the effects of our undervolting technique for both software and hardware variability. We achieve more than 3X power-efficiency (GOPs/W ) gain via undervolting. 2.6X of this gain is the result of eliminating the voltage guardband region, i.e., the safe voltage region below the nominal level that is set by FPGA vendor to ensure correct functionality in worst-case environmental and circuit conditions. 43% of the power-efficiency gain is due to further undervolting below the guardband, which comes at the cost of accuracy loss in the CNN accelerator. We evaluate an effective frequency underscaling technique that prevents this accuracy loss, and find that it reduces the power-efficiency gain from 43% to 25%.",
                    "files": {
                        "openAccessPdf": "https://upcommons.upc.edu/bitstream/2117/330567/1/2005.03451.pdf"
                    },
                    "abstract_zh": "我们根据经验评估了一种欠电压调整技术，即将电路电源电压调整到标称水平以下，以提高映射到现场可编程门阵列(FPGAs)的卷积神经网络(CNN)加速器的功效。低于安全电压水平的欠电压会由于电路延迟过度增加而导致时序故障。我们评估了此类加速器的可靠性-功耗权衡。具体来说，我们通过实验研究了真实FPGAs的多个组件的降压操作，表征了CNN加速器的相应可靠性行为，提出了将降压操作的缺点降至最低的技术，并将欠电压与架构CNN优化技术(即量化和修剪)相结合。我们研究了环境温度对这种加速器的可靠性-功率平衡的影响。我们在现代Xilinx ZCU102 FPGA平台的三个相同样本上使用五个最先进的图像分类CNN基准进行实验。这种方法允许我们研究我们的欠电压技术对软件和硬件可变性的影响。我们通过欠电压实现了超过3倍的功效比(GOPs/W)增益。此增益的2.6倍是消除电压保护带区域的结果，即低于标称水平的安全电压区域，标称水平由FPGA供应商设置，以确保在最差环境和电路条件下的正确功能。43%的功效增益是由于保护带以下的进一步欠电压，这是以CNN加速器的精度损失为代价的。我们评估了一种防止这种精度损失的有效频率下调技术，发现它可以将功效增益从43%降至25%。",
                    "title_zh": "现代FPGAs降压操作用于神经网络加速的实验研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00033",
                    "title": "Quantifying DNN Model Robustness to the Real-World Threats",
                    "authors": "Zhenyu Zhong, Zhisheng Hu, Xiaowei Chen",
                    "abstract": "DNN models have suffered from adversarial example attacks, which lead to inconsistent prediction results. As opposed to the gradient-based attack, which assumes white-box access to the model by the attacker, we focus on more realistic input perturbations from the real-world and their actual impact on the model robustness without any presence of the attackers. In this work, we promote a standardized framework to quantify the robustness against real-world threats. It is composed of a set of safety properties associated with common violations, a group of metrics to measure the minimal perturbation that causes the offense, and various criteria that reflect different aspects of the model robustness. By revealing comparison results through this framework among 13 pre-trained ImageNet classifiers, three state-of-the-art object detectors, and three cloud-based content moderators, we deliver the status quo of the real-world model robustness. Beyond that, we provide robustness benchmarking datasets for the community.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "DNN模型遭受了对抗性的例子攻击，导致不一致的预测结果。与基于梯度的攻击相反，基于梯度的攻击假设攻击者对模型进行白盒访问，我们关注来自真实世界的更真实的输入扰动，以及它们在没有攻击者存在的情况下对模型鲁棒性的实际影响。在这项工作中，我们提出了一个标准化的框架来量化对现实世界威胁的鲁棒性。它由一组与常见违规相关的安全属性、一组用于测量导致违规的最小扰动的指标以及反映模型稳健性不同方面的各种标准组成。通过在13个预训练的ImageNet分类器、三个最先进的对象检测器和三个基于云的内容调节器之间通过该框架显示比较结果，我们提供了真实世界模型鲁棒性的现状。除此之外，我们还为社区提供健壮性基准数据集。",
                    "title_zh": "量化DNN模型对现实世界威胁的稳健性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00034",
                    "title": "The Mystery of the Failing Jobs: Insights from Operational Data from Two University-Wide Computing Systems",
                    "authors": "Rakesh Kumar",
                    "abstract": "Node downtime and failed jobs in a computing cluster translate into wasted resources and user dissatisfaction. Therefore understanding why nodes and jobs fail in HPC clusters is essential. This paper provides analyses of node and job failures in two university-wide computing clusters at two Tier I US research universities. We analyzed approximately 3.0M job execution data of System A and 2.2M of System B with data sources coming from accounting logs, resource usage for all primary local and remote resources (memory, IO, network), and node failure data. We observe different kinds of correlations of failures with resource usages and propose a job failure prediction model to trigger event-driven checkpointing and avoid wasted work. Additionally, we present user history based resource usage and runtime prediction models. These models have the potential to avoid system related issues such as contention, and improve quality of service such as lower mean queue time, if their predictions are used to make a more informed scheduling decision. As a proof of concept, we simulate an easy backfill scheduler to use predictions of one of these models, i.e., runtime and show the improvements in terms of lower mean queue time. Arising out of these observations, we provide generalizable insights for cluster management to improve reliability, such as, for some execution environments local contention dominates, while for others system-wide contention dominates.",
                    "files": {
                        "openAccessPdf": "https://figshare.com/articles/thesis/The_Mystery_of_the_Failing_Jobs_Insights_from_Operational_Data_from_Two_University-Wide_Computing_Systems/9044138/1/files/16604810.pdf"
                    },
                    "abstract_zh": "计算集群中的节点停机时间和失败的作业会导致资源浪费和用户不满。因此，了解HPC集群中节点和作业失败的原因至关重要。本文分析了美国两所一级研究型大学的两个大学计算集群中的节点和作业故障。我们分析了系统A的大约300万个作业执行数据和系统B的220万个作业执行数据，数据源来自记帐日志、所有主要本地和远程资源(内存、IO、网络)的资源使用情况以及节点故障数据。我们观察了失败与资源使用的不同类型的相关性，并提出了一个作业失败预测模型来触发事件驱动的检查点并避免浪费工作。此外，我们提出了基于用户历史的资源使用和运行时预测模型。如果使用这些模型的预测来做出更明智的调度决策，则这些模型有可能避免与系统相关的问题，例如争用，并提高服务质量，例如更低的平均排队时间。作为概念验证，我们模拟了一个简单的回填调度器，以使用这些模型之一的预测，即运行时，并显示了在较低平均队列时间方面的改进。根据这些观察，我们为集群管理提供了一般性的见解，以提高可靠性，例如，对于一些执行环境，本地争用占主导地位，而对于其他执行环境，系统范围的争用占主导地位。",
                    "title_zh": "失败工作的奥秘:来自两所大学计算系统运行数据的洞察"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00035",
                    "title": "Reliable, Efficient Recovery for Complex Services with Replicated Subsystems",
                    "authors": "Edward Tremel, Sagar Jha, Weijia Song, David Chu, Ken Birman",
                    "abstract": "Applications with internal substructure are common in the cloud, where many systems are organized as independently logged and replicated subsystems that interact via flows of objects or some form of RPC. Restarting such an application is difficult: a restart algorithm needs to efficiently provision the subsystems by mapping them to nodes with needed data and compute resources, while simultaneously guaranteeing that replicas are in distinct failure domains. Additional failures can occur during recovery, hence the restart process must itself be a restartable procedure. In this paper we present an algorithm for efficiently restarting a service composed of sharded subsystems, each using a replicated state machine model, into a state that (1) has the same fault-tolerance guarantees as the running system, (2) satisfies resource constraints and has all needed data to restart into a consistent state, (3) makes safe decisions about which updates to preserve from the logged state, (4) ensures that the restarted state will be mutually consistent across all subsystems and shards, and (5) ensures that no committed updates will be lost. If restart is not currently possible, the algorithm will await additional resources, then retry.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "具有内部子结构的应用程序在云中很常见，在云中，许多系统被组织为独立记录和复制的子系统，这些子系统通过对象流或某种形式的RPC进行交互。重启这样的应用是困难的:重启算法需要通过将子系统映射到具有所需数据和计算资源的节点来有效地供应子系统，同时保证副本在不同的故障域中。恢复过程中可能会出现其他故障，因此重启过程本身必须是一个可重启的过程。在本文中，我们提出了一种算法，用于有效地重新启动由分片子系统组成的服务，每个子系统使用复制的状态机模型，进入一种状态，该状态(1)具有与运行系统相同的容错保证，(2)满足资源约束，并且具有重新启动到一致状态所需的所有数据，(3)做出关于从记录状态保留哪些更新的安全决策，(4)确保重新启动的状态在所有子系统和分片之间相互一致，以及(5)确保不会丢失已提交的更新。如果当前无法重启，该算法将等待额外的资源，然后重试。",
                    "title_zh": "具有复制子系统的复杂服务的可靠、高效恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00036",
                    "title": "HAMS: High Availability for Distributed Machine Learning Service Graphs",
                    "authors": "Shixiong Zhao, Xusheng Chen, Cheng Wang, Fanxin Li, Qi Ji, Heming Cui, Cheng Li, Sen Wang",
                    "abstract": "Mission-critical services often deploy multiple Machine Learning (ML) models in a distributed graph manner, where each model can be deployed on a distinct physical host. Practical fault tolerance for such ML service graphs should meet three crucial requirements: high availability (fast failover), low normal case performance overhead, and global consistency under non-determinism (e.g., threads in a GPU can do floating point additions in random order). Unfortunately, despite much effort, existing fault tolerance systems, including those taking the primary-backup approach or the checkpoint-replay approach, cannot meet all these three requirements. To tackle this problem, we present HAMS, which starts from the primary-backup approach to replicate each stateful ML model, and we leverage the causal logging technique from the checkpoint-replay approach to eliminate the notorious stop-and-buffer delay in the primary-backup approach. Extensive evaluation on 25 ML models and six ML services shows that: (1) in normal case, HAMS achieved 0.5%-3.7% overhead on latency compared with bare metal; (2) HAMS took 116.12ms-254.19ms to recover one stateful model in all services, 155.1X-1067.9X faster than a relevant system Lineage Stash (LS); and (3) HAMS recovered these services with global consistency even when the GPU non-determinism exists, not supported by LS. HAMS's code is released ongithub.com/hku-systems/hams.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "关键任务服务通常以分布式图形方式部署多个机器学习(ML)模型，其中每个模型可以部署在不同的物理主机上。这种ML服务图的实际容错应该满足三个关键要求:高可用性(快速故障转移)、低正常情况性能开销以及非确定性下的全局一致性(例如，GPU中的线程可以以随机顺序进行浮点加法)。不幸的是，尽管做了很多努力，现有的容错系统，包括那些采用主备份方法或检查点重放方法的系统，都不能满足所有这三个要求。为了解决这个问题，我们提出了HAMS，它从主备份方法开始复制每个有状态ML模型，并且我们利用来自检查点重放方法的因果日志记录技术来消除主备份方法中臭名昭著的停止和缓冲延迟。对25个ML模型和6个ML服务的广泛评估表明:(1)在正常情况下，HAMS比裸机实现了0.5%-3.7%的延迟开销；(2) HAMS在所有服务中恢复一个有状态模型需要116.12ms-254.19ms，比相关系统沿袭存储(LS)快155.1 x-1067.9 x；以及(3)即使当GPU不确定性存在时，HAMS也以全局一致性恢复这些服务，这不受LS支持。哈姆的代码在ongithub.com/hku-systems/hams.发布",
                    "title_zh": "HAMS:分布式机器学习服务图的高可用性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00037",
                    "title": "Fine-Grained Fault Tolerance for Resilient pVM-Based Virtual Machine Monitors",
                    "authors": "Djob Mvondo, Alain Tchana, Renaud Lachaize, Daniel Hagimont, Noël De Palma",
                    "abstract": "Virtual machine monitors (VMMs) play a crucial role in the software stack of cloud computing platforms: their design and implementation have a major impact on performance, security and fault tolerance. In this paper, we focus on the latter aspect (fault tolerance), which has received less attention, although it is now a significant concern. Our work aims at improving the resilience of the \"pVM-based\" VMMs, a popular design pattern for virtualization platforms. In such a design, the VMM is split into two main components: a bare-metal hypervisor and a privileged guest virtual machine (pVM). We highlight that the pVM is the least robust component and that the existing fault-tolerance approaches provide limited resilience guarantees or prohibitive overheads. We present three design principles (disaggregation, specialization, and pro-activity), as well as optimized implementation techniques for building a resilient pVM without sacrificing end-user application performance. We validate our contribution on the mainstream Xen platform.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-02959252/file/final_dsn_paper.pdf"
                    },
                    "abstract_zh": "虚拟机监视器(VMM)在云计算平台的软件堆栈中起着至关重要的作用:它们的设计和实现对性能、安全性和容错性有着重大影响。在本文中，我们将重点放在后一个方面(容错),虽然现在它是一个重要的关注点，但它受到的关注较少。我们的工作旨在提高“基于pVM”的VMMs的弹性，这是一种流行的虚拟化平台设计模式。在这种设计中，VMM分为两个主要组件:裸机虚拟机管理程序和特权客户虚拟机(pVM)。我们强调pVM是最不健壮的组件，并且现有的容错方法提供有限的弹性保证或禁止性开销。我们提出了三个设计原则(分解、专门化和主动),以及在不牺牲最终用户应用程序性能的情况下构建弹性pVM的优化实现技术。我们在主流Xen平台上验证了我们的贡献。",
                    "title_zh": "基于pVM的弹性虚拟机监视器的细粒度容错"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00038",
                    "title": "Data-Driven Model-Based Analysis of the Ethereum Verifier's Dilemma",
                    "authors": "Maher Alharby, Roben Castagna Lunardi, Amjad Aldweesh, Aad van Moorsel",
                    "abstract": "In proof-of-work based blockchains such as Ethereum, verification of blocks is an integral part of establishing consensus across nodes. However, in Ethereum, miners do not receive a reward for verifying. This implies that miners face the Verifier's Dilemma: use resources for verification, or use them for the more lucrative mining of new blocks? We provide an extensive analysis of the Verifier's Dilemma, using a data-driven model-based approach that combines closed-form expressions, machine learning techniques and discrete-event simulation. We collect data from over 300,000 smart contracts and experimentally obtain their CPU execution times. Gaussian Mixture Models and Random Forest Regression transform the data into distributions and inputs suitable for the simulator. We show that, indeed, it is often economically rational not to verify, in particular for miners with less hashing power. We consider two approaches to mitigate the implications of the Verifier's Dilemma, namely parallelization and active insertion of invalid blocks, both will be shown to be effective.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2004.12768"
                    },
                    "abstract_zh": "在以太坊等基于工作证明的区块链中，块验证是跨节点建立共识的一个不可或缺的部分。然而，在以太坊，矿工不会因为验证而获得奖励。这意味着采矿者面临验证者的困境:使用资源进行验证，还是将其用于更有利可图的新区块开采？我们使用数据驱动的基于模型的方法，结合封闭形式的表达式、机器学习技术和离散事件模拟，对验证者的困境进行了广泛的分析。我们从超过300，000个智能合约中收集数据，并通过实验获得它们的CPU执行时间。高斯混合模型和随机森林回归将数据转换成适合模拟器的分布和输入。我们证明，事实上，不验证通常是经济上合理的，特别是对于散列能力较弱的矿工。我们考虑了两种方法来减轻验证者困境的影响，即并行化和主动插入无效块，这两种方法都将被证明是有效的。",
                    "title_zh": "基于数据驱动模型的以太坊验证者困境分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00039",
                    "title": "SMACS: Smart Contract Access Control Service",
                    "authors": "Bowen Liu, Siwei Sun, Pawel Szalachowski",
                    "abstract": "Although blockchain-based smart contracts promise a \"trustless\" way of enforcing agreements even with monetary consequences, they suffer from multiple security issues. Many of these issues could be mitigated via an effective access control system, however, its realization is challenging due to the properties of current blockchain platforms (like lack of privacy, costly on-chain resources, or latency). To address this problem, we propose the SMACS framework, where updatable and sophisticated Access Control Rules (ACRs) for smart contracts can be realized with low cost. SMACS shifts the burden of expensive ACRs validation and management operations to an off-chain infrastructure, while implementing on-chain only lightweight token-based access control. SMACS is flexible and in addition to simple access control lists can easily implement rules enhancing the runtime security of smart contracts. With dedicated ACRs backed by vulnerability-detection tools, SMACS can protect vulnerable contracts after deployment. We fully implement SMACS and evaluate it.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2003.07495"
                    },
                    "abstract_zh": "尽管总部位于区块链的智能合约承诺以一种“不可信”的方式执行协议，即使有金钱上的后果，但它们存在多重安全问题。许多这些问题可以通过有效的访问控制系统来缓解，但是，由于当前区块链平台的属性(如缺乏隐私、昂贵的链上资源或延迟)，其实现具有挑战性。为了解决这个问题，我们提出了SMACS框架，在这个框架中，可以以较低的成本实现智能合约的可更新和复杂的访问控制规则(ACRs)。SMACS将昂贵的ACRs验证和管理操作的负担转移到链外基础设施，同时实现仅链上的轻量级基于令牌的访问控制。SMACS非常灵活，除了简单的访问控制列表之外，还可以轻松实现增强智能合约运行时安全性的规则。借助漏洞检测工具支持的专用ACR，SMACS可以在部署后保护易受攻击的合同。我们完全实现SMACS并对其进行评估。",
                    "title_zh": "SMACS:智能合同访问控制服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00040",
                    "title": "Smart Contracts on the Move",
                    "authors": "Enrique Fynn, Alysson Bessani, Fernando Pedone",
                    "abstract": "Blockchain systems have received much attention and promise to revolutionize many services. Yet, despite their popularity, current blockchain systems exist in isolation, that is, they cannot share information. While interoperability is crucial for blockchain to reach widespread adoption, it is difficult to achieve due to differences among existing blockchain technologies. This paper presents a technique to allow blockchain interoperability. The core idea is to provide a primitive operation to developers so that contracts and objects can switch from one blockchain to another, without breaking consistency and violating key blockchain properties. To validate our ideas, we implemented our protocol in two popular blockchain clients that use the Ethereum virtual machine. We discuss how to build applications using the proposed protocol and show examples of applications based on real use cases that can move across blockchains. To analyze the system performance we use a real trace from one of the most popular Ethereum applications and replay it in a multi-blockchain environment.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "区块链系统备受关注，并有望彻底改变许多服务。然而，尽管它们很受欢迎，当前的区块链系统是孤立存在的，也就是说，它们不能共享信息。虽然互操作性对于区块链实现广泛采用至关重要，但由于现有区块链技术之间的差异，很难实现。本文介绍了一种允许区块链互操作性的技术。核心思想是为开发人员提供一个原始操作，这样契约和对象可以从一个区块链切换到另一个，而不会破坏一致性和违反关键区块链属性。为了验证我们的想法，我们在两个流行的使用以太坊虚拟机的区块链客户端上实现了我们的协议。我们将讨论如何使用建议的协议构建应用程序，并展示基于真实用例的应用程序示例，这些应用程序可以在整个区块链移动。为了分析系统性能，我们使用了一个最流行的以太坊应用程序的真实轨迹，并在一个多区块链环境中重放它。",
                    "title_zh": "移动智能合同"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00041",
                    "title": "Impact of Geo-Distribution and Mining Pools on Blockchains: A Study of Ethereum",
                    "authors": "Paulo Silva, David Vavricka, João Barreto, Miguel Matos",
                    "abstract": "Given the large adoption and economical impact of permissionless blockchains, the complexity of the underlying systems and the adversarial environment in which they operate, it is fundamental to properly study and understand the emergent behavior and properties of these systems. We describe our experience on a detailed, one-month study of the Ethereum network from several geographically dispersed observation points. We leverage multiple geographic vantage points to assess the key pillars of Ethereum, namely geographical dispersion, network efficiency, blockchain efficiency and security, and the impact of mining pools. Among other new findings, we identify previously undocumented forms of selfish behavior and show that the prevalence of powerful mining pools exacerbates the geographical impact on block propagation delays. Furthermore, we provide a set of open measurement and processing tools, as well as the data set of the collected measurements, in order to promote further research on understanding permissionless blockchains.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2005.06356"
                    },
                    "abstract_zh": "鉴于无许可区块链的广泛采用和经济影响，潜在系统的复杂性及其运行的敌对环境，正确研究和理解这些系统的涌现行为和属性是至关重要的。我们描述了我们从几个地理上分散的观察点对以太坊网络进行的一个月的详细研究的经验。我们利用多个地理优势来评估以太坊的关键支柱，即地理分散性、网络效率、区块链效率和安全性，以及矿池的影响。在其他新发现中，我们确定了以前未记录的自私行为形式，并表明强大的矿池的流行加剧了地理对块传播延迟的影响。此外，我们提供了一套开放的测量和处理工具，以及收集的测量数据集，以促进对理解无许可区块链的进一步研究。",
                    "title_zh": "地理分布和采矿池对区块链的影响:以太坊研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00042",
                    "title": "Ephemeral Exit Bridges for Tor",
                    "authors": "Zhao Zhang, Tavish Vaidya, Kartik Subramanian, Wenchao Zhou, Micah Sherr",
                    "abstract": "This paper examines an existential threat to Tor---the increasing frequency at which websites apply discriminatory behavior to users who arrive via the anonymity network. Our main contribution is the introduction of Tor exit bridges. Exit bridges, constructed as short-lived virtual machines on cloud service providers, serve as alternative egress points for Tor and are designed to bypass server-side censorship. Due to the proliferation of managed cloud-based desktop services (e.g., Amazon Workspaces), there is already a surprisingly large fraction of web requests that originate in the cloud. Trivially disrupting exit bridges by blocking requests from the cloud would thus lead to significant collateral damage. Our experiments demonstrate that exit bridges effectively circumvent server-side blocking of Tor with low overhead. Additionally, we perform a cost-analysis of exit bridges and show that even a large-scale deployment can be done at low cost.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文考察了Tor面临的一个生存威胁——网站对通过匿名网络访问的用户实施歧视行为的频率越来越高。我们的主要贡献是引入了Tor出口桥。出口桥是作为云服务提供商的短期虚拟机构建的，作为Tor的替代出口点，旨在绕过服务器端审查。由于托管的基于云的桌面服务(例如，Amazon Workspaces)的激增，已经有相当大一部分web请求源自云。因此，通过阻止来自云的请求来中断出口桥会导致重大的附带损害。我们的实验表明，出口网桥以较低的开销有效地规避了Tor的服务器端阻塞。此外，我们还对出口网桥进行了成本分析，结果表明即使是大规模部署也能以较低的成本完成。",
                    "title_zh": "Tor的临时出口桥"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00043",
                    "title": "The Impact of DNS Insecurity on Time",
                    "authors": "Philipp Jeitner, Haya Shulman, Michael Waidner",
                    "abstract": "We demonstrate the first practical off-path time shifting attacks against NTP as well as against Man-in-the-Middle (MitM) secure Chronos-enhanced NTP. Our attacks exploit the insecurity of DNS allowing us to redirect the NTP clients to attacker controlled servers. We perform large scale measurements of the attack surface in NTP clients and demonstrate the threats to NTP due to vulnerable DNS.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2010.09338"
                    },
                    "abstract_zh": "我们展示了针对NTP以及针对中间人(MitM)安全Chronos增强型NTP的第一次实际路径外时移攻击。我们的攻击利用了DNS的不安全性，允许我们将NTP客户端重定向到攻击者控制的服务器。我们对NTP客户端的攻击面进行了大规模测量，并展示了易受攻击的DNS对NTP造成的威胁。",
                    "title_zh": "DNS不安全性对时间的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S50200.2020.00036",
                    "title": "Depending on HTTP/2 for Privacy? Good Luck!",
                    "authors": "Gargi Mitra",
                    "abstract": "HTTP/2 introduced multi-threaded server operation for performance improvement over HTTP/1.1. Recent works have discovered that multi-threaded operation results in multiplexed object transmission, that can also have an unanticipated positive effect on TLS/SSL privacy. In fact, these works go on to design privacy schemes that rely heavily on multiplexing to obfuscate the sizes of the objects based on which the attackers inferred sensitive information. Orthogonal to these works, we examine if the privacy offered by such schemes work in practice. In this work, we show that it is possible for a network adversary with modest capabilities to completely break the privacy offered by the schemes that leverage HTTP/2 multiplexing. Our adversary works based on the following intuition: restricting only one HTTP/2 object to be in the server queue at any point of time will eliminate multiplexing of that object and any privacy benefit thereof. In our scheme, we begin by studying if (1) packet delays, (2) network jitter, (3) bandwidth limitation, and (4) targeted packet drops have an impact on the number of HTTP/2 objects processed by the server at an instant of time. Based on these insights, we design our adversary that forces the server to serialize object transmissions, thereby completing the attack. Our adversary was able to break the privacy of a real-world HTTP/2 website 90% of the time, the code for which will be released. To the best of our knowledge, this is the first privacy attack on HTTP/2.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "HTTP/2引入了多线程服务器操作，以提高HTTP/1.1的性能。最近的研究发现，多线程操作会导致多路复用的对象传输，这也会对TLS/SSL隐私产生意想不到的积极影响。事实上，这些工作继续设计隐私方案，这些方案严重依赖于多路复用来混淆对象的大小，攻击者基于这些大小推断敏感信息。在这些工作的基础上，我们检验了这些方案提供的隐私在实践中是否有效。在这项工作中，我们表明，对于一个能力有限的网络对手来说，完全破坏利用HTTP/2多路复用的方案所提供的隐私是可能的。我们的对手基于以下直觉工作:在任何时间点限制服务器队列中只有一个HTTP/2对象将消除该对象的多路复用以及由此带来的任何隐私好处。在我们的方案中，我们首先研究(1)分组延迟，(2)网络抖动，(3)带宽限制，以及(4)目标分组丢弃是否对服务器在某一时刻处理的HTTP/2对象的数量有影响。基于这些认识，我们设计了我们的对手，迫使服务器序列化对象传输，从而完成攻击。我们的对手能够在90%的时间里破坏真实世界HTTP/2网站的隐私，其代码将被公布。据我们所知，这是对HTTP/2的第一次隐私攻击。",
                    "title_zh": "依靠HTTP/2实现隐私？祝你好运！"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00045",
                    "title": "Diving into Email Bomb Attack",
                    "authors": "Markus Schneider, Haya Shulman, Adi Sidis, Ravid Sidis, Michael Waidner",
                    "abstract": "We explore Email Bomb - a particularly devastating type of Denial of Service (DOS) attack that recently gained traction. During the attack Email account of a victim is targeted with a flood of Emails. Existing anti-spam defences fail at filtering this Emails' flood, since the Emails are not sent from spoofed addresses, but originate from legitimate web services on the Internet which are exploited as reflectors. We perform a two-year study of the Email bomb attack and the affected actors - the victims and the reflectors. We show that although the attack is rented for one day, the Email flood proceeds over longer time periods often lasting months after the initial attack. We identify the properties that allow the attackers to recruit web sites as potential reflectors and demonstrate how the attackers harvest web reflectors. We show that even popular Alexa web sites, such as booking.com, are exploited to launch Email bomb attacks. The main problem is that such attacks are extremely simple to launch and can be rented for 5USD on darknet. We setup a tool which periodically collects and analyses the Emails received during the attack, the analysis as well as the data is presented online at http://emailbombresearch.xyz. We argue that email bomb attacks do not only pose inconvenience and hinder the ability of victims to function, but also we provide the first demonstration how such attacks can be leveraged for hiding other devastating attacks which take place in parallel. We show that existing countermeasures fall short of preventing email bomb attacks and provide effective mitigation recommendations that are based on our study of this attack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们探讨电子邮件炸弹——一种特别具有破坏性的拒绝服务(DOS)攻击，最近这种攻击越来越流行。在攻击过程中，受害者的电子邮件帐户成为大量电子邮件的目标。现有的反垃圾邮件防御无法过滤这种电子邮件泛滥，因为电子邮件不是从欺骗地址发送的，而是来自互联网上被利用作为反射器的合法web服务。我们对电子邮件炸弹攻击和受影响的参与者——受害者和反映者——进行了为期两年的研究。我们发现，尽管攻击只持续了一天，但电子邮件泛滥会持续更长时间，通常会在首次攻击后持续数月。我们确定了允许攻击者招募网站作为潜在反射者的属性，并演示了攻击者如何获取web反射者。我们发现，即使是受欢迎的Alexa网站，如booking.com，也被用来发动电子邮件炸弹攻击。主要问题是，这种攻击非常容易发动，在darknet上只需花5美元就能租到。我们设置了一个工具，定期收集和分析攻击期间收到的电子邮件，分析结果和数据在http://emailbombresearch.xyz上在线提供。我们认为电子邮件炸弹攻击不仅造成不便并妨碍受害者的工作能力，而且我们首次展示了此类攻击如何被用来隐藏同时发生的其他毁灭性攻击。我们表明现有的对策不足以防止电子邮件炸弹攻击，并根据我们对这种攻击的研究提供了有效的缓解建议。",
                    "title_zh": "潜入电子邮件炸弹攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00046",
                    "title": "HardSnap: Leveraging Hardware Snapshotting for Embedded Systems Security Testing",
                    "authors": "Nassim Corteggiani, Aurélien Francillon",
                    "abstract": "Advanced dynamic analysis techniques such as fuzzing and Dynamic Symbolic Execution (DSE) are a cornerstone of software security testing and are becoming popular with embedded systems testing. Testing software in a virtual machine provides more visibility and control. VM snapshots also save testing time by facilitating crash reproduction, performing root cause analysis and avoiding re-executing programs from the start. However, because embedded systems are very diverse virtual machines that perfectly emulate them are often unavailable. Previous work therefore either attempt to model hardware or perform partial emulation (forwarding interaction to the real hardware), which leads to inaccurate or slow emulation. However, such limitations are unnecessary when the whole design is available, e.g., to the device manufacturer or on open hardware. In this paper, we therefore propose a novel approach, called HardSnap, for co-testing hardware and software with a high level of introspection. HardSnap aims at improving security testing of hardware/software co-designed systems, where embedded systems designers have access to the whole HW/SW stack. HardSnap is a virtual-machine-based solution that extends visibility and controllability to the hardware peripherals with a negligible overhead. HardSnap introduces the concept of a hardware snapshot that collects the hardware state (together with software state). In our prototype, Verilog hardware blocks are either simulated in software or synthesized to an FPGA. In both cases HardSnap is able to generate HW/SW snapshot on demand. HardSnap is designed to support new peripherals automatically, to have high performance, and full controllability and visibility on software and hardware. We evaluated HardSnap on open-source peripherals and synthetic firmware to demonstrate improved ability to find and diagnose security issues.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "模糊化和动态符号执行(DSE)等高级动态分析技术是软件安全测试的基石，在嵌入式系统测试中越来越受欢迎。在虚拟机中测试软件提供了更多的可见性和控制。虚拟机快照还通过简化崩溃再现、执行根本原因分析以及避免从头开始重新执行程序来节省测试时间。然而，由于嵌入式系统非常多样化，完美地模拟它们的虚拟机通常是不可用的。因此，先前的工作要么试图模拟硬件，要么执行部分仿真(将交互转发到真实硬件)，这导致不准确或缓慢的仿真。然而，当整个设计可用于例如设备制造商或开放硬件时，这种限制是不必要的。因此，在本文中，我们提出了一种新的方法，称为HardSnap，用于以高水平的自省来共同测试硬件和软件。HardSnap旨在改善硬件/软件协同设计系统的安全性测试，嵌入式系统设计人员可以访问整个硬件/软件堆栈。HardSnap是一种基于虚拟机的解决方案，以可忽略不计的开销将可见性和可控性扩展到硬件外围设备。HardSnap引入了收集硬件状态(以及软件状态)的硬件快照的概念。在我们的原型中，Verilog硬件模块要么在软件中模拟，要么合成到FPGA中。在这两种情况下，HardSnap都能够按需生成硬件/软件快照。HardSnap旨在自动支持新的外围设备，具有高性能以及对软件和硬件的完全可控性和可见性。我们在开源外围设备和合成固件上评估了HardSnap，以展示发现和诊断安全问题的改进能力。",
                    "title_zh": "HardSnap:利用硬件快照进行嵌入式系统安全测试"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00047",
                    "title": "iScanU: A Portable Scanner for Undocumented Instructions on RISC Processors",
                    "authors": "Rens Dofferhoff, Michael Göbel, Kristian F. D. Rietveld, Erik van der Kouwe",
                    "abstract": "Undocumented and faulty CPU instructions can cause undefined behavior and system instability, impairing software efforts such as OS crash recovery and resilience, and system security. Although often not considered, the identification of such undocumented instructions is critical. We present a portable RISC instruction scanner that is able to search for undocumented instructions on a wide range of RISC architectures, empowering users to verify the reliable and secure operation of their systems. We propose two methods to look for undocumented instructions. Both attempt to execute a single instruction word in a controlled manner, regaining control afterwards. Subsequently, we determine if the instruction word is considered valid by the processor, comparing this result to the processor's ISA specification. Our prototype scanner can scan multiple ARMv8 and RISC-V systems. Various inconsistencies were discovered in the QEMU emulator and disassemblers used as ground truth. Furthermore, we found an undocumented instruction on a RISC-V chip.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "未记录的和错误的CPU指令会导致未定义的行为和系统不稳定，损害软件工作，如操作系统崩溃恢复和弹性，以及系统安全性。虽然经常不被考虑，但是识别这种未记录的指令是至关重要的。我们提出了一种便携式RISC指令扫描器，它能够在各种RISC架构上搜索未记录的指令，使用户能够验证其系统的可靠和安全操作。我们提出两种方法来寻找未记录的指令。两者都试图以受控方式执行单个指令字，然后重新获得控制。随后，我们将该结果与处理器的ISA规范进行比较，确定处理器是否认为该指令字有效。我们的原型扫描仪可以扫描多个ARMv8和RISC-V系统。在QEMU仿真器和反汇编器中发现了各种不一致的地方。此外，我们在RISC-V芯片上发现了一条未记录的指令。",
                    "title_zh": "iScanU:一个用于RISC处理器上未记录指令的便携式扫描器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00048",
                    "title": "Libspector : Context-Aware Large-Scale Network Traffic Analysis of Android Applications",
                    "authors": "Onur Zungur, Gianluca Stringhini, Manuel Egele",
                    "abstract": "Android applications (apps) are a combination of code written by the developers as well as third-party libraries that carry out most commonly used functionalities such as advertisement and payments. Running apps in a monitoring environment allows researchers to measure how much network traffic is exchanged between an app and remote endpoints. However, current systems currently do not have the ability to reliably distinguish traffic that is generated by different libraries. This is important, because while mobile users are paying for data traffic without distinctions, some of this traffic is useful (e.g., data for core app functionalities), whereas the rest of the traffic can be considered a nuisance (e.g., excessive advertisements). In this paper, we present Libspector, a system that precisely attributes network traffic coming from an Android app to the library that generated it. To this end, we instrument the Android Framework to inspect the network connections initiated by apps, provide fine-grained information on the libraries in use, and calculate method coverage information while performing dynamic analysis. We then perform a measurement on 25,000 popular Android apps and investigate the relation between different categories of apps with the use of specific libraries. We analyze the method coverage of our dynamic analysis method, and further characterize the endpoint connections established by the Android apps. Our results indicate that advertisement libraries account for over a quarter of the total data transmission. We further observe that there is no strict 1-to-1 correlation between the similar categories of network endpoints and libraries which initiated the data transfer.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Android应用程序(apps)是由开发者编写的代码和第三方库的组合，执行最常用的功能，如广告和支付。在监控环境中运行应用程序允许研究人员测量应用程序和远程端点之间交换的网络流量。然而，当前的系统不具备可靠地区分不同库产生的流量的能力。这一点很重要，因为虽然移动用户不加区别地为数据流量付费，但其中一些流量是有用的(例如核心应用功能的数据)，而其余的流量则可能被视为令人讨厌的(例如过多的广告)。在本文中，我们介绍了Libspector，这是一个可以精确地将来自Android应用程序的网络流量归属于生成它的库的系统。为此，我们使用Android框架来检查应用程序启动的网络连接，提供正在使用的库的细粒度信息，并在执行动态分析的同时计算方法覆盖信息。然后，我们对25，000个流行的Android应用程序进行了测量，并调查了不同类别的应用程序与特定库的使用之间的关系。我们分析了我们的动态分析方法的方法覆盖范围，并进一步描述了Android应用程序建立的端点连接。我们的结果表明，广告库占总数据传输的四分之一以上。我们进一步观察到，在发起数据传输的相似类别的网络端点和库之间没有严格的一对一的关联。",
                    "title_zh": "libspector:Android应用的上下文感知大规模网络流量分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00049",
                    "title": "Foosball Coding: Correcting Shift Errors and Bit Flip Errors in 3D Racetrack Memory",
                    "authors": "Samantha Archer, Georgios Mappouras, A. Robert Calderbank, Daniel J. Sorin",
                    "abstract": "Racetrack memory is a promising new non-volatile memory technology, especially because of the density of its 3D implementation. However, for 3D racetrack to reach its potential, certain reliability issues must be overcome. Prior work used per-track encoding to tolerate the shift errors that are unique to racetrack, but no solutions existed for tolerating both shift errors and bit flip errors. We introduce Foosball Coding, which combines per-track coding for shift errors with a novel across-track coding for bit flips. Moreover, our per-track coding scheme methodically explores the design of inter-codeword delimiters and introduces the novel concept of multi-purpose delimiters, in which the existence of multiple delimiter options can be used to provide additional information.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "赛道存储器是一种有前途的新型非易失性存储器技术，尤其是因为其3D实现的密度。然而，为了让3D赛道发挥其潜力，必须克服某些可靠性问题。先前的工作使用每轨迹编码来容忍赛道特有的移位错误，但是不存在容忍移位错误和比特翻转错误的解决方案。我们引入了足球编码，它将针对移位错误的每道编码与针对比特翻转的新颖的跨道编码相结合。此外，我们的每轨道编码方案系统地探索了码字间分隔符的设计，并引入了多用途分隔符的新概念，其中多个分隔符选项的存在可用于提供附加信息。",
                    "title_zh": "足球编码:纠正3D跑道存储器中的移位错误和位翻转错误"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00050",
                    "title": "Extreme Protection Against Data Loss with Single-Overlap Declustered Parity",
                    "authors": "Huan Ke, Haryadi S. Gunawi, David Bonnie, Nathan DeBardeleben, Michael Grosskopf, Terry Grové, Dominic Manno, Elisabeth Moore, Brad Settlemyer",
                    "abstract": "Massive storage systems composed of tens of thou-sands of disks are increasingly common in high-performance computing data centers. With such an enormous number of components integrated within the storage system the probability for correlated failures across a large number of components becomes a critical concern in preventing data loss. In this paper we reconsider the efficiency of traditional declustered parity data protection schemes in the presence of correlated failures. To better protect against correlated failures we introduce Single-Overlap Declustered Parity (SODP), a novel declustered parity design that tolerates more disk failures than traditional declus-tered parity. We then introduce CoFaCTOR, a tool for exploring operational reliability in the presence of many types of correlated failures. By seeding CoFaCTOR with real failure traces from LANL's data center we are able to create a failure model that accurately describes the existing file system's failure model and can use that model to generate failure data for hypothetical system designs. Our evaluation using CoFaCTOR traces shows that when compared to the state of the art our SODP-based placement algorithms can achieve a 30x improvement in the probability of data loss during failure bursts and achieves similar data protection using only half as much parity overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由数万个磁盘组成的海量存储系统在高性能计算数据中心越来越常见。由于存储系统中集成了如此大量的组件，跨大量组件的相关故障的概率成为防止数据丢失的关键问题。在本文中，我们重新考虑了传统的去簇奇偶校验数据保护方案在相关失效情况下的效率。为了更好地防止相关故障，我们引入了单重叠去集群奇偶校验(SODP)，这是一种新型的去集群奇偶校验设计，比传统的去集群奇偶校验能够容忍更多的磁盘故障。然后，我们介绍了余因子，这是一种在多种相关故障情况下探索操作可靠性的工具。通过将LANL数据中心的真实故障跟踪植入辅因子，我们能够创建准确描述现有文件系统故障模型的故障模型，并使用该模型为假设的系统设计生成故障数据。我们使用余因子跟踪进行的评估表明，与现有技术相比，我们基于SODP的放置算法可以将故障突发期间的数据丢失概率提高30倍，并使用一半的奇偶校验开销实现类似的数据保护。",
                    "title_zh": "借助单重叠去集群奇偶校验，防止数据丢失"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00051",
                    "title": "Chaser: An Enhanced Fault Injection Tool for Tracing Soft Errors in MPI Applications",
                    "authors": "Qiang Guan, Xunchao Hu, Terence Grove, Bo Fang, Hailong Jiang, Heng Yin, Nathan DeBardeleben",
                    "abstract": "Resilient computation has been an emerging topic in the field of high-performance computing (HPC). In particular, studies show that tolerating faults on leadership-class supercomputers (such as exascale supercomputers) is expected to be one of the main challenges. In this paper, we utilize dynamic binary instrumentation and virtual machine based fault injection to emulate soft errors and study the soft errors' impact on the behavior of applications. We propose Chaser, a fine-grained, accountable, flexible, and efficient fault injection framework built on top of QEMU. Chaser offers just-in-time fault injection, the ability to trace fault propagation, and flexible and programable interfaces. In the case study, we demonstrate the usage of Chaser on Matvec and a real DOE mini MPI application",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "弹性计算已经成为高性能计算领域的一个新兴话题。特别是，研究表明，容忍领导级超级计算机(如亿亿次超级计算机)上的故障预计将是主要挑战之一。在本文中，我们利用动态二进制插装和基于虚拟机的故障注入来模拟软错误，并研究软错误对应用程序行为的影响。我们提出了Chaser，一个基于QEMU之上的细粒度、可问责、灵活、高效的故障注入框架。Chaser提供即时故障注入、跟踪故障传播的能力以及灵活的可编程接口。在案例研究中，我们展示了Chaser在Matvec上的用法和一个真实的DOE mini MPI应用程序",
                    "title_zh": "Chaser:一个增强的故障注入工具，用于跟踪MPI应用程序中的软错误"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00052",
                    "title": "ProFIPy: Programmable Software Fault Injection as-a-Service",
                    "authors": "Domenico Cotroneo, Luigi De Simone, Pietro Liguori, Roberto Natella",
                    "abstract": "In this paper, we present a new fault injection tool (ProFIPy) for Python software. The tool is designed to be programmable, in order to enable users to specify their software fault model, using a domain-specific language (DSL) for fault injection. Moreover, to achieve better usability, ProFIPy is provided as software-as-a-service and supports the user through the configuration of the faultload and workload, failure data analysis, and full automation of the experiments using container- based virtualization and parallelization.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2005.04990"
                    },
                    "abstract_zh": "在本文中，我们提出了一种新的Python软件故障注入工具(ProFIPy)。该工具被设计为可编程的，以便使用户能够指定他们的软件故障模型，使用特定领域语言(DSL)进行故障注入。此外，为了实现更好的可用性，ProFIPy作为软件即服务提供，并通过配置故障负载和工作负载、故障数据分析以及使用基于容器的虚拟化和并行化实现实验的完全自动化来支持用户。",
                    "title_zh": "ProFIPy:可编程软件故障注入即服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00053",
                    "title": "Hybrid Firmware Analysis for Known Mobile and IoT Security Vulnerabilities",
                    "authors": "Pengfei Sun, Luis Garcia, Gabriel Salles-Loustau, Saman A. Zonouz",
                    "abstract": "Mobile and IoT operating systems–and their ensuing software updates–are usually distributed as binary files. Given that these binary files are commonly closed source, users or businesses who want to assess the security of the software need to rely on reverse engineering. Further, verifying the correct application of the latest software patches in a given binary is an open problem. The regular application of software patches is a central pillar for improving mobile and IoT device security. This requires developers, integrators, and vendors to propagate patches to all affected devices in a timely and coordinated fashion. In practice, vendors follow different and sometimes improper security update agendas for both mobile and IoT products. Moreover, previous studies revealed the existence of a hidden patch gap: several vendors falsely reported that they patched vulnerabilities. Therefore, techniques to verify whether vulnerabilities have been patched or not in a given binary are essential. Deep learning approaches have shown to be promising for static binary analyses with respect to inferring binary similarity as well as vulnerability detection. However, these approaches fail to capture the dynamic behavior of these systems, and, as a result, they may inundate the analysis with false positives when performing vulnerability discovery in the wild. In particular, they cannot capture the fine-grained characteristics necessary to distinguish whether a vulnerability has been patched or not. In this paper, we present PATCHECKO, a vulnerability and patch presence detection framework for executable binaries. PATCHECKO relies on a hybrid, cross-platform binary code similarity analysis that combines deep learning-based static binary analysis with dynamic binary analysis. PATCHECKO does not require access to the source code of the target binary nor that of vulnerable functions. We evaluate PATCHECKO on the most recent Google Pixel 2 smartphone and the Android Things IoT firmware images, within which 25 known CVE vulnerabilities have been previously reported and patched. Our deep learning model shows a vulnerability detection accuracy of over 93%. We further prune the candidates found by the deep learning stage–which includes false positives–via dynamic binary analysis. Consequently, PATCHECKO successfully identifies the correct matches among the candidate functions in the top 3 ranked outcomes 100% of the time. Furthermore, PATCHECKO's differential engine distinguishes between functions that are still vulnerable and those that are patched with an accuracy of 96%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "移动和物联网操作系统——及其随之而来的软件更新——通常以二进制文件的形式分发。鉴于这些二进制文件通常是封闭源代码，想要评估软件安全性的用户或企业需要依靠逆向工程。此外，验证给定二进制文件中最新软件补丁的正确应用是一个公开的问题。定期应用软件补丁是提高移动和物联网设备安全性的核心支柱。这要求开发人员、集成商和供应商及时、协调地将补丁传播到所有受影响的设备。在实践中，对于移动和物联网产品，供应商遵循不同且有时不正确的安全更新议程。此外，以前的研究揭示了隐藏的补丁漏洞的存在:几个供应商错误地报告他们修补了漏洞。因此，验证给定二进制文件中的漏洞是否已被修补的技术是必不可少的。深度学习方法已被证明在推断二进制相似性以及脆弱性检测方面对于静态二进制分析是有前途的。然而，这些方法无法捕捉这些系统的动态行为，因此，当在野外执行漏洞发现时，它们可能会使分析淹没在误报中。特别是，它们无法捕获区分漏洞是否已被修补所需的细粒度特征。在本文中，我们介绍了PATCHECKO，这是一个针对可执行二进制文件的漏洞和补丁检测框架。PATCHECKO依靠一种混合的、跨平台的二进制代码相似性分析，该分析结合了基于深度学习的静态二进制分析和动态二进制分析。PATCHECKO不需要访问目标二进制文件的源代码，也不需要访问易受攻击的函数的源代码。我们在最新的谷歌Pixel 2智能手机和Android Things物联网固件映像上评估了PATCHECKO，其中25个已知的CVE漏洞此前已被报告和修补。我们的深度学习模型显示漏洞检测准确率超过93%。我们通过动态二进制分析，进一步删减深度学习阶段发现的候选项，其中包括误报。因此，PATCHECKO在100%的时间里成功地在前3个排序结果的候选函数中识别出正确的匹配。此外，PATCHECKO的差分引擎以96%的准确率区分了仍易受攻击的函数和已修补的函数。",
                    "title_zh": "针对已知移动和物联网安全漏洞的混合固件分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00054",
                    "title": "Real-Time Context-Aware Detection of Unsafe Events in Robot-Assisted Surgery",
                    "authors": "Mohammad Samin Yasar, Homa Alemzadeh",
                    "abstract": "Cyber-physical systems for robotic surgery have enabled minimally invasive procedures with increased precision and shorter hospitalization. However, with increasing complexity and connectivity of software and major involvement of human operators in the supervision of surgical robots, there remain significant challenges in ensuring patient safety. This paper presents a safety monitoring system that, given the knowledge of the surgical task being performed by the surgeon, can detect safety-critical events in real-time. Our approach integrates a surgical gesture classifier that infers the operational context from the time-series kinematics data of the robot with a library of erroneous gesture classifiers that given a surgical gesture can detect unsafe events. Our experiments using data from two surgical platforms show that the proposed system can detect unsafe events caused by accidental or malicious faults within an average reaction time window of 1,693 milliseconds and F1 score of 0.88 and human errors within an average reaction time window of 57 milliseconds and F1 score of 0.76.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2005.03611"
                    },
                    "abstract_zh": "用于机器人手术的信息物理系统使得微创手术变得更加精确，住院时间更短。然而，随着软件的复杂性和连接性的增加以及人类操作员在外科手术机器人的监督中的主要参与，在确保患者安全方面仍然存在重大挑战。本文介绍了一种安全监控系统，在已知外科医生正在执行的手术任务的情况下，该系统可以实时检测安全关键事件。我们的方法将从机器人的时间序列运动学数据推断操作环境的手术手势分类器与错误手势分类器的库相集成，该错误手势分类器在给定手术手势的情况下可以检测不安全事件。我们使用来自两个手术平台的数据进行的实验表明，所提出的系统可以在1，693毫秒的平均反应时间窗口和0.88的f 1分数内检测由意外或恶意故障引起的不安全事件，并且可以在57毫秒的平均反应时间窗口和0.76的F1分数内检测人为错误。",
                    "title_zh": "机器人辅助手术中不安全事件的实时上下文感知检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00055",
                    "title": "Scalable Approach to Enhancing ICS Resilience by Network Diversity",
                    "authors": "Tingting Li, Cheng Feng, Chris Hankin",
                    "abstract": "Network diversity has been widely recognized as an effective defense strategy to mitigate the spread of malware. Optimally diversifying network resources can improve the resilience of a network against malware propagation. This work proposes a scalable method to compute such an optimal deployment, in the context of upgrading a legacy Industrial Control System with modern IT infrastructure. Our approach can tolerate various constraints when searching for optimal diversification, such as outdated products and strict configuration policies. We explicitly measure the vulnerability similarity of products based on the CVE/NVD, to estimate the infection rate of malware between products. A Stuxnet-inspired case demonstrates our optimal diversification in practice, particularly when constrained by various requirements. We then measure the improved resilience of the diversified network in terms of a well-defined diversity metric and Mean-time-to-compromise (MTTC), to verify the effectiveness of our approach. Finally, we show the competitive scalability of our approach in finding optimal solutions within a couple of seconds to minutes for networks of large scales (up to 10,000 hosts) and high densities (up to 240,000 edges).",
                    "files": {
                        "openAccessPdf": "https://orca.cardiff.ac.uk/id/eprint/131582/1/DSN2020_FINAL.pdf"
                    },
                    "abstract_zh": "网络多样性被广泛认为是减缓恶意软件传播的有效防御策略。优化网络资源的多样化可以提高网络抵御恶意软件传播的能力。在用现代IT基础设施升级遗留工业控制系统的背景下，这项工作提出了一种可扩展的方法来计算这样的最优部署。我们的方法可以在搜索最优多样化时容忍各种约束，例如过时的产品和严格的配置策略。我们基于CVE/NVD显式地度量产品的漏洞相似性，以估计产品之间的恶意软件感染率。一个受Stuxnet启发的案例展示了我们在实践中的最佳多样化，特别是在受到各种要求约束的情况下。然后，我们根据明确定义的多样性度量和平均妥协时间(MTTC)来衡量多样化网络的弹性，以验证我们方法的有效性。最后，我们展示了我们的方法在大规模(最多10，000台主机)和高密度(最多240，000条边)的网络中在几秒到几分钟内找到最佳解决方案的竞争性可扩展性。",
                    "title_zh": "通过网络多样性增强ICS弹性的可扩展方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00056",
                    "title": "Cross-App Interference Threats in Smart Homes: Categorization, Detection and Handling",
                    "authors": "Haotian Chi, Qiang Zeng, Xiaojiang Du, Jiaping Yu",
                    "abstract": "Internet of Thing platforms prosper home automation applications (apps). Prior research concerns intra-app security. Our work reveals that automation apps, even secured individually, still cause a family of threats when they interplay, termed as Cross-App Interference (CAI) threats. We systematically categorize such threats and encode them using satisfiability modulo theories (SMT). We present HomeGuard, a system for detecting and handling CAI threats in real deployments. A symbolic executor is built to extract rule semantics, and instrumentation is utilized to capture configuration during app installation. Rules and configuration are checked against SMT models, the solutions of which indicate the existence of corresponding CAI threats. We further combine app functionalities, device attributes and CAI types to label the risk level of CAI instances. In our evaluation, HomeGuard discovers 663 CAI instances from 146 SmartThings market apps, imposing minor latency upon app installation and no runtime overhead.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1808.02125"
                    },
                    "abstract_zh": "物联网平台繁荣家庭自动化应用(apps)。先前的研究关注应用程序内部的安全性。我们的工作揭示了自动化应用程序，即使是单独安全的，当它们相互作用时，仍然会造成一系列威胁，称为跨应用程序干扰(CAI)威胁。我们系统地对这些威胁进行分类，并使用可满足性模理论(SMT)对它们进行编码。我们介绍了HomeGuard，一个用于在实际部署中检测和处理CAI威胁的系统。构建了一个符号执行器来提取规则语义，并在应用程序安装期间使用工具来捕获配置。对照SMT模型检查规则和配置，SMT模型的解决方案表明存在相应的CAI威胁。我们进一步结合应用程序功能、设备属性和CAI类型来标记CAI实例的风险级别。在我们的评估中，HomeGuard从146个SmartThings market应用程序中发现了663个CAI实例，对应用程序安装施加了较小的延迟，并且没有运行时开销。",
                    "title_zh": "智能家居中的跨应用程序干扰威胁:分类、检测和处理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00057",
                    "title": "From Byzantine Replication to Blockchain: Consensus is Only the Beginning",
                    "authors": "Alysson Bessani, Eduardo Alchieri, João Sousa, André Oliveira, Fernando Pedone",
                    "abstract": "The popularization of blockchains leads to a resurgence of interest in Byzantine Fault-Tolerant (BFT) state machine replication protocols. However, much of the work on this topic focuses on the underlying consensus protocols, with emphasis on their lack of scalability, leaving other subtle limitations unaddressed. These limitations are related to the effects of maintaining a durable blockchain instead of a write-ahead log and the requirement for reconfiguring the set of replicas in a decentralized way. We demonstrate these limitations using a digital coin blockchain application and BFT-SMaRt, a popular BFT replication library. We show how they can be addressed both at a conceptual level, in a protocol-agnostic way, and by implementing SMaRtChain, a blockchain platform based on BFT-SMaRt. SMaRtChain improves the performance of our digital coin application by a factor of eight when compared with a naive implementation on top of BFT-SMaRt. Moreover, SMaRtChain achieves a throughput 8x and 33x better than Tendermint and Hyperledger Fabric, respectively, when ensuring strong durability on its blockchain.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2004.14527"
                    },
                    "abstract_zh": "区块链的普及引起了人们对拜占庭容错(BFT)状态机复制协议的兴趣。然而，关于这一主题的大部分工作都集中在底层的共识协议上，强调它们缺乏可伸缩性，而忽略了其他微妙的限制。这些限制与维护持久区块链而不是预写日志的效果以及以分散方式重新配置副本集的要求有关。我们用一个数字硬币区块链应用程序和一个流行的BFT复制库BFT智能演示了这些限制。我们展示了如何以协议无关的方式在概念层面上解决这些问题，以及如何实施SMaRtChain，这是一个基于BFT智能的区块链平台。与基于BFT智能的简单实现相比，SMaRtChain将我们的数字硬币应用程序的性能提高了8倍。此外，SMaRtChain的吞吐量分别是Tendermint和Hyperledger织物的8倍和33倍，同时确保了其区块链的耐用性。",
                    "title_zh": "从拜占庭复制到区块链:共识只是开始"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00058",
                    "title": "EPIC: Efficient Asynchronous BFT with Adaptive Security",
                    "authors": "Chao Liu, Sisi Duan, Haibin Zhang",
                    "abstract": "Asynchronous BFT protocols such as HoneyBadgerBFT and BEAT are inherently robust against timing, performance, and denial-of-service attacks. The protocols, however, achieve static security, where the adversary needs to choose the set of corrupted replicas before the execution of the protocol. The situation is in contrast to that of most of existing BFT protocols (e.g., PBFT) which achieve adaptive security, where the adversary can choose to corrupt replicas at any moment during the execution of the protocol. We present EPIC, a novel and efficient asynchronous BFT protocol with adaptive security. Via a five-continent deployment on Amazon EC2, we show that EPIC is slightly slower for small and medium-sized networks than the most efficient asynchronous BFT protocols with static security. We also find as the number of replicas is smaller than 46, EPIC's throughput is stable, achieving peak throughput of 8,000--12,500 tx/sec using t2.medium VMs. When the network size grows larger, EPIC is not as efficient as those with static security, with throughput of 4,000--6,300 tx/sec.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "诸如HoneyBadgerBFT和BEAT之类的异步BFT协议本质上可以抵御计时、性能和拒绝服务攻击。然而，这些协议实现了静态安全性，其中对手需要在执行协议之前选择一组被破坏的副本。这种情况与大多数现有的实现自适应安全性的BFT协议(例如PBFT)形成对比，其中对手可以在协议执行期间的任何时刻选择破坏副本。我们提出了一种新颖有效的具有自适应安全性的异步BFT协议EPIC。通过在Amazon EC2上的五大洲部署，我们表明EPIC对于中小型网络来说比具有静态安全性的最有效的异步BFT协议稍慢。我们还发现，当副本数量小于46时，EPIC的吞吐量是稳定的，使用t2.medium虚拟机实现了8，000 - 12，500 tx/sec的峰值吞吐量。当网络规模变大时，EPIC的效率不如那些静态安全的，吞吐量为4000-6300 tx/sec。",
                    "title_zh": "EPIC:具有自适应安全性的高效异步BFT"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00059",
                    "title": "On Incentive Compatible Role-Based Reward Distribution in Algorand",
                    "authors": "Mehdi Fooladgar, Mohammad Hossein Manshaei, Murtuza Jadliwala, Mohammad Ashiqur Rahman",
                    "abstract": "Algorand is a recent, open-source public or permissionless blockchain system that employs a novel proof-of-stake Byzantine consensus protocol to efficiently scale the distributed transaction agreement problem to billions of users. Despite its promise, one relatively understudied aspect of this protocol has been the incentive compatibility of its reward sharing approach, without which cooperation among rational network users cannot be guaranteed, resulting in protocol failure. This paper is the first attempt to address this problem. By carefully modeling the participation costs and rewards received within a strategic interaction scenario in Algorand, we first show that even a small number of non-participating users (due to insufficiency of the expected incentives) can result in the network failing to append new transaction blocks. We further show that this effect, which was observed in simulations, can be formalized by means of a game-theoretic model that realistically captures the strategic interactions between users in Algorand. Specifically, we formally prove that mutual cooperation under the currently proposed reward sharing approach in Algorand is not a Nash equilibrium. To remedy this, we propose a novel reward sharing approach for Algorand and formally show that it is incentive-compatible, i.e., it can guarantee cooperation within a group of selfish users. Extensive numerical and Algorand simulation results further confirm our analytical findings. Moreover, these results show that for a given distribution of stakes in the network, our reward sharing approach can guarantee cooperation with a significantly smaller reward per round.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1911.03356"
                    },
                    "abstract_zh": "Algorand是一个最近的开源公共或无许可区块链系统，它采用了一种新的利益证明拜占庭共识协议，以有效地将分布式交易协议问题扩展到数十亿用户。尽管有其承诺，但该协议一个相对不足的方面是其奖励共享方法的激励兼容性，没有它，理性网络用户之间的合作无法得到保证，导致协议失败。本文是解决这一问题的首次尝试。通过在Algorand中对战略互动场景中的参与成本和获得的回报进行仔细建模，我们首先表明，即使少量的未参与用户(由于预期激励不足)也会导致网络无法追加新的交易块。我们进一步表明，这种在模拟中观察到的效果可以通过一个博弈论模型来形式化，该模型真实地捕捉了Algorand中用户之间的战略互动。具体来说，我们正式证明了在目前提出的奖励分享方法下的相互合作不是纳什均衡。为了弥补这一点，我们提出了一种新的奖励分享方法，并正式证明了它是激励兼容的，即它可以保证一组自私用户之间的合作。大量的数值和算法模拟结果进一步证实了我们的分析结果。此外，这些结果表明，对于网络中给定的股份分布，我们的奖励分享方法可以保证每轮奖励明显较小的合作。",
                    "title_zh": "论激励相容的基于角色的报酬分配"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00060",
                    "title": "FSTR: Funds Skewness Aware Transaction Routing for Payment Channel Networks",
                    "authors": "Siyi Lin, Jingjing Zhang, Weigang Wu",
                    "abstract": "Payment channel is an effective and popular technique to improve the scalability and throughput of blockchains by transferring transactions from on-chain to off-chain. Multiple payment channels can constitute a payment network and realize transaction execution via multi-hop paths. How to find a feasible and efficient transaction path, i.e., transaction routing, is a key issue in payment channel networks, and different solutions have been proposed. However, the problem of funds skewness, which may cause routing failures, has been largely ignored in existing routing algorithms. In this work, we design FSTR, a routing algorithm that attempts to route transactions using a funds skewness based path selection scheme so as to reduce funds skewness and increase transaction success probability. To evaluate the performance of FSTR, we conduct experiments using the real-world dataset of Ripple. The experiment results show that FSTR outperforms existing routing algorithms, in terms of success ratio, delay, and overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "支付通道通过将交易从链上转移到链下来提高区块链的可扩展性和吞吐量，是一种有效且流行的技术。多个支付通道可以构成一个支付网络，通过多跳路径实现交易执行。如何找到可行且高效的交易路径，即交易路由，是支付通道网络中的一个关键问题，已经提出了不同的解决方案。然而，现有的路由算法在很大程度上忽略了可能导致路由失败的资金偏斜问题。在本文中，我们设计了一个路由算法FSTR，它试图使用一个基于资金偏斜度的路径选择方案来路由交易，以减少资金偏斜度，提高交易成功概率。为了评估FSTR的性能，我们使用真实世界的Ripple数据集进行了实验。实验结果表明，FSTR在成功率、延迟和开销方面优于现有的路由算法。",
                    "title_zh": "FSTR:支付通道网络的资金偏斜感知交易路由"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00061",
                    "title": "SeGShare: Secure Group File Sharing in the Cloud using Enclaves",
                    "authors": "Benny Fuhry, Lina Hirschoff, Samuel Koesnadi, Florian Kerschbaum",
                    "abstract": "File sharing applications using cloud storage are increasingly popular for personal and business use. Due to data protection concerns, end-to-end encryption is often a desired feature of these applications. Many attempts at designing cryptographic solutions fail to be adopted due to missing relevant features. We present SeGShare, a new architecture for end-to-end encrypted, group-based file sharing using trusted execution environments (TEE), e.g., Intel SGX. SeGShare is the first solution to protect the confidentiality and integrity of all data and management files; enforce immediate permission and membership revocations; support deduplication; and mitigate rollback attacks. Next to authentication, authorization and file system management, our implementation features an optimized TLS layer that enables high throughput and low latency. The encryption overhead of our implementation is extremely small in computation and storage resources. Our enclave code comprises less than 8500 lines of code enabling efficient mitigation of common pitfalls in deploying code to TEEs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "使用云存储的文件共享应用程序越来越受个人和企业的欢迎。出于数据保护方面的考虑，端到端加密通常是这些应用程序的一个理想特性。许多设计加密解决方案的尝试由于缺少相关特征而未能被采用。我们提出了SeGShare，这是一种使用可信执行环境(TEE )(如SGX)进行端到端加密、基于组的文件共享的新架构。SeGShare是第一个保护所有数据和管理文件的机密性和完整性的解决方案；强制执行即时许可和成员资格撤销；支持重复数据删除；和减轻回滚攻击。除了身份验证、授权和文件系统管理之外，我们的实施还具有一个优化的TLS层，可实现高吞吐量和低延迟。我们实现的加密开销在计算和存储资源方面非常小。我们的enclave代码包含不到8500行代码，能够有效地减少将代码部署到tee中的常见缺陷。",
                    "title_zh": "SeGShare:使用Enclaves在云中安全共享组文件"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00062",
                    "title": "Omega: a Secure Event Ordering Service for the Edge",
                    "authors": "Cláudio Correia, Miguel Correia, Luís Rodrigues",
                    "abstract": "The edge computing paradigm extends cloud computing with storage and processing capacity close to the edge of the network, which can be materialized by using many fog nodes placed in multiple geographic locations. Fog nodes are likely to be vulnerable to tampering, so it is important to protect the functions they provide from attacks. A key building block of many distributed applications is an ordering service that keeps track of cause-effect dependencies among events and that allows events to be processed in an order that respects causality. This article presents the design and implementation of a secure event ordering service for fog nodes. Our service, named Omega, leverages the availability of a Trusted Execution Environment (TEE), based on SGX technology, to offer fog clients guarantees regarding the order in which events are applied and served, even when fog nodes are compromised. We have also built OmegaKV, a key-value store that uses Omega to offer causal consistency. Experimental results show that the ordering service can be secured without violating the latency constraints of time-sensitive edge applications, despite the overhead associated with using a TEE. Omega introduces an additional latency of approximately 4ms, that contrary to cloud based solutions, allows latency values in the 5ms-30ms range, as required by time-sensitive edge applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "边缘计算范式通过接近网络边缘的存储和处理能力来扩展云计算，这可以通过使用放置在多个地理位置的许多雾节点来实现。Fog节点很容易被篡改，因此保护它们提供的功能免受攻击非常重要。许多分布式应用程序的一个关键构造块是一个排序服务，它跟踪事件之间的因果依赖关系，并允许按照符合因果关系的顺序处理事件。本文介绍了一个面向fog节点的安全事件订购服务的设计和实现。我们的服务名为Omega，利用基于SGX技术的可信执行环境(TEE)的可用性，为fog客户端提供关于事件应用和服务顺序的保证，即使当fog节点被破坏时也是如此。我们还构建了OmegaKV，一个使用Omega提供因果一致性的键值存储。实验结果表明，尽管存在与使用TEE相关联的开销，但是在不违反时间敏感边缘应用的延迟约束的情况下，订购服务是安全的。Omega引入了大约4毫秒的额外延迟，与基于云的解决方案相反，它允许时间敏感型边缘应用所需的5毫秒至30毫秒范围内的延迟值。",
                    "title_zh": "Omega:面向边缘的安全事件订购服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00063",
                    "title": "Trust Management as a Service: Enabling Trusted Execution in the Face of Byzantine Stakeholders",
                    "authors": "Franz Gregor, Wojciech Ozga, Sébastien Vaucher, Rafael Pires, Do Le Quoc, Sergei Arnautov, André Martin, Valerio Schiavoni, Pascal Felber, Christof Fetzer",
                    "abstract": "Trust is arguably the most important challenge for critical services both deployed as well as accessed remotely over the network. These systems are exposed to a wide diversity of threats, ranging from bugs to exploits, active attacks, rogue operators, or simply careless administrators. To protect such applications, one needs to guarantee that they are properly configured and securely provisioned with the \"secrets\" (e.g., encryption keys) necessary to preserve not only the confidentiality, integrity and freshness of their data but also their code. Furthermore, these secrets should not be kept under the control of a single stakeholder—which might be compromised and would represent a single point of failure—and they must be protected across software versions in the sense that attackers cannot get access to them via malicious updates. Traditional approaches for solving these challenges often use ad hoc techniques and ultimately rely on a hardware security module (HSM) as root of trust. We propose a more powerful and generic approach to trust management that instead relies on trusted execution environments (TEEs) and a set of stakeholders as root of trust. Our system, PALÆMON, can operate as a managed service deployed in an untrusted environment, i.e., one can delegate its operations to an untrusted cloud provider with the guarantee that data will remain confidential despite not trusting any individual human (even with root access) nor system software. PALÆMON addresses in a secure, efficient and cost-effective way five main challenges faced when developing trusted networked applications and services. Our evaluation on a range of benchmarks and real applications shows that PALÆMON performs efficiently and can protect secrets of services without any change to their source code.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2003.14099"
                    },
                    "abstract_zh": "信任可以说是部署和通过网络远程访问的关键服务的最大挑战。这些系统面临着各种各样的威胁，从漏洞到利用，主动攻击，流氓操作员，或者只是粗心的管理员。为了保护这样的应用程序，需要保证它们被适当地配置并且安全地提供有“秘密”(例如，加密密钥)，该“秘密”不仅是保护它们的数据的机密性、完整性和新鲜度所必需的，而且是保护它们的代码所必需的。此外，这些秘密不应该由单个利益相关者控制，这可能会受到损害并代表单点故障，而且它们必须在软件版本之间得到保护，也就是说，攻击者不能通过恶意更新来访问它们。解决这些挑战的传统方法通常使用特定技术，并最终依赖硬件安全模块(HSM)作为信任根。我们提出了一种更强大、更通用的信任管理方法，它依赖可信执行环境(TEEs)和一组利益相关者作为信任的根。我们的系统palmon可以作为部署在不受信任的环境中的托管服务运行，也就是说，用户可以将其操作委托给不受信任的云提供商，尽管不信任任何个人(即使有root访问权限)也不信任系统软件，也能保证数据的机密性。palmon以安全、高效和经济的方式解决了开发可信网络应用和服务时面临的五大挑战。我们对一系列基准测试和实际应用的评估表明，palmon运行高效，能够保护服务的秘密，而无需对其源代码进行任何更改。",
                    "title_zh": "信任管理即服务:面对错综复杂的利益相关者实现可信执行"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00064",
                    "title": "UPA: An Automated, Accurate and Efficient Differentially Private Big-Data Mining System",
                    "authors": "Tsz On Li, Jianyu Jiang, Ji Qi, Chi Chiu So, Jiacheng Ma, Xusheng Chen, Tianxiang Shen, Heming Cui, Yuexuan Wang, Peng Wang",
                    "abstract": "In the era of big-data, individuals and institutions store their sensitive data on clouds, and these data are often analyzed and computed by MapReduce frameworks (e.g., Spark). However, releasing the computation result on these data may leak privacy. Differential Privacy (DP) is a powerful method to preserve the privacy of an individual data record from a computation result. Given an input dataset and a query, DP typically perturbs an output value with noise proportional to sensitivity, the greatest change on an output value when a record is added to or removed from the input dataset. Unfortunately, directly computing the sensitivity value for a query and an input dataset is computationally infeasible, because it requires adding or removing every record from the dataset and repeatedly running the same query on the dataset: a dataset of one million input records requires running the same query for more than one million times. This paper presents UPA, the first automated, accurate, and efficient sensitivity inferring approach for big-data mining applications. Our key observation is that MapReduce operators often have commutative and associative properties in order to enable parallelism and fault tolerance among computers. Therefore, UPA can greatly reduce the repeated computations at runtime while computing a precise sensitivity value automatically for general big-data queries. We compared UPA with FLEX, the most relevant work that does static analysis on queries to infer sensitivity values. Based on an extensive evaluation on nine diverse Spark queries, UPA supports all the nine evaluated queries, while FLEX supports only five of the nine queries. For the five queries which both UPA and FLEX can support, UPA enforces DP with five orders of magnitude more accurate sensitivity values than FLEX. UPA has reasonable performance overhead compared to native Spark. UPA's source code is available on https://github.com/hku-systems/UPA.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在大数据时代，个人和机构将他们的敏感数据存储在云上，这些数据通常由MapReduce框架(如Spark)进行分析和计算。然而，发布这些数据的计算结果可能会泄露隐私。差分隐私(DP)是从计算结果中保护个人数据记录隐私的强大方法。给定一个输入数据集和一个查询，DP通常会使用与敏感度成比例的噪声干扰输出值，敏感度是在输入数据集中添加或移除记录时输出值的最大变化。不幸的是，直接计算查询和输入数据集的敏感度值在计算上是不可行的，因为这需要添加或移除数据集中的每条记录，并对数据集重复运行相同的查询:包含一百万条输入记录的数据集需要运行相同的查询超过一百万次。本文介绍了UPA，它是第一个用于大数据挖掘应用的自动化、精确和高效的灵敏度推断方法。我们的主要观察结果是，MapReduce操作符通常具有交换和关联属性，以便在计算机之间实现并行性和容错性。因此，UPA可以大大减少运行时的重复计算，同时为一般的大数据查询自动计算精确的敏感度值。我们将UPA与FLEX进行了比较，FLEX是对查询进行静态分析以推断敏感度值的最相关的工作。基于对九个不同Spark查询的广泛评估，UPA支持所有九个评估的查询，而FLEX仅支持九个查询中的五个。对于UPA和FLEX都支持的五个查询，UPA使用比FLEX精确五个数量级的敏感度值来实施DP。与原生Spark相比，UPA具有合理的性能开销。https://github.com/hku-systems/UPA.上有UPA的源代码",
                    "title_zh": "UPA:一个自动、准确、高效的差分私有大数据挖掘系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00065",
                    "title": "Enhancing Reliability-Aware Speedup Modelling via Replication",
                    "authors": "Zaeem Hussain, Taieb Znati, Rami G. Melhem",
                    "abstract": "Reliability-aware speedup models study the expected speedup of a parallel application as a function of the number of processors, on a platform susceptible to processor failures. Existing works in this area have developed models using checkpoint-restart (without replication) as the only fault tolerance mechanism, and have studied the upper bound on the number of processors beyond which the application speedup starts to degrade due to increasing likelihood of failure. In this work, we develop speedup models in which replication, specifically dual replication, is also employed for resilience. We demonstrate that the upper bound on the number of processors to execute a perfectly parallel application using dual replication is of the order λ^-^2 where λ is the individual processor failure rate. We also compare the dual replication model with that of no-replication. Specifically, we found that, given the same hardware resources, replication starts offering better speedup just before the upper bound on the number of processors for no-replication is reached. Taken together, our results indicate that replication can significantly enhance reliability-aware speedup models by i) pushing the number of processors that yield the optimal speedup to a much higher value than what is possible without replication, and ii) improving on the optimal speedup possible through checkpoint-restart alone.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可靠性感知加速模型研究在易受处理器故障影响的平台上，并行应用程序的预期加速与处理器数量的函数关系。该领域中的现有工作已经开发了使用检查点重启(无复制)作为唯一容错机制的模型，并且已经研究了处理器数量的上限，超过该上限，由于故障的可能性增加，应用加速开始降级。在这项工作中，我们开发了加速模型，其中复制，特别是双复制，也被用于恢复。我们证明了使用双复制来执行完美并行应用的处理器数量上限是λ^-^2量级的，其中λ是单个处理器的故障率。我们还比较了双复制模型和无复制模型。具体来说，我们发现，在给定相同硬件资源的情况下，就在达到非复制处理器数量的上限之前，复制开始提供更好的加速。综上所述，我们的结果表明，复制可以通过以下方式显著增强可靠性感知加速模型:I)将产生最佳加速的处理器数量提高到比没有复制时高得多的值，以及ii)仅通过检查点重启来提高最佳加速。",
                    "title_zh": "通过复制增强可靠性感知加速建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00066",
                    "title": "Service-Based Resilience for Embedded IoT Networks",
                    "authors": "Doganalp Ergenc, Jacek Rak, Mathias Fischer",
                    "abstract": "Embedded IoT networks are the backbone of safety-critical systems like smart factories, autonomous vehicles, and airplanes. Therefore, resilience against failures and attacks should be a prior concern already in their design stage. In this study, we introduce a service-based network model as an MILP optimization problem for the efficient deployment of a service overlay to the embedded network by meeting QoS and resilience requirements. We show the complexity and boundaries of the problem and propose several heuristics to relax the service deployment phase and increase the fault-tolerance against node and link failures. Our results indicate that the heuristics achieve results close to the optimum for small sizes of the problem with up to 10^8 time faster solution time. We also show that the heuristics can solve larger problem sizes and can maintain the service availability for 85% of all potential single node failures.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "嵌入式物联网网络是智能工厂、自动驾驶汽车和飞机等安全关键系统的支柱。因此，在设计阶段，对故障和攻击的恢复能力就应该是优先考虑的问题。在这项研究中，我们引入了一个基于服务的网络模型作为MILP优化问题，通过满足QoS和弹性要求来有效地将服务覆盖部署到嵌入式网络。我们展示了问题的复杂性和边界，并提出了几种启发式方法来放松服务部署阶段，并增加对节点和链路故障的容错能力。我们的结果表明，对于小规模的问题，启发式算法可以获得接近最优的结果，并具有高达10^8时间的更快的求解时间。我们还表明，启发式算法可以解决更大规模的问题，并可以在85%的潜在单节点故障下保持服务可用性。",
                    "title_zh": "嵌入式物联网网络基于服务的弹性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00067",
                    "title": "Mining Multivariate Discrete Event Sequences for Knowledge Discovery and Anomaly Detection",
                    "authors": "Bin Nie, Jianwu Xu, Jacob Alter, Haifeng Chen, Evgenia Smirni",
                    "abstract": "Modern physical systems deploy large numbers of sensors to record at different time-stamps the status of different systems components via measurements such as temperature, pressure, speed, but also the component's categorical state. Depending on the measurement values, there are two kinds of sequences: continuous and discrete. For continuous sequences, there is a host of state-of-the-art algorithms for anomaly detection based on time-series analysis, but there is a lack of effective methodologies that are tailored specifically to discrete event sequences. This paper proposes an analytics framework for discrete event sequences for knowledge discovery and anomaly detection. During the training phase, the framework extracts pairwise relationships among discrete event sequences using a neural machine translation model by viewing each discrete event sequence as a \"natural language\". The relationship between sequences is quantified by how well one discrete event sequence is \"translated\" into another sequence. These pairwise relationships among sequences are aggregated into a multivariate relationship graph that clusters the structural knowledge of the underlying system and essentially discovers the hidden relationships among discrete sequences. This graph quantifies system behavior during normal operation. During testing, if one or more pairwise relationships are violated, an anomaly is detected. The proposed framework is evaluated on two real-world datasets: a proprietary dataset collected from a physical plant where it is shown to be effective in extracting sensor pairwise relationships for knowledge discovery and anomaly detection, and a public hard disk drive dataset where its ability to effectively predict upcoming disk failures is illustrated.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代物理系统部署了大量传感器，通过测量温度、压力、速度以及组件的分类状态，在不同的时间戳记录不同系统组件的状态。根据测量值的不同，有两种序列:连续序列和离散序列。对于连续序列，有许多基于时间序列分析的异常检测算法，但缺乏专门针对离散事件序列的有效方法。本文提出了一个用于知识发现和异常检测的离散事件序列分析框架。在训练阶段，该框架通过将每个离散事件序列视为“自然语言”，使用神经机器翻译模型来提取离散事件序列之间的成对关系。序列之间的关系通过一个离散事件序列被“翻译”成另一个序列的程度来量化。序列之间的这些成对关系被聚集到多元关系图中，该多元关系图聚集了基础系统的结构知识，并且本质上发现了离散序列之间的隐藏关系。该图量化了正常运行期间的系统行为。在测试过程中，如果违反了一个或多个成对关系，就会检测到异常。在两个真实世界的数据集上对所提出的框架进行了评估:从物理工厂收集的专有数据集，在该物理工厂中，它被证明在提取用于知识发现和异常检测的传感器成对关系方面是有效的；以及公共硬盘驱动器数据集，在该公共硬盘驱动器数据集中，其有效预测即将到来的磁盘故障的能力被示出。",
                    "title_zh": "挖掘多元离散事件序列用于知识发现和异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48063.2020.00068",
                    "title": "Learning to Reliably Deliver Streaming Data with Apache Kafka",
                    "authors": "Han Wu, Zhihao Shang, Katinka Wolter",
                    "abstract": "The rise of streaming data processing is driven by mass deployment of sensors, the increasing popularity of mobile devices, and the rapid growth of online financial trading. Apache Kafka is often used as a real-time messaging system for many stream processors. However, efficiently running Kafka as a reliable data source is challenging, especially in the case of real-time processing with unstable network connection. We find that changing configuration parameters can significantly impact the guarantee of message delivery in Kafka. Therefore the key to solving the above problem is to predict the reliability of Kafka given various configurations and network conditions. We define two reliability metrics to be predicted, the probability of message loss and the probability of message duplication. Artificial neural networks (ANN) are applied in our prediction model and we select some key parameters, as well as network metrics as the features. To collect sufficient training data for our model we build a Kafka testbed based on Docker containers. With the neural network model we can predict Kafka's reliability for different application scenarios given various network environments. Combining with other metrics that a streaming application user may care for, a weighted key performance indicator (KPI) of Kafka is proposed for selecting proper configuration parameters. In the experiments we propose a rough dynamic configuration scheme, which significantly improves the reliability while guaranteeing message timeliness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传感器的大规模部署、移动设备的日益普及以及在线金融交易的快速增长推动了流数据处理的兴起。Apache Kafka经常被用作许多流处理器的实时消息传递系统。然而，高效地运行Kafka作为可靠的数据源是具有挑战性的，尤其是在网络连接不稳定的实时处理的情况下。我们发现改变配置参数会显著影响Kafka中消息传递的保证。因此，解决上述问题的关键是在给定各种配置和网络条件下预测Kafka的可靠性。我们定义了两个要预测的可靠性度量，消息丢失的概率和消息重复的概率。人工神经网络(ANN)应用于我们的预测模型，我们选择了一些关键参数，以及网络度量作为特征。为了为我们的模型收集足够的训练数据，我们基于Docker容器构建了一个Kafka测试床。通过神经网络模型，我们可以预测Kafka在各种网络环境下不同应用场景的可靠性。结合流媒体应用用户可能关心的其他指标，提出了Kafka的加权关键绩效指标(KPI)来选择合适的配置参数。在实验中，我们提出了一个粗略的动态配置方案，在保证消息及时性的同时显著提高了可靠性。",
                    "title_zh": "学习使用Apache Kafka可靠地传送流数据"
                }
            ]
        }
    ],
    "2021": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2021w.html",
            "conf_title": "51st DSN 2021: Taipei, Taiwan - Workshops",
            "conf_url": "https://doi.org/10.1109/DSN-W52860.2021",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00006",
                    "title": "Third International Workshop on Data-Centric Dependability and Security (DCDS)",
                    "authors": "Ibéria Medeiros, Ilir Gashi, Michael Kamp, Pedro Ferreira",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9502413/9502428/09502460.pdf"
                    },
                    "abstract_zh": "",
                    "title_zh": "第三届以数据为中心的可靠性和安全性国际研讨会(DCDS)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00007",
                    "title": "7th International Workshop on Safety and Security of Intelligent Vehicles - SSIV 2021",
                    "authors": "Michaël Lauer, Kalinka Branco, João Carlos Cunha",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9502413/9502428/09502462.pdf"
                    },
                    "abstract_zh": "",
                    "title_zh": "第七届智能车辆安全国际研讨会- SSIV 2021"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00008",
                    "title": "International Workshop On Application of Intelligent Technology in Security - AITS 2021",
                    "authors": "Xiaofeng Lu, Pietro Liò",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9502413/9502428/09502449.pdf"
                    },
                    "abstract_zh": "",
                    "title_zh": "智能技术在安全领域的应用国际研讨会- AITS 2021"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00009",
                    "title": "Fourth International Workshop on Dependable and Secure Machine Learning - DSML 2021",
                    "authors": "Hui Xu, Guanpeng Li, Homa Alemzadeh, Rakesh Bobba, Varun Chandrasekaran, David E. Evans, Nicolas Papernot, Karthik Pattabiraman, Florian Tramèr",
                    "abstract": "On behalf of the Organizing Committee, it is our pleasure to welcome you to the fourth International Workshop on Dependable and Secure Machine Learning (DSML). This year, due to the COVID-19 situation, the DSML workshop will be held online, in conjunction with the 51th IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) on Monday, 21 June 2021. © 2021 IEEE.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9502413/9502428/09502432.pdf"
                    },
                    "abstract_zh": "代表组委会，我们很高兴欢迎你参加第四届可靠和安全机器学习国际研讨会(DSML)。今年，由于新冠肺炎的形势，DSML研讨会将于2021年6月21日(星期一)与第51届IEEE/IFIP可靠系统和网络国际会议(DSN)同时在线举行。2021年IEEE。",
                    "title_zh": "第四届可靠和安全机器学习国际研讨会- DSML 2021"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00010",
                    "title": "Workshop on Safer Autonomous Systems: Special theme: safety-aware design and validation of autonomous systems",
                    "authors": "Hélène Waeselynck, Raul Sena Ferreira, Luca Vittorio Sartori",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/9502413/9502428/09502430.pdf"
                    },
                    "abstract_zh": "",
                    "title_zh": "更安全的自主系统研讨会:特别主题:自主系统的安全意识设计和验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00012",
                    "title": "USB-IDS-1: a Public Multilayer Dataset of Labeled Network Flows for IDS Evaluation",
                    "authors": "Marta Catillo, Andrea Del Vecchio, Luciano Ocone, Antonio Pecchia, Umberto Villano",
                    "abstract": "The scarceness of publicly available data from real-life operational networks is a long-standing problem for the security research community. Many public intrusion detection datasets have spread in the literature; however, they may lack relevant details concerning the victim servers and applications. This paper describes USB-IDS-1, a novel public intrusion detection dataset developed at the University of Sannio at Benevento, Italy. The dataset considers both network traffic and application-level facets, such as performance measurements, configuration and defense modules of the victim server under attack. The paper describes the collection environment, provides key insights into traffic data and demonstrates the impact of the attacks adopted against the server in hand.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "来自真实操作网络的公开可用数据的缺乏是安全研究社区的一个长期问题。许多公共入侵检测数据集已经在文献中传播；但是，它们可能缺少受害者服务器和应用程序的相关详细信息。本文描述了USB-IDS-1，这是一种新型的公共入侵检测数据集，由意大利贝内文托的Sannio大学开发。该数据集考虑了网络流量和应用程序级别的方面，如受攻击的受害服务器的性能测量、配置和防御模块。该白皮书描述了收集环境，提供了对流量数据的关键见解，并展示了针对现有服务器采取的攻击的影响。",
                    "title_zh": "USB-IDS-1:一个用于IDS评估的公共多层网络流数据集"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00013",
                    "title": "SMS Goes Nuclear: Fortifying SMS-Based MFA in Online Account Ecosystem",
                    "authors": "Weizhao Jin, Xiaoyu Ji, Ruiwen He, Zhou Zhuang, Wenyuan Xu, Yuan Tian",
                    "abstract": "With the rapid growth of online services, the number of online accounts proliferates. The security of a single user account no longer depends merely on its own service provider but also the accounts on other service platforms (We refer to this online account environment as Online Account Ecosystem). In this paper, we first uncover the vulnerability of Online Account Ecosystem, which stems from the defective multi-factor authentication (MFA), specifically the ones with SMS-based verification, and dependencies among accounts on different platforms. We propose Chain Reaction Attack that exploits the weakest point in Online Account Ecosystem and can ultimately compromise the most secure platform. Furthermore, we design and implement ActFort, a systematic approach to detect the vulnerability of Online Account Ecosystem by analyzing the authentication credential factors and sensitive personal information as well as evaluating the dependency relationships among online accounts. We evaluate our system on hundreds of representative online services listed in Alexa in diversified fields. Based on the analysis from ActFort, we provide several pragmatic insights into the current Online Account Ecosystem and propose several feasible countermeasures including the online account exposed information protection mechanism and the built-in authentication to fortify the security of Online Account Ecosystem.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.08651"
                    },
                    "abstract_zh": "随着在线服务的快速增长，在线账户的数量激增。单个用户账户的安全性不再仅仅取决于其自身的服务提供商，还取决于其他服务平台上的账户(我们将这种在线账户环境称为在线账户生态系统)。在本文中，我们首先揭示了在线帐户生态系统的脆弱性，这种脆弱性源于有缺陷的多因素身份认证(MFA)，特别是基于SMS的验证，以及不同平台上帐户之间的依赖性。我们建议进行连锁反应攻击，利用在线帐户生态系统中最薄弱的环节，最终危及最安全的平台。此外，我们设计并实现了ActFort，这是一种通过分析身份认证证书因素和敏感个人信息以及评估在线帐户之间的依赖关系来检测在线帐户生态系统漏洞的系统方法。我们在Alexa中列出的数百个不同领域的代表性在线服务上评估我们的系统。基于ActFort的分析，我们对当前的在线账户生态系统提供了一些实用的见解，并提出了一些可行的对策，包括在线账户暴露信息保护机制和内置认证，以加强在线账户生态系统的安全性。",
                    "title_zh": "短信核化:加强在线账户生态系统中基于短信的MFA"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00014",
                    "title": "Statistical Approach For Cloud Security: Microsoft Office 365 audit logs case study",
                    "authors": "Louis-Simon Létourneau, Chaymae El Jabri, Marc Frappier, Pierre-Martin Tardif, Guy Lépine, Guillaume Boisvert",
                    "abstract": "Detecting abnormal user interaction with a computer system is paramount to prevent unauthorized access. With the growth in the use of cloud services, both from a personal and business perspective, cloud service accounts are a profitable target for cyber attacks. This work is a practical attempt to improve SaaS security through accessible and adaptable solutions. We used kernel density estimation in order to classify events from Microsoft audit logs. We were able to model the active hours of each user within an organization and then detect when an action was made outside of these hours.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "检测用户与计算机系统的异常交互对于防止未经授权的访问至关重要。随着云服务使用的增长，从个人和商业角度来看，云服务帐户都是网络攻击的有利可图的目标。这项工作是通过可获得的和适应性强的解决方案来改善SaaS安全的实际尝试。我们使用内核密度估计来对来自微软审计日志的事件进行分类。我们能够对组织内每个用户的活动时间进行建模，然后检测在这些时间之外何时进行了操作。",
                    "title_zh": "云安全的统计方法:Microsoft Office 365审计日志案例研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00015",
                    "title": "Vehicular Platoon Communication: Cybersecurity Threats and Open Challenges",
                    "authors": "Sean Joe Taylor, Farhan Ahmad, Hoang Nga Nguyen, Siraj Ahmed Shaikh, David Evans, David Price",
                    "abstract": "Vehicular platooning is an emerging technology that promises to save space on congested roadways, improve safety and utilise less fuel for transporting goods, reducing greenhouse gas emissions. This technology will draw the attention of attackers seeking to profit or prove themselves to their peers by disrupting the platoons. A platoon has several attack surfaces that attackers can exploit to achieve their goals (either personal or financial). This paper aims to discuss various attacks that the attackers can launch against platoons by exploiting wireless communication weaknesses. Furthermore, we will present different known strategies which are currently used to defend platoons from attackers. This paper’s primary contribution we believe will help new researchers in this domain, as well as automotive industries and smart cities planners.",
                    "files": {
                        "openAccessPdf": "https://pure.coventry.ac.uk/ws/files/52679649/Taylor_et_al_Vehicular_Platoon_Communication.pdf"
                    },
                    "abstract_zh": "车辆排队是一项新兴技术，有望节省拥挤道路上的空间，提高安全性，减少运输货物所需的燃料，减少温室气体排放。这项技术将吸引攻击者的注意力，他们试图通过扰乱队列来获利或向同伴证明自己。一个排有几个攻击面，攻击者可以利用这些攻击面来实现他们的目标(个人目标或财务目标)。本文旨在讨论攻击者利用无线通信的弱点对部队发动的各种攻击。此外，我们将提出不同的已知策略，目前用于保护排从攻击者。我们相信，这篇论文的主要贡献将有助于该领域的新研究人员，以及汽车行业和智能城市规划者。",
                    "title_zh": "车辆编队通信:网络安全威胁和公开挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00016",
                    "title": "SaSeVAL: A Safety/Security-Aware Approach for Validation of Safety-Critical Systems",
                    "authors": "Christian Wolschke, Behrooz Sangchoolie, Jacob Simon, Stefan Marksteiner, Tobias Braun, Hayk Hamazaryan",
                    "abstract": "Increasing communication and self-driving capabilities for road vehicles lead to threats which could potentially be exploited by attackers. Especially attacks leading to safety violations have to be identified to address them by appropriate measures. The impact of an attack depends on the threat exploited, potential countermeasures and the traffic situation. In order to identify such attacks and to use them for testing, we propose the systematic approach SaSeVAL for deriving attacks of autonomous vehicles.SaSeVAL is based on threats identification and safety-security analysis. The impact of automotive use cases to attacks is considered. The threat identification considers the attack interface of vehicles and classifies threat scenarios according to threat types, which are then mapped to attack types. The safety-security analysis identifies the necessary requirements which have to be tested based on the architecture of the system under test. It determines which safety impact a security violation may have, and in which traffic situations the highest impact is expected. Finally, the results of threat identification and safety-security analysis are used to describe attacks.The goal of SaSeVAL is to achieve safety validation of the vehicle w.r.t. security concerns. It traces safety goals to threats and to attacks explicitly. Hence, the coverage of safety concerns by security testing is assured. Two use cases of vehicle communication and autonomous driving are investigated to prove the applicability of the approach.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2106.13499"
                    },
                    "abstract_zh": "道路车辆日益增长的通信和自动驾驶能力导致了可能被攻击者利用的威胁。特别是导致违反安全的攻击必须被识别，以便通过适当的措施来解决它们。攻击的影响取决于所利用的威胁、潜在的对策和流量情况。为了识别这种攻击并使用它们进行测试，我们提出了一种系统化的方法SaSeVAL，用于推导自主车辆的攻击。SaSeVAL基于威胁识别和安全保障分析。考虑汽车用例对攻击的影响。威胁识别考虑车辆的攻击接口，并根据威胁类型对威胁场景进行分类，然后映射到攻击类型。安全性分析确定了必须根据被测系统的体系结构进行测试的必要需求。它决定了安全违规可能产生的安全影响，以及在何种交通情况下预期会产生最大的影响。最后，威胁识别和安全性分析的结果用于描述攻击。SaSeVAL的目标是实现车辆w.r.t .安全问题的安全验证。它明确地将安全目标追溯到威胁和攻击。因此，安全测试对安全问题的覆盖是有保证的。通过对车辆通信和自动驾驶两个用例的研究，证明了该方法的适用性。",
                    "title_zh": "SaSeVAL:一种用于验证安全关键系统的安全/安保感知方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00017",
                    "title": "Suraksha: A Quantitative AV Safety Evaluation Framework to Analyze Safety Implications of Perception Design Choices",
                    "authors": "Hengyu Zhao, Siva Kumar Sastry Hari, Timothy Tsai, Michael B. Sullivan, Stephen W. Keckler, Jishen Zhao",
                    "abstract": "This paper proposes an automated AV safety evaluation framework, Suraksha that quantifies and analyzes the sensitivities of different design parameters on AV safety. It employs a set of driving scenarios generated based on a user-specified difficulty level. It enables the exploration of tradeoffs in requirements either in existing AV implementations to find opportunities for improvement or during the development process to explore the component-level requirements for an optimal and safe AV architecture. As perception is a resource demanding task, we employ Suraksha to analyze the safety effects of using various perception parameters on an industrial AV system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了一个自动化的AV安全性评估框架，Suraksha，该框架量化和分析了不同设计参数对AV安全性的敏感性。它采用了一套基于用户指定的难度级别生成的驾驶场景。它支持探索现有AV实现中的需求权衡，以找到改进的机会，或者在开发过程中探索最佳和安全AV架构的组件级需求。由于感知是一项资源要求很高的任务，我们采用Suraksha来分析在工业AV系统中使用各种感知参数的安全效果。",
                    "title_zh": "Suraksha:一个定量的AV安全评估框架，用于分析感知设计选择的安全含义"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00018",
                    "title": "Evaluation of a Fail-Over Mechanism for 1oo2D Architectures in Highly-Automated Driving",
                    "authors": "Rupert Schorn, Wilfried Steiner",
                    "abstract": "While self-driving cars show remarkable progress in their autonomy capabilities, they are still lacking a necessary and sufficient level of dependability. As a consequence, todays self-driving cars require a human operator to monitor the car for potential safety violations and to take over control in critical situations. The challenges on the way to a truly dependable and trustworthy self-driving car are manifold. One of the challenges is the design of an appropriate fault-tolerant architecture. In this paper we investigate the 1-out-of-2 with Diagnostics (1oo2D) architecture paradigm for highly-automated driving and study the fail-over mechanism in detail. We present an implementation based on industrial techniques and technologies and evaluation results of fault-injection studies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然自动驾驶汽车在自主能力方面取得了显著进步，但它们仍然缺乏必要和足够的可靠性。因此，今天的自动驾驶汽车需要人类操作员来监控汽车的潜在安全违规行为，并在危急情况下接管控制权。在通往真正可靠和值得信赖的自动驾驶汽车的道路上，挑战是多方面的。挑战之一是设计适当的容错架构。在本文中，我们研究了用于高度自动驾驶的1-out-of-2 with Diagnostics(1oo 2d)架构范例，并详细研究了故障转移机制。我们提出了一个基于工业技术和技术的实现和故障注入研究的评估结果。",
                    "title_zh": "高度自动驾驶中1oo2D架构故障转移机制的评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00019",
                    "title": "Safety Verification of Neural Network Controlled Systems",
                    "authors": "Arthur Clavière, Eric Asselin, Christophe Garion, Claire Pagetti",
                    "abstract": "In this paper, we propose a system-level approach for verifying the safety of systems combining a continuous-time physical system with a discrete-time neural network based controller. We define a generic modelling approach and an associated reachability analysis that soundly approximates the reachable states of the overall system. We illustrate our approach through a real-world use case.",
                    "files": {
                        "openAccessPdf": "https://oatao.univ-toulouse.fr/28559/1/Claviere_28559..pdf"
                    },
                    "abstract_zh": "在本文中，我们提出了一种系统级的方法来验证系统的安全性，该方法将连续时间物理系统与基于离散时间神经网络的控制器相结合。我们定义了一个通用的建模方法和一个相关的可达性分析，它非常接近整个系统的可达状态。我们通过一个真实的用例来说明我们的方法。",
                    "title_zh": "神经网络控制系统的安全性验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00020",
                    "title": "Certifying Emergency Landing for Safe Urban UAV",
                    "authors": "Joris Guérin, Kevin Delmas, Jérémie Guiochet",
                    "abstract": "Unmanned Aerial Vehicles (UAVs) have the potential to be used for many applications in urban environments. However, allowing UAVs to fly above densely populated areas raises concerns regarding safety. One of the main safety issues is the possibility for a failure to cause the loss of navigation capabilities, which can result in the UAV falling/landing in hazardous areas such as busy roads, where it can cause fatal accidents. Current standards, such as the SORA published in 2019, do not consider applicable mitigation techniques to handle this kind of hazardous situations. Consequently, certifying UAV urban operations implies to demonstrate very high levels of integrity, which results in prohibitive development costs. To address this issue, this paper explores the concept of Emergency Landing (EL). A safety analysis is conducted on an urban UAV case study, and requirements are proposed to enable the integration of EL as an acceptable mitigation mean in the SORA. Based on these requirements, an EL implementation was developed, together with a runtime monitoring architecture to enhance confidence in the system. Preliminary qualitative results are presented and the monitor seem to be able to detect errors of the EL system effectively.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.14928"
                    },
                    "abstract_zh": "无人驾驶飞行器(UAV)具有在城市环境中用于许多应用的潜力。然而，允许无人机在人口稠密地区上空飞行引发了对安全的担忧。一个主要的安全问题是故障导致导航能力丧失的可能性，这可能导致无人机坠落/降落在危险区域，如繁忙的道路，在那里它可能导致致命的事故。目前的标准，如2019年发布的SORA，没有考虑适用的缓解技术来处理这种危险情况。因此，认证无人机城市作战意味着证明非常高水平的完整性，这导致了令人望而却步的开发成本。为了解决这个问题，本文探讨了紧急着陆(EL)的概念。对城市无人机案例研究进行了安全分析，并提出了要求，以使EL作为一种可接受的缓解手段纳入SORA。基于这些需求，开发了一个EL实现，以及一个运行时监控架构，以增强对系统的信心。给出了初步的定性结果，并且监视器似乎能够有效地检测EL系统的错误。",
                    "title_zh": "认证安全城市无人机的紧急着陆"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00021",
                    "title": "CyberGSN: A Semi-formal Language for Specifying Safety Cases",
                    "authors": "Tewodros A. Beyene, Carmen Cârlan",
                    "abstract": "The use of safety cases to explicitly present safety considerations and decisions is a common practice in the safety-critical domain. A safety case can be used to scrutinize the safety assessment approach used by practitioners internally, or as an input for the certification process for an external certifying authority. However, safety cases are still created manually to explicate the followed safety assessment and assurance measures. In addition, although safety cases may be created in a modular way by multiple entities, and it may be critical for each entity to digitally sign its part of the assurance for accountability, the common notations are not expressive enough to include the notion of entity. Especially in cyber-security applications, the notion of entity is very critical. In this paper, we propose a formal logic based language called CyberGSN, with an explicit notion of entity, that can be used for specifying safety cases and safety case patterns, enabling the automated creation and maintenance of safety cases.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "使用安全案例明确提出安全考虑和决策是安全关键领域的常见做法。安全案例可用于审查内部从业者使用的安全评估方法，或作为外部认证机构认证过程的输入。然而，安全案例仍然是手工创建的，以阐明随后的安全评估和保证措施。此外，尽管安全案例可以由多个实体以模块化的方式创建，并且对于每个实体来说，对其负责的保证部分进行数字签名可能是至关重要的，但是通用符号的表达能力不足以包括实体的概念。尤其是在网络安全应用中，实体的概念非常关键。在本文中，我们提出了一种基于形式逻辑的语言CyberGSN，它具有明确的实体概念，可用于指定安全案例和安全案例模式，实现安全案例的自动创建和维护。",
                    "title_zh": "CyberGSN:一种描述安全案例的半正式语言"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00022",
                    "title": "A Safety Architecture for Centralized E/E Architectures",
                    "authors": "Victor Bandur, Vera Pantelic, Timofey Tomashevskiy, Mark Lawford",
                    "abstract": "A safety architecture for domain-centralized E/E (Electric and/or Electronic) architectures is proposed to specifically address the scenario where the domain controller of a centralized vehicle domain fails catastrophically. The proposed architecture is based on decentralized control implementing a functional fallback strategy that is distributed over the remaining functioning ECUs in the affected domain. The safety architecture is also applicable to cross-domain E/E architectures.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "提出了一种用于域集中式E/E(电气和/或电子)架构的安全架构，以专门解决集中式车辆域的域控制器发生灾难性故障的情况。所提出的体系结构基于分散控制，实现功能性回退策略，该策略分布在受影响域中的剩余功能ECU上。该安全架构也适用于跨域的E/E架构。",
                    "title_zh": "集中式E/E架构的安全架构"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00023",
                    "title": "Ant Hole: Data Poisoning Attack Breaking out the Boundary of Face Cluster",
                    "authors": "Zhiqiu Huang, Yuqing Zhang, Wengjie Wang, Haitao He",
                    "abstract": "With the continuous improvement of the open ability of machine learning, more and more users are benefited. Therefore, the impact on its security also expands. However, most of the research on the security of machine learning focuses on supervised learning, while the security of unsupervised learning has not been paid enough attention. In this paper, we propose a data poisoning attack method aimed at the face clustering open source project. We innovatively propose a fusion iterative method. It can smoothly generate a series of fusion face images which will fool the clustering algorithm.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着机器学习开放能力的不断提高，越来越多的用户从中受益。因此，对其安全性的影响也随之扩大。然而，对机器学习安全性的研究大多集中在有监督学习上，而无监督学习的安全性还没有得到足够的重视。本文提出了一种针对人脸聚类开源项目的数据中毒攻击方法。创新性地提出了一种融合迭代方法。它可以平滑地生成一系列融合的人脸图像来欺骗聚类算法。",
                    "title_zh": "蚂蚁洞:突破面群边界的数据中毒攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00024",
                    "title": "Authenticating Mobile Wireless Device Through Per-packet Channel State Information",
                    "authors": "Bing Chen, Yubo Song, Zhenchao Zhu, Shang Gao, Junbo Wang, Aiqun Hu",
                    "abstract": "Non-cryptographic mobile wireless device authentication based on channel signature has aroused extensive attention. This technology uses the mobile device’s physical characteristics to mark and verify its identity, and can be used to detect impersonation attacks and information forgery attacks. Channel State Information (CSI) has been used to generate fine-grained channel signatures. However, there are two sticking points in using CSI-based signature for authentication in association phase. The first is that the channel state will change as the device moves, which means that the local authenticator should be updated in real time to adapts to the latest channel state. The second is that the time complexity of authentication should be small enough to do packet-level authentication in association phase and detect attackers in time. In this paper, we propose a CSI-based authentication scheme, which can authenticate mobile devices at the packet level. Further, we provide an packet-level authentication framework based on neural networks. It uses a simple real-time authenticator update method to keep the authenticator valid. What’s more, an ensemble of small-scale autoencoders are used to build the authenticator. It has been shown to significantly reduce the authentication’s time complexity while maintaining the accuracy, providing the possibility for packet-level authentication. The evaluation shows that the packet-level framework can authenticate legitimate mobile devices with 95.19% accuracy and filter out attackers with even greater accuracy, which has higher time efficiency than traditional large-scale neural networks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于信道签名的非密码移动无线设备认证引起了广泛关注。这项技术使用移动设备的物理特征来标记和验证其身份，并可用于检测假冒攻击和信息伪造攻击。信道状态信息(CSI)已被用于生成细粒度的信道签名。然而，在关联阶段使用基于CSI的签名进行认证有两个难点。第一个是信道状态将随着设备移动而改变，这意味着本地认证器应该实时更新以适应最新的信道状态。二是认证的时间复杂度要足够小，在关联阶段做包级认证，及时检测攻击者。在本文中，我们提出了一个基于CSI的认证方案，该方案可以在数据包级别对移动设备进行认证。此外，我们提供了一个基于神经网络的包级认证框架。它使用简单的实时认证器更新方法来保持认证器有效。更重要的是，一套小规模的自动编码器被用来建立认证器。它已经被证明在保持准确性的同时显著降低了认证的时间复杂度，为分组级认证提供了可能性。评测表明，该包级框架能够以95.19%的准确率认证合法的移动设备，并以更高的准确率过滤掉攻击者，比传统的大规模神经网络具有更高的时间效率。",
                    "title_zh": "通过每分组信道状态信息认证移动无线设备"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00025",
                    "title": "Whether the sensitive information statement of the IoT privacy policy is consistent with the actual behavior",
                    "authors": "Xiao Yu, Yiyu Yang, Wengjie Wang, Yuqing Zhang",
                    "abstract": "With the popularization of the Internet of Things(IoT), as the IoT devices carry a large amount of sensitive information, more and more attention is paid to the privacy and security of the IoT. According to legal requirements, vendors are obliged to provide a privacy policy to inform users of their privacy practices and to ensure that actual behavior complies with the published privacy policy. However, we found that the reality is not the case. In this paper, we design an IoT privacy policy consistency detection framework that can automatically extract sensitive information in the request packets sent by IoT apps, and can detect whether the privacy policy declared by the vendor is consistent with the actual collection and sharing behavior. We create a sensitive word list and a sensitive field mapping dictionary in the IoT wearable scene. The sensitive word list contains almost all sensitive words representing sensitive information in the IoT wearable scene. The sensitive field mapping dictionary can realize the IoT wearable in the scenario, the special fields in the data packets sent by the APP to the cloud are mapped to the words in the sensitive word list. We tested 6 IoT platforms, including 9 devices and 14 APPs, and extracted a total of 245 items of sensitive information, of which 57 items of sensitive information were not claimed in their corresponding privacy policies. The test results showed that some representative IoT platforms (e.g. Huawei, Amazfit) have violated their user privacy policies to collect and share actual sensitive information, which prove that the inconsistence between platforms’ privacy statement and actual behaviors is prevalent.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着物联网的普及，由于物联网设备承载着大量的敏感信息，物联网的私密性和安全性越来越受到关注。根据法律要求，供应商有义务提供隐私政策，以告知用户他们的隐私做法，并确保实际行为符合公布的隐私政策。然而，我们发现现实并非如此。本文设计了一个物联网隐私策略一致性检测框架，能够自动提取物联网app发送的请求包中的敏感信息，并能够检测厂商声明的隐私策略是否与实际的收集和分享行为一致。我们在物联网可穿戴场景中创建了敏感词表和敏感场映射字典。敏感词表几乎包含了物联网可穿戴场景中所有代表敏感信息的敏感词。敏感字段映射词典可以实现场景下的物联网穿戴，APP发送到云端的数据包中的特殊字段映射到敏感词表中的词。我们测试了6个物联网平台，包括9个设备和14个app，共提取了245项敏感信息，其中57项敏感信息未在其相应的隐私政策中声明。测试结果显示，一些有代表性的物联网平台(如华为、Amazfit)违反了他们的用户隐私政策来收集和分享实际敏感信息，这证明平台的隐私声明和实际行为之间的不一致是普遍存在的。",
                    "title_zh": "物联网隐私政策的敏感信息声明是否与实际行为一致"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00026",
                    "title": "BBregLocator: A Vulnerability Detection System Based on Bounding Box Regression",
                    "authors": "Junfeng Tian, Junkun Zhang, Fanming Liu",
                    "abstract": "The automatic detection of software vulnerabilities is a very active research area in software security. Existing machine learning-based vulnerability detectors have been able to attain improved detection capabilities, but they face the problem of a coarse detection granularity or low positioning accuracy. In this paper, we introduce the bounding box regression method to vulnerability detection by referring to the methods and ideas in the target detection field. At the same time, combined with the vulnerability detection based on deep learning, we propose and design a fine-grained vulnerability detection system called BBregLocator. The system uses bounding boxes to mark the locations of vulnerabilities, can simultaneously detect and locate vulnerabilities, and improves the accuracy of vulnerability location through bounding box regression. The experimental results show that BBregLocator can effectively improve the vulnerability location accuracy while maintaining low false-positive and false-negative rates.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件漏洞的自动检测是软件安全中一个非常活跃的研究领域。现有的基于机器学习的漏洞检测器已经能够获得改进的检测能力，但是它们面临粗检测粒度或低定位精度的问题。本文借鉴目标检测领域的方法和思想，将包围盒回归方法引入到漏洞检测中。同时，结合基于深度学习的漏洞检测，提出并设计了一个细粒度的漏洞检测系统BBregLocator。该系统使用包围盒标记漏洞位置，可以同时检测和定位漏洞，并通过包围盒回归提高漏洞定位的准确性。实验结果表明，BBregLocator能有效提高漏洞定位的准确率，同时保持较低的误报率和漏报率。",
                    "title_zh": "BBregLocator:基于包围盒回归的漏洞检测系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00027",
                    "title": "Insight into traffic security: A correlation discovery of urban spatial features and traffic flow patterns",
                    "authors": "Juhua Pu, Zhuang Liu, Yue Wang, Xingwu Liu",
                    "abstract": "With the rapid development of urbanization, urban traffic security problems become increasingly prominent, and traffic accidents occur frequently. It is becoming increasingly critical to use data mining methods to solve actual problems in traffic security. But we don’t just rely on the analysis of urban traffic surface operation rules, it is to study the mechanism of traffic operation. Therefore, in this paper, we aim to discover the correlation between spatial features and traffic flow patterns in urban regions to improve traffic security. In order to obtain deeper spatial semantic meanings for every urban region, we propose a spatial feature method based on regional hierarchy, which fuses the hierarchical structure of region and POI (point of interest) information. For traffic flow patterns, we propose a self-representation learning optimization method to find the similarity of region traffic flow. Then, we match the spatial features and flow patterns to discover the correlation of them. Experiments show that our approaches are effective.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着城市化的快速发展，城市交通安全问题日益突出，交通事故频繁发生。利用数据挖掘方法解决交通安全中的实际问题变得越来越重要。但是我们不仅仅依靠对城市交通表面运行规律的分析，而是要研究交通运行的机理。因此，本文旨在发现城市区域空间特征与交通流模式之间的相关性，以提高交通安全性。为了获得每个城市区域更深层次的空间语义，提出了一种基于区域层次的空间特征方法，融合了区域的层次结构和兴趣点信息。对于交通流模式，我们提出了一种自表示学习优化方法来寻找区域交通流的相似性。然后，我们匹配空间特征和流模式以发现它们之间的相关性。实验表明我们的方法是有效的。",
                    "title_zh": "洞察交通安全:城市空间特征与交通流模式的关联发现"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00028",
                    "title": "Automatically Constructing Peer Slices via Semanticand Context-Aware Security Checks in the Linux Kernel",
                    "authors": "Yongzhi Liu, Xiarun Chen, Zhou Yang, Weiping Wen",
                    "abstract": "OS kernels enforce many security checks to validate system states. We observe that paths containing security checks are in fact very informative in inferring critical semantics in OS kernel. In particular, Such slices are valuable for detecting kernel semantic bugs because understanding semantics is typically required by the detection. However, there are few studies that address security checks, and constructing these slices is challenging due to not only a lack of clear criteria but also the large and complex OS. In this paper, combining security checks with program slicing, we first systematically study security check peer slices and propose an automatic approach to construct security check peer slices in OS kernel. Using an inter-procedural, semantic- and context-aware analysis, we can find slices sharing similar semantics in similar contexts. Based on the information offered by security check peer slices, we then introduce the Scenarios for semantic vulnerability detection by security check peer slices: missing security check and inaccurate security check. The evaluation results show that our approach can accurately constructing security check peer slices.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "OS内核执行许多安全检查来验证系统状态。我们观察到，包含安全检查的路径事实上在推断OS内核中的关键语义方面非常有用。特别是，这样的切片对于检测内核语义错误是有价值的，因为理解语义通常是检测所需要的。然而，很少有研究涉及安全检查，构建这些切片具有挑战性，不仅因为缺乏明确的标准，而且因为操作系统庞大而复杂。本文将安全检查与程序切片相结合，首先系统地研究了安全检查对等切片，提出了一种在操作系统内核中自动构造安全检查对等切片的方法。使用过程间、语义和上下文感知分析，我们可以找到在相似上下文中共享相似语义的切片。基于安全检查对等切片提供的信息，我们介绍了安全检查对等切片进行语义漏洞检测的场景:安全检查缺失和安全检查不准确。评估结果表明，该方法能够准确地构造安全检查对等切片。",
                    "title_zh": "在Linux内核中通过语义和上下文感知安全检查自动构建对等切片"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00029",
                    "title": "Detection Algorithm of the Mimicry Attack based on Variational Auto-Encoder",
                    "authors": "Qunke Wang, Lanting Fang, Zhenchao Zhu, Jie Huang",
                    "abstract": "Mimicry attack is a fraud attack in which an attack can forge a legitimate user by imitating a legitimate user’s media access control address or other identity credentials. In this paper, we propose an unsupervised model, namely DAMA, to detect mimicry attack by using the time-series of received signal strength (RSS) to detect the change of the device’s location. The RSS of a device is related to its location, so it is difficult to forge. According to our experimental results, the F1 of DAMA is two times higher than state-of-the-art and the false alarm rate of DAMA is only 18% of state-of-the-art.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "模仿攻击是一种欺诈攻击，攻击者可以通过模仿合法用户的媒体访问控制地址或其他身份凭证来伪造合法用户。本文提出了一种无监督模型，即DAMA，通过接收信号强度(RSS)的时间序列来检测设备位置的变化，从而检测模仿攻击。设备的RSS与其位置有关，因此很难伪造。根据我们的实验结果，DAMA的F1比现有技术高两倍，并且DAMA的虚警率只有现有技术的18%",
                    "title_zh": "基于变分自动编码器的模仿攻击检测算法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00030",
                    "title": "Sensitive Instruction Detection Based on the Context of IoT Sensors",
                    "authors": "Yucheng Wang, Xuejun Li, Peiyang Jia, Yiyu Yang, He Wang",
                    "abstract": "With the development of Internet of Things (IoT) technology and the increasing popularity of smart devices, smart homes’ IoT devices are becoming more and more intelligent. However, with the access of sensor technology and the gradual increase in the number of devices, some security issues will inevitably occur in smart homes, such as ensuring that the instructions currently executed by the device are legal instructions issued by legitimate users. To solve such challenges, we propose a framework for detecting sensitive instructions. At the same time, we collected a large amount of automation strategy data in smart homes. We used machine learning to extract the sensor cooperative work context characteristics during the execution of sensitive instructions. Finally, We used the test set data to verify and evaluate the performance of our framework. Our evaluation results show that for some sensitive instructions, the goal of being able to intercept high-threat instructions actively has been achieved. The accuracy of the attack detection framework model has also reached more than 89.23%, and some devices even exceed 95%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着物联网技术的发展和智能设备的日益普及，智能家居的物联网设备越来越智能化。然而，随着传感器技术的接入和设备数量的逐渐增加，智能家居中不可避免地会出现一些安全问题，比如确保设备当前执行的指令是合法用户发出的合法指令。为了解决这样的挑战，我们提出了一个检测敏感指令的框架。同时，我们收集了智能家居中大量的自动化策略数据。我们使用机器学习来提取敏感指令执行过程中的传感器协同工作上下文特征。最后，我们使用测试集数据来验证和评估我们的框架的性能。我们的评测结果表明，对于一些敏感指令，达到了能够主动拦截高威胁指令的目的。攻击检测框架模型的准确率也达到了89.23%以上，部分设备甚至超过了95%。",
                    "title_zh": "基于物联网传感器上下文的敏感指令检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00031",
                    "title": "Network Intrusion Detection Based on Active Semi-supervised Learning",
                    "authors": "Yong Zhang, Jie Niu, Guojian He, Lin Zhu, Da Guo",
                    "abstract": "With the increasing scale and automation of network attacks, traditional detection methods have been unable to meet the demand for intrusion detection in the current network environment, and we always face with the scarcity of label data in the network environment. In view of this situation, this paper proposes a network intrusion detection algorithm based on active semi-supervised learning, by setting a minimum class-distance threshold for active learning and a highest classification threshold for semi-supervised learning, then selecting unlabeled samples with rich information content, which labeled and added to the training set to retrain the model, and iterating repeatedly until meet the established conditions. The proposed algorithm combines the weak sensitivity of semi-supervised learning to labels and the selectivity of active learning for implicit information. The experimental results on the CTU and CICIDS2017 datasets show that the various indicators of the combined algorithm have been significantly improved.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着网络攻击规模的不断扩大和自动化程度的不断提高，传统的检测方法已经无法满足当前网络环境下的入侵检测需求，并且在网络环境下我们一直面临着标签数据稀缺的问题。针对这种情况，提出了一种基于主动半监督学习的网络入侵检测算法，通过设置主动学习的最小类距离阈值和半监督学习的最高分类阈值，然后选取信息量丰富的未标记样本，将其标记并加入训练集重新训练模型，反复迭代直到满足既定条件。该算法结合了半监督学习对标签的弱敏感性和主动学习对隐含信息的选择性。在CTU和CICIDS2017数据集上的实验结果表明，组合算法的各项指标都得到了显著提高。",
                    "title_zh": "基于主动半监督学习的网络入侵检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00032",
                    "title": "A Statistical Learning Model with Deep Learning Characteristics",
                    "authors": "Lei Liao, Zhiqiu Huang, Wengjie Wang",
                    "abstract": "Although machine learning has achieved great success in many fields, the lack of interpretability and excessive computational amount and poor robustness severely limits its wide application in real-world tasks, especially security-sensitive tasks. But the current deep learning research is still far from truly solving these problems. In order to overcome these problems encountered by the deep learning model, this article does not intend to modify the deep learning model itself, but design a new machine learning model to avoid various problems of deep learning. We proposes a new statistical learning model that learn from the characteristics of deep learning. Then we evaluate these models on two datasets and found that the new model is significantly better than the deep learning model in terms of computational complexity, robustness and interpretability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管机器学习在许多领域取得了巨大的成功，但缺乏可解释性、计算量过大和鲁棒性差等问题严重限制了其在现实任务中的广泛应用，尤其是对安全敏感的任务。但是目前的深度学习研究还远远没有真正解决这些问题。为了克服深度学习模型遇到的这些问题，本文不打算对深度学习模型本身进行修改，而是设计一种新的机器学习模型来避免深度学习的各种问题。我们借鉴深度学习的特点，提出了一种新的统计学习模型。然后我们在两个数据集上评估这些模型，发现新模型在计算复杂度、鲁棒性和可解释性方面明显优于深度学习模型。",
                    "title_zh": "一种具有深度学习特征的统计学习模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00033",
                    "title": "A Queueing Analysis of Multi-model Multi-input Machine Learning Systems",
                    "authors": "Yuta Makino, Tuan Phung-Duc, Fumio Machida",
                    "abstract": "A multi-model multi-input machine learning system (MLS) is an architectural approach to improve the reliability of the MLS output by using multiple models and multiple sensor inputs. While the errors in MLS output can be reduced by redundancy with diversity, the performance overhead/gain caused by the employed architecture may also be concerned in safety-critical applications such as a self-driving car. In this paper, we proposed queueing models for analyzing a multi-model multi-input MLS performance in two architectures, namely a parallel MLS and a shared MLS. The parallel MLS architecture runs two different machine learning models in parallel, while the shared MLS architecture runs a single machine learning model but uses two different sensor inputs. We model the behavior of the parallel MLS by a quasi-birth-death process. On the other hand, we model dynamics of the shared MLS as a continuous-time Markov chain of GI/M/1 type. The numerical experiments on the proposed models show that the parallel MLS generally achieves better throughput performance than the shared MLS under the same parameter settings. We also show that the throughput performance of the shared MLS can be improved when the input data arrival rates are sufficiently high.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "多模型多输入机器学习系统(MLS)是一种通过使用多模型和多传感器输入来提高MLS输出可靠性的架构方法。虽然MLS输出中的误差可以通过具有多样性的冗余来减少，但是在自动驾驶汽车等安全关键型应用中，所采用的架构引起的性能开销/增益也可能受到关注。在本文中，我们提出了用于分析多模型多输入MLS在两种结构中性能的排队模型，即并行MLS和共享MLS。并行MLS架构并行运行两个不同的机器学习模型，而共享MLS架构运行单个机器学习模型，但使用两个不同的传感器输入。我们通过一个准生灭过程来模拟并行MLS的行为。另一方面，我们将共享MLS的动力学建模为GI/M/1类型的连续时间马尔可夫链。对所提出模型的数值实验表明，在相同的参数设置下，并行MLS通常比共享MLS获得更好的吞吐量性能。我们还表明，当输入数据到达率足够高时，共享MLS的吞吐量性能可以得到改善。",
                    "title_zh": "多模型多输入机器学习系统的排队分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00034",
                    "title": "An Approach for Peer-to-Peer Federated Learning",
                    "authors": "Tobias Wink, Zoltán Nochta",
                    "abstract": "We present a novel approach for the collaborative training of neural network models in decentralized federated environments. In the iterative process a group of autonomous peers run multiple training rounds to train a common model. Thereby, participants perform all model training steps locally, such as stochastic gradient descent optimization, using their private, e.g. mission-critical, training datasets. Based on locally updated models, participants can jointly determine a common model by averaging all associated model weights without sharing the actual weight values. For this purpose we introduce a simple n-out-of-n secret sharing schema and an algorithm to calculate average values in a peer-to-peer manner. Our experimental results with deep neural networks on well-known sample datasets prove the generic applicability of the approach, with regard to model quality parameters. Since there is no need to involve a central service provider in model training, the approach can help establish trustworthy collaboration platforms for businesses with high security and data protection requirements.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了一种在分散联邦环境中协作训练神经网络模型的新方法。在迭代过程中，一组自治对等体运行多轮训练来训练公共模型。因此，参与者使用他们的私有(例如关键任务)训练数据集，在本地执行所有模型训练步骤，例如随机梯度下降优化。基于本地更新的模型，参与者可以通过平均所有相关联的模型权重来共同确定公共模型，而无需共享实际权重值。为此，我们引入了一个简单的n取n秘密共享方案和一个以对等方式计算平均值的算法。我们在众所周知的样本数据集上使用深度神经网络的实验结果证明了该方法在模型质量参数方面的一般适用性。由于在模型训练中不需要涉及中央服务提供商，该方法可以帮助为具有高安全性和数据保护要求的企业建立值得信赖的协作平台。",
                    "title_zh": "一种对等联合学习方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00035",
                    "title": "Poisoning Attacks via Generative Adversarial Text to Image Synthesis",
                    "authors": "Keshav Kasichainula, Hadi Mansourifar, Weidong Shi",
                    "abstract": "A poisoning attack is where the adversary can inject a small fraction of poisoning instances into the training data used to train a machine learning model to compromise the performance. Poison attacks can significantly affect the learning process and performance as the model is trained on incorrect data. We have seen many works on data poisoning over the years, but it is limited to few deep learning networks. In this work, we introduce a novel approach by leveraging Generative Adversarial Text to Image Synthesis to create poison attacks against machine learning classifiers. Our approach has three components, which are the generator, discriminator, and the target classifier. We performed an extensive experimental evaluation that proves our attack’s efficiency to compromise machine learning classifiers including deep networks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "中毒攻击是指对手可以将一小部分中毒实例注入到用于训练机器学习模型的训练数据中，从而损害性能。由于模型是在不正确的数据上训练的，毒性攻击会显著影响学习过程和性能。这些年来我们看到了很多关于数据中毒的作品，但是仅限于很少的深度学习网络。在这项工作中，我们介绍了一种新的方法，通过利用生成对立文本的图像合成来创建针对机器学习分类器的毒药攻击。我们的方法有三个组件，即生成器、鉴别器和目标分类器。我们进行了广泛的实验评估，证明了我们的攻击对危害包括深度网络在内的机器学习分类器的效率。",
                    "title_zh": "通过生成性对抗文本对图像合成的中毒攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00036",
                    "title": "Fault-Tolerant Low-Precision DNNs using Explainable AI",
                    "authors": "Muhammad Sabih, Frank Hannig, Jürgen Teich",
                    "abstract": "Hardware-efficient machine learning systems deployed in safety-critical systems need to be optimized for two conflicting objectives. One is making neural networks more compact and efficient by techniques such as quantization and pruning. The other is making them robust against faults. Robustness of Deep Neural Networks (DNNs) becomes a challenge in low-bit precision neural networks such as networks quantized with 8-bit integer precision or less and on custom DNN accelerators with emerging memory technologies and techniques such as approximate memory. Errors in the processing of DNNs can be modeled as bit-flips at the software level. These bit-flips can be caused by persistent memory errors, manifesting themselves in corrupted DNN weights, or they can be caused by transient soft errors.In this work, we introduce an open-source fault-injection framework to simulate both persistent errors and transient errors on PyTorch. Subsequently, we propose novel algorithms that utilize explainable AI methods to make DNNs robust against both kinds, i.e., persistent memory errors and transient soft errors, while keeping the overhead small. We show that our approach can be beneficially used here to mitigate (1) persistent errors by identifying important bits in weights and selectively protecting these using error correcting codes, and (2) transient errors by identifying important samples in activations and selectively protecting these using Triple Modular Redundancy (TMR). Our proposed method outperforms the previously known work on selectively protecting DNN bits in terms of performance and creates further opportunities for research in the area of utilizing explainable AI for robustness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "部署在安全关键系统中的硬件高效的机器学习系统需要针对两个冲突的目标进行优化。一是通过量化和修剪等技术使神经网络更加紧凑和有效。另一个是使它们对故障具有鲁棒性。深度神经网络(DNNs)的鲁棒性在低位精度神经网络中成为一个挑战，例如以8位整数精度或更低精度量化的网络，以及在具有新兴存储器技术和近似存储器等技术的定制DNN加速器上。DNNs处理中的错误可以被建模为软件级的比特翻转。这些比特翻转可以由持续的存储器错误引起，表现为DNN权重被破坏，或者它们可以由瞬时软错误引起。在本文中，我们引入了一个开源的错误注入框架来模拟PyTorch上的持久错误和瞬时错误。随后，我们提出了新的算法，利用可解释的人工智能方法，使DNNs对两种错误都具有鲁棒性，即持久的存储错误和短暂的软错误，同时保持较小的开销。我们表明，我们的方法在这里可以有益地用于减轻(1)通过识别权重中的重要位并使用纠错码选择性地保护这些位的持久错误，以及(2)通过识别激活中的重要样本并使用三模冗余(TMR)选择性地保护这些样本的瞬时错误。我们提出的方法在性能方面优于先前已知的选择性保护DNN位的工作，并为利用可解释人工智能实现鲁棒性的领域的研究创造了进一步的机会。",
                    "title_zh": "基于可解释人工智能的容错低精度DNNs"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00037",
                    "title": "Byzantine Fault-Tolerant Distributed Machine Learning with Norm-Based Comparative Gradient Elimination",
                    "authors": "Nirupam Gupta, Shuo Liu, Nitin H. Vaidya",
                    "abstract": "This paper considers the Byzantine fault-tolerance problem in distributed stochastic gradient descent (D-SGD) method – a popular algorithm for distributed multi-agent machine learning. In this problem, each agent samples data points independently from a certain data-generating distribution. In the fault-free case, the D-SGD method allows all the agents to learn a mathematical model best fitting the data collectively sampled by all agents. We consider the case when a fraction of agents may be Byzantine faulty. Such faulty agents may not follow a prescribed algorithm correctly, and may render traditional D-SGD method ineffective by sharing arbitrary incorrect stochastic gradients. We propose a norm-based gradient-filter, named comparative gradient elimination (CGE), that robustifies the D-SGD method against Byzantine agents. We show that the CGE gradient-filter guarantees fault-tolerance against a bounded fraction of Byzantine agents under standard stochastic assumptions, and is computationally simpler compared to many existing gradient-filters such as multi-KRUM, geometric median-of-means, and the spectral filters. We empirically show, by simulating distributed learning on neural networks, that the fault-tolerance of CGE is comparable to that of existing gradient-filters. We also empirically show that exponential averaging of stochastic gradients improves the fault-tolerance of a generic gradient-filter.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文研究分布式随机梯度下降(D-SGD)方法中的拜占庭容错问题，D-SGD方法是一种流行的分布式多智能体机器学习算法。在这个问题中，每个代理从某个数据生成分布中独立地采样数据点。在无故障情况下，D-SGD方法允许所有代理学习一个数学模型，该模型最适合所有代理集体采样的数据。我们考虑一部分代理可能是拜占庭故障的情况。这种有缺陷的代理可能不正确地遵循规定的算法，并且可能由于共享任意不正确的随机梯度而使传统的D-SGD方法无效。我们提出了一种基于范数的梯度滤波器，命名为比较梯度消除(CGE)，这种方法对拜占庭代理的D-SGD方法是鲁棒的。我们证明，在标准随机假设下，CGE梯度滤波器保证了对有限部分拜占庭代理的容错性，并且与许多现有的梯度滤波器(如多KRUM、几何均值和谱滤波器)相比，计算更简单。通过在神经网络上模拟分布式学习，我们从经验上表明，CGE的容错性与现有的梯度滤波器相当。我们还根据经验表明，随机梯度的指数平均提高了一般梯度滤波器的容错性。",
                    "title_zh": "基于范数的比较梯度消除的拜占庭容错分布式机器学习"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00038",
                    "title": "RADICS: Runtime Assurance of Distributed Intelligent Control Systems",
                    "authors": "Brian Wheatman, Jerry Chen, Tamim Sookoor, Yair Amir",
                    "abstract": "We describe RADICS: Runtime Assurance of Distributed Intelligent Control Systems, which combines a Simplex-based, black-box monitor with a white-box monitor to ensure correct behavior and good performance of AI systems. The black-box monitor allows the system to detect when the AI controller is on a failing trajectory and use a provably safe, but less performant algorithm, to right the system. The white-box monitor predicts when the AI controller will be put on such a trajectory before it happens and helps maximize the performance of the overall system. We describe the overall approach in detail and implement a simple version of it on a case study into controlling the lights in a small traffic grid.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们描述RADICS:分布式智能控制系统的运行时保证，它将基于单纯形的黑盒监视器与白盒监视器相结合，以确保AI系统的正确行为和良好性能。黑盒监视器允许系统检测AI控制器何时处于故障轨迹，并使用可证明安全但性能较差的算法来纠正系统。白盒监视器预测人工智能控制器何时会在它发生之前进入这样的轨迹，并帮助最大限度地提高整个系统的性能。我们详细描述了整个方法，并在一个小型交通网格的交通灯控制案例研究中实现了它的一个简单版本。",
                    "title_zh": "RADICS:分布式智能控制系统的运行时保证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W52860.2021.00039",
                    "title": "Detecting Deep Neural Network Defects with Data Flow Analysis",
                    "authors": "Jiazhen Gu, Huanlin Xu, Haochuan Lu, Yangfan Zhou, Xin Wang",
                    "abstract": "Deep neural networks (DNNs) are shown to be promising solutions in many challenging artificial intelligence tasks, including object recognition, natural language processing, and even unmanned driving. A DNN model, generally based on statistical summarization of in-house training data, aims to predict correct output given an input encountered in the wild. In general, 100% precision is therefore impossible due to its probabilistic nature. For DNN practitioners, it is very hard, if not impossible, to figure out whether the low precision of a DNN model is an inevitable result, or caused by defects such as bad network design or improper training process. This paper aims at addressing this challenging problem. We approach with a careful categorization of the root causes of low precision. We find that the internal data flow footprints of a DNN model can provide insights to locate the root cause effectively. We then develop a tool, namely, DeepMorph (DNN Tomography) to analyze the root cause, which can instantly guide a DNN developer to improve the model. Case studies on four popular datasets show the effectiveness of DeepMorph.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1909.02190"
                    },
                    "abstract_zh": "深度神经网络(DNNs)在许多具有挑战性的人工智能任务中被证明是有前途的解决方案，包括对象识别、自然语言处理，甚至无人驾驶。DNN模型通常基于内部训练数据的统计总结，旨在预测给定在野外遇到的输入的正确输出。一般来说，由于概率性，100%的精度是不可能的。对于DNN的从业者来说，很难(如果不是不可能的话)弄清楚DNN模型的低精度是不可避免的结果，还是由糟糕的网络设计或不当的培训过程等缺陷造成的。本文旨在解决这一具有挑战性的问题。我们对低精度的根本原因进行了仔细的分类。我们发现，DNN模型的内部数据流足迹可以提供有效定位根本原因的洞察力。然后，我们开发了一个工具，即DeepMorph (DNN层析成像)来分析根本原因，它可以立即指导DNN开发人员改进模型。在四个流行数据集上的案例研究表明了DeepMorph的有效性。",
                    "title_zh": "利用数据流分析检测深层神经网络缺陷"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2021.html",
            "conf_title": "51st DSN 2021: Taipei, Taiwan",
            "conf_url": "https://doi.org/10.1109/DSN48987.2021",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00016",
                    "title": "Keynote I: Advances in memory state-preserving fault tolerance",
                    "authors": "Tzi-cker Chiueh",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "",
                    "title_zh": "主题演讲1:内存状态保持容错的进展"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00018",
                    "title": "A Low-cost Fault Corrector for Deep Neural Networks through Range Restriction",
                    "authors": "Zitao Chen, Guanpeng Li, Karthik Pattabiraman",
                    "abstract": "The adoption of deep neural networks (DNNs) in safety-critical domains has engendered serious reliability concerns. A prominent example is hardware transient faults that are growing in frequency due to the progressive technology scaling, and can lead to failures in DNNs. This work proposes Ranger, a low-cost fault corrector, which directly rectifies the faulty output due to transient faults without re-computation. DNNs are inherently resilient to benign faults (which will not cause output corruption), but not to critical faults (which can result in erroneous output). Ranger is an automated transformation to selectively restrict the value ranges in DNNs, which reduces the large deviations caused by critical faults and transforms them to benign faults that can be tolerated by the inherent resilience of the DNNs. Our evaluation on 8 DNNs demonstrates Ranger significantly increases the error resilience of the DNNs (by 3x to 50x), with no loss in accuracy, and with negligible overheads.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2003.13874"
                    },
                    "abstract_zh": "深度神经网络(DNNs)在安全关键领域的采用已经引起了严重的可靠性问题。一个突出的例子是硬件瞬态故障，由于技术的不断发展，其频率越来越高，并可能导致dnn中的故障。本文提出了Ranger，一种低成本的故障校正器，它直接校正由于瞬时故障引起的故障输出，而无需重新计算。dnn对良性故障(不会导致输出损坏)具有固有的弹性，但对严重故障(可能导致错误输出)不具有弹性。Ranger是一种自动转换，用于有选择地限制dnn中的值范围，这减少了由严重故障引起的大偏差，并将它们转换为dnn固有弹性可以容忍的良性故障。我们在8个dnn上的评估表明，Ranger显著提高了dnn的错误恢复能力(3到50倍)，没有损失精度，并且开销可以忽略不计。",
                    "title_zh": "一种通过范围限制的低成本深度神经网络故障校正器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00019",
                    "title": "Toward Intrusion Tolerance as a Service: Confidentiality in Partially Cloud-Based BFT Systems",
                    "authors": "Maher Khan, Amy Babay",
                    "abstract": "Recent work on intrusion-tolerance has shown that resilience to sophisticated network attacks requires system replicas to be deployed across at least three geographically distributed sites. While commodity data centers offer an attractive solution for hosting these sites due to low cost and management overhead, their use raises significant confidentiality concerns: system operators may not want private data or proprietary algorithms exposed to servers outside their direct control. We present a new model for Byzantine Fault Tolerant replicated systems that moves toward “intrusion tolerance as a service”. Under this model, application logic and data are only exposed to servers hosted on the system operator’s premises. Additional offsite servers hosted in data centers can support the needed resilience without executing application logic or accessing unencrypted state. We have implemented this approach in the open-source Spire system, and our evaluation shows that the performance overhead of providing confidentiality can be less than 4% in terms of latency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近在入侵容忍方面的工作表明，对复杂网络攻击的恢复能力需要在至少三个地理上分布的站点上部署系统副本。虽然由于低成本和管理开销，商用数据中心为托管这些站点提供了有吸引力的解决方案，但它们的使用引起了严重的保密问题:系统运营商可能不希望私有数据或专有算法暴露给他们直接控制之外的服务器。我们提出了一种新的拜占庭容错复制系统模型，该模型朝着“入侵容忍即服务”的方向发展。在这种模式下，应用程序逻辑和数据只暴露给系统运营商处所托管的服务器。托管在数据中心的其他异地服务器可以支持所需的弹性，而无需执行应用程序逻辑或访问未加密状态。我们已经在开源Spire系统中实现了这种方法，我们的评估表明，在延迟方面，提供机密性的性能开销可以小于4%。",
                    "title_zh": "将入侵容忍作为一种服务:部分基于云的BFT系统中的保密性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00020",
                    "title": "PID-Piper: Recovering Robotic Vehicles from Physical Attacks",
                    "authors": "Pritam Dash, Guanpeng Li, Zitao Chen, Mehdi Karimibiuki, Karthik Pattabiraman",
                    "abstract": "Robotic Vehicles (RV) rely extensively on sensor inputs to operate autonomously. Physical attacks such as sensor tampering and spoofing can feed erroneous sensor measurements to deviate RVs from their course and result in mission failures. In this paper, we present PID-Piper, a novel framework for automatically recovering RVs from physical attacks. We use machine learning (ML) to design an attack resilient Feed-Forward Controller (FFC), which runs in tandem with the RV’s primary controller and monitors it. Under attacks, the FFC takes over from the RV’s primary controller to recover the RV, and allows the RV to complete its mission successfully. Our evaluation on 6 RV systems including 3 real RVs shows that PID-Piper achieves high accuracy in emulating the RV’s controller, in the absence of attacks, with no false positives. Further, PID-Piper allows RVs to complete their missions successfully despite attacks in 83% of the cases, while incurring low performance overheads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "机器人车辆(RV)广泛依赖于传感器输入来自主操作。传感器篡改和欺骗等物理攻击会导致错误的传感器测量值，从而使遥控潜水器偏离其航线，导致任务失败。在本文中，我们提出了PID-Piper，一种新的框架，自动恢复RVs从物理攻击。我们使用机器学习(ML)来设计一个抗攻击的前馈控制器(FFC)，它与RV的主控制器协同运行并监控它。在受到攻击时，FFC从RV的主控制器接管以恢复RV，并允许RV成功完成其任务。我们对包括3个真实RV在内的6个RV系统的评估表明，PID-Piper在没有攻击的情况下，在仿真RV控制器方面实现了高精度，没有误报。此外，PID-Piper允许RVs成功地完成它们的任务，尽管在83%的情况下受到攻击，同时招致低性能开销。",
                    "title_zh": "PID-Piper:从物理攻击中恢复机器人车辆"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00021",
                    "title": "GARFIELD: System Support for Byzantine Machine Learning (Regular Paper)",
                    "authors": "Rachid Guerraoui, Arsany Guirguis, Jérémy Plassmann, Anton Ragot, Sébastien Rouault",
                    "abstract": "We present GARFIELD, a library to transparently make machine learning (ML) applications, initially built with popular (but fragile) frameworks, e.g., TensorFlow and PyTorch, Byzantine–resilient. GARFIELD relies on a novel object–oriented design, reducing the coding effort, and addressing the vulnerability of the shared–graph architecture followed by classical ML frameworks. GARFIELD encompasses various communication patterns and supports computations on CPUs and GPUs, allowing addressing the general question of the practical cost of Byzantine resilience in ML applications. We report on the usage of GARFIELD on three main ML architectures: (a) a single server with multiple workers, (b) several servers and workers, and (c) peer–to–peer settings. Using GARFIELD, we highlight interesting facts about the cost of Byzantine resilience. In particular, (a) Byzantine resilience, unlike crash resilience, induces an accuracy loss, (b) the throughput overhead comes more from communication than from robust aggregation, and (c) tolerating Byzantine servers costs more than tolerating Byzantine workers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们介绍GARFIELD，一个透明地制作机器学习(ML)应用程序的库，最初是用流行的(但脆弱的)框架构建的，例如TensorFlow和PyTorch，Byzantine-resilient。GARFIELD依赖于一种新颖的面向对象的设计，减少了编码工作，并解决了传统ML框架所遵循的共享图架构的漏洞。GARFIELD包含各种通信模式，并支持CPU和GPU上的计算，允许解决ML应用程序中拜占庭弹性的实际成本的一般问题。我们报告了GARFIELD在三个主要ML架构上的使用情况:(a)一个有多个工作器的服务器，(b)几个服务器和工作器，以及(c)对等设置。借助加菲尔德，我们强调了拜占庭式弹性成本的有趣事实。特别是，(a)拜占庭式弹性，不同于崩溃弹性，会导致准确性损失，(b)吞吐量开销更多地来自通信而不是健壮的聚合，以及(c)容忍拜占庭式服务器的成本比容忍拜占庭式工作人员的成本更高。",
                    "title_zh": "加菲尔德:拜占庭机器学习的系统支持(常规论文)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00022",
                    "title": "Plinius: Secure and Persistent Machine Learning Model Training",
                    "authors": "Peterson Yuhala, Pascal Felber, Valerio Schiavoni, Alain Tchana",
                    "abstract": "With the increasing popularity of cloud based machine learning (ML) techniques there comes a need for privacy and integrity guarantees for ML data. In addition, the significant scalability challenges faced by DRAM coupled with the high access-times of secondary storage represent a huge performance bottleneck for ML systems. While solutions exist to tackle the security aspect, performance remains an issue. Persistent memory (PM) is resilient to power loss (unlike DRAM), provides fast and fine-granular access to memory (unlike disk storage) and has latency and bandwidth close to DRAM (in the order of ns and GB/s, respectively). We present PLINIUS, a ML framework using Intel SGX enclaves for secure training of ML models and PM for fault tolerance guarantees. PLINIUS uses a novel mirroring mechanism to create and maintain (i) encrypted mirror copies of ML models on PM, and (ii) encrypted training data in byte-addressable PM, for near-instantaneous data recovery after a system failure. Compared to disk-based checkpointing systems, PLINIUS is 3.2× and 3.7× faster respectively for saving and restoring models on real PM hardware, achieving robust and secure ML model training in SGX enclaves.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.02987"
                    },
                    "abstract_zh": "随着基于云的机器学习(ML)技术的日益流行，出现了对ML数据的隐私和完整性保证的需求。此外，DRAM面临的巨大可扩展性挑战以及二级存储的高访问时间是ML系统的巨大性能瓶颈。虽然存在解决安全问题的解决方案，但性能仍然是一个问题。永久存储器(PM)对断电具有弹性(不同于DRAM)，提供对存储器的快速和精细访问(不同于磁盘存储)，并且具有接近DRAM的延迟和带宽(分别为ns和GB/s的数量级)。我们介绍了PLINIUS，这是一个使用英特尔SGX飞地进行ML模型安全训练和PM进行容错保证的ML框架。PLINIUS使用一种新颖的镜像机制来创建和维护(I)PM上的ML模型的加密镜像副本，以及(ii)字节可寻址PM中的加密训练数据，以便在系统故障后进行近乎即时的数据恢复。与基于磁盘的检查点系统相比，PLINIUS在真实PM硬件上保存和恢复模型的速度分别快3.2倍和3.7倍，在SGX飞地实现了健壮和安全的ML模型训练。",
                    "title_zh": "Plinius:安全和持久的机器学习模型训练"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00023",
                    "title": "Decamouflage: A Framework to Detect Image-Scaling Attacks on CNN",
                    "authors": "Bedeuro Kim, Alsharif Abuadbba, Yansong Gao, Yifeng Zheng, Muhammad Ejaz Ahmed, Surya Nepal, Hyoungshick Kim",
                    "abstract": "Image-scaling is a typical operation that processes the input image before feeding it into convolutional neural network models. However, it is vulnerable to the newly revealed image-scaling attack. This work presents an image-scaling attack detection framework, Decamouflage, consisting of three independent detection methods: scaling, filtering, and steganalysis, to detect the attack through examining distinct image characteristics. Decamouflage has a pre-determined detection threshold that is generic. More precisely, as we have validated, the threshold determined from one dataset is also applicable to other different datasets. Extensive experiments show that Decamouflage achieves detection accuracy of 99.9% and 98.5% in the white-box and the black-box settings, respectively. We also measured its running time overhead on a PC with an Intel i5 CPU and 8GB RAM. The experimental results show that image-scaling attacks can be detected in milliseconds. Moreover, Decamouflage is highly robust against adaptive image-scaling attacks (e.g., attack image size variances).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "图像缩放是在将输入图像馈送到卷积神经网络模型之前处理输入图像的典型操作。然而，它容易受到新发现的图像缩放攻击。本文提出了一个图像缩放攻击检测框架Decamouflage，它由三种独立的检测方法组成:缩放、过滤和隐写分析，通过检查不同的图像特征来检测攻击。Decamouflage具有通用的预定检测阈值。更准确地说，正如我们已经验证的，从一个数据集确定的阈值也适用于其他不同的数据集。大量实验表明，Decamouflage在白盒和黑盒环境下分别达到了99.9%和98.5%的检测准确率。我们还在配备英特尔i5 CPU和8GB RAM的电脑上测量了它的运行时间开销。实验结果表明，可以在几毫秒内检测出图像缩放攻击。此外，Decamouflage对自适应图像缩放攻击(例如，攻击图像大小变化)非常鲁棒。",
                    "title_zh": "Decamouflage:一个检测CNN图像缩放攻击的框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00024",
                    "title": "MILR: Mathematically Induced Layer Recovery for Plaintext Space Error Correction of CNNs",
                    "authors": "Jonathan Ponader, Kyle Thomas, Sandip Kundu, Yan Solihin",
                    "abstract": "The increased use of Convolutional Neural Networks (CNN) in mission-critical systems has increased the need for robust and resilient networks in the face of both naturally occurring faults as well as security attacks. The lack of robustness and resiliency can lead to unreliable inference results. Current methods that address CNN robustness require hardware modification, network modification, or network duplication. This paper proposes MILR a software-based CNN error detection and error correction system that enables recovery from single and multi-bit errors. The recovery capabilities are based on mathematical relationships between the inputs, outputs, and parameters(weights) of the layers; exploiting these relationships allows the recovery of erroneous parameters (iveights) throughout a layer and the network. MILR is suitable for plaintext-space error correction (PSEC) given its ability to correct whole-weight and even whole-layer errors in CNNs.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2010.14687"
                    },
                    "abstract_zh": "卷积神经网络(CNN)在任务关键型系统中的使用越来越多，这就增加了面对自然发生的故障以及安全攻击时对健壮且有弹性的网络的需求。缺乏健壮性和弹性会导致不可靠的推理结果。解决CNN鲁棒性的当前方法需要硬件修改、网络修改或网络复制。本文向MILR提出了一种基于软件的CNN错误检测和纠错系统，该系统能够从单比特和多比特错误中恢复。恢复能力基于层的输入、输出和参数(权重)之间的数学关系；利用这些关系允许在整个层和网络中恢复错误参数(iveights)。MILR适合于明文空间纠错(PSEC ),因为它有能力纠正CNN中的全权重甚至全层错误。",
                    "title_zh": "MILR:CNN明文空间纠错的数学诱导层恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00025",
                    "title": "Fast IPv6 Network Periphery Discovery and Security Implications",
                    "authors": "Xiang Li, Baojun Liu, Xiaofeng Zheng, Haixin Duan, Qi Li, Youjun Huang",
                    "abstract": "Numerous measurement researches have been performed to discover the IPv4 network security issues by leveraging the fast Internet-wide scanning techniques. However, IPv6 brings the 128-bit address space and renders brute-force network scanning impractical. Although significant efforts have been dedicated to enumerating active IPv6 hosts, limited by technique efficiency and probing accuracy, large-scale empirical measurement studies under the increasing IPv6 networks are infeasible now. To fill this research gap, by leveraging the extensively adopted IPv6 address allocation strategy, we propose a novel IPv6 network periphery discovery approach. Specifically, XMap, a fast network scanner, is developed to find the periphery, such as a home router. We evaluate it on twelve prominent Internet service providers and harvest 52M active peripheries. Grounded on these found devices, we explore IPv6 network risks of the unintended exposed security services and the flawed traffic routing strategies. First, we demonstrate the unintended exposed security services in IPv6 networks, such as DNS, and HTTP, have become emerging security risks by analyzing 4.7M peripheries. Second, by inspecting the periphery’s packet routing strategies, we present the flawed implementations of IPv6 routing protocol affecting 5.8M router devices. Attackers can exploit this common vulnerability to conduct effective routing loop attacks, inducing DoS to the ISP’s and home routers with an amplification factor of $\\gt {200}$. We responsibly disclose those issues to all involved vendors and ASes and discuss mitigation solutions. Our research results indicate that the security community should revisit IPv6 network strategies immediately.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过利用快速互联网范围的扫描技术，已经执行了许多测量研究来发现IPv4网络安全问题。然而，IPv6带来了128位地址空间，使得强力网络扫描变得不切实际。尽管大量的工作致力于枚举活跃的IPv6主机，但受限于技术效率和探测精度，在日益增长的IPv6网络下进行大规模的经验测量研究是不可行的。为了填补这一研究空白，通过利用广泛采用的IPv6地址分配策略，我们提出了一种新的IPv6网络边缘发现方法。具体来说，XMap是一种快速网络扫描器，用于查找外围设备，如家庭路由器。我们对12家著名的互联网服务提供商进行了评估，收获了5200万活跃用户。基于这些发现的设备，我们探讨了无意暴露的安全服务和有缺陷的流量路由策略的IPv6网络风险。首先，我们通过分析4.7M外围设备，证明了IPv6网络中意外暴露的安全服务，如DNS和HTTP，已经成为新出现的安全风险。其次，通过检查外围设备的分组路由策略，我们展示了影响5.8M路由器设备的IPv6路由协议的有缺陷的实现。攻击者可以利用这一常见漏洞进行有效的路由环路攻击，以$\\gt {200}$的放大系数诱导ISP和家庭路由器拒绝服务。我们负责任地向所有相关的供应商和ase披露这些问题，并讨论缓解方案。我们的研究结果表明，安全社区应该立即重新审视IPv6网络策略。",
                    "title_zh": "快速IPv6网络外围发现和安全含义"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00026",
                    "title": "A Comprehensive Study of Bugs in Software Defined Networks",
                    "authors": "Ayush Bhardwaj, Zhenyu Zhou, Theophilus A. Benson",
                    "abstract": "Software-defined networking (SDN) enables innovative and impressive solutions in the networking domain by decoupling the control plane from the data plane. In an SDN environment, the network control logic for load balancing, routing, and access control is written in software running on a decoupled control plane. As with any software development cycle, the SDN control plane is prone to bugs that impact the network’s performance and availability. Yet, as a community, we lack holistic, in-depth studies of bugs within the SDN ecosystem. A bug taxonomy is one of the most promising ways to lay the foundations required for (1) evaluating and directing emerging research directions on fault detection and recovery, and (2) informing operational practices of network administrators. This paper takes the first step towards laying this foundation by providing a comprehensive study and analysis of over 500 ‘critical’ bugs (including $\\sim 150$ with manual analysis) in three of the most widely-used SDN controllers, i.e., FAUCET, ONOS, and CORD. We create a taxonomy of these SDN bugs, analyze their operational impact, and implications for the developers. We use our taxonomy to analyze the effectiveness and coverage of several prominent SDN fault tolerance and diagnosis techniques. This study is the first of its kind in scale and coverage to the best of our knowledge.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(SDN)通过将控制平面与数据平面分离，在网络领域实现了令人印象深刻的创新解决方案。在SDN环境中，用于负载平衡、路由和访问控制的网络控制逻辑是在分离控制平面上运行的软件中编写的。与任何软件开发周期一样，SDN控制平面容易出现影响网络性能和可用性的错误。然而，作为一个社区，我们缺乏对SDN生态系统中的缺陷的全面、深入的研究。bug分类法是为(1)评估和指导故障检测和恢复的新兴研究方向，以及(2)通知网络管理员的操作实践奠定基础的最有前途的方法之一。本文通过对三种最广泛使用的SDN控制器(即水龙头、ONOS和线缆)中超过500个“关键”错误(包括$\\sim 150$和手动分析)的全面研究和分析，为奠定这一基础迈出了第一步。我们对这些SDN错误进行了分类，分析了它们的运营影响，以及对开发人员的启示。我们使用我们的分类法来分析几种著名的SDN容错和诊断技术的有效性和覆盖范围。就我们所知，这项研究在规模和覆盖面上都是第一次。",
                    "title_zh": "软件定义网络中错误的综合研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00027",
                    "title": "Enabling Novel Interconnection Agreements with Path-Aware Networking Architectures",
                    "authors": "Simon Scherrer, Markus Legner, Adrian Perrig, Stefan Schmid",
                    "abstract": "Path-aware networks (PANs) are emerging as an intriguing new paradigm with the potential to significantly improve the dependability and efficiency of networks. However, the benefits of PANs can only be realized if the adoption of such architectures is economically viable. This paper shows that PANs enable novel interconnection agreements among autonomous systems, which allow to considerably improve both economic profits and path diversity compared to today’s Internet. Specifically, by supporting packet forwarding along a path selected by the packet source, PANs do not require the Gao–Rexford conditions to ensure stability. Hence, autonomous systems can establish novel agreements, creating new paths which demonstrably improve latency and bandwidth metrics in many cases. This paper also expounds two methods to set up agreements which are Pareto-optimal, fair, and thus attractive to both parties. We further present a bargaining mechanism that allows two parties to efficiently automate agreement negotiations.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.02346"
                    },
                    "abstract_zh": "路径感知网络(pan)正成为一种有趣的新模式，具有显著提高网络可靠性和效率的潜力。然而，只有在采用这种架构在经济上可行的情况下，才能实现pan的优势。该论文表明，pan使自治系统之间的新型互连协议成为可能，与今天的互联网相比，这种协议允许显著提高经济利润和路径多样性。具体来说，通过支持沿着分组源选择的路径转发分组，pan不需要Gao-rex Ford条件来确保稳定性。因此，自治系统可以建立新的协议，创建新的路径，这在许多情况下明显改善了延迟和带宽指标。本文还阐述了两种建立帕累托最优的、公平的、对双方都有吸引力的协议的方法。我们还提出了一种谈判机制，允许双方有效地自动化协议谈判。",
                    "title_zh": "利用路径感知网络架构实现新型互连协议"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00028",
                    "title": "Self-Healing Protocol: Repairing Schedules Online after Link Failures in Time-Triggered Networks",
                    "authors": "Francisco Pozo, Guillermo Rodríguez-Navas, Hans Hansson",
                    "abstract": "Switched networks following the time-triggered paradigm rely on static schedules that determine the communication pattern over each link. In order to tolerate link failures, methods based on spatial redundancy and based on resynthesis and replacement of schedules have been proposed. These methods, however, do not scale to larger networks, which may be needed e.g. for future large-scale cyberphysical systems. We propose a distributed Self-Healing Protocol (SHP) that, instead of recomputing the whole schedule, repairs the existent schedule at runtime. For that, it relies on the coordination among the nodes of the network to redefine the repair problem as a number of local synthesis problems of significantly smaller size, which are solved in parallel by the nodes that need to reroute the frames affected by link failures. SHP exhibits a high success rate compared to full rescheduling, as well as remarkable scalability; it repairs the schedule in milliseconds, whereas rescheduling may require minutes for large networks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "遵循时间触发模式的交换网络依靠静态调度来决定每条链路上的通信模式。为了容忍链路故障，已经提出了基于空间冗余和基于调度的重新合成和替换的方法。然而，这些方法不能扩展到更大的网络，例如未来的大规模网络物理系统可能需要更大的网络。我们提出了一种分布式自愈协议(SHP ),它在运行时修复已有的调度，而不是重新计算整个调度。为此，它依赖于网络节点之间的协调来将修复问题重新定义为许多规模小得多的局部合成问题，这些问题由需要重新路由受链路故障影响的帧的节点并行解决。与完全重新安排相比，SHP表现出高成功率，以及显著的可伸缩性；它在几毫秒内修复调度，而对于大型网络，重新调度可能需要几分钟。",
                    "title_zh": "自愈协议:时间触发网络中链路故障后在线修复调度"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00029",
                    "title": "The Master and Parasite Attack",
                    "authors": "Lukas Baumann, Elias Heftrig, Haya Shulman, Michael Waidner",
                    "abstract": "We explore a new type of malicious script attacks: the persistent parasite attack. Persistent parasites are stealthy scripts, which persist for a long time in the browser’s cache. We show to infect the caches of victims with parasite scripts via TCP injection.Once the cache is infected, we implement methodologies for propagation of the parasites to other popular domains on the victim client as well as to other caches on the network. We show how to design the parasites so that they stay long time in the victim’s cache not restricted to the duration of the user’s visit to the web site. We develop covert channels for communication between the attacker and the parasites, which allows the attacker to control which scripts are executed and when, and to exfiltrate private information to the attacker, such as cookies and passwords. We then demonstrate how to leverage the parasites to perform sophisticated attacks, and evaluate the attacks against a range of applications and security mechanisms on popular browsers. Finally we provide recommendations for countermeasures.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2107.06415"
                    },
                    "abstract_zh": "我们探索一种新类型的恶意脚本攻击:持续性寄生虫攻击。持久寄生虫是隐形脚本，在浏览器的缓存中持续很长时间。我们展示了通过TCP注射用寄生虫脚本感染受害者的缓存。一旦缓存被感染，我们就实施方法将寄生虫传播到受害客户端上的其他流行域以及网络上的其他缓存。我们展示了如何设计寄生虫，使它们在受害者的缓存中停留很长时间，而不限于用户访问网站的持续时间。我们为攻击者和寄生虫之间的通信开发了秘密通道，这允许攻击者控制执行哪些脚本以及何时执行，并向攻击者泄露私人信息，如cookies和密码。然后，我们演示如何利用寄生虫来执行复杂的攻击，并针对流行浏览器上的一系列应用程序和安全机制来评估攻击。最后提出了对策建议。",
                    "title_zh": "主人和寄生虫的攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00030",
                    "title": "PatchDB: A Large-Scale Security Patch Dataset",
                    "authors": "Xinda Wang, Shu Wang, Pengbin Feng, Kun Sun, Sushil Jajodia",
                    "abstract": "Security patches, embedding both vulnerable code and the corresponding fixes, are of great significance to vulnerability detection and software maintenance. However, the existing patch datasets suffer from insufficient samples and low varieties. In this paper, we construct a large-scale patch dataset called PatchDB that consists of three components, namely, NVD-based dataset, wild-based dataset, and synthetic dataset. The NVD-based dataset is extracted from the patch hyperlinks indexed by the NVD. The wild-based dataset includes security patches that we collect from the commits on GitHub. To improve the efficiency of data collection and reduce the effort on manual verification, we develop a new nearest link search method to help find the most promising security patch candidates. Moreover, we provide a synthetic dataset that uses a new oversampling method to synthesize patches at the source code level by enriching the control flow variants of original patches. We conduct a set of studies to investigate the effectiveness of the proposed algorithms and evaluate the properties of the collected dataset. The experimental results show that PatchDB can help improve the performance of security patch identification.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全补丁嵌入了易受攻击的代码和相应的补丁，对漏洞检测和软件维护具有重要意义。然而，现有的斑块数据集存在样本不足和多样性低的问题。本文构建了一个名为PatchDB的大规模斑块数据集，该数据集由三部分组成，即基于NVD的数据集、基于野生环境的数据集和合成数据集。基于NVD的数据集是从NVD索引的修补程序超链接中提取的。基于wild的数据集包括我们从GitHub上的提交中收集的安全补丁。为了提高数据收集的效率并减少人工验证的工作量，我们开发了一种新的最近链接搜索方法来帮助找到最有希望的安全补丁候选。此外，我们提供了一个合成数据集，它使用一种新的过采样方法，通过丰富原始补丁的控制流变体，在源代码级别合成补丁。我们进行了一系列研究来调查所提出的算法的有效性，并评估所收集的数据集的属性。实验结果表明，PatchDB有助于提高安全补丁识别的性能。",
                    "title_zh": "PatchDB:大规模安全补丁数据集"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00031",
                    "title": "PDGraph: A Large-Scale Empirical Study on Project Dependency of Security Vulnerabilities",
                    "authors": "Qiang Li, Jinke Song, Dawei Tan, Haining Wang, Jiqiang Liu",
                    "abstract": "The reuse of libraries in software development has become prevalent for improving development efficiency and software quality. However, security vulnerabilities of reused libraries propagated through software project dependency pose a severe security threat, but they have not yet been well studied. In this paper, we present the first large-scale empirical study of project dependencies with respect to security vulnerabilities. We developed PDGraph, an innovative approach for analyzing publicly known security vulnerabilities among numerous project dependencies, which provides a new perspective for assessing security risks in the wild. As a large-scale software collection in dependency, we find 337,415 projects and 1,385,338 dependency relations. In particular, PDGraph generates a project dependency graph, where each node is a project, and each edge indicates a dependency relationship. We conducted experiments to validate the efficacy of PDGraph and characterized its features for security analysis. We revealed that 1,014 projects have publicly disclosed vulnerabilities, and more than 67,806 projects are directly dependent on them. Among these, 42,441 projects still manifest 67,581 insecure dependency relationships, indicating that they are built on vulnerable versions of reused libraries even though their vulnerabilities are publicly known. During our eight-month observation period, only 1,266 insecure edges were fixed, and corresponding vulnerable libraries were updated to secure versions. Furthermore, we uncovered four underlying dependency risks that can significantly reduce the difficulty of compromising systems. We conducted a quantitative analysis of dependency risks on the PDGraph.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了提高开发效率和软件质量，在软件开发中重用库已经变得很普遍。然而，通过软件项目依赖传播的可重用库的安全漏洞构成了严重的安全威胁，但它们尚未得到很好的研究。在本文中，我们提出了第一个关于安全漏洞的项目依赖性的大规模实证研究。我们开发了PDGraph，这是一种用于分析众多项目依赖关系中众所周知的安全漏洞的创新方法，它为评估野外安全风险提供了一个新的视角。作为一个大规模的软件依赖集合，我们发现337，415个项目和1，385，338个依赖关系。具体来说，PDGraph生成一个项目依赖图，其中每个节点都是一个项目，每条边表示一个依赖关系。我们通过实验验证了PDGraph的有效性，并描述了其用于安全性分析的特征。我们发现有1，014个项目公开披露了漏洞，超过67，806个项目直接依赖于它们。其中，42，441个项目仍然表现出67，581个不安全的依赖关系，表明它们建立在易受攻击的重用库版本上，尽管它们的漏洞是众所周知的。在我们8个月的观察期内，仅修复了1266个不安全的边缘，相应的易受攻击的库被更新为安全版本。此外，我们发现了四个潜在的依赖性风险，它们可以显著降低危害系统的难度。我们在PDGraph上进行了依赖风险的定量分析。",
                    "title_zh": "PDGraph:安全漏洞项目依赖性的大规模实证研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00032",
                    "title": "OCTOPOCS: Automatic Verification of Propagated Vulnerable Code Using Reformed Proofs of Concept",
                    "authors": "Seongkyeong Kwon, Seunghoon Woo, Gangmo Seong, Heejo Lee",
                    "abstract": "Addressing vulnerability propagation has become a major issue in software ecosystems. Existing approaches hold the promise of detecting widespread vulnerabilities but cannot be applied to verify effectively whether propagated vulnerable code still poses threats. We present OCTOPOCS, which uses a reformed Proof-of-Concept (PoC), to verify whether a vulnerability is propagated. Using context-aware taint analysis, OCTOPOCS extracts crash primitives (the parts used in the shared code area between the original vulnerable software and propagated software) from the original PoC. OCTOPOCS then utilizes directed symbolic execution to generate guiding inputs that direct the execution of the propagated software from the entry point to the shared code area. Thereafter, OCTOPOCS creates a new PoC by combining crash primitives and guiding inputs. It finally verifies the propagated vulnerability using the created PoC. We evaluated OCTOPOCS with 15 real-world C and C++ vulnerable software pairs, with results showing that OCTOPOCS successfully verified 14 propagated vulnerabilities.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "解决漏洞传播已经成为软件生态系统中的一个主要问题。现有方法有望检测到广泛存在的漏洞，但无法有效验证传播的易受攻击代码是否仍然构成威胁。我们提出OCTOPOCS，它使用一种改进的概念证明(PoC)来验证漏洞是否传播。使用上下文感知污点分析，OCTOPOCS从原始PoC中提取崩溃原语(在原始易受攻击软件和传播软件之间的共享代码区域中使用的部分)。OCTOPOCS然后利用定向符号执行来生成引导输入，该引导输入将传播的软件的执行从入口点引导到共享代码区域。此后，OCTOPOCS通过组合崩溃原语和引导输入来创建新的PoC。它最后使用创建的PoC验证传播的漏洞。我们用15个真实世界的C和C++易受攻击软件对评估了OCTOPOCS，结果显示OCTOPOCS成功验证了14个传播的漏洞。",
                    "title_zh": "OCTOPOCS:使用改进的概念证明自动验证传播的易受攻击代码"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00033",
                    "title": "NVCache: A Plug-and-Play NVMM-based I/O Booster for Legacy Systems",
                    "authors": "Rémi Dulong, Rafael Pires, Andreia Correia, Valerio Schiavoni, Pedro Ramalhete, Pascal Felber, Gaël Thomas",
                    "abstract": "This paper introduces NVCACHE, an approach that uses a non-volatile main memory (NVMM) as a write cache to improve the write performance of legacy applications. We compare NVCACHE against file systems tailored for NVMM (Ext4-DAX and NOVA) and with I/O-heavy applications (SQLite, RocksDB). Our evaluation shows that NVCACHE reaches the performance level of the existing state-of-the-art systems for NVMM, but without their limitations: NVCACHE does not limit the size of the stored data to the size of the NVMM, and works transparently with unmodified legacy applications, providing additional persistence guarantees even when their source code is not available.",
                    "files": {
                        "openAccessPdf": "https://infoscience.epfl.ch/record/288184/files/paper-nvcache.pdf"
                    },
                    "abstract_zh": "本文介绍了NVCACHE，这是一种使用非易失性主内存(NVMM)作为写缓存来提高传统应用程序写性能的方法。我们将NVCACHE与为NVMM定制的文件系统(Ext4-DAX和NOVA)以及I/O密集型应用程序(SQLite、RocksDB)进行了比较。我们的评估表明，NVCACHE达到了NVMM现有最先进系统的性能水平，但没有它们的限制:NVCACHE不会将存储数据的大小限制为NVMM的大小，并且可以透明地与未经修改的传统应用程序一起工作，即使源代码不可用，也能提供额外的持久性保证。",
                    "title_zh": "NVCache:一个即插即用的基于NVMM的I/O加速器，用于遗留系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00034",
                    "title": "K2: Reading Quickly from Storage Across Many Datacenters",
                    "authors": "Khiem Ngo, Haonan Lu, Wyatt Lloyd",
                    "abstract": "The infrastructure available to large-scale and medium-scale web services now spans dozens of geographically dispersed datacenters. Deploying across many datacenters has the potential to significantly reduce end-user latency by serving users nearer their location. However, deploying across many datacenters requires the backend storage system be partially replicated. In turn, this can sacrifice the low latency benefits of many datacenters, especially when a storage system provides guarantees on what operations will observe. We present the K2 storage system that provides lower latency for large-scale and medium-scale web services using partial replication of data over many datacenters with strong guarantees: causal consistency, read-only transactions, and write-only transactions. K2 provides the best possible worst-case latency for partial replication, a single round trip to remote datacenters, and often avoids sending any requests to far away datacenters using a novel replication approach, write-only transaction algorithm, and read-only transaction algorithm.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可用于大规模和中等规模web服务的基础设施现在跨越数十个地理上分散的数据中心。跨多个数据中心部署有可能通过为离用户位置更近的用户提供服务来显著降低最终用户的延迟。但是，跨多个数据中心部署需要部分复制后端存储系统。反过来，这可能会牺牲许多数据中心的低延迟优势，尤其是当存储系统对操作将观察到的内容提供保证时。我们展示了K2存储系统，它通过在许多数据中心上使用数据的部分复制，为大规模和中等规模的web服务提供了更低的延迟，并具有强大的保证:因果一致性、只读事务和只写事务。K2为部分复制(到远程数据中心的单次往返)提供了最佳的最坏情况延迟，并且通常使用一种新颖的复制方法、只写事务算法和只读事务算法来避免向远程数据中心发送任何请求。",
                    "title_zh": "K2:跨多个数据中心快速读取存储"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00035",
                    "title": "Horus: Non-Intrusive Causal Analysis of Distributed Systems Logs",
                    "authors": "Francisco Neves, Nuno Machado, Ricardo Vilaça, José Pereira",
                    "abstract": "Logs are still the primary resource for debugging distributed systems executions. Complexity and heterogeneity of modern distributed systems, however, make log analysis extremely challenging. First, due to the sheer amount of messages, in which the execution paths of distinct system components appear interleaved. Second, due to unsynchronized physical clocks, simply ordering the log messages by timestamp does not suffice to obtain a causal trace of the execution. To address these issues, we present Horus, a system that enables the refinement of distributed system logs in a causally-consistent and scalable fashion. Horus leverages kernel-level probing to capture events for tracking causality between application-level logs from multiple sources. The events are then encoded as a directed acyclic graph and stored in a graph database, thus allowing the use of rich query languages to reason about runtime behavior. Our case study with TrainTicket, a ticket booking application with 40+ microservices, shows that Horus surpasses current widely-adopted log analysis systems in pinpointing the root cause of anomalies in distributed executions. Also, we show that Horus builds a causally-consistent log of a distributed execution with much higher performance (up to 3 orders of magnitude) and scalability than prior state-of-the-art solutions. Finally, we show that Horus’ approach to query causality is up to 30 times faster than graph database built-in traversal algorithms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "日志仍然是调试分布式系统执行的主要资源。然而，现代分布式系统的复杂性和异构性使得日志分析极具挑战性。首先，由于消息数量庞大，不同系统组件的执行路径交错出现。其次，由于不同步的物理时钟，简单地通过时间戳对日志消息进行排序不足以获得执行的因果跟踪。为了解决这些问题，我们提出了Horus，这是一个能够以因果一致和可扩展的方式细化分布式系统日志的系统。Horus利用内核级探测来捕获事件，以跟踪来自多个来源的应用程序级日志之间的因果关系。然后，事件被编码为有向非循环图并存储在图数据库中，从而允许使用丰富的查询语言来推理运行时行为。我们对拥有40多个微服务的订票应用TrainTicket的案例研究表明，Horus在查明分布式执行中异常的根本原因方面优于当前广泛采用的日志分析系统。此外，我们还展示了Horus构建了分布式执行的因果一致性日志，其性能(高达3个数量级)和可伸缩性远高于现有的最先进的解决方案。最后，我们证明Horus的因果关系查询方法比图数据库内置遍历算法快30倍。",
                    "title_zh": "Horus:分布式系统日志的非侵入式因果分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00036",
                    "title": "Asteria: Deep Learning-based AST-Encoding for Cross-platform Binary Code Similarity Detection",
                    "authors": "Shouguo Yang, Long Cheng, Yicheng Zeng, Zhe Lang, Hongsong Zhu, Zhiqiang Shi",
                    "abstract": "Binary code similarity detection is a fundamental technique for many security applications such as vulnerability search, patch analysis, and malware detection. There is an increasing need to detect similar code for vulnerability search across architectures with the increase of critical vulnerabilities in IoT devices. The variety of IoT hardware architectures and software platforms requires to capture semantic equivalence of code fragments in the similarity detection. However, existing approaches are insufficient in capturing the semantic similarity. We notice that the abstract syntax tree (AST) of a function contains rich semantic information. Inspired by successful applications of natural language processing technologies in sentence semantic understanding, we propose a deep learning-based AST-encoding method, named ASTERIA, to measure the semantic equivalence of functions in different platforms. Our method leverages the Tree-LSTM network to learn the semantic representation of a function from its AST. Then the similarity detection can be conducted efficiently and accurately by measuring the similarity between two representation vectors. We have implemented an open-source prototype of ASTERIA. The Tree-LSTM model is trained on a dataset with 1,022,616 function pairs and evaluated on a dataset with 95,078 function pairs. Evaluation results show that our method outperforms the AST-based tool Diaphora and the-state-of-art method Gemini by large margins with respect to the binary similarity detection. And our method is several orders of magnitude faster than Diaphora and Gemini for the similarity calculation. In the application of vulnerability search, our tool successfully identified 75 vulnerable functions in 5,979 IoT firmware images.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2108.06082"
                    },
                    "abstract_zh": "二进制代码相似性检测是许多安全应用的基本技术，例如漏洞搜索、补丁分析和恶意软件检测。随着物联网设备中关键漏洞的增加，越来越需要跨架构检测类似的漏洞搜索代码。物联网硬件架构和软件平台的多样性要求在相似性检测中捕获代码片段的语义等价。然而，现有的方法不足以捕捉语义相似度。我们注意到函数的抽象语法树包含了丰富的语义信息。受自然语言处理技术在句子语义理解中的成功应用的启发，我们提出了一种基于深度学习的AST编码方法，命名为ASTERIA，用于度量不同平台中函数的语义等价性。我们的方法利用树-LSTM网络从函数的AST中学习函数的语义表示。然后，通过测量两个表示向量之间的相似性，可以高效且准确地进行相似性检测。我们已经实现了ASTERIA的开源原型。树-LSTM模型在具有1，022，616个函数对的数据集上训练，并且在具有95，078个函数对的数据集上评估。评估结果表明，在二元相似性检测方面，我们的方法大大优于基于AST的工具Diaphora和最新的方法Gemini。对于相似性计算，我们的方法比Diaphora和Gemini快几个数量级。在漏洞搜索的应用中，我们的工具成功识别了5979个物联网固件镜像中的75个漏洞函数。",
                    "title_zh": "阿斯忒瑞亚:基于深度学习的AST编码用于跨平台二进制代码相似性检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00037",
                    "title": "Sentiment Analysis based Error Detection for Large-Scale Systems",
                    "authors": "Khalid Ayedh Alharthi, Arshad Jhumka, Sheng Di, Franck Cappello, Edward Chuah",
                    "abstract": "Today’s large-scale systems such as High Performance Computing (HPC) Systems are designed/utilized towards exascale computing, inevitably decreasing its reliability due to the increasing design complexity. HPC systems conduct extensive logging of their execution behaviour. In this paper, we leverage the inherent meaning behind the log messages and propose a novel sentiment analysis-based approach for the error detection in large-scale systems, by automatically mining the sentiments in the log messages. Our contributions are four-fold. (1) We develop a machine learning (ML) based approach to automatically build a sentiment lexicon, based on the system log message templates. (2) Using the sentiment lexicon, we develop an algorithm to detect system errors. (3) We develop an algorithm to identify the nodes and components with erroneous behaviors, based on sentiment polarity scores. (4) We evaluate our solution vs. other state-of-the-art machine/deep learning algorithms based on three representative supercomputers’ system logs. Experiments show that our error detection algorithm can identify error messages with an average MCC score and f-score of 91% and 96% respectively, while state of the art ML/deep learning model (LSTM) obtains only 67% and 84%. To the best of our knowledge, this is the first work leveraging the sentiments embedded in log entries of large-scale systems for system health analysis.",
                    "files": {
                        "openAccessPdf": "http://wrap.warwick.ac.uk/151241/1/WRAP-Sentiment-analysis-based-error-detection-large-scale-systems-2021.pdf"
                    },
                    "abstract_zh": "当今的大规模系统(如高性能计算(HPC)系统)是针对亿亿次计算而设计/利用的，由于设计复杂性的增加，不可避免地会降低其可靠性。HPC系统对它们的执行行为进行大量的日志记录。本文利用日志消息背后的内在含义，通过自动挖掘日志消息中的情感，提出了一种新的基于情感分析的大规模系统错误检测方法。我们的贡献有四个方面。(1)基于系统日志消息模板，我们开发了一种基于机器学习的方法来自动构建情感词典。(2)利用情感词典，我们开发了一个检测系统错误的算法。(3)我们开发了一种基于情感极性得分的算法来识别具有错误行为的节点和组件。(4)我们基于三台具有代表性的超级计算机的系统日志，将我们的解决方案与其他最先进的机器/深度学习算法进行了评估。实验表明，我们的错误检测算法可以识别错误消息，平均MCC分数和f分数分别为91%和96%，而最先进的ML/深度学习模型(LSTM)仅获得67%和84%。据我们所知，这是第一个利用大规模系统日志条目中的情感进行系统健康分析的工作。",
                    "title_zh": "基于情感分析的大规模系统错误检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00038",
                    "title": "Time-Window Based Group-Behavior Supported Method for Accurate Detection of Anomalous Users",
                    "authors": "Lun-Pin Yuan, Euijin Choo, Ting Yu, Issa Khalil, Sencun Zhu",
                    "abstract": "Autoencoder-based anomaly detection methods have been used in identifying anomalous users from large-scale enterprise logs with the assumption that adversarial activities do not follow past habitual patterns. Most existing approaches typically build models by reconstructing single-day and individual-user behaviors. However, without capturing long-term signals and group-correlation signals, the models cannot identify low-signal yet long-lasting threats, and will wrongly report many normal users as anomalies on busy days, which, in turn, lead to high false positive rate. In this paper, we propose ACOBE, an Anomaly detection method based on COmpound BEhavior, which takes into consideration long-term patterns and group behaviors. ACOBE leverages a novel behavior representation and an ensemble of deep autoencoders and produces an ordered investigation list. Our evaluation shows that ACOBE outperforms prior work by a large margin in terms of precision and recall, and our case study demonstrates that ACOBE is applicable in practice for cyberattack detection.",
                    "files": {
                        "openAccessPdf": "https://scholarsphere.psu.edu/resources/e6179873-83ad-4052-bb2a-9f3d6b257d62/downloads/22059"
                    },
                    "abstract_zh": "基于自动编码器的异常检测方法已经被用于从大规模企业日志中识别异常用户，假设敌对活动不遵循过去的习惯模式。大多数现有方法通常通过重建单日和个人用户行为来建立模型。然而，如果不捕获长期信号和组相关性信号，这些模型就无法识别低信号但持久的威胁，并且会在繁忙的日子里将许多正常用户错误地报告为异常，从而导致高误报率。本文提出了一种基于复合行为的异常检测方法ACOBE，该方法考虑了长期模式和群体行为。ACOBE利用一种新颖的行为表示和一组深度自动编码器，并生成一个有序的调查列表。我们的评估表明，ACOBE在准确率和召回率方面大大优于以前的工作，我们的案例研究表明，ACOBE在网络攻击检测的实践中是适用的。",
                    "title_zh": "基于时间窗的群体行为支持的异常用户精确检测方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00039",
                    "title": "General Feature Selection for Failure Prediction in Large-scale SSD Deployment",
                    "authors": "Fan Xu, Shujie Han, Patrick P. C. Lee, Yi Liu, Cheng He, Jiongzhou Liu",
                    "abstract": "Solid-state drive (SSD) failures are likely to cause system-level failures leading to downtime, enabling SSD failure prediction to be critical to large-scale SSD deployment. Existing SSD failure prediction studies are mostly based on customized SSDs with proprietary monitoring metrics, which are difficult to reproduce. To support general SSD failure prediction of different drive models and vendors, this paper proposes Wear-out-updating Ensemble Feature Ranking (WEFR) to select the SMART attributes as learning features in an automated and robust manner. WEFR combines different feature ranking results and automatically generates the final feature selection based on the complexity measures and the change point detection of wear-out degrees. We evaluate our approach using a dataset of nearly 500K working SSDs at Alibaba. Our results show that the proposed approach is effective and outperforms related approaches. We have successfully applied the proposed approach to improve the reliability of cloud storage systems in production SSD-based data centers. We release our dataset for public use.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "固态硬盘(SSD)故障可能会导致系统级故障，进而导致停机，因此SSD故障预测对于大规模SSD部署至关重要。现有的固态硬盘故障预测研究大多基于定制的固态硬盘，具有专有的监控指标，难以重现。为了支持不同驱动器型号和供应商的通用SSD故障预测，提出磨损更新集成特征排序(WEFR)以自动和鲁棒的方式选择智能属性作为学习特征。WEFR组合不同的特征排序结果，并基于复杂度测量和磨损程度的变化点检测自动生成最终的特征选择。我们使用阿里巴巴近50万个工作固态硬盘的数据集来评估我们的方法。实验结果表明，该方法是有效的，并优于相关方法。我们已经成功地将所提出的方法应用于基于SSD的生产数据中心，以提高云存储系统的可靠性。我们发布数据集供公众使用。",
                    "title_zh": "大规模SSD部署中故障预测的通用特征选择"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00040",
                    "title": "Data-centric Reliability Management in GPUs",
                    "authors": "Gurunath Kadam, Evgenia Smirni, Adwait Jog",
                    "abstract": "Graphics Processing Units (GPUs) have become the default choice of acceleration in a wide range of application domains. To keep up with computational demands, the GPU memory system is constantly being innovated from both the cache and DRAM perspectives. Such innovations can adversely affect GPU reliability and in fact, can lead to an increase in the number of multi-bit faults. To address this problem, we systematically study a wide range of GPGPU applications and find that usually, only a small percentage of data needs protection to increase application resilience. This data is highly accessed and shared (constitutes hot memory), which implies that faults in this space can often lead to incorrect application output. An in-depth analysis of application code shows that information of such data can be passed on to the hardware to guide low-overhead detection/correction schemes. In this vein, we developed low-overhead partial data replication schemes that exploit latency tolerance in GPUs. Overall, this data-centric approach dramatically improves GPGPU application resilience, with a minimal additional average performance overhead of 1.2% for detection-only and 3.4% for detection-and-correction.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "图形处理单元(GPU)已经成为许多应用领域中加速的默认选择。为了满足计算需求，GPU内存系统不断从缓存和DRAM两个角度进行创新。这种创新可能会对GPU的可靠性产生不利影响，事实上，可能会导致多位故障的数量增加。为了解决这个问题，我们系统地研究了各种各样的GPGPU应用程序，发现通常只有一小部分数据需要保护来提高应用程序的弹性。这些数据被高度访问和共享(构成热内存)，这意味着这个空间中的错误经常会导致不正确的应用程序输出。对应用程序代码的深入分析表明，这些数据的信息可以传递给硬件，以指导低开销的检测/纠正方案。在这种情况下，我们开发了低开销的部分数据复制方案，利用了GPU中的延迟容限。总的来说，这种以数据为中心的方法极大地提高了GPGPU应用程序的弹性，仅检测的平均性能开销仅为1.2%，检测和纠正的平均性能开销为3.4%。",
                    "title_zh": "GPU中以数据为中心的可靠性管理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00041",
                    "title": "NVBitFI: Dynamic Fault Injection for GPUs",
                    "authors": "Timothy Tsai, Siva Kumar Sastry Hari, Michael B. Sullivan, Oreste Villa, Stephen W. Keckler",
                    "abstract": "GPUs have found wide acceptance in domains such as high-performance computing and autonomous vehicles, which require fast processing of large amounts of data along with provisions for reliability, availability, and safety. A key component of these dependability characteristics is the propagation of errors and their eventual effect on system outputs. In addition to analytical and simulation models, fault injection is an important technique that can evaluate the effect of errors on a complete computing system running the full software stack. However, the complexity of modern GPU systems and workloads challenges existing fault injection tools. Some tools require the recompilation of source code that may not be available, struggle to handle dynamic libraries, lack support for modern GPUs, or add unacceptable performance overheads. We introduce the NVBitFI tool for fault injection into GPU programs. In contrast with existing tools, NVBitFI performs instrumentation of code dynamically and selectively to instrument the minimal set of target dynamic kernels; as it requires no access to source code, NVBitFI provides improvements in performance and usability. The NVBitFI tool is publicly available for download and use at https://github.com/NVlabs/nvbitfi.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "GPU在高性能计算和自动驾驶汽车等领域得到了广泛认可，这些领域需要快速处理大量数据，并提供可靠性、可用性和安全性。这些可靠性特征的一个关键组成部分是误差的传播及其对系统输出的最终影响。除了分析和仿真模型之外，故障注入是一种重要的技术，可以评估错误对运行完整软件栈的完整计算系统的影响。然而，现代GPU系统和工作负载的复杂性对现有的故障注入工具提出了挑战。一些工具需要重新编译可能不可用的源代码，难以处理动态库，缺乏对现代GPU的支持，或者增加了不可接受的性能开销。我们引入了NVBitFI工具，用于将故障注入到GPU程序中。与现有工具相比，NVBitFI动态且选择性地执行代码的检测，以检测最小的目标动态内核集；由于不需要访问源代码，NVBitFI提供了性能和可用性方面的改进。NVBitFI工具可在https://github.com/NVlabs/nvbitfi.公开下载和使用",
                    "title_zh": "NVBitFI:面向GPU的动态故障注入"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00042",
                    "title": "Revealing GPUs Vulnerabilities by Combining Register-Transfer and Software-Level Fault Injection",
                    "authors": "Fernando Fernandes dos Santos, Josie E. Rodriguez Condia, Luigi Carro, Matteo Sonza Reorda, Paolo Rech",
                    "abstract": "The complexity of both hardware and software makes GPUs reliability evaluation extremely challenging. A low level fault injection on a GPU model, despite being accurate, would take a prohibitively long time (months to years), while software fault injection, despite being quick, cannot access critical resources for GPUs and typically uses synthetic fault models (e.g., single bit-flips) that could result in unrealistic evaluations. This paper proposes to combine the accuracy of Register- Transfer Level (RTL) fault injection with the efficiency of software fault injection. First, on an RTL GPU model (FlexGripPlus), we inject over 1.5 million faults in low-level resources that are unprotected and hidden to the programmer, and characterize their effects on the output of common instructions. We create a pool of possible fault effects on the operation output based on the instruction opcode and input characteristics. We then inject these fault effects, at the application level, using an updated version of a software framework (NVBitFI). Our strategy reduces the fault injection time from the tens of years an RTL evaluation would need to tens of hours, thus allowing, for the first time on GPUs, to track the fault propagation from the hardware to the output of complex applications. Additionally, we provide a more realistic fault model and show that single bit-flip injection would underestimate the error rate of six HPC applications and two convolutional neural networks by up to 48parcent (18parcent on average). The RTL fault models and the injection framework we developed are made available in a public repository to enable third-party evaluations and ease results reproducibility.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "硬件和软件的复杂性使得GPU可靠性评估极具挑战性。GPU模型上的低级错误注入尽管是准确的，但将花费非常长的时间(几个月到几年)，而软件错误注入尽管很快，但不能访问GPU的关键资源，并且通常使用可能导致不切实际的评估的合成错误模型(例如，单比特翻转)。提出将寄存器传输级(RTL)故障注入的准确性与软件故障注入的效率相结合。首先，在RTL GPU模型(FlexGripPlus)上，我们在未受保护且对程序员隐藏的低级资源中注入了超过150万个错误，并表征了它们对通用指令输出的影响。我们根据指令操作码和输入特征，创建了一个可能对操作输出产生错误影响的池。然后，我们使用软件框架(NVBitFI)的更新版本，在应用程序级别注入这些故障影响。我们的策略将故障注入时间从RTL评估所需的几十年减少到几十小时，从而首次允许在GPU上跟踪从硬件到复杂应用输出的故障传播。此外，我们提供了一个更现实的故障模型，并表明单个位翻转注入将低估六个HPC应用程序和两个卷积神经网络的错误率高达48 %(平均18%)。我们开发的RTL断层模型和注入框架可在公共存储库中获得，以支持第三方评估并简化结果再现性。",
                    "title_zh": "结合寄存器传输和软件级故障注入揭示GPU漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00043",
                    "title": "Examining Failures and Repairs on Supercomputers with Multi-GPU Compute Nodes",
                    "authors": "Amir Taherin, Tirthak Patel, Giorgis Georgakoudis, Ignacio Laguna, Devesh Tiwari",
                    "abstract": "Understanding the reliability characteristics of supercomputers has been a key focus of the HPC and dependability communities. However, there is no current study that analyzes both the failure and recovery characteristics over multiple generations of a GPU-based supercomputer with multiple GPUs on the same node. This paper bridges that gap and reveals surprising insights based on monitoring and analyzing the failures and repairs on the Tsubame-2 and Tsubame-3 supercomputers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "理解超级计算机的可靠性特征一直是HPC和可靠性社区的重点。然而，目前没有研究分析在同一节点上具有多个GPU的基于GPU的超级计算机的多代故障和恢复特征。本文填补了这一空白，并基于对Tsubame-2和Tsubame-3超级计算机的故障和修复的监控和分析，揭示了令人惊讶的见解。",
                    "title_zh": "在具有多个GPU计算节点的超级计算机上检查故障和修复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00044",
                    "title": "An Application Agnostic Defense Against the Dark Arts of Cryptojacking",
                    "authors": "Nada Lachtar, Abdulrahman Abu Elkhail, Anys Bacha, Hafiz Malik",
                    "abstract": "The popularity of cryptocurrencies has garnered interest from cybercriminals, spurring an onslaught of cryptojacking campaigns that aim to hijack computational resources for the purpose of mining cryptocurrencies. In this paper, we present a cross-stack cryptojacking defense system that spans the hardware and OS layers. Unlike prior work that is confined to detecting cryptojacking behavior within web browsers, our solution is application agnostic. We show that tracking instructions that are frequently used in cryptographic hash functions serve as reliable signatures for fingerprinting cryptojacking activity. We demonstrate that our solution is resilient to multi-threaded and throttling evasion techniques that are commonly employed by cryptojacking malware. We characterize the robustness of our solution by extensively testing a diverse set of workloads that include real consumer applications. Finally, an evaluation of our proof-of-concept implementation shows minimal performance impact while running a mix of benchmark applications",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "加密货币的流行引起了网络犯罪分子的兴趣，刺激了旨在劫持计算资源以挖掘加密货币的加密劫持活动的冲击。在本文中，我们提出了一个跨硬件层和操作系统层的跨栈密码劫持防御系统。不像以前的工作局限于检测网络浏览器中的密码劫持行为，我们的解决方案是应用不可知的。我们证明了在加密哈希函数中频繁使用的跟踪指令可以作为指纹加密劫持活动的可靠签名。我们证明了我们的解决方案对加密劫持恶意软件通常采用的多线程和节流规避技术具有弹性。我们通过广泛测试包括真实消费者应用程序在内的各种工作负载来描述我们解决方案的稳定性。最后，对我们的概念验证实施的评估显示，在运行多种基准应用程序时，性能影响极小",
                    "title_zh": "一种与应用程序无关的防御加密劫持的黑魔法的方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00045",
                    "title": "Catch You With Cache: Out-of-VM Introspection to Trace Malicious Executions",
                    "authors": "Chao Su, Xuhua Ding, Qingkai Zeng",
                    "abstract": "Out-of-VM introspection is an imperative part of security analysis. The legacy methods either modify the system, introducing enormous overhead, or rely heavily on hardware features, which are neither available nor practical in most cloud environments. In this paper, we propose a novel analysis method, named as Catcher, that utilizes CPU cache to perform out-of-VM introspection. Catcher does not make any modifications to the target program and its running environment, nor demands special hardware support. Implemented upon Linux KVM, it natively introspects the target’s virtual memory. More importantly, it uses the cache-based side channel to infer the target control flow. To deal with the inherent limitations of the side channel, we propose several heuristics to improve the accuracy and stability of Catcher. Our experiments against various malware armored with packing techniques show that Catcher can recover the control flow in real time with around 67% to 97% accuracy scores. Catcher incurs a negligible overhead to the system and can be launched at anytime to monitor an ongoing attack inside a virtual machine.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虚拟机外自省是安全分析的必要组成部分。传统方法要么修改系统，引入巨大的开销，要么严重依赖硬件功能，这些功能在大多数云环境中既不可用也不实用。在本文中，我们提出了一种新的分析方法，称为Catcher，它利用CPU缓存来执行虚拟机外自省。Catcher不需要对目标程序及其运行环境做任何修改，也不需要特殊的硬件支持。在Linux KVM上实现后，它可以自动检查目标的虚拟内存。更重要的是，它使用基于缓存的侧通道来推断目标控制流。为了处理侧信道的固有限制，我们提出了几种启发式方法来提高捕捉器的准确性和稳定性。我们针对各种使用打包技术伪装的恶意软件的实验表明，Catcher可以实时恢复控制流，准确率在67%到97%左右。Catcher对系统的开销可以忽略不计，并且可以随时启动来监控虚拟机内部正在进行的攻击。",
                    "title_zh": "用缓存抓住你:虚拟机外自省跟踪恶意执行"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00046",
                    "title": "Towards Optimal Use of Exception Handling Information for Function Detection",
                    "authors": "Chengbin Pang, Ruotong Yu, Dongpeng Xu, Eric Koskinen, Georgios Portokalidis, Jun Xu",
                    "abstract": "Function entry detection is critical for security of binary code. Conventional methods heavily rely on patterns, inevitably missing true functions and introducing errors. Recently, call frames have been used in exception-handling for function start detection. However, existing methods have two problems. First, they combine call frames with heuristic-based approaches, which often brings error and uncertain benefits. Second, they trust the fidelity of call frames, without handling the errors that are introduced by call frames. In this paper, we first study the coverage and accuracy of existing approaches in detecting function starts using call frames. We found that although recursive disassembly with call frames can maximize coverage, using extra heuristic-based approaches does not improve coverage and actually hurts accuracy. Second, we unveil call-frame errors and develop the first approach to fix them, making their use more reliable.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.03168"
                    },
                    "abstract_zh": "函数入口检测对于二进制代码的安全性至关重要。传统方法严重依赖模式，不可避免地会遗漏真正的功能并引入错误。最近，调用帧已经被用于函数开始检测的异常处理中。然而，现有的方法有两个问题。首先，他们将调用框架与基于启发式的方法相结合，这通常会带来错误和不确定的好处。第二，他们信任呼叫帧的保真度，而不处理由呼叫帧引入的错误。在本文中，我们首先研究了使用调用帧检测函数开始的现有方法的覆盖率和准确性。我们发现，尽管使用调用帧的递归反汇编可以最大化覆盖率，但使用额外的基于启发式的方法并不能提高覆盖率，反而会损害准确性。其次，我们揭示了调用框架错误，并开发了第一种修复它们的方法，使它们的使用更加可靠。",
                    "title_zh": "面向函数检测的异常处理信息的优化使用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00047",
                    "title": "CloudSkulk: A Nested Virtual Machine Based Rootkit and Its Detection",
                    "authors": "Joseph Connelly, Taylor Roberts, Xing Gao, Jidong Xiao, Haining Wang, Angelos Stavrou",
                    "abstract": "When attackers compromise a computer system and obtain root control over the victim system, retaining that control and avoiding detection become their top priority. To achieve this goal, various rootkits have been developed. However, existing rootkits are still easy to detect as long as defenders can gain control at a lower level, such as the operating system level, the hypervisor level, or the hardware level. In this paper, we present a new type of rootkit called CloudSkulk, which is a nested virtual machine (VM) based rootkit. While nested virtualization has attracted sufficient attention from the security and cloud community, to the best of our knowledge, we are the first to reveal and demonstrate how nested virtualization can be used by attackers to develop rootkits. We then, from defenders’ perspective, present a novel approach to detecting CloudSkulk rootkits at the host level. Our experimental results show that the proposed approach is effective in detecting CloudSkulk rootkits.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当攻击者危害计算机系统并获得对受害系统的根控制时，保持这种控制并避免被检测成为他们的首要任务。为了实现这个目标，已经开发了各种rootkits。然而，现有的rootkits仍然很容易被检测到，只要防御者可以在较低的级别获得控制，如操作系统级别、管理程序级别或硬件级别。本文提出了一种新的rootkit，称为CloudSkulk，它是一种基于嵌套虚拟机的rootkit。虽然嵌套虚拟化已经引起了安全和云社区的足够重视，但据我们所知，我们是第一个揭示和演示攻击者如何利用嵌套虚拟化来开发rootkits的人。然后，我们从防御方的角度，提出了一种在主机级别检测CloudSkulk rootkits的新方法。实验结果表明，该方法能有效地检测出CloudSkulk rootkits。",
                    "title_zh": "CloudSkulk:基于嵌套虚拟机的Rootkit及其检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00048",
                    "title": "FIRestarter: Practical Software Crash Recovery with Targeted Library-level Fault Injection",
                    "authors": "Koustubha Bhat, Erik van der Kouwe, Herbert Bos, Cristiano Giuffrida",
                    "abstract": "Despite advances in software testing, many bugs still plague deployed software, leading to crashes and thus service disruption in high-availability production applications. Existing crash recovery solutions are either limited to transient faults or require manual annotations to target predetermined persistent bugs. Moreover, existing solutions are generally inefficient, hindering practical deployment.In this paper, we present FIRestarter (Fault Injection-based Restarter), an efficient and automatic crash recovery solution for commodity user applications. To eliminate the need for manual annotations, FIRestarter injects targeted software faults at the library interface to automatically trigger error handling code for standard library calls already part of the application. In particular, when a crash occurs, we roll back the application state before the last recoverable library call, inject a fault, and restart execution forcing the call to immediately return a predetermined error code. This strategy allows the application to automatically bypass the crashing code upon such a restart and exploits existing error-handling code to recover from even persistent bugs. Moreover, since library calls lie pervasively throughout the code, our design provides a large recovery surface despite the automated approach. Finally, FIRestarter’s recovery windows are small and frequent compared to traditional checkpoint-restart, which enables new optimizations such as the ability to support rollback by means of hybrid hardware/software transactional memory instrumentation and improve performance. We apply FIRestarter to a number of event-driven server applications and show our solution achieves near-instantaneous, state-preserving crash recovery in the face of even persistent crashes. On popular web servers, our evaluation results show a recovery surface of at least 77%, with low performance overhead of at most 17%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管软件测试取得了进步，但许多错误仍然困扰着已部署的软件，导致崩溃，从而中断高可用性生产应用程序中的服务。现有的崩溃恢复解决方案要么局限于瞬时故障，要么需要手动注释来针对预定的持续错误。此外，现有的解决方案通常效率低下，阻碍了实际部署。在本文中，我们介绍了FIRestarter(基于故障注入的重启程序)，这是一个面向商业用户应用的高效、自动的故障恢复解决方案。为了消除手动注释的需要，FIRestarter在库接口上注入有针对性的软件错误，以自动触发应用程序中已有的标准库调用的错误处理代码。特别是，当崩溃发生时，我们回滚到最后一次可恢复库调用之前的应用程序状态，注入一个错误，并重新开始执行，迫使调用立即返回一个预定的错误代码。这种策略允许应用程序在重启时自动绕过崩溃代码，并利用现有的错误处理代码来恢复甚至是持久的错误。此外，由于库调用普遍存在于整个代码中，尽管采用了自动化方法，我们的设计还是提供了一个大的恢复面。最后，与传统的检查点重启相比，FIRestarter的恢复窗口小而频繁，这实现了新的优化，如通过混合硬件/软件事务内存工具支持回滚的能力，并提高了性能。我们将FIRestarter应用于许多事件驱动的服务器应用程序，并展示了我们的解决方案在面临持续崩溃时实现了近乎即时的状态保持崩溃恢复。在流行的web服务器上，我们的评估结果显示至少77%的恢复面，最多17%的低性能开销。",
                    "title_zh": "FIRestarter:具有目标库级故障注入的实用软件崩溃恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00049",
                    "title": "WazaBee: attacking Zigbee networks by diverting Bluetooth Low Energy chips",
                    "authors": "Romain Cayre, Florent Galtier, Guillaume Auriol, Vincent Nicomette, Mohamed Kaâniche, Géraldine Vache Marconato",
                    "abstract": "This paper discusses the security of wireless communication protocols of the Internet of Things (IoT) and presents a new attack targeting these protocols, called WazaBee, which could have a critical impact and be difficult to detect. Specifically, WazaBee is a pivotal attack aimed at hijacking BLE devices, commonly used in IoT networks, in order to communicate with and possibly attack through a different wireless network technology, considering protocols based on 802.15.4, in particular Zigbee. We present the key principles of the attack and describe some real-world experiments that allowed us to demonstrate its practical feasibility. The attack takes advantage of the compatibility that exists between the two modulation techniques used by these two protocols. Finally, the paper briefly discusses possible countermeasures to mitigate the impact of this attack.",
                    "files": {
                        "openAccessPdf": "https://hal.laas.fr/hal-03193299/file/wazabee_final.pdf"
                    },
                    "abstract_zh": "本文讨论了物联网无线通信协议的安全性，并提出了一种针对这些协议的新攻击，称为WazaBee，它可能会产生严重的影响，并且难以检测。具体来说，WazaBee是一种关键的攻击，旨在劫持物联网网络中常用的BLE设备，以便通过不同的无线网络技术进行通信并可能进行攻击，考虑到基于802.15.4的协议，特别是Zigbee。我们介绍了攻击的关键原理，并描述了一些真实世界的实验，这些实验使我们能够展示其实际可行性。这种攻击利用了这两种协议使用的两种调制技术之间的兼容性。最后，本文简要讨论了减轻这种攻击影响的可能对策。",
                    "title_zh": "WazaBee:通过转移蓝牙低能耗芯片攻击Zigbee网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00050",
                    "title": "InjectaBLE: Injecting malicious traffic into established Bluetooth Low Energy connections",
                    "authors": "Romain Cayre, Florent Galtier, Guillaume Auriol, Vincent Nicomette, Mohamed Kaâniche, Géraldine Vache Marconato",
                    "abstract": "Bluetooth Low Energy (BLE) is nowadays one of the most popular wireless communication protocols for Internet of Things (IoT) devices. As a result, several attacks have targeted this protocol or its implementations in recent years, illustrating the growing interest for this technology. However, some major challenges remain from an offensive perspective, such as injecting arbitrary frames, hijacking the Slave role or performing a Manin-The-Middle in an already established connection. In this paper, we describe a novel attack called InjectaBLE, allowing to inject malicious traffic into an existing connection. This attack is highly critical as the vulnerability exploited is inherent to the BLE specification itself, which means that any BLE connection can be possibly vulnerable, regardless of the BLE devices involved in the connection. We describe the theoretical foundations of the attack, how to implement it in practice, and we explore four critical attack scenarios allowing to maliciously trigger a specific feature of the target device, hijack the Slave and Master role or to perform a Man-in-the-Middle attack. Finally, we discuss the impact of this attack and outline some mitigation measures.",
                    "files": {
                        "openAccessPdf": "https://hal.laas.fr/hal-03193297v2/file/injectable_final_version.pdf"
                    },
                    "abstract_zh": "蓝牙低能耗(BLE)是目前物联网设备最流行的无线通信协议之一。因此，近年来已经出现了几起针对该协议或其实现的攻击，这表明了对该技术的兴趣日益增长。然而，从攻击的角度来看，仍然存在一些重大挑战，例如注入任意帧、劫持从属角色或在已经建立的连接中执行中间人操作。在本文中，我们描述了一种称为可注入的新型攻击，它允许将恶意流量注入到现有连接中。这种攻击非常严重，因为被利用的漏洞是ble规范本身固有的，这意味着任何BLE连接都可能易受攻击，无论连接中涉及的BLE设备如何。我们描述了攻击的理论基础，如何在实践中实施，并探讨了四种关键的攻击场景，这些场景允许恶意触发目标设备的特定功能，劫持从设备和主设备角色或执行中间人攻击。最后，我们讨论了这种攻击的影响，并概述了一些缓解措施。",
                    "title_zh": "可注入:将恶意流量注入已建立的蓝牙低能耗连接"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00051",
                    "title": "Glitching Demystified: Analyzing Control-flow-based Glitching Attacks and Defenses",
                    "authors": "Chad Spensky, Aravind Machiry, Nathan Burow, Hamed Okhravi, Rick Housley, Zhongshu Gu, Hani Jamjoom, Christopher Kruegel, Giovanni Vigna",
                    "abstract": "Hardware fault injection, or glitching, attacks can compromise the security of devices even when no software vulnerabilities exist. Attempts to analyze the hardware effects of glitching are subject to the Heisenberg effect and there is typically a disconnect between what people “think” is possible and what is actually possible with respect to these attacks. In this work, we attempt to provide some clarity to the impacts of attacks and defenses for control-flow modification through glitching. First, we introduce a glitching emulation framework, which provides a scalable playground to test the effects of bit flips on specific instruction set architectures (ISAs) (i.e., the fault tolerance of the instruction encoding). Next, we examine real glitching experiments using the ChipWhisperer, a popular microcontroller using open-source glitching hardware. These real-world experiments provide novel insights into how glitching attacks are realized and might be defended against in practice. Finally, we present GLITCHRESISTOR, an open-source, software-based glitching defense tool that can automatically insert glitching defenses into any existing source code, in an architecture-independent way. We evaluated GLITCHRESISTOR, which integrates numerous software-only defenses against powerful and real-world glitching attacks. Our findings indicate that software-only defenses can be implemented with acceptable run-time and size overheads, while completely mitigating some single-glitch attacks, minimizing the likelihood of a successful multi-glitch attack (i.e., a success rate of 0.000306%), and detecting failed glitching attempts at a high rate (between 79.2% and 100%).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "即使不存在软件漏洞，硬件故障注入或故障攻击也会危及设备的安全性。试图分析故障的硬件影响会受到海森堡效应的影响，人们“认为”的可能性与这些攻击的实际可能性之间通常存在脱节。在这项工作中，我们试图通过故障为控制流修改的攻击和防御的影响提供一些清晰度。首先，我们引入一个故障仿真框架，它提供了一个可扩展的平台来测试位翻转对特定指令集架构(isa)的影响(即指令编码的容错)。接下来，我们使用ChipWhisperer检查真实的毛刺实验，ChipWhisperer是一种使用开源毛刺硬件的流行微控制器。这些真实世界的实验为如何实现毛刺攻击以及如何在实践中防御毛刺攻击提供了新的见解。最后，我们介绍GLITCHRESISTOR，这是一个开源的、基于软件的毛刺防御工具，它可以以独立于架构的方式自动将毛刺防御插入到任何现有的源代码中。我们评估了GLITCHRESISTOR，它集成了许多针对强大的真实世界故障攻击的纯软件防御措施。我们的研究结果表明，纯软件防御可以以可接受的运行时间和大小开销来实施，同时完全减轻一些单毛刺攻击，最小化成功的多毛刺攻击的可能性(即，0.000306%的成功率)，并以高比率(在79.2%和100%之间)检测失败的毛刺尝试。",
                    "title_zh": "故障揭秘:分析基于控制流的故障攻击和防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00052",
                    "title": "Practical and Efficient in-Enclave Verification of Privacy Compliance",
                    "authors": "Weijie Liu, Wenhao Wang, Hongbo Chen, Xiaofeng Wang, Yaosong Lu, Kai Chen, Xinyu Wang, Qintao Shen, Yi Chen, Haixu Tang",
                    "abstract": "A trusted execution environment (TEE) such as Intel Software Guard Extension (SGX) runs attestation to prove to a data owner the integrity of the initial state of an enclave, including the program to operate on her data. For this purpose, the data-processing program is supposed to be open to the owner or a trusted third party, so its functionality can be evaluated before trust being established. In the real world, however, increasingly there are application scenarios in which the program itself needs to be protected (e.g., proprietary algorithm). So its compliance with privacy policies as expected by the data owner should be verified without exposing its code.To this end, this paper presents DEFLECTION, a new model for TEE-based delegated and flexible in-enclave code verification. Given that the conventional solutions do not work well under the resource-limited and TCB-frugal TEE, we come up with a new design inspired by Proof-Carrying Code. Our design strategically moves most of the workload to the code generator, which is responsible for producing easy-to-check code, while keeping the consumer simple. Also, the whole consumer can be made public and verified through a conventional attestation. We implemented this model on Intel SGX and demonstrate that it introduces a very small part of TCB. We also thoroughly evaluated its performance on micro-and macro-benchmarks and real-world applications, showing that the design only incurs a small overhead when enforcing several categories of security policies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "诸如英特尔软件保护扩展(SGX)之类的可信执行环境(TEE)运行证明，以向数据所有者证明enclave初始状态的完整性，包括对其数据进行操作的程序。出于这个目的，数据处理程序应该对所有者或受信任的第三方开放，因此可以在建立信任之前评估其功能。然而，在现实世界中，越来越多的应用场景需要保护程序本身(例如，专有算法)。因此，应该在不暴露代码的情况下验证它是否符合数据所有者所期望的隐私策略。为此，本文提出了偏转，一种新的基于TEE的委托和灵活的飞地内代码验证模型。鉴于传统的解决方案在资源有限和TCB节俭的情况下效果不佳，我们提出了一种受验证代码启发的新设计。我们的设计战略性地将大部分工作转移到代码生成器，代码生成器负责生成易于检查的代码，同时保持消费者的简单性。此外，整个消费者可以公开，并通过常规证明进行验证。我们在英特尔SGX上实现了这一模型，并证明它只引入了TCB的很小一部分。我们还全面评估了它在微观和宏观基准以及真实应用程序上的性能，结果表明，在实施几类安全策略时，该设计只会产生少量开销。",
                    "title_zh": "实用高效的隐私合规性内部验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00053",
                    "title": "ADAM-CS: Advanced Asynchronous Monotonic Counter Service",
                    "authors": "André Martin, Cong Lian, Franz Gregor, Robert Krahn, Valerio Schiavoni, Pascal Felber, Christof Fetzer",
                    "abstract": "Trusted execution environments (TEEs) offer the technological breakthrough to allow several applications to be deployed and executed over untrusted public cloud environments. Although TEEs (e. g., Intel SGX, ARM TrustZone, AMD SEV) provide several mechanisms to ensure confidentiality and integrity of data and code, they do not offer freshness out of the box, a critical aspect yet often overlooked, for instance, to protect against rollback attacks. Monotonic counters are a popular way to detect rollbacks, as their counter values cannot be decremented. However, counter increments are slow (i.e., 10th of milliseconds), making their use impractical for distributed services and applications processing thousands of transactions simultaneously, for which an order of magnitude improvement is needed. ADAM-CS is an asynchronous monotonic counter service to protect such high-traffic applications against rollback attacks. Leveraging a set of distributed monotonic counters and specific algorithms, ADAM-CS minimizes the maximum vulnerability window (MVW), i.e., the amount of transactions an adversary could successfully rollback. Thanks to its asynchronous nature, ADAM-CS supports thousands of increments per second without introducing additional latency in the transactions performed by applications. Our measurements indicate that we can keep the MVW well below 10ms while supporting a throughput of more than 21K requests/s when using eight counters.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可信执行环境(TEEs)提供了技术突破，允许在不可信的公共云环境上部署和执行多个应用程序。尽管tee(例如，英特尔SGX、ARM TrustZone、AMD SEV)提供了多种机制来确保数据和代码的机密性和完整性，但它们并不提供开箱即用的新鲜度，这是一个经常被忽视的关键方面，例如，防止回滚攻击。单调计数器是检测回滚的常用方法，因为它们的计数器值不能递减。然而，计数器增量很慢(即，几十分之一毫秒)，这使得它们的使用对于同时处理数千个事务的分布式服务和应用来说是不切实际的，这需要数量级的改进。ADAM-CS是一种异步单调计数器服务，用于保护此类高流量应用免受回滚攻击。利用一组分布式单调计数器和特定算法，ADAM-CS最小化最大漏洞窗口(MVW)，即对手可以成功回滚的交易量。由于其异步特性，ADAM-CS支持每秒数千个增量，而不会给应用程序执行的事务带来额外的延迟。我们的测量表明，当使用八个计数器时，我们可以将MVW保持在10ms以下，同时支持超过21K请求/s的吞吐量。",
                    "title_zh": "ADAM-CS:高级异步单调计数器服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00054",
                    "title": "EncDBDB: Searchable Encrypted, Fast, Compressed, In-Memory Database Using Enclaves",
                    "authors": "Benny Fuhry, Jayanth Jain H. A, Florian Kerschbaum",
                    "abstract": "Data confidentiality is an important requirement for clients when outsourcing databases to the cloud. Trusted execution environments, such as Intel SGX, offer an efficient solution to this confidentiality problem. However, existing TEE-based solutions are not optimized for column-oriented, in-memory databases and pose impractical memory requirements on the enclave. We present EncDBDB, a novel approach for client-controlled encryption of a column-oriented, in-memory databases allowing range searches using an enclave. EncDBDB offers nine encrypted dictionaries, which provide different security, performance, and storage efficiency tradeoffs for the data. It is especially suited for complex, read-oriented, analytic queries as present, e.g., in data warehouses. The computational overhead compared to plaintext processing is within a millisecond even for databases with millions of entries and the leakage is limited. Compressed encrypted data requires less space than a corresponding plaintext column. Furthermore, EncDBDB’s enclave is very small reducing the potential for security-relevant implementation errors and side-channel leakages.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2002.05097"
                    },
                    "abstract_zh": "当将数据库外包给云时，数据机密性是客户的一个重要要求。英特尔SGX等可信执行环境为这一保密性问题提供了有效的解决方案。然而，现有的基于TEE的解决方案并没有针对面向列的内存数据库进行优化，并且对enclave提出了不切实际的内存需求。我们提出了EncDBDB，这是一种客户端控制的面向列的内存数据库加密的新方法，允许使用enclave进行范围搜索。EncDBDB提供了九个加密字典，它们为数据提供了不同的安全性、性能和存储效率。它特别适合于复杂的、面向读取的分析查询，例如在数据仓库中。与明文处理相比，即使对于具有数百万条目的数据库，计算开销也在一毫秒之内，并且泄漏是有限的。压缩的加密数据比相应的明文列需要更少的空间。此外，EncDBDB的enclave非常小，减少了安全相关的实现错误和旁路泄漏的可能性。",
                    "title_zh": "EncDBDB:使用Enclaves的可搜索加密、快速、压缩的内存数据库"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00055",
                    "title": "Conservative Confidence Bounds in Safety, from Generalised Claims of Improvement & Statistical Evidence",
                    "authors": "Kizito Salako, Lorenzo Strigini, Xingyu Zhao",
                    "abstract": "“Proven-in-use”, “globally-at-least-equivalent”, “stress-tested”, are concepts that come up in diverse contexts in acceptance, certification or licensing of critical systems. Their common feature is that dependability claims for a system in a certain operational environment are supported, in part, by evidence – viz of successful operation – concerning different, though related, system[s] and/or environment[s], together with an auxiliary argument that the target system/environment offers the same, or improved, safety. We propose a formal probabilistic (Bayesian) organisation for these arguments. Through specific examples of evidence for the “improvement” argument above, we demonstrate scenarios in which formalising such arguments substantially increases confidence in the target system, and show why this is not always the case. Example scenarios concern vehicles and nuclear plants. Besides supporting stronger claims, the mathematical formalisation imposes precise statements of the bases for “improvement” claims: seemingly similar forms of prior beliefs are sometimes revealed to imply substantial differences in the claims they can support.",
                    "files": {
                        "openAccessPdf": "https://openaccess.city.ac.uk/id/eprint/26128/1/DSN2021_178_PostReview.pdf"
                    },
                    "abstract_zh": "“经过使用验证”、“至少全球等效”、“经过压力测试”，这些概念出现在关键系统的验收、认证或许可的不同背景下。它们的共同特点是，在某一操作环境中，系统的可靠性声明部分地由证据支持——即成功操作的证据——涉及不同但相关的系统和/或环境，以及一个辅助论点，即目标系统/环境提供相同或改进的安全性。我们提出了一个正式的概率(贝叶斯)组织这些论点。通过上述“改进”论证的具体例子，我们展示了正式化这种论证大大增加了对目标系统的信心的情景，并展示了为什么情况并非总是如此。示例场景涉及车辆和核电站。除了支持更强有力的主张之外，数学形式化还对“改进”主张的基础进行了精确的陈述:看似相似的先前信念形式有时被揭示为暗示它们所能支持的主张中的实质性差异。",
                    "title_zh": "安全性的保守置信界限，来自改进的概括声明和统计证据"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00056",
                    "title": "Model Checking the Multi-Formalism Language FIGARO",
                    "authors": "Shahid Khan, Matthias Volk, Joost-Pieter Katoen, Alexis Braibant, Marc Bouissou",
                    "abstract": "This paper presents a probabilistic model-checking tool for FIGARO, a multi-formalism modelling language that includes e.g., generalised stochastic Petri nets, Boolean-logic driven Markov processes, telecommunication networks, dynamic reliability block diagrams, process diagrams, and electric circuits. FIGARO has been developed and maintained by EDF for the analysis of system dependability such as reliability, availability and maintainability. We present a probabilistic model-checking tool for FIGARO models. It combines efficient, fully automated verification algorithms with numerical analysis techniques. Whereas the existing FIGARO tools, the Monte Carlo simulator YAMS and the most-probable-sequence explorer FiGSEQ, provide respectively statistical guarantees and upper bounds for unreliability and unavailability, our tool provides hard guarantees: its results are correct up to a given numerical accuracy. The key ingredient is the tool-component FiGAROAPI that enables the state-space generation for FIGARO models thus facilitating model checking. This paper describes the details of FiGAROAPI and empirically evaluates the feasibility and merits of the proposed framework. FiGAROAPI leverages upon the state-of-the-art STORM model checker as back-end, and it can model check various types of formalism in their FIGARO representation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了一个用于FIGARO的概率模型检查工具，FIGARO是一种多形式建模语言，包括例如广义随机Petri网、布尔逻辑驱动的马尔可夫过程、电信网络、动态可靠性框图、过程图和电路。FIGARO由EDF开发和维护，用于分析系统可靠性，如可靠性、可用性和可维护性。我们提出了一个费加罗模型的概率模型检验工具。它将高效的全自动验证算法与数值分析技术相结合。现有的FIGARO工具，Monte Carlo simulator YAMS和最可能序列探测器FiGSEQ，分别提供了不可靠性和不可用性的统计保证和上限，而我们的工具提供了硬保证:其结果在给定的数值精度内是正确的。关键要素是工具组件FiGAROAPI，它支持FIGARO模型的状态空间生成，从而有助于模型检查。本文描述了FiGAROAPI的细节，并对提出的框架的可行性和优点进行了实证评估。FiGAROAPI利用最先进的STORM模型检查器作为后端，它可以对FIGARO表示中的各种形式主义进行模型检查。",
                    "title_zh": "多形式语言的模型检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00057",
                    "title": "Avis: In-Situ Model Checking for Unmanned Aerial Vehicles",
                    "authors": "Max Taylor, Haicheng Chen, Feng Qin, Christopher Stewart",
                    "abstract": "Control firmware in unmanned aerial vehicles (UAVs) uses sensors to model and manage flight operations, from takeoff to landing to flying between waypoints. However, sensors can fail at any time during a flight. If control firmware mishandles sensor failures, UAVs can crash, fly away, or suffer other unsafe conditions. In-situ model checking finds sensor failures that could lead to unsafe conditions by systematically failing sensors. However, the type of sensor failure and its timing within a flight affect its manifestation, creating a large search space. We propose Avis, an in-situ model checker to quickly uncover UAV sensor failures that lead to unsafe conditions. Avis exploits operating modes, i.e., a label that maps software execution to corresponding flight operations. Widely used control firmware already support operating modes. Avis injects sensor failures as the control firmware transitions between modes – a key execution point where mishandled software exceptions can trigger unsafe conditions. We implemented Avis and applied it to ArduPilot and PX4. Avis found unsafe conditions 2.4X faster than Bayesian Fault Injection, the leading, state-of-theart approach. Within the current code base of ArduPilot and PX4, Avis discovered 10 previously unknown software bugs that lead to unsafe conditions. Additionally, we reinserted 5 known bugs that caused serious, unsafe conditions and Avis correctly reported all of them.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2106.14959"
                    },
                    "abstract_zh": "无人驾驶飞行器(UAV)中的控制固件使用传感器来模拟和管理飞行操作，从起飞到着陆，再到在航路点之间飞行。然而，传感器在飞行过程中随时都可能发生故障。如果控制固件错误处理传感器故障，无人机可能会坠毁，飞走，或遭受其他不安全的情况。原位模型检查通过系统地使传感器发生故障来发现可能导致不安全状况的传感器故障。然而，传感器故障的类型及其在飞行中的时间会影响其表现，从而产生很大的搜索空间。我们建议使用Avis，一种原位模型检查器来快速发现导致不安全状况的UAV传感器故障。Avis利用操作模式，即一个将软件执行映射到相应飞行操作的标签。广泛使用的控制固件已经支持操作模式。当控制固件在模式之间转换时，Avis会注入传感器故障，这是一个关键的执行点，处理不当的软件异常会触发不安全的情况。我们实现了Avis，并将其应用于ArduPilot和PX4。Avis发现不安全状况的速度比领先的先进方法贝叶斯故障注入快2.4倍。在ArduPilot和PX4的当前代码库中，Avis发现了10个以前未知的软件错误，这些错误会导致不安全的情况。此外，我们重新插入了5个导致严重不安全情况的已知错误，Avis正确地报告了所有这些错误。",
                    "title_zh": "Avis:无人驾驶飞行器的现场模型检验"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00058",
                    "title": "Data-driven Design of Context-aware Monitors for Hazard Prediction in Artificial Pancreas Systems",
                    "authors": "Xugui Zhou, Bulbul Ahmed, James H. Aylor, Philip Asare, Homa Alemzadeh",
                    "abstract": "Medical Cyber-physical Systems (MCPS) are vulnerable to accidental or malicious faults that can target their controllers and cause safety hazards and harm to patients. This paper proposes a combined model and data-driven approach for designing context-aware monitors that can detect early signs of hazards and mitigate them in MCPS. We present a framework for formal specification of unsafe system context using Signal Temporal Logic (STL) combined with an optimization method for patient-specific refinement of STL formulas based on real or simulated faulty data from the closed-loop system for the generation of monitor logic. We evaluate our approach in simulation using two state-of-the-art closed-loop Artificial Pancreas Systems (APS). The results show the context-aware monitor achieves up to 1.4 times increase in average hazard prediction accuracy (F1score) over several baseline monitors, reduces false-positive and false-negative rates, and enables hazard mitigation with a 54% success rate while decreasing the average risk for patients.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.02545"
                    },
                    "abstract_zh": "医疗信息物理系统(MCPS)容易受到意外或恶意故障的攻击，这些故障可能针对其控制器，并导致安全隐患和对患者的伤害。本文提出了一种结合模型和数据驱动的方法来设计环境感知监测器，该监测器可以检测早期灾害迹象并在MCPS减轻它们。我们提出了一个框架，用于使用信号时序逻辑(STL)的不安全系统上下文的形式规格说明，并结合了一种优化方法，用于基于来自闭环系统的真实或模拟故障数据对STL公式进行针对患者的细化，以生成监控逻辑。我们使用两个最先进的闭环人工胰腺系统(APS)在模拟中评估我们的方法。结果显示，与几个基线监测器相比，环境感知监测器的平均危险预测准确性(f1得分)提高了1.4倍，降低了假阳性和假阴性率，并以54%的成功率实现了危险缓解，同时降低了患者的平均风险。",
                    "title_zh": "用于人工胰腺系统中危险预测的上下文感知监视器的数据驱动设计"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00059",
                    "title": "Sanitizing the IoT Cyber Security Posture: An Operational CTI Feed Backed up by Internet Measurements",
                    "authors": "Morteza Safaei Pour, Dylan Watson, Elias Bou-Harb",
                    "abstract": "The Internet-of-Things (IoT) paradigm at large continues to be compromised, hindering the privacy, dependability, security, and safety of our nations. While the operational security communities (i.e., CERTS, SOCs, CSIRT, etc.) continue to develop capabilities for monitoring cyberspace, tools which are IoT-centric remain at its infancy. To this end, we address this gap by innovating an actionable Cyber Threat Intelligence (CTI) feed related to Internet-scale infected IoT devices. The feed analyzes, in near real-time, 3.6TB of daily streaming passive measurements ($\\approx$ 1M pps) by applying a custom-developed learning methodology to distinguish between compromised IoT devices and non-IoT nodes, in addition to labeling the type and vendor. The feed is augmented with third party information to provide contextual information. We report on the operation, analysis, and shortcomings of the feed executed during an initial deployment period. We make the CTI feed available for ingestion through a public, authenticated API and a front-end platform.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "物联网(IoT)范式总体上继续受到损害，阻碍了我们国家的隐私、可靠性、安全性和安全性。而运营安全团体(即CERTS、SOC、CSIRT等。)继续开发监控网络空间的能力，以物联网为中心的工具仍处于起步阶段。为此，我们通过创新与互联网规模的受感染物联网设备相关的可操作网络威胁情报(CTI)源来解决这一差距。除了标记类型和供应商之外，该馈送还通过应用定制开发的学习方法来区分受损的物联网设备和非物联网节点，从而近乎实时地分析3.6TB的每日流被动测量(约100万美元pps)。该订阅源用第三方信息增强以提供上下文信息。我们报告在初始部署期间执行的提要的操作、分析和缺点。我们通过一个公共的、经过认证的API和一个前端平台来提供CTI feed。",
                    "title_zh": "净化物联网网络安全态势:由互联网测量支持的操作CTI反馈"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00060",
                    "title": "Physics-Aware Security Monitoring against Structural Integrity Attacks in 3D Printers",
                    "authors": "Sriharsha Etigowni, Sizhuang Liang, Saman A. Zonouz, Raheem Beyah",
                    "abstract": "STereoLithography (STL) files describe the geometry of objects to be printed in additive manufacturing. Previous studies have shown that the STL files that describe functional objects can be attacked such that the objects appear normal during inspection, but fail during operation. Such attacks lead to damage to systems that use the objects and possibly loss of life. The detection of any defects caused due to the attacks nowadays is limited to the quality control process after the objects are manufactured.We present a Trusted Integrity Verifier (TIV) to detect such attacks on 3D printed objects in the early stage of the manufacturing process. These type of new attacks cannot be detected by traditional software security mechanisms since they only focus on the printers and do not consider the inputs (STL design files) to the printer. Early detection of attacks prevents from printing malicious objects resulting in saving time, resources and manufacturing efforts. TIV detects malicious STL files using multidisciplinary approaches unlike the traditional integrity verification techniques. TIV develops a void detection module based on computer vision techniques to identify the internal defects such as voids. Some of these features could be from the design and some could be due to the attack. To differentiate the malicious features from the design features, TIV develops safety verification module based on a numerical method. TIV’s safety verification module is used to differentiate the malicious features from the design features by calculating the load bearing mechanical stress on the objects. These mechanical stresses are compared to the safety operational conditions to determine if the printed object will break or fail during its normal operation.To illustrate TIV’s generality and scalability, we conducted a large-scale analysis on 16,000 real-world 3D print STL files. TIV verified the STL files successfully as either safe or malicious with high accuracy of 92% for object classification and 96.5% for void detection.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "立体平版印刷(STL)文件描述了在增材制造中要打印的对象的几何形状。先前的研究表明，描述功能对象的STL文件可以被攻击，使得对象在检查期间看起来正常，但在操作期间失败。这种攻击会对使用这些对象的系统造成损害，并可能导致生命损失。如今，对由攻击引起的任何缺陷的检测仅限于物品制造后的质量控制过程。我们提出了一种可信的完整性验证器(TIV ),用于在制造过程的早期阶段检测对3D打印对象的这种攻击。这些类型的新攻击不能被传统的软件安全机制检测到，因为它们只关注打印机而不考虑打印机的输入(STL设计文件)。攻击的早期检测可防止打印恶意对象，从而节省时间、资源和制造工作。与传统的完整性验证技术不同，TIV使用多学科的方法来检测恶意的STL文件。TIV开发了一个基于计算机视觉技术的空洞检测模块，用于识别内部缺陷，如空洞。这些特征中的一些可能来自设计，一些可能是由于攻击。为了区分恶意特征和设计特征，TIV开发了基于数值方法的安全验证模块。TIV的安全验证模块用于通过计算对象上的承载机械应力来区分恶意特征和设计特征。将这些机械应力与安全操作条件进行比较，以确定印刷物体在其正常操作期间是否会断裂或失效。为了说明TIV的通用性和可扩展性，我们对16，000个真实世界的3D打印STL文件进行了大规模分析。TIV成功地验证了STL文件是安全的还是恶意的，对象分类的准确率达到92%，空洞检测的准确率达到96.5%。",
                    "title_zh": "针对3D打印机中结构完整性攻击的物理感知安全监控"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00061",
                    "title": "Compromised Computers Meet Voice Assistants: Stealthily Exfiltrating Data as Voice over Telephony",
                    "authors": "Zhengxian He, Mohit Narayan Rajput, Mustaque Ahamad",
                    "abstract": "New security concerns arise due to the growing popularity of voice assistants (VA) in home and enterprise networks. We explore how malware infected computers can encode sensitive data into audio and leverage nearby VAs to exfiltrate it. Such low cost attacks can be launched remotely, at scale, and can bypass network defenses. By using Dual-Tone Multi-Frequency tones to encode data into audio that is played over ordinary computer speakers, modest amounts of data (e.g., a kilobyte) can be transmitted with a phone call lasting a few minutes. This can be done while making the audio nearly inaudible for most people. With the help of a prototype built by us, we experimentally assess the impact of several factors that impact data transfer rates and transmission accuracy achieved by such attacks. Our results show that voice assistants in the vicinity of computers can pose new threats to data stored on them.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于语音助手(VA)在家庭和企业网络中日益流行，出现了新的安全问题。我们探索了受恶意软件感染的计算机如何将敏感数据编码到音频中，并利用附近的虚拟设备对其进行渗透。这种低成本的攻击可以大规模远程发起，并且可以绕过网络防御。通过使用双音多频音将数据编码成通过普通计算机扬声器播放的音频，适量的数据(例如，一千字节)可以通过持续几分钟的电话呼叫来传输。这可以在大多数人几乎听不到音频的情况下完成。在我们构建的原型的帮助下，我们通过实验评估了影响此类攻击实现的数据传输率和传输准确性的几个因素的影响。我们的结果表明，电脑附近的语音助手会对电脑上存储的数据构成新的威胁。",
                    "title_zh": "被入侵的计算机遇到了语音助手:通过电话以语音的形式秘密地泄露数据"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00062",
                    "title": "BigMap: Future-proofing Fuzzers with Efficient Large Maps",
                    "authors": "Alif Ahmed, Jason D. Hiser, Anh Nguyen-Tuong, Jack W. Davidson, Kevin Skadron",
                    "abstract": "Coverage-guided fuzzing is a powerful technique for finding security vulnerabilities and latent bugs in software. Such fuzzers usually store the coverage information in a small bitmap. Hash collision within this bitmap is a well-known issue and can reduce fuzzers’ ability to discover potential bugs. Prior works noted that collision mitigation with naïvely enlarging the hash space leads to an unacceptable runtime overhead. This paper describes BigMap, a two-level hashing scheme that enables using an arbitrarily large coverage_bitmap with low overhead. The key observation is that the overhead stems from frequent operations performed on the full bitmap, although only a fraction of the map is actively used. BigMap condenses these scattered active regions on a second bitmap and limits the operations only on that condensed area. We implemented our approach on top of the popular fuzzer AFL and conducted experiments on 19 benchmarks from FuzzBench and OSS-Fuzz. The results indicate that BigMap does not suffer from increased runtime overhead even with large map sizes. Compared to AFL, BigMap achieved an average of 4.5x higher test case generation throughput for a 2MB map and 33.1x for an 8MB map. The throughput gain for the 2MB map increased further to 9.2x with parallel fuzzing sessions, indicating superior scalability of BigMap. More importantly, BigMap’s compatibility with most coverage metrics, along with its efficiency on bigger maps, enabled exploring aggressive compositions of expensive coverage metrics and fuzzing algorithms, uncovering 33% more unique crashes. BigMap makes using large bitmaps practical and enables researchers to explore a wider design space of coverage metrics",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "覆盖引导模糊化是一种发现软件安全漏洞和潜在缺陷的强大技术。这种模糊器通常将覆盖范围信息存储在一个小位图中。该位图中的哈希冲突是一个众所周知的问题，它会降低fuzzers发现潜在错误的能力。先前的工作指出，天真地扩大散列空间的冲突缓解会导致不可接受的运行时开销。本文描述了BigMap，这是一种两级哈希方案，能够以较低的开销使用任意大的coverage_bitmap。关键的观察是开销来自于在整个位图上执行的频繁操作，尽管只有一小部分位图被主动使用。BigMap将这些分散的活动区域压缩在第二个位图上，并将操作限制在该压缩区域上。我们在流行的fuzzer AFL上实现了我们的方法，并在FuzzBench和OSS-Fuzz的19个基准上进行了实验。结果表明，即使使用大的Map，BigMap也不会增加运行时开销。与AFL相比，BigMap在2MB map和8MB map上分别实现了平均4.5倍和33.1倍的测试用例生成吞吐量。通过并行模糊化会话，2MB map的吞吐量增益进一步提高到9.2倍，表明BigMap具有卓越的可伸缩性。更重要的是，BigMap与大多数覆盖指标的兼容性，以及它在更大地图上的效率，使人们能够探索昂贵的覆盖指标和模糊算法的积极组成，发现33%以上的独特崩溃。BigMap使得使用大位图变得可行，并使研究人员能够探索更广阔的覆盖度量设计空间",
                    "title_zh": "大地图:具有高效大地图的面向未来的模糊器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00063",
                    "title": "When Program Analysis Meets Bytecode Search: Targeted and Efficient Inter-procedural Analysis of Modern Android Apps in BackDroid",
                    "authors": "Daoyuan Wu, Debin Gao, Robert H. Deng, Rocky K. C. Chang",
                    "abstract": "Widely-used Android static program analysis tools, e.g., Amandroid and FlowDroid, perform the whole-app inter-procedural analysis that is comprehensive but fundamentally difficult to handle modern (large) apps. The average app size has increased three to four times over five years. In this paper, we explore a new paradigm of targeted inter-procedural analysis that can skip irrelevant code and focus only on the flows of security-sensitive sink APIs. To this end, we propose a technique called on-the-fly bytecode search, which searches the disassembled app bytecode text just in time when a caller needs to be located. In this way, it guides targeted (and backward) inter-procedural analysis step by step until reaching entry points, without relying on a whole-app graph. Such search-based inter-procedural analysis, however, is challenging due to Java polymorphism, callbacks, asynchronous flows, static initializers, and inter-component communication in Android apps. We overcome these unique obstacles in our context by proposing a set of bytecode search mechanisms that utilize flexible searches and forward object taint analysis. Atop this new inter-procedural analysis, we further adjust the traditional backward slicing and forward constant propagation to provide the complete dataflow tracking of sink API calls. We have implemented a prototype called BackDroid and compared it with Amandroid in analyzing 3,178 modern popular apps for crypto and SSL misconfigurations. The evaluation shows that for such sink-based problems, BackDroid is 37 times faster (2.13v.s. 78.15 minutes) and has no timed-out failure (v.s. 35% in Amandroid) while maintaining close or even better detection effectiveness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "广泛使用的Android静态程序分析工具，如Amandroid和FlowDroid，执行全面的整个应用程序间分析，但从根本上难以处理现代(大型)应用程序。在过去的五年中，应用程序的平均大小增加了三到四倍。在本文中，我们探索了一种新的有针对性的过程间分析范式，它可以跳过不相关的代码，只关注安全敏感的sink APIs流。为此，我们提出了一种称为动态字节码搜索的技术，当需要定位调用者时，它会及时搜索反汇编的应用程序字节码文本。通过这种方式，它一步一步地指导有针对性的(和向后的)过程间分析，直到到达入口点，而不依赖于整个应用程序图。然而，由于Java多态性、回调、异步流、静态初始化器和Android应用中的组件间通信，这种基于搜索的过程间分析具有挑战性。我们通过提出一组字节码搜索机制来克服我们上下文中的这些独特障碍，这些机制利用了灵活的搜索和转发对象污点分析。在这个新的过程间分析之上，我们进一步调整了传统的向后切片和向前常数传播，以提供对接收器API调用的完整数据流跟踪。我们实现了一个名为BackDroid的原型，并将其与Amandroid进行了比较，分析了3178个现代流行应用程序的加密和SSL错误配置。评估表明，对于这种基于sink的问题，BackDroid的速度快了37倍(2.13v.s. 78.15分钟)，并且没有超时故障(在Amandroid中为35%)，同时保持接近甚至更好的检测效率。",
                    "title_zh": "当程序分析遇到字节码搜索:BackDroid中现代Android应用程序的有针对性和高效的程序间分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00064",
                    "title": "Hiding in the Particles: When Return-Oriented Programming Meets Program Obfuscation",
                    "authors": "Pietro Borrello, Emilio Coppa, Daniele Cono D'Elia",
                    "abstract": "Largely known for attack scenarios, code reuse techniques at a closer look reveal properties that are appealing also for program obfuscation. We explore the popular return-oriented programming paradigm under this light, transforming program functions into ROP chains that coexist seamlessly with the surrounding software stack. We show how to build chains that can withstand popular static and dynamic deobfuscation approaches, evaluating the robustness and overheads of the design over common programs. The results suggest a significant amount of computational resources would be required to carry a deobfuscation attack for secret finding and code coverage goals.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2012.06658"
                    },
                    "abstract_zh": "众所周知的攻击场景，代码重用技术在更近的观察中揭示了对程序混淆也有吸引力的属性。我们在这种情况下探索流行的面向返回的编程范式，将程序功能转换为与周围软件堆栈无缝共存的ROP链。我们展示了如何构建能够承受流行的静态和动态去模糊方法的链，评估了设计的健壮性和开销。结果表明，为了实现秘密发现和代码覆盖的目标，进行去模糊攻击需要大量的计算资源。",
                    "title_zh": "隐藏在粒子中:当面向返回的编程遇到程序混淆时"
                },
                {
                    "url": "https://doi.org/10.1109/DSN48987.2021.00065",
                    "title": "Statically Detecting JavaScript Obfuscation and Minification Techniques in the Wild",
                    "authors": "Marvin Moog, Markus Demmel, Michael Backes, Aurore Fass",
                    "abstract": "JavaScript is both a popular client-side programming language and an attack vector. While malware developers transform their JavaScript code to hide its malicious intent and impede detection, well-intentioned developers also transform their code to, e.g., optimize website performance. In this paper, we conduct an in-depth study of code transformations in the wild. Specifically, we perform a static analysis of JavaScript files to build their Abstract Syntax Tree (AST), which we extend with control and data flows. Subsequently, we define two classifiers, benefitting from AST-based features, to detect transformed samples along with specific transformation techniques. Besides malicious samples, we find that transforming code is increasingly popular on Node.js libraries and client-side JavaScript, with, e.g., 90% of Alexa Top 10k websites containing a transformed script. This way, code transformations are no indicator of maliciousness. Finally, we showcase that benign code transformation techniques and their frequency both differ from the prevalent malicious ones.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "JavaScript既是一种流行的客户端编程语言，也是一种攻击媒介。虽然恶意软件开发者变换他们的JavaScript代码以隐藏其恶意意图并阻碍检测，但是善意的开发者也变换他们的代码以例如优化网站性能。在本文中，我们对代码转换进行了深入的研究。具体来说，我们对JavaScript文件执行静态分析，以构建它们的抽象语法树(AST)，我们用控制和数据流来扩展它。随后，我们定义了两个分类器，受益于基于AST的特征，以检测转换样本以及特定的转换技术。除了恶意样本，我们发现在Node.js库和客户端JavaScript上转换代码越来越受欢迎，例如，90%的Alexa Top 10k网站包含转换后的脚本。这样，代码转换就不是恶意的指示器。最后，我们展示了良性代码转换技术及其频率都不同于流行的恶意代码转换技术。",
                    "title_zh": "静态检测JavaScript混淆和缩小技术"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2021s.html",
            "conf_title": "51th DSN 2021: Taipei, Taiwan - Supplemental Volume",
            "conf_url": "https://doi.org/10.1109/DSN-S52858.2021",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00011",
                    "title": "Cleaning the NVD: Comprehensive Quality Assessment, Improvements, and Analyses",
                    "authors": "Afsah Anwar, Ahmed Abusnaina, Songqing Chen, Frank Li, David Mohaisen",
                    "abstract": "Vulnerability databases are vital sources of information on emergent software security concerns. How reliable and accurate are these databases though? This paper explores this question through the National Vulnerability Database (NVD), the U.S. government’s vulnerability repository that arguably serves as the industry standard. Our investigations uncover data inconsistency or incompleteness in the NVD that can impact its practical usage, by affecting information such as the vulnerability publication dates, the affected vendor and product names, severity scores, and vulnerability type fields. Preliminary results suggest shifting trends, unveiling common mistakes, suggestions, and strategies for their avoidance.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2006.15074"
                    },
                    "abstract_zh": "漏洞数据库是紧急软件安全问题的重要信息来源。这些数据库有多可靠和准确呢？本文通过国家漏洞数据库(NVD)来探讨这个问题，该数据库是美国政府的漏洞库，可以说是行业标准。我们的调查揭示了NVD中的数据不一致或不完整，这些数据会影响漏洞发布日期、受影响的供应商和产品名称、严重性分数和漏洞类型字段等信息，从而影响其实际用途。初步结果表明趋势正在转变，揭示了常见错误、建议以及避免这些错误的策略。",
                    "title_zh": "清洁NVD:综合质量评估、改进和分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00012",
                    "title": "Systemically Evaluating the Robustness of ML-based IoT Malware Detectors",
                    "authors": "Ahmed Abusnaina, Afsah Anwar, Sultan Alshamrani, Abdulrahman Alabduljabbar, Rhongho Jang, DaeHun Nyang, David Mohaisen",
                    "abstract": "The rapid growth of the Internet of Things (IoT) devices is paralleled by them being on the front-line of malicious attacks caused by malicious software. Machine learning (ML) algorithms, alongside the traditional signature-based methods, are typically used to detect malicious activities and behaviors. However, they are susceptible to malware evolution and sophistication, making them limited to the patterns that they have been trained upon. In this work, we systematically examine the state-of-the-art malware detection approaches using various representations, under a range of adversarial settings. Our preliminary analyses highlight the instability of the learning algorithms in learning patterns that distinguish the benign from the malicious. Our mutations with functionality-preserving operations, e.g., software stripping and binary padding, significantly deteriorate the accuracy of malware detectors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "与物联网(IoT)设备的快速增长并行的是，它们处于由恶意软件引起的恶意攻击的前沿。机器学习(ML)算法以及传统的基于签名的方法通常用于检测恶意活动和行为。但是，他们容易受到恶意软件演变和复杂性的影响，这使他们局限于他们接受过培训的模式。在这项工作中，我们系统地研究了在一系列敌对环境下使用各种表现形式的最新恶意软件检测方法。我们的初步分析强调了在区分良性和恶意的学习模式中学习算法的不稳定性。我们的功能保留操作(如软件剥离和二进制填充)的突变会显著降低恶意软件检测器的准确性。",
                    "title_zh": "系统评估基于最大似然的物联网恶意软件检测器的鲁棒性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00013",
                    "title": "Detecting Operational Adversarial Examples for Reliable Deep Learning",
                    "authors": "Xingyu Zhao, Wei Huang, Sven Schewe, Yi Dong, Xiaowei Huang",
                    "abstract": "The utilisation of Deep Learning (DL) raises new challenges regarding its dependability in critical applications. Sound verification and validation methods are needed to assure the safe and reliable use of DL. However, state-of-the-art debug testing methods on DL that aim at detecting adversarial examples (AEs) ignore the operational profile, which statistically depicts the software’s future operational use. This may lead to very modest effectiveness on improving the software’s delivered reliability, as the testing budget is likely to be wasted on detecting AEs that are unrealistic or encountered very rarely in real-life operation. In this paper, we first present the novel notion of “operational AEs” which are AEs that have relatively high chance to be seen in future operation. Then an initial design of a new DL testing method to efficiently detect “operational AEs” is provided, as well as some insights on our prospective research plan.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.06015"
                    },
                    "abstract_zh": "深度学习(DL)的利用对其在关键应用中的可靠性提出了新的挑战。需要良好的验证和确认方法来确保DL的安全可靠使用。然而，针对DL的最新调试测试方法旨在检测敌对实例(AEs ),忽略了操作剖面，该操作剖面从统计上描述了软件的未来操作用途。这可能导致提高软件交付可靠性的效果非常有限，因为测试预算可能会浪费在检测不切实际或在实际操作中很少遇到的不良事件上。在本文中，我们首先提出了“可操作AEs”的新概念，这是在未来操作中有相对高的机会被看到的AEs。然后提供了有效检测“操作性不良事件”的新DL测试方法的初步设计，以及对我们未来研究计划的一些见解。",
                    "title_zh": "检测用于可靠深度学习的操作对立示例"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00014",
                    "title": "Iteratively Checking Program Properties Involving Non-Boolean Values",
                    "authors": "Long Wang",
                    "abstract": "This paper presents our experience of iteratively checking program properties involving non-boolean values. We abstract a program into a set of transition rules and apply rewriting-logic based bounded model checker to do property computation. Exact values of integers and strings are captured in the abstract model of the program. Counterexamples found in the bounded model checking are used to refine the abstraction for pruning infeasible counterexamples. We demonstrated the effectiveness of the methodology by discovering a property violation in a real-world application (WuFTPD).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了我们迭代检查包含非布尔值的程序属性的经验。我们将程序抽象为一组转换规则，并使用基于重写逻辑的有界模型检测器来进行属性计算。整数和字符串的精确值在程序的抽象模型中被捕获。在有界模型检查中发现的反例被用来提炼用于修剪不可行反例的抽象。我们通过在现实世界的应用程序(WuFTPD)中发现一个属性违反来证明该方法的有效性。",
                    "title_zh": "迭代检查涉及非布尔值的程序属性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00015",
                    "title": "Negotiating PQC for DNSSEC",
                    "authors": "Kris Shrishak, Haya Shulman",
                    "abstract": "Domain Name System Security Extensions (DNSSEC) provides authentication and integrity to Domain Name System (DNS) through the use of digital signatures based on public-key cryptography. Quantum computers threaten public key cryptography and DNSSEC is unprepared. As the process to change algorithms in DNSSEC involves a lot of overhead, requires significant investment and takes many years, we advocate for deployment of long term cryptography for DNSSEC. In this work we explore the challenges and obstacles towards deployment of post-quantum signatures and explain that smooth adoption towards quantum-safe ciphers can be achieved with cipher-suite negotiation for DNSSEC.Cipher-suite negotiation, which DNSSEC currently does not support, ensures that the best cryptographic algorithms supported by the server and the resolver are used. Servers usually do not deprecate old algorithms because they are unaware whether resolvers support new algorithms. The signals in cipher-suite negotiation inform the servers and the resolvers of algorithm support that creates a feedback loop that could accelerate adoption of post-quantum signatures and the deprecation of old algorithms while preventing packet fragmentation. As a consequence, cipher-suite negotiation can contribute towards a greater adoption of DNSSEC.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "域名系统安全扩展(DNSSEC)通过使用基于公钥加密的数字签名为域名系统(DNS)提供身份验证和完整性。量子计算机威胁公钥密码学，DNSSEC毫无准备。由于在DNSSEC更改算法的过程涉及大量的开销，需要大量的投资，并且需要很多年，我们主张在DNSSEC部署长期加密技术。在这篇文章中，我们探索了部署后量子签名面临的挑战和障碍，并解释了通过DNSSEC的密码套件协商可以实现量子安全密码的顺利采用。DNSSEC目前不支持的密码组协商可确保使用服务器和解析器支持的最佳加密算法。服务器通常不反对旧算法，因为它们不知道解析器是否支持新算法。密码组协商中的信号通知服务器和解析器算法支持，该算法支持创建反馈环，该反馈环可以加速后量子签名的采用和旧算法的废弃，同时防止分组碎片。因此，密码组协商有助于更广泛地采用DNSSEC。",
                    "title_zh": "为DNSSEC谈判PQC"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00016",
                    "title": "Spatio-Temporal Split Learning",
                    "authors": "Joongheon Kim, Seunghoon Park, Soyi Jung, Seehwan Yoo",
                    "abstract": "Machine learning requires a large volume of sample data, especially when it is used in high-accuracy medical applications. However, patient records are one of the most sensitive private information that is not usually shared among institutes. This paper presents spatio-temporal split learning, a distributed deep neural network framework, which is a turning point in allowing collaboration among privacy-sensitive organizations. Our spatio-temporal split learning presents how distributed machine learning can be efficiently conducted with minimal privacy concerns. The proposed split learning consists of a number of clients and a centralized server. Each client has only has one hidden layer, which acts as the privacy-preserving layer, and the centralized server comprises the other hidden layers and the output layer. Since the centralized server does not need to access the training data and trains the deep neural network with parameters received from the privacy-preserving layer, privacy of original data is guaranteed. We have coined the term, spatio-temporal split learning, as multiple clients are spatially distributed to cover diverse datasets from different participants, and we can temporally split the learning process, detaching the privacy preserving layer from the rest of the learning process to minimize privacy breaches. This paper shows how we can analyze the medical data whilst ensuring privacy using our proposed multi-site spatio-temporal split learning algorithm on Coronavirus Disease-19 (COVID-19) chest Computed Tomography (CT) scans, MUsculoskeletal RAdiographs (MURA) X-ray images, and cholesterol levels.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/6287639/9312710/09524632.pdf"
                    },
                    "abstract_zh": "机器学习需要大量的样本数据，尤其是在高精度医疗应用中。然而，患者记录是最敏感的私人信息之一，通常不会在机构间共享。本文介绍了时空分裂学习，一个分布式深度神经网络框架，这是一个转折点，允许隐私敏感组织之间的合作。我们的时空分裂学习展示了分布式机器学习如何在最小的隐私问题下有效地进行。提议的分割学习包括多个客户端和一个中央服务器。每个客户端只有一个隐藏层，作为隐私保护层，中央服务器包括其他隐藏层和输出层。由于中央服务器不需要访问训练数据，并且使用从隐私保护层接收的参数来训练深度神经网络，因此保证了原始数据的隐私。我们创造了术语时空分割学习，因为多个客户端在空间上分布以覆盖来自不同参与者的不同数据集，我们可以在时间上分割学习过程，将隐私保护层与学习过程的其余部分分离，以最大限度地减少隐私泄露。本文展示了我们如何在冠状病毒疾病-19(新冠肺炎)胸部计算机断层扫描(CT)扫描、肌肉骨骼x光照片(MURA) X射线图像和胆固醇水平上使用我们提出的多站点时空分裂学习算法来分析医疗数据，同时确保隐私。",
                    "title_zh": "时空分裂学习"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00017",
                    "title": "Mitigation of Automotive Control Modules Hardware Replacement-based Attacks Through Hardware Signature",
                    "authors": "Franco Oberti, Ernesto Sánchez, Alessandro Savino, Filippo Parisi, Stefano Di Carlo",
                    "abstract": "Authentication of hardware modules connected through Controller Area Networks (CAN) in modern vehicles is becoming an increasing security issue. Untrusted modules introduced on the market may alter the secure boot infrastructure of a complex vehicle, thus completely compromising its security. This paper introduces the problem and highlights a preliminary idea for reaching better protection and preventing or limiting this category of attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在现代车辆中，通过控制器局域网(CAN)连接的硬件模块的认证正成为日益增加的安全问题。市场上引入的不可信模块可能会改变复杂车辆的安全启动基础设施，从而完全危及其安全性。本文介绍了这个问题，并强调了实现更好的保护以及防止或限制这类攻击的初步想法。",
                    "title_zh": "通过硬件签名减轻基于汽车控制模块硬件替换的攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00018",
                    "title": "Machine Learning Analysis of IP ID Applications",
                    "authors": "Haya Shulman, Shujie Zhao",
                    "abstract": "The IP identifier (IP ID) in the IP header has become enormously popular as a side channel leaking valuable information on destinations. In the recent decades, the researchers have exploited the IP ID in a variety of different applications, from estimating outgoing server traffic, to covert communication and to remotely understanding firewall rules and port status. However, the complexity of inferring IP ID due to high fluctuating traffic rates from multiple sources leaves it an open question how practical the applications that leverage IP ID are.We perform the first Internet wide study of IP ID behaviour in the Internet and evaluate how practical it is to build applications on top of IP ID. We analyse experimentally the applications on the dataset of IP ID values that we collected. We show that our SVM classifier can achieve the accuracy of the IP ID prediction of more than 99%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "IP报头中的IP标识符(IP ID)作为泄漏目的地的有价值信息的辅助通道已经变得非常流行。在最近几十年里，研究人员已经在各种不同的应用中开发了IP ID，从估计传出的服务器流量，到隐蔽通信和远程了解防火墙规则和端口状态。然而，由于来自多个来源的高波动流量率，推断IP ID的复杂性使得利用IP ID的应用程序有多实用成为一个公开的问题。我们对互联网中的IP ID行为进行了首次互联网范围的研究，并评估了在IP ID之上构建应用程序的可行性。我们实验性地分析了在我们收集的IP ID值数据集上的应用。我们表明，我们的SVM分类器可以实现超过99%的IP ID预测的准确性。",
                    "title_zh": "IP ID应用的机器学习分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00019",
                    "title": "S-ADA: Software as an Autonomous, Dependable and Affordable System",
                    "authors": "Kai-Yuan Cai, Kishor S. Trivedi, Beibei Yin",
                    "abstract": "ADA is a popular programming language that was named after Lady Ada Lovelace (1815-1852) and recommended by Department of Defense, USA, for development of large scale safety-critical software systems. In this Fast Abstract, ADA is reinterpreted as Autonomous, Dependable and Affordable. It is argued that future software systems should be ADA. A few affordable techniques are briefly described to highlight how to make software systems ADA.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "ADA是一种流行的编程语言，以阿达·洛芙莱斯女士(1815-1852)的名字命名，并由美国国防部推荐用于开发大型安全关键软件系统。在这篇简短的摘要中，ADA被重新解释为自主、可靠和负担得起。有人认为未来的软件系统应该是ADA。简要描述了一些负担得起的技术，以强调如何使软件系统成为ADA。",
                    "title_zh": "S-ADA:作为自主、可靠和可负担系统的软件"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00020",
                    "title": "Finding Web Application Vulnerabilities with an Ensemble Fuzzing",
                    "authors": "João Caseirito, Ibéria Medeiros",
                    "abstract": "Cyberattacks have been a constant on the Internet and their impact and cost have risen to billions of dollars. They are usually associated with the exploitation of vulnerabilities in web applications, the most common form of accessing services and organizations’ data. These applications support a myriad of services for handling multiples daily needs of our lives (e.g., social media, e-commerce, bank account access). There are currently almost 2 billion of websites active [1] and the number of vulnerabilities disclosed and associated with applications they handle continues growing [2] . Cross Site Scripting (XSS) and SQL injection (SQLi) are the two most prevalent web vulnerabilities and they pose the first place in OWASP Top 10 [3] . Although these vulnerability classes are really well known, they continue appearing in recent applications used by millions of consumers [4] .",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络攻击在互联网上一直存在，其影响和成本已经上升到数十亿美元。它们通常与利用web应用程序中的漏洞有关，web应用程序是访问服务和组织数据的最常见形式。这些应用程序支持各种服务，用于处理我们生活中的多种日常需求(例如，社交媒体、电子商务、银行账户访问)。目前有近20亿个活跃的网站[1],并且与它们处理的应用程序相关的漏洞数量还在继续增长[2]。跨站点脚本(XSS)和SQL注入(SQLi)是两种最普遍的web漏洞，它们在OWASP十大漏洞中排名第一[3]。尽管这些漏洞类别是众所周知的，但它们继续出现在最近被数百万消费者使用的应用程序中[4]。",
                    "title_zh": "利用集成模糊技术发现Web应用程序漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00021",
                    "title": "Towards Automated Software Testing with Generative Adversarial Networks",
                    "authors": "Xiujing Guo",
                    "abstract": "This paper discusses software testing methods based on Generative Adversarial Network (GAN). GAN is a generative model that can create new data instances that resemble training data. A GAN consists of a generator network and a discriminator network. In our testing scheme, the trained generator network is used as a test case generator. In addition, we propose a framework with GAN, which is a testing strategy used to increase the test coverage.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "讨论了基于生成对抗网络的软件测试方法。GAN是一个生成模型，可以创建类似于训练数据的新数据实例。一个GAN由一个发生器网络和一个鉴别器网络组成。在我们的测试方案中，经过训练的生成器网络被用作测试用例生成器。此外，我们提出了一个基于GAN的测试框架，这是一种用来提高测试覆盖率的测试策略。",
                    "title_zh": "用生成式对抗网络实现自动化软件测试"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00022",
                    "title": "A Useful Parametric Family to Characterize NHPP-based Software Reliability Models",
                    "authors": "Siqiao Li",
                    "abstract": "In this note, we attempt to use the Burr-type distributions to describe the software fault-detection time distribution, and develop somewhat different non-homogeneous Poisson process (NHPP)-based software reliability models (SRMs). From the viewpoints of the goodness-of-fit and predictive performances, we compare Burr-type NHPP-based SRMs with the existing ones having the well-known fault-detection time distributions. Throughout numerical examples with 16 software fault count data (8 time data and 8 group data) observed in actual software development projects, we show the usefulness of the Burr-type NHPP-based SRMs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在这篇文章中，我们试图使用毛刺型分布来描述软件故障检测时间分布，并开发了一些不同的非齐次泊松过程(NHPP)为基础的软件可靠性模型(SRMs)。从拟合优度和预测性能的角度，我们比较了基于Burr型NHPP的SRM和现有的具有众所周知的故障检测时间分布的SRM。通过在实际软件开发项目中观察到的16个软件故障计数数据(8个时间数据和8个组数据)的数值例子，我们展示了基于Burr型NHPP的SRMs的有效性。",
                    "title_zh": "表征基于NHPP的软件可靠性模型的有用参数族"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00023",
                    "title": "Model-based design, analysis and assessment framework for safety-critical systems",
                    "authors": "Kuen-Long Lu, Yung-Yuan Chen",
                    "abstract": "Safety-critical systems like autonomous driving systems, intelligent robotics and medical surgeon robots, require a stringent dependability while the systems are in operation. Therefore, the safety and reliability issues must be addressed in the development of safety-critical intelligent systems. Nevertheless, the incorporation of the safety/reliability requirements into the system will raise the design complexity apparently. Furthermore, the international safety standards only provide guidelines and lack concrete design methodology and flow. Therefore, developing an effective safety process to assist system engineers in tackling the complexity of the system design and verification, and in the meantime, satisfying the requirements of international safety standard, become an important and valuable research topic. In this study, we will propose a model-based safety-critical system design, analysis and assessment framework which incorporates fault tree-based weak-point analysis, system hardware architecture exploration and safety mechanism effectiveness assessment with model-implemented fault injection. Failure modes and diagnostic coverage analysis (FMEDA) report will be generated after performing the framework. The proposed framework can facilitate the system engineers in designing, assessing and enhancing the safety/robustness of a system with an efficient manner.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动驾驶系统、智能机器人和外科医生机器人等安全关键系统在运行时需要严格的可靠性。因此，在开发安全关键智能系统时，必须解决安全性和可靠性问题。然而，将安全/可靠性要求纳入系统将明显增加设计的复杂性。此外，国际安全标准仅提供指南，缺乏具体的设计方法和流程。因此，开发一个有效的安全过程来帮助系统工程师处理复杂的系统设计和验证，同时满足国际安全标准的要求，成为一个重要而有价值的研究课题。在本研究中，我们将提出一个基于模型的安全关键系统设计、分析和评估框架，该框架将基于故障树的弱点分析、系统硬件架构探索和安全机制有效性评估与模型实现的故障注入相结合。执行框架后，将生成故障模式和诊断覆盖分析(FMEDA)报告。该框架可帮助系统工程师有效地设计、评估和增强系统的安全性/稳健性。",
                    "title_zh": "安全关键系统的基于模型的设计、分析和评估框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00024",
                    "title": "On The Local Sensitivity Analysis for Phase Expansion",
                    "authors": "Jiahao Zhang",
                    "abstract": "This paper presents the local sensitivity for phase expansion. The purpose of phase expansion is to determine the phase-type (PH) parameters to approximate the original distribution with the fitted PH distribution. Since PH parameters are estimated from the original distribution, whose parameters may contain estimation errors, it is important to investigate the effects of variations in original parameters on PH parameters. In this paper, we focus on the local sensitivity of PH expansion to clarify such effects.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了相位展开的局部灵敏度。相位扩展的目的是确定相位类型(PH)参数，以用拟合的PH分布来近似原始分布。由于PH参数是从原始分布估计的，而原始分布的参数可能包含估计误差，因此研究原始参数的变化对PH参数的影响是很重要的。在本文中，我们将重点放在PH膨胀的局部敏感性，以阐明这种影响。",
                    "title_zh": "关于相位展开的局部灵敏度分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00025",
                    "title": "Designing Adversarial Attack and Defence for Robust Android Malware Detection Models",
                    "authors": "Hemant Rathore, Sanjay K. Sahay, Jasleen Dhillon, Mohit Sewak",
                    "abstract": "The last decade witnessed an exponential rise of Android smartphones and malware attacks on them. Researchers have investigated and proposed many promising malware detection models based on machine learning. However, these malware detection models are susceptible to adversarial attacks which threaten the Android security ecosystem. In this article, we propose to develop malware detection models which are more robust against adversarial attacks. We first designed an i-bit adversarial attack policy which achieved an average fooling rate of 51% with maximum ten modifications across twelve different malware detection models. Later we also propose an adversarial defence mechanism which enhanced the robustness of the malware detection models by reducing the fooling rate to one-third against the same adversarial attack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "过去十年见证了Android智能手机和恶意软件攻击的指数级增长。研究人员已经研究并提出了许多基于机器学习的有前途的恶意软件检测模型。然而，这些恶意软件检测模型容易受到威胁Android安全生态系统的对抗性攻击。在这篇文章中，我们提出开发恶意软件检测模型，更强大的对抗敌对攻击。我们首先设计了一个I位对抗性攻击策略，在12个不同的恶意软件检测模型中，通过最多10次修改，实现了51%的平均欺骗率。随后，我们还提出了一种对抗性防御机制，通过将相同对抗性攻击的愚弄率降低到三分之一，增强了恶意软件检测模型的鲁棒性。",
                    "title_zh": "为鲁棒的Android恶意软件检测模型设计对抗性攻击和防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00026",
                    "title": "AMD EPYC™ 7002 Series - A Processor with Improved Soft Error Resilience",
                    "authors": "Cristian Constantinescu",
                    "abstract": "Computing and networking equipment power most of the applications we use daily. Therefore, dependability of these systems is of utmost importance. The impact of the neutron induced soft errors on the AMD EPYC™ 7002 Series processor is examined in this paper. The architecture of the processor and fault/error handling mechanisms are briefly presented. The experimental setup, used at Los Alamos Neutron Science Center (LANSCE) for soft error characterization, is described and the test results are analyzed. Two workloads are employed in the accelerated measurements, the high performance Linpack (HPL) benchmark and the STREAM benchmark. The neutron impact is quantified by the mean-time to failure (MTTF). The AMD EPYC 7002 MTTF is also compared against the MTTF of the previous generation of processors, AMD EPYC™ 7001, and confidence intervals are derived. The OS error logs are collected throughout the experiment. The measurement results are discussed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "计算和网络设备驱动着我们日常使用的大多数应用程序。因此，这些系统的可靠性至关重要。本文研究了中子诱发的软错误对AMD EPYC 7002系列处理器的影响。简要介绍了处理器的体系结构和故障/错误处理机制。描述了美国洛斯阿拉莫斯中子科学中心用于软误差表征的实验装置，并对实验结果进行了分析。在加速测量中采用了两种工作负载，即高性能Linpack (HPL)基准测试和STREAM基准测试。中子影响通过平均故障时间(MTTF)量化。AMD EPYC 7002 MTTF还与上一代处理器AMD EPYC 7001的MTTF进行了比较，并得出了置信区间。在整个实验过程中收集操作系统错误日志。对测量结果进行了讨论。",
                    "title_zh": "AMD EPYC 7002系列-具有改进的软错误恢复能力的处理器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00027",
                    "title": "Near-Realtime Server Reboot Monitoring and Root Cause Analysis in a Large-Scale System",
                    "authors": "Fan Fred Lin, Bhargav Bolla, Eric Pinkham, Neil Kodner, Daniel Moore, Amol Desai, Sriram Sankar",
                    "abstract": "Large-scale Internet services run on a fleet of distributed servers, and the continuous availability of the hardware is key to the robustness of the services. Unplanned reboots disrupt the services running on the hardware and lower the fleet availability. Server reboots are also important signals that could indicate underlying issues such as memory leaks from the services, catastrophic hardware failures, and network or power disruptions at the datacenters.In this paper, we present an at-scale, near-realtime reboot monitoring framework built with multiple state-of-the-art data infrastructures, as well as machine learning-based anomaly detection and automated root cause analysis across hundreds of server attribute combinations. We observed that 1% of the reboots in our hardware fleet were associated with kernel panics and out-of-memory events, and these reboots exhibit strong locality temporally and across services",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大规模互联网服务运行在一群分布式服务器上，硬件的连续可用性是服务健壮性的关键。计划外重启会中断硬件上运行的服务，降低设备可用性。服务器重启也是重要的信号，可能表明潜在的问题，如服务的内存泄漏、灾难性硬件故障以及数据中心的网络或电源中断。在本文中，我们提出了一个大规模、接近实时的重启监控框架，该框架由多个最先进的数据基础架构以及基于机器学习的异常检测和跨数百种服务器属性组合的自动化根本原因分析构建而成。我们观察到，我们的硬件设备中有1%的重启与内核崩溃和内存不足事件有关，并且这些重启在时间上和跨服务上表现出很强的局部性",
                    "title_zh": "大规模系统中的近实时服务器重启监控和根本原因分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00028",
                    "title": "The Importance of Safety Invariants in Robustness Testing Autonomy Systems",
                    "authors": "Milda Zizyte, Casidhe Hutchison, Raewyn Duvall, Claire Le Goues, Philip Koopman",
                    "abstract": "Common testing approaches can involve unit tests that test for functionality, or robustness tests that check for software crashes. In the case of autonomy systems, we posit that robustness testing must involve invariant checking of safety properties to be effective, because passing unit tests and the absence of software crashes do not make a sufficient safety case. In this work, we present empirical data that shows a large proportion of bugs found in mature systems would not have been discovered without invariant checking; and, in most cases, represent physical safety violations of the systems. We also discuss common invariant violations we have seen while testing systems, to serve as a starting point for future testing efforts. We conclude that invariant checking is indeed important for autonomy systems and recommend that autonomy system test teams write safety specifications and invariant checkers in order to help assure that their projects are tested for safety.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "常见的测试方法包括测试功能的单元测试，或者检查软件崩溃的健壮性测试。在自治系统的情况下，我们假设健壮性测试必须包括安全属性的不变检查才能有效，因为通过单元测试和没有软件崩溃并不能构成充分的安全案例。在这项工作中，我们提出的经验数据表明，在成熟系统中发现的大部分错误如果没有不变量检查是不会被发现的；并且在大多数情况下，代表系统的物理安全违规。我们还讨论了我们在测试系统时看到的常见不变违例，作为未来测试工作的起点。我们得出结论，不变量检查对于autonomy系统确实很重要，并建议autonomy系统测试团队编写安全规范和不变量检查器，以帮助确保他们的项目得到安全测试。",
                    "title_zh": "安全不变量在自治系统健壮性测试中的重要性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00029",
                    "title": "BACGraph: Automatic Extraction of Object Relationships in the BACnet Protocol",
                    "authors": "Herson Esquivel-Vargas, Marco Caselli, Andreas Peter",
                    "abstract": "This work presents BACGRAPH, a tool that extracts relationships among configuration parameters of Building Automation and Control Systems (BACSs) implemented using the BACnet protocol (ISO 16484-5). BACnet models these configuration parameters as object data structures comprised of multiple properties, some of which contain references to other objects. Given the regular exchange of objects among devices, we leverage these explicit references to build a graph of BACnet objects exclusively from network traffic. We tested BACGRAPH using traffic collected from a real building located at the University of Twente. After analyzing 66.8 hours of traffic, the resulting graph is comprised of 13,733 nodes and 3,169 edges. Such a graph improves the system visibility that BACS administrators have over their infrastructure, which is crucial for troubleshooting and security.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "这项工作介绍了BACGRAPH，这是一个提取使用BACnet协议(ISO 16484-5)实现的楼宇自动化和控制系统(BACSs)的配置参数之间的关系的工具。BACnet将这些配置参数建模为由多个属性组成的对象数据结构，其中一些属性包含对其他对象的引用。考虑到设备间对象的定期交换，我们利用这些显式引用来构建专门来自网络流量的BACnet对象图。我们使用从位于特温特大学的真实建筑中收集的流量来测试BACGRAPH。在分析了66.8小时的流量后，结果图由13，733个节点和3，169条边组成。这样的图表提高了BACS管理员对其基础架构的系统可见性，这对故障排除和安全性至关重要。",
                    "title_zh": "BAC graph:BAC net协议中对象关系的自动提取"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00030",
                    "title": "A Matter of Trust: Verification of Security and Performance for Network Platform as a Service",
                    "authors": "Tim Alberdingk Thijm, Gary Atkinson, Lalita Jagadeesan, Marina Thottan",
                    "abstract": "Network platform as a Service (NPaaS) is an emerging concept in the telecommunications industry, in which services are deployed across a multitude of communication service provider (CSP) networks. In addition to connectivity requirements, these services will have associated and varied security and performance requirements. While such requirements must be verified across multiple CSP networks, CSPs will be selective about the degree of network information and guarantees they are willing to provide to NPaaS providers, application service providers, and other CSPs. Furthermore, all such providers are likely to be wary about network information or guarantees provided by CSPs with whom they do not have trust relationships. In this short paper, we present some challenges facing NPaaS security and performance, and demonstrate through an example case study how recent formal network verification techniques and the open-source network verification toolset NV can be used as a framework to verify security and performance requirements in an NPaaS context.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络平台即服务(NPaaS)是电信行业中的一个新兴概念，其中服务部署在众多通信服务提供商(CSP)网络中。除了连接性要求之外，这些服务还会有各种相关的安全和性能要求。虽然这些要求必须在多个CSP网络中进行验证，但CSP会对他们愿意向NPaaS提供商、应用服务提供商和其他CSP提供的网络信息和保证的程度进行选择。此外，所有此类提供商可能会对他们没有信任关系的通信服务提供商提供的网络信息或担保保持警惕。在这篇短文中，我们介绍了NPaaS安全和性能面临的一些挑战，并通过一个示例案例研究展示了如何使用最新的正式网络验证技术和开源网络验证工具集NV作为框架来验证NPaaS环境中的安全和性能要求。",
                    "title_zh": "信任问题:验证网络平台即服务的安全性和性能"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00031",
                    "title": "SymPLe: Complexity-Aware Design for Safety Critical I&C Systems",
                    "authors": "Richard Hite, Abhi Rajagopala, Smitha Gautham, Christopher J. Deloglos, Athira V. Jayakumar, Aidan G. Collins, Carl R. Elks, Matt Gibson",
                    "abstract": "Complexity significantly erodes confidence and trust in both the design and the operation of safety critical systems. During the design phase, complexity impedes the verification and certification processes that guarantee the prevention and control of system errors (or hazards) during operation. This paper presents a novel architectural framework, known as SymPLe, to manage the complexity of highly-assured systems. This framework explores the impact of architectural Complexity-Awareness during design to enhance the verifiability of a field-programmable gate array (FPGA) instrumentation and control (I&C) platform for nuclear power safety applications. SymPLe leverages model-based design and Complexity-Aware principles such that it is verifiable and implementable under IEC 61508-3 safety integrity level (SIL) 3/4 standards. An independent verification activity demonstrates the benefits of the Complexity-Aware design of the SymPLe overlay architecture.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "复杂性极大地削弱了对安全关键系统的设计和操作的信心和信任。在设计阶段，复杂性阻碍了确保在运行期间预防和控制系统错误(或危险)的验证和认证过程。本文提出了一种新的架构框架，称为SymPLe，用于管理高度可靠系统的复杂性。该框架探讨了设计期间架构复杂性意识的影响，以增强核电安全应用的现场可编程门阵列(FPGA)仪器仪表和控制(I&C)平台的可验证性。SymPLe利用基于模型的设计和复杂性感知原则，因此它在IEC 61508-3安全完整性等级(SIL) 3/4标准下是可验证和可实施的。一项独立的验证活动展示了SymPLe overlay架构的复杂性感知设计的优势。",
                    "title_zh": "安全关键I&C系统的复杂性感知设计"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00032",
                    "title": "Hardware Support for Low-Cost Memory Safety",
                    "authors": "Rick Boivie, Gururaj Saileshwar, Tong Chen, Benjamin Segal, Alper Buyuktosunoglu",
                    "abstract": "Programs written in C/C++ are vulnerable to memory-safety errors like buffer-overflows and use-after-free. While several mechanisms to detect such errors have been previously proposed, they suffer from a variety of drawbacks including poor performance, imprecise or probabilistic detection of errors, or requiring invasive changes to the binary-layout or source-code. Consequently, memory-safety errors continue to exist in production-software and are a principal cause of security problems.In our project at IBM, we worked on a minimally-invasive and low-cost hardware-based bounds-checking framework for preventing out-of-bounds accesses and use-after-free errors. The key idea is to re-purpose \"unused bits\" in a pointer to store an index into a bounds-information table that can be used to catch out-of-bounds errors and use-after-free errors without any change to the binary layout. Using this bounds-checking framework, we implement a design for preventing Out-of-Bounds accesses and Use-After-Free for heap-objects, that are responsible for the majority of memory-safety errors in the wild.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "用C/C++编写的程序容易出现内存安全错误，比如缓冲区溢出和释放后使用。虽然先前已经提出了检测这种错误的几种机制，但是它们都有各种缺点，包括性能差、错误检测不精确或不确定、或者需要对二进制布局或源代码进行侵入性改变。因此，内存安全错误继续存在于生产软件中，并且是安全问题的主要原因。在我们在IBM的项目中，我们致力于一个微创和低成本的基于硬件的边界检查框架，用于防止越界访问和释放后使用错误。关键思想是重新利用指针中的“未使用位”来将索引存储到边界信息表中，该表可用于捕捉越界错误和释放后使用错误，而无需对二进制布局进行任何更改。使用这个边界检查框架，我们实现了一个设计来防止堆对象的越界访问和释放后使用，这是造成大部分内存安全错误的原因。",
                    "title_zh": "低成本存储器安全的硬件支持"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00033",
                    "title": "SERMiner : A Framework for Early-stage Reliability Estimation for IBM Processors",
                    "authors": "Karthik Swaminathan, Ramon Bertran, Hans M. Jacobson, Pradip Bose, Matthias Pflanz, Doug Balazich",
                    "abstract": "Early stage modeling of processor reliability is a key feature in the design and manufacturing cycle of IBM server-class processors. In this paper, we present SERMiner, a highly adaptable methodology for early-stage processor reliability estimation. We demonstrate how this methodology can be used to evaluate potential processor vulnerability to soft errors. We carry out extensive evaluations to determine the vulnerability across a comprehensive suite of synthetic and real-world benchmarks and also show how this estimation evolves across different processor generations and stages of design.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "处理器可靠性的早期建模是IBM服务器级处理器的设计和制造周期中的一个关键特性。在这篇文章中，我们提出了SERMiner，一种高度适用于早期处理器可靠性评估的方法。我们演示了如何使用这种方法来评估处理器对软错误的潜在脆弱性。我们进行了广泛的评估，以确定一套综合的合成和真实基准的漏洞，并展示了这种评估如何在不同代处理器和设计阶段中演变。",
                    "title_zh": "ser miner:IBM处理器早期可靠性评估框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00034",
                    "title": "TQEA: Temporal Quantum Error Analysis",
                    "authors": "Betis Baheri, Daniel Chen, Bo Fang, Samuel Alexander Stein, Vipin Chaudhary, Ying Mao, Shuai Xu, Ang Li, Qiang Guan",
                    "abstract": "The growth of need of quantum computers in many domains such as machine learning, numerical scientific simulation and finance has urged the quantum computers to produce more stable and less error-prone results. However, to mitigate the impact of the noise inside each quantum device remains a present challenge. In this paper, we investigate the temporal behavior of noisy intermediate-scale quantum (NISQ) computer errors based on calibration data and the characteristics of individual devices. In particular, we collect calibration data of IBM-Q machines over 90 days and compare the quantum error robustness across processor types, quantum topology and quantum volumes. We analyze the aging effect by comparing the quantum error data from four IBM quantum computers during 2019-2021 showing that only one computer experienced significant error growth overtime. In this study, we simply analyze the collected data and run temporal test analysis to observe the behaviour of IBM-Q computers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "机器学习、数值科学模拟和金融等许多领域对量子计算机需求的增长促使量子计算机产生更稳定、更不易出错的结果。然而，减轻每个量子器件内部噪声的影响仍然是一个挑战。在本文中，我们基于校准数据和单个设备的特性，研究了噪声中尺度量子(NISQ)计算机误差的时间行为。特别是，我们收集了IBM-Q机器超过90天的校准数据，并比较了处理器类型、量子拓扑和量子卷之间的量子错误鲁棒性。我们通过比较2019-2021年期间四台IBM量子计算机的量子错误数据来分析老化效应，这些数据显示只有一台计算机随着时间的推移出现了明显的错误增长。在本研究中，我们简单地分析收集的数据，并运行时间测试分析来观察IBM-Q计算机的行为。",
                    "title_zh": "TQEA:时间量子误差分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00035",
                    "title": "Overdrive Fault Attacks on GPUs",
                    "authors": "Majid Sabbagh, Yunsi Fei, David R. Kaeli",
                    "abstract": "Graphics processing units (GPUs) are widely used to accelerate applications including cryptographic operations. The reliability and security of GPUs have become a concern. Prior work reported power and timing side-channel attacks on GPUs. In this paper, we present our project about a new class of fault attacks targeting modern GPUs, the overdrive fault attacks. This attack exploits voltage-frequency scaling features present on most commercial GPUs to introduce random faults during kernel execution. We demonstrate an effective fault- based attack on a commercial GPU, recovering the AES keys in minutes and inducing misclassifications in a CNN kernel. Such software-controlled fault injections also pose serious threats to data integrity and service availability in the cloud.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "图形处理单元(GPU)被广泛用于加速包括加密操作在内的应用。GPU的可靠性和安全性已经成为一个问题。先前的工作报告了对GPU的功率和定时旁路攻击。在本文中，我们提出了一种针对现代GPU的新型故障攻击——过载故障攻击。这种攻击利用大多数商用GPU上存在的电压频率缩放功能，在内核执行期间引入随机故障。我们演示了一种对商用GPU的有效的基于错误的攻击，在几分钟内恢复AES密钥，并在CNN内核中引起错误分类。这种软件控制的故障注入也对云中的数据完整性和服务可用性构成严重威胁。",
                    "title_zh": "对GPU的超速故障攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S52858.2021.00036",
                    "title": "Simulation-based Fault Injection in Advanced Driver Assistance Systems Modelled in SUMO",
                    "authors": "Mehdi Maleki, Behrooz Sangchoolie",
                    "abstract": "Embedded electronic systems used in vehicles are becoming more exposed and thus vulnerable to different types of faults and cybersecurity attacks. Examples of these systems are advanced driver assistance systems (ADAS). Failures in these systems could have severe consequences. Therefore, these systems should be thoroughly evaluated during different stages of product development. An effective way of evaluating these systems is through the injection of faults and monitoring their impacts on these systems. Fault injection can be conducted either through the field tests or simulation-based tests. While conducting field tests could be costly and sometimes life-threatening [1] , [2] , simulation-based tests provide a wide range of advantages, such as adaptation of tests to a variety of traffic scenarios and avoiding the life-threatening situations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "车辆中使用的嵌入式电子系统变得更加暴露，因此容易受到不同类型的故障和网络安全攻击。这些系统的例子是高级驾驶员辅助系统(ADAS)。这些系统的故障可能会产生严重的后果。因此，应该在产品开发的不同阶段对这些系统进行全面评估。评估这些系统的有效方法是通过注入故障并监控它们对这些系统的影响。故障注入可以通过现场测试或基于模拟的测试来进行。虽然进行现场测试可能成本高昂，有时甚至会危及生命[1]，[2]，但基于模拟的测试提供了广泛的优势，例如使测试适应各种交通场景，并避免危及生命的情况。",
                    "title_zh": "在SUMO中模拟的高级驾驶员辅助系统中基于模拟的故障注入"
                }
            ]
        }
    ],
    "2022": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2022s.html",
            "conf_title": "52nd DSN 2022: Baltimore, MD, USA - Supplemental Volume",
            "conf_url": "https://doi.org/10.1109/DSN-S54099.2022",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00011",
                    "title": "Long-Term Study of Honeypots in a Public Cloud",
                    "authors": "Rakshit Agrawal, Jack W. Stokes, Lukas Rist, Ryan Littlefield, Xun Fan, Ken Hollis, Zane Coppedge, Noah Chesterman, Christian Seifert",
                    "abstract": "Public cloud hosting environments offer convenient computation and storage resources for cloud service providers, and these resources are also beneficial for adversaries to host malicious web-based attacks. As a result, cloud-based virtual machines are often attacked. In the paper, we conduct a long-term deployment and analysis of honeypots in a public cloud hosting environment. In particular, we deploy five low-interaction honeypots and one medium-interaction honeypot and measure the attack patterns over eleven months. In our study, we found that the low-interaction honeypots were attacked repeatedly, but the activity on the medium-interaction honeypot was small. We first provide an overview of the attack traffic activity. We then use Latent Dirichlet Allocation (LDA) to discover topics in the log data.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "公共云托管环境为云服务提供商提供了便利的计算和存储资源，这些资源也有利于对手托管恶意的基于web的攻击。因此，基于云的虚拟机经常受到攻击。在本文中，我们对公共云托管环境中的蜜罐进行了长期部署和分析。特别是，我们部署了五个低交互蜜罐和一个中等交互蜜罐，并测量了十一个月的攻击模式。在我们的研究中，我们发现低交互蜜罐被反复攻击，而中等交互蜜罐上的活跃性很小。我们首先概述攻击流量活动。然后，我们使用潜在的狄利克雷分配(LDA)来发现日志数据中的主题。",
                    "title_zh": "公共云中蜜罐的长期研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00012",
                    "title": "An industrial perspective on web scraping characteristics and open issues",
                    "authors": "Elisa Chiapponi, Marc Dacier, Olivier Thonnard, Mohamed Fangar, Mattias Mattsson, Vincent Rigal",
                    "abstract": "An ongoing battle has been running for more than a decade between e-commerce websites owners and web scrapers. Whenever one party finds a new technique to prevail, the other one comes up with a solution to defeat it. Based on our industrial experience, we know this problem is far from being solved. New solutions are needed to address automated threats. In this work, we will describe the actors taking part in the battle, the weapons at their disposal, and their allies on either side. We will present a real-world setup to explain how e-commerce websites operators try to defend themselves and the open problems they seek solutions for.",
                    "files": {
                        "openAccessPdf": "https://repository.kaust.edu.sa/bitstream/10754/679931/1/DSN_2022_Chiapponi_AnIndustrial_2022%20%283%29.pdf"
                    },
                    "abstract_zh": "电子商务网站所有者和网页抓取者之间的战争已经持续了十多年。每当一方发现一种新技术占了上风，另一方就会想出办法来击败它。根据我们的工业经验，我们知道这个问题远远没有解决。需要新的解决方案来应对自动化威胁。在这部作品中，我们将描述参加战斗的演员，他们手中的武器，以及他们在任何一方的盟友。我们将展示一个真实世界的场景，解释电子商务网站运营商如何试图保护自己，以及他们寻求解决方案的公开问题。",
                    "title_zh": "从行业角度看web抓取特性和未决问题"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00013",
                    "title": "SimLane: A Risk-Orientated Benchmark for Lane Detection",
                    "authors": "Xinyang Zhang, Zhisheng Hu, Shengjian Guo, Zhenyu Zhong, Kang Li",
                    "abstract": "Lane detection, which detects lanes on the road from a camera frame, plays an essential role in the successful and safe application of autonomous driving. A few previous works explore their robustness to adversarial road conditions (e.g., dirty patch [1]); however, to the best of our knowledge, no prior work systematically studies their robustness to common environmental variations, like weather, lighting, etc. Those variations will inevitably happen to autonomous vehicles worldwide, owning to the long-tail nature of driving. Therefore, it is critical to understand whether state-of-the-art lane detection models are sensitive to such environmental variations. This paper fills this research gap by collecting a dataset of variations from simulations and benchmarking state-of-the-art models against this new dataset.We first systematically investigate and categorize environmental variations that might incur negative impacts against lane detection based on existing datasets and online driving clips. We then develop a pipeline to collect driving clips under these variations from simulations. The dataset we collected, called SimLane, consists of 149 driving clips of eight different variations that could also serve as a baseline for future research on lane detection safety. Our empirical results verify that state-of-art models suffer from sensitivity to environmental variations from a minor scale to a vast scale. In particular, road graffiti with a medium dense level will cause the detection accuracy of SCNN model ([2], trained on TuSimple Dataset [3]) to drop from 0.897 to 0.219.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "车道检测从摄像机帧中检测道路上的车道，在自动驾驶的成功和安全应用中起着至关重要的作用。一些先前的工作探索了它们对不利路况的鲁棒性(例如，脏路面[1])；然而，据我们所知，以前的工作没有系统地研究它们对常见环境变化，如天气、光照等的鲁棒性。由于驾驶的长尾特性，这些变化将不可避免地发生在全球的自动驾驶汽车上。因此，了解最先进的车道检测模型是否对这种环境变化敏感至关重要。本文通过收集模拟的变化数据集，并根据这个新数据集对最新模型进行基准测试，填补了这一研究空白。我们首先基于现有的数据集和在线驾驶片段系统地调查和分类可能对车道检测产生负面影响的环境变化。然后，我们开发了一个管道来收集模拟中这些变化下的驱动剪辑。我们收集的数据集名为SimLane，由八种不同变化的149个驾驶片段组成，这也可以作为未来车道检测安全研究的基线。我们的实证结果证实，从小尺度到大尺度，最先进的模型都存在对环境变化敏感的问题。特别是中等密集程度的道路涂鸦会导致SCNN模型([2]，在TuSimple数据集[3]上训练)的检测精度从0.897下降到0.219。",
                    "title_zh": "SimLane:面向风险的车道检测基准"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00014",
                    "title": "Revisiting Tendermint: Design Tradeoffs, Accountability, and Practical Use",
                    "authors": "Ethan Buchman, Rachid Guerraoui, Jovan Komatovic, Zarko Milosevic, Dragos-Adrian Seredinschi, Josef Widder",
                    "abstract": "Tendermint is a deterministic consensus protocol and is one of the most mature implementations of its kind. This implementation is used as the core for building State Machine Replication (SMR) platforms with Byzantine fault-tolerant (BFT) guarantees. A noteworthy deployment of Tendermint has been in continuous operation since 2019 within a blockchain called Cosmos Hub. The Cosmos Hub supports the development of decentralized applications, and stands as one of the largest and most stable ongoing deployments of a BFT SMR platform.While successful in practice, the Tendermint consensus protocol has no definitive description in the literature. It is not clear what makes this protocol unique or how it fits into a blockchain protocol stack. In this short paper, we revisit Tendermint. We contrast Tendermint with other major consensus algorithms, examining its unique design choices. We also focus on the requirements which dictated Tendermint’s design. Lastly, we briefly analyze the accountability support which Tendermint provides.",
                    "files": {
                        "openAccessPdf": "https://infoscience.epfl.ch/record/296217/files/Accountable_Tendermint___DSN_2022.pdf"
                    },
                    "abstract_zh": "Tendermint是一种确定性共识协议，是同类协议中最成熟的实现之一。该实现用作构建具有拜占庭容错(BFT)保证的状态机复制(SMR)平台的核心。Tendermint的一个值得注意的部署自2019年以来一直在一个名为Cosmos Hub的区块链内持续运行。Cosmos Hub支持分散式应用程序的开发，是BFT SMR平台最大、最稳定的部署之一。虽然在实践中是成功的，但Tendermint共识方案在文献中没有明确的描述。尚不清楚是什么使这种协议独一无二，也不清楚它如何适合区块链协议栈。在这篇短文中，我们重新审视Tendermint。我们将Tendermint与其他主要的共识算法进行对比，检查其独特的设计选择。我们还关注了Tendermint设计的要求。最后，我们简要分析了Tendermint提供的责任支持。",
                    "title_zh": "重温Tendermint:设计权衡、责任和实际使用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00015",
                    "title": "On the Scalability of HeapCheck",
                    "authors": "Rick Boivie, Gururaj Saileshwar, Tong Chen, Benjamin Segal, Alper Buyuktosunoglu",
                    "abstract": "In our DSN 2021 paper, we introduced HeapCheck, a combination of hardware and software that provides strong protection against memory-safety vulnerabilities with minimal performance overhead. In this short paper, we discuss how HeapCheck can support programs that use very large numbers of objects, and we also compare HeapCheck to two recently announced industry approaches to memory-safety.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在我们的DSN 2021论文中，我们介绍了HeapCheck，这是一种硬件和软件的组合，可以以最小的性能开销提供强大的内存安全漏洞保护。在这篇短文中，我们讨论了HeapCheck如何支持使用大量对象的程序，并且我们还将HeapCheck与最近宣布的两种业界内存安全方法进行了比较。",
                    "title_zh": "关于HeapCheck的可伸缩性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00016",
                    "title": "Challenges/Opportunities to Enable Dependable Scale-out System with Groq Deterministic Tensor-Streaming Processors",
                    "authors": "Dennis Abts, Ibrahim Ahmed, Andrew Bitar, Matthew Boyd, John Kim, Garrin Kimmell, Andrew C. Ling",
                    "abstract": "The Groq tensor streaming processor (TSP) architecture is an hardware accelerator that provides a new paradigm for achieving both flexibility and massive parallelism without the limitations and communication overheads of conventional CPU or GPU architectures. In particular, the Groq TSP execution and performance is deterministic as the flow of instructions through the the hardware is completely orchestrated and scheduled, making processing both efficient and predictable. When scaling out to multiple TSPs, the same deterministic execution needs to be provided in a distributed system. In this work, we explore the challenges and opportunities to scale such deterministic architecture across multiple processors to ensure a dependable scale-out system. In particular, maintaining synchronization across multiple TSPs to enable a software-scheduled network is a challenge; yet, the high-radix, low diameter topology enables N + 1 redundancy to improve the reliability of the system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Groq张量流处理器(TSP)架构是一种硬件加速器，它提供了一种新的模式来实现灵活性和大规模并行性，而没有传统CPU或GPU架构的限制和通信开销。特别是，Groq TSP的执行和性能是确定的，因为通过硬件的指令流是完全协调和调度的，使得处理既高效又可预测。当扩展到多个tsp时，需要在分布式系统中提供相同的确定性执行。在这项工作中，我们探索了在多个处理器上扩展这种确定性架构的挑战和机遇，以确保可靠的横向扩展系统。特别是，保持多个tsp之间的同步以支持软件调度的网络是一个挑战；然而，高基数、低直径拓扑实现了N + 1冗余，从而提高了系统的可靠性。",
                    "title_zh": "利用Groq确定性张量流处理器实现可靠横向扩展系统的挑战/机遇"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00017",
                    "title": "Improving the Fault Resilience of Neural Network Applications Through Security Mechanisms",
                    "authors": "Nikolaos Ioannis Deligiannis, Riccardo Cantoro, Matteo Sonza Reorda, Marcello Traiola, Emanuele Valea",
                    "abstract": "Numerous electronic systems store valuable intellectual property (IP) information inside non-volatile memories. In order to protect the integrity of such sensitive information from an unauthorized access or modification, encryption mechanisms are employed. From a reliability standpoint, such information can be vital to the system’s functionality and thus, dedicated techniques are employed to detect possible reliability threats (e.g., transient faults in the memory content). In this paper we explore the capability of encryption mechanisms to guarantee protection from both unauthorized access and faults, while considering a Convolutional Neural Network application whose weights represent the valuable IP of the system. Experimental results show that it is possible to achieve very high fault detection rates, thus exploiting the benefits of security mechanisms for reliability purposes as well.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-03887704/file/_DSN2022_Improving_the_Fault_Resilience_of_Neural_Network_Applications.pdf"
                    },
                    "abstract_zh": "许多电子系统在非易失性存储器中存储有价值的知识产权(IP)信息。为了保护这种敏感信息的完整性，防止未经授权的访问或修改，采用了加密机制。从可靠性的角度来看，这种信息对于系统的功能是至关重要的，因此，采用专用技术来检测可能的可靠性威胁(例如，存储器内容中的瞬时故障)。在本文中，我们探讨了加密机制保证防止未授权访问和故障的能力，同时考虑了卷积神经网络应用，其权重表示系统的有价值的IP。实验结果表明，有可能实现非常高的故障检测率，从而利用安全机制的好处来实现可靠性目的。",
                    "title_zh": "通过安全机制提高神经网络应用的故障恢复能力"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00018",
                    "title": "Reliability of Google's Tensor Processing Units for Convolutional Neural Networks",
                    "authors": "Rubens Luiz Rech Junior, Paolo Rech",
                    "abstract": "This abstract presents the result of extensive reliability evaluation of Google’s Coral Tensor Processing Unit (TPU), which is one of the latest low power accelerators for CNNs. We report experimental data equivalent to more than 30 million years of natural irradiation and analyze the behavior of TPUs executing atomic operations (standard or depthwise convolutions) with increasing input sizes as well as eight CNN designs typical of embedded applications, including transfer learning and reduced data-set configurations. We found that, despite the high error rate, most neutrons-induced errors only slightly modify the convolution output and do not change the CNNs detection or classification. By reporting details about the fault model and error rate, we provide valuable information on how to evaluate and improve the reliability of CNNs executed on a TPU.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本摘要介绍了对谷歌的Coral张量处理单元(TPU)进行广泛可靠性评估的结果，该单元是CNN最新的低功耗加速器之一。我们报告了相当于超过3000万年自然辐射的实验数据，并分析了TPU执行原子操作(标准或深度方向卷积)的行为，输入大小不断增加，以及嵌入式应用的八种典型CNN设计，包括迁移学习和简化的数据集配置。我们发现，尽管错误率很高，但大多数中子引起的错误仅轻微修改卷积输出，而不改变CNN的检测或分类。通过报告关于故障模型和错误率的细节，我们提供了关于如何评估和改进在TPU上执行的CNN的可靠性的有价值的信息。",
                    "title_zh": "卷积神经网络Google张量处理单元的可靠性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00019",
                    "title": "Reliability assessment of FreeRTOS in Embedded Systems",
                    "authors": "Alberto Bosio, Maurizio Rebaudengo, Alessandro Savino",
                    "abstract": "This work studies the reliability of a FreeRTOS operating system when affected by Single Event Upset faults. The methodology is based on fault injection to target the most relevant variables and data structures. Results confirm the selectivity in the OS fault tolerance, paving the way to a tailored design of fault-tolerant mechanisms, such as selective hardening of the OS.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文研究了FreeRTOS操作系统在受到单粒子翻转故障影响时的可靠性。该方法基于故障注入，以最相关的变量和数据结构为目标。结果证实了操作系统容错的选择性，为容错机制的定制设计铺平了道路，如操作系统的选择性强化。",
                    "title_zh": "嵌入式系统中自由操作系统的可靠性评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00020",
                    "title": "Formal Foundations for SCONE Attestation",
                    "authors": "Muhammad Usama Sardar, Christof Fetzer",
                    "abstract": "One of the essential features of confidential computing is the ability to attest to an application remotely. Our work focuses on ensuring correctness of attestation mechanisms and policies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "机密计算的一个重要特性是能够远程验证应用程序。我们的工作重点是确保证明机制和策略的正确性。",
                    "title_zh": "SCONE认证的正式基础"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00021",
                    "title": "Effectiveness on C Flaws Checking and Removal",
                    "authors": "João Inácio, Ibéria Medeiros",
                    "abstract": "The use of software daily has become inevitable nowadays. Almost all everyday tools and the most different areas (e.g., medicine or telecommunications) are dependent on software. The C programming language is one of the most used languages for software development, such as operating systems, drivers, embedded systems, and industrial products. Even with the appearance of new languages, it remains one of the most used [1] . At the same time, C lacks verification mechanisms, like array boundaries, leaving the entire responsibility to the developer for the correct management of memory and resources. These weaknesses are at the root of buffer overflows (BO) vulnerabilities, which range the first place in the CWE’s top 25 of the most dangerous weaknesses [2] . The exploitation of BO when existing in critical safety systems, such as railways and autonomous cars, can have catastrophic effects for manufacturers or endanger human lives.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，软件的日常使用已经不可避免。几乎所有的日常工具和最不同的领域(例如，医学或电信)都依赖于软件。C编程语言是软件开发中最常用的语言之一，例如操作系统、驱动程序、嵌入式系统和工业产品。即使出现了新的语言，它仍然是最常用的语言之一。同时，C缺乏验证机制，如数组边界，将正确管理内存和资源的全部责任留给了开发人员。这些弱点是缓冲区溢出(BO)漏洞的根源，在CWE最危险的25个弱点中名列第一[2]。当BO存在于铁路和自动驾驶汽车等关键安全系统中时，对它的利用可能会对制造商产生灾难性影响，或者危及人类生命。",
                    "title_zh": "C缺陷检查和消除的有效性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00022",
                    "title": "Towards Fuzzing Target Lines",
                    "authors": "Nuno Neves",
                    "abstract": "Fuzzers are often considered one of the most effective tools to uncover bugs in software, including security vulnerabilities. Current tools are designed to test the full programs by employing strategies that select and generate testcases that increase code coverage. In this paper, we propose to evolve these ideas to make fuzzers focus on specific portions (i.e., lines) of the code, which we call targets, avoiding wasting resources on the other regions. The aim is to support efficient testing of evolving software, and other practical scenarios such as confirming the results from static analysis.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Fuzzers通常被认为是发现软件缺陷(包括安全漏洞)的最有效的工具之一。当前的工具被设计成通过采用选择和生成增加代码覆盖率的测试用例的策略来测试完整的程序。在本文中，我们建议改进这些想法，使模糊器专注于代码的特定部分(即行)，我们称之为目标，避免在其他区域浪费资源。目标是支持演化软件的有效测试，以及其他实际场景，比如确认静态分析的结果。",
                    "title_zh": "模糊目标线"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00023",
                    "title": "A Policy Driven AI-Assisted PoW Framework",
                    "authors": "Trisha Chakraborty, Shaswata Mitra, Sudip Mittal, Maxwell Young",
                    "abstract": "Proof of Work (PoW) based cyberdefense systems require incoming network requests to expend effort solving an arbitrary mathematical puzzle. Current state of the art is unable to differentiate between trustworthy and untrustworthy connections, requiring all to solve complex puzzles. In this paper, we introduce an Artificial Intelligence (AI)-assisted PoW framework that utilizes IP traffic based features to inform an ‘adaptive’ issuer which can then generate puzzles with varying hardness. The modular framework uses these capabilities to ensure that untrustworthy clients solve harder puzzles thereby incurring longer latency than authentic requests to receive a response from the server. Our preliminary findings reveal our approach effectively throttles untrustworthy traffic.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于工作证明(PoW)的网络防御系统要求输入的网络请求花费精力解决任意的数学难题。现有技术无法区分可信和不可信的连接，需要所有人解决复杂的难题。在本文中，我们介绍了一个人工智能(AI)辅助的PoW框架，该框架利用基于IP流量的特征来通知“自适应”发行者，该发行者然后可以生成具有不同难度的谜题。模块化框架使用这些能力来确保不可信的客户端解决更难的难题，从而导致比从服务器接收响应的可信请求更长的等待时间。我们的初步发现显示，我们的方法有效地扼制不可信的流量。",
                    "title_zh": "一种策略驱动人工智能辅助电源框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00024",
                    "title": "Modeling Composition of Cloud Services with Complex Dependencies for Availability Assessment",
                    "authors": "Xingjian Zhang, Long Wang",
                    "abstract": "This paper presents a methodology to assess availability of cloud services through Bayesian network-based availability model. We propose a modeling technology to represent heterogeneous dependencies of cloud services in the methodology. We show that our modeling technology provides more expressive capability for complex dependencies than classic tools like RBD.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "提出一种通过基于贝叶斯网络的可用性模型评估云服务可用性的方法。我们提出了一种建模技术来表示该方法中云服务的异构依赖性。我们展示了我们的建模技术为复杂的依赖关系提供了比像RBD这样的经典工具更强的表达能力。",
                    "title_zh": "面向可用性评估的复杂依赖云服务组合建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00025",
                    "title": "Real-Time Digital Filtering for IoT Data in Programmable Network Switches",
                    "authors": "Nathaniel Nauman, Ruochong Wu, Saurabh Bagchi",
                    "abstract": "This study seeks to optimally approximate fixed-point multiplication on a programmable switch to perform digital IIR filtering. For a stream of real-time IoT data, offloading digital filtering computations allows edge devices to allocate more CPU cycles for processing analytics in parallel. Multiplication is approximated through an adaptive bit width precision lookup table, and the formulas for the maximum possible percentage error and the memory consumption are shown. The users can access and alter the 32-bit filter coefficients to reflect the specifications of the desired IIR filter. This offers extensive flexibility for users to alter the filter characteristics through software.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本研究寻求在可编程开关上最佳逼近定点乘法，以执行数字IIR滤波。对于实时物联网数据流，卸载数字过滤计算允许边缘设备分配更多CPU周期来并行处理分析。乘法通过自适应位宽精度查找表来近似，并显示了最大可能百分比误差和内存消耗的公式。用户可以访问和更改32位滤波器系数，以反映所需IIR滤波器的规格。这为用户通过软件改变滤波器特性提供了广泛的灵活性。",
                    "title_zh": "可编程网络交换机中物联网数据的实时数字过滤"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00026",
                    "title": "Personalized Cryptography Algorithms - A Comparison Between Classic and Cognitive Methods",
                    "authors": "Radoslaw Bulat, Marek R. Ogiela",
                    "abstract": "The main goal of this work is to present a method of personalized cryptography that differs from the biometrical ones by putting in elements of cognitive cryptography and would be useful to work in an IoT environment. Thus a state-of-the-art review of existing methods and their usefulness has already been made in the context of comparing them with a preliminary cognitive algorithm based on the author’s own work. The first half of the abstract would consist of various types of personalized cryptography, beginning with the oldest and most widespread and ending with the newest breakthroughs and inventions in the field. The other half would introduce a new algorithm based on cognitive computing and embedding context recognition into the data streams. Such an algorithm would be shortly presented compared to the other methods, and possible applications or drawbacks would be discussed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "这项工作的主要目标是提出一种个性化加密方法，该方法通过加入认知加密的元素而不同于生物统计学方法，并将有助于在物联网环境中工作。因此，在将现有方法与基于作者自己工作的初步认知算法进行比较的背景下，已经对现有方法及其有用性进行了最先进的审查。摘要的前半部分将包括各种类型的个性化加密，从最古老和最广泛的开始，到该领域的最新突破和发明结束。另一半将引入一种基于认知计算的新算法，并将上下文识别嵌入数据流中。与其他方法相比，这种算法将很快介绍，并讨论可能的应用或缺点。",
                    "title_zh": "个性化密码算法——经典方法和认知方法的比较"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00027",
                    "title": "Predictive Resilience Modeling",
                    "authors": "Priscila Silva",
                    "abstract": "Resilience is the ability of a system to respond, absorb, adapt, and recover from a disruptive event. Dozens of metrics to quantify resilience have been proposed in the literature. However, fewer studies have proposed models to predict these metrics or the time at which a system will be restored to its nominal performance level after experiencing degradation. This paper presents two alternative approaches to model and predict performance and resilience metrics with techniques from reliability engineering, including (i) bathtub-shaped hazard functions and (ii) mixture distributions . Given their ease of accessibility, historical data sets on job losses during recessions in the United States are used to assess the predictive accuracy of these approaches. Goodness of fit measures and confidence interval are computed to assess how well the models perform on the data sets considered. The results suggest that both approaches can produce accurate predictions for data sets exhibiting V and U shaped curves, but that L and W shaped curves that respectively experience a sudden drop in performance or deviate from the assumption of a single decrease and subsequent increase cannot be characterized well by either class of model proposed, necessitating additional modeling efforts that can capture these more general scenarios.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "弹性是系统对破坏性事件做出响应、吸收、适应和恢复的能力。文献中已经提出了数十种量化弹性的指标。然而，很少有研究提出模型来预测这些指标或系统在经历降级后恢复到其标称性能水平的时间。本文介绍了两种使用可靠性工程技术对性能和弹性指标进行建模和预测的替代方法，包括(I)浴盆形风险函数和(ii)混合分布。鉴于这些方法易于获取，美国经济衰退期间失业的历史数据集被用来评估这些方法的预测准确性。计算拟合优度和置信区间，以评估模型在所考虑的数据集上的表现。结果表明，这两种方法都可以对呈现V形和U形曲线的数据集产生准确的预测，但是L形和W形曲线分别经历性能的突然下降或偏离单一下降和随后上升的假设，这两种方法都不能很好地用所提出的任何一类模型来表征，从而需要额外的建模工作来捕捉这些更一般的情况。",
                    "title_zh": "预测弹性建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00032",
                    "title": "CSAI-4-CPS: A Cyber Security characterization model based on Artificial Intelligence For Cyber Physical Systems",
                    "authors": "Hebert de Oliveira Silva",
                    "abstract": "The model called CSAI-4-CPS is proposed to characterize the use of Artificial Intelligence in Cybersecurity applied to the context of CPS - Cyber-Physical Systems. The model aims to establish a methodology being able to self-adapt using shared machine learning models, without incurring the loss of data privacy. The model will be implemented in a generic framework, to assess accuracy across different datasets, taking advantage of the federated learning and machine learning approach. The proposed solution can facilitate the construction of new AI cybersecurity tools and systems for CPS, enabling a better assessment and increasing the level of security/robustness of these systems more efficiently.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "被称为CSAI-4-CPS的模型被提出来描述应用于CPS -网络物理系统的人工智能在网络安全中的使用。该模型旨在建立一种方法，能够使用共享的机器学习模型进行自适应，而不会导致数据隐私的损失。该模型将在一个通用框架中实现，以评估不同数据集的准确性，利用联邦学习和机器学习方法。所提出的解决方案可以促进为CPS构建新的人工智能网络安全工具和系统，实现更好的评估，并更有效地提高这些系统的安全/稳健性水平。",
                    "title_zh": "CSAI-4-CPS:基于人工智能的网络物理系统安全表征模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00028",
                    "title": "Understanding Trust Assumptions for Attestation in Confidential Computing",
                    "authors": "Muhammad Usama Sardar",
                    "abstract": "Despite its critical role, remote attestation in Intel Software Guard Extensions (SGX) and Trust Domain Extensions (TDX) is poorly specified by Intel with some obvious flaws. We believe that it is part of Intel’s strategic policy to create resistance to revealing trust assumptions of the process.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管远程证明在英特尔软件保护扩展(SGX)和信任域扩展(TDX)中发挥着重要作用，但英特尔对其规定不完善，存在一些明显的缺陷。我们认为，抵制披露流程的信任假设是英特尔战略政策的一部分。",
                    "title_zh": "理解机密计算中证明的信任假设"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00029",
                    "title": "Daric: A Storage Efficient Payment Channel With Penalization Mechanism",
                    "authors": "Arash Mirzaei",
                    "abstract": "Lightning Network (LN), the most widely deployed payment channel for Bitcoin, requires channel parties to generate and store distinct revocation keys for all n payments of a channel to resolve fraudulent channel closures. To reduce the required storage in a payment channel, eltoo introduces a new signature type for Bitcoin to enable payment versioning. This allows a channel party to revoke all stale payments by using a payment with a higher version number, reducing the complexity of storage from $\\mathcal{O}(n)$ to $\\mathcal{O}(1)$. However, eltoo lacks a penalization mechanism, which may incentivise profit-driven channel parties to close a payment channel with a stale payment state, to their own advantage. This paper introduces Daric, a payment channel for Bitcoin that simultaneously disincentivize profit-driven attackers and achieves optimal storage. In addition, to achieve higher efficiency and robustness, Daric does not rely on any particular properties of the underlying digital signature to prevent state duplication.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "闪电网络(LN)是部署最广泛的比特币支付渠道，它要求渠道各方为渠道的所有n次支付生成并存储不同的撤销密钥，以解决欺诈性的渠道关闭问题。为了减少支付通道中所需的存储，eltoo为比特币引入了一种新的签名类型，以实现支付版本控制。这允许渠道方通过使用具有更高版本号的支付来撤销所有过期的支付，从而将存储的复杂性从$\\mathcal{O}(n)$降低到$\\mathcal{O}(1)$。然而，eltoo缺乏一种惩罚机制，这种机制可能会激励受利润驱动的渠道方关闭具有陈旧支付状态的支付渠道，从而对自己有利。本文介绍了Daric，它是一种比特币支付渠道，能够同时抑制利益驱动的攻击者并实现最优存储。此外，为了实现更高的效率和健壮性，Daric不依赖底层数字签名的任何特定属性来防止状态复制。",
                    "title_zh": "Daric:一种具有惩罚机制的存储高效支付通道"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S54099.2022.00030",
                    "title": "Pay or Not Pay? A Game-Theoretical Analysis of Ransomware Interactions Considering a Defender's Deception Architecture",
                    "authors": "Rudra Prasad Baksi",
                    "abstract": "Malware created by the Advanced Persistent Threat (APT) groups do not typically carry out the attacks in a single stage. The “Cyber Kill Chain” framework developed by Lockheed Martin describes an APT through a seven stage life cycle [5] . APT groups are generally nation state actors [1] . They perform highly targeted attacks and do not stop until the goal is achieved [7] . Researchers are always working toward developing a system and a process to create an environment safe from APT type attacks [2] . In this paper, the threat considered is ransomware which are developed by APT groups. WannaCry is an example of a highly sophisticated ransomware created by the Lazurus group of North Korea and its level of sophistication is evident from the existence of a contingency plan of attack upon being discovered [3] [6] . The major contribution of this research is the analysis of APT type ransomware using game theory to present optimal strategies for the defender through the development of equilibrium solutions when faced with APT type ransomware attack. The goal of the equilibrium solutions is to help the defender in preparedness before the attack and in minimization of losses during and after the attack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由高级持续威胁(APT)组创建的恶意软件通常不会在单一阶段实施攻击。洛克希德·马丁公司开发的“网络杀伤链”框架描述了APT的七个生命周期阶段[5]。APT团体通常是民族国家行为者[1]。他们执行高度有针对性的攻击，不达目的誓不罢休[7]。研究人员一直致力于开发一个系统和一个过程来创建一个免受APT类型攻击的安全环境[2]。本文考虑的威胁是由APT组织开发的勒索软件。WannaCry是朝鲜Lazurus集团创造的高度复杂的勒索软件的一个例子，其复杂程度从被发现后的攻击应急计划中显而易见[3] [6]。本研究的主要贡献是使用博弈论分析APT型勒索软件，通过开发平衡解决方案为防御方提供最优策略，以应对APT型勒索软件攻击。均衡解决方案的目标是帮助防御者在攻击前做好准备，并在攻击期间和之后将损失最小化。",
                    "title_zh": "交还是不交？考虑防御方欺骗架构的勒索软件交互博弈分析"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2022.html",
            "conf_title": "52nd DSN 2022: Baltimore, MD, USA",
            "conf_url": "https://doi.org/10.1109/DSN53405.2022",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00014",
                    "title": "HDiff: A Semi-automatic Framework for Discovering Semantic Gap Attack in HTTP Implementations",
                    "authors": "Kaiwen Shen, Jianyu Lu, Yaru Yang, Jianjun Chen, Mingming Zhang, Haixin Duan, Jia Zhang, Xiaofeng Zheng",
                    "abstract": "The Internet has become a complex distributed network with numerous middle-boxes, where an end-to-end HTTP request is often processed by multiple intermediate servers before it reaches its destination. However, a general problem in this distributed network is the semantic gap attack, which is defined as inconsistent semantic interpretations in the processing chain. While some studies have found individual semantic gap attacks, most of them are based on ad-hoc manual analysis, which is inadequate for fundamentally enhancing the security assurance of a system as complex as the HTTP network.In this work, we propose HDiff, a novel semi-automatic detecting framework, systematically exploring semantic gap attacks in HTTP implementations. We designed a documentation analyzer that employs natural language processing techniques to extract rules from specifications, and utilized differential testing to discover semantic gap attacks. We implemented and evaluated it to find three kinds of semantic gap attacks in 10 popular HTTP implementations. In total, HDiff found 14 vulnerabilities and 29 affected server pairs covering all three types of attacks. In particular, HDiff also discovered three new types of attack vectors. We have already duly reported all identified vulnerabilities to the involved HTTP software vendors and obtained 7 new CVEs from well-known HTTP software, including Apache, Tomcat, Weblogic, and Microsoft IIS Server.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Internet已经成为一个复杂的分布式网络，有许多中间盒，在到达目的地之前，端到端的HTTP请求通常由多个中间服务器处理。然而，这种分布式网络中的一个普遍问题是语义鸿沟攻击，它被定义为处理链中不一致的语义解释。虽然一些研究已经发现了个别的语义鸿沟攻击，但是它们中的大多数是基于特别的人工分析，这不足以从根本上增强像HTTP网络这样复杂的系统的安全保证。在这篇论文中，我们提出了一种新的半自动检测框架HDiff，系统地研究了HTTP实现中的语义鸿沟攻击。我们设计了一个文档分析器，它采用自然语言处理技术从规范中提取规则，并利用差异测试来发现语义差距攻击。我们实现并评估了它，以在10个流行的HTTP实现中找到三种语义鸿沟攻击。总的来说，HDiff发现了14个漏洞和29个受影响的服务器对，涵盖了所有三种类型的攻击。特别是，HDiff还发现了三种新的攻击媒介。我们已经及时向相关HTTP软件供应商报告了所有已发现的漏洞，并从知名HTTP软件(包括Apache、Tomcat、Weblogic和Microsoft IIS Server)获得了7个新的CVE。",
                    "title_zh": "HDiff:一个发现HTTP实现中语义鸿沟攻击的半自动框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00015",
                    "title": "Treaty: Secure Distributed Transactions",
                    "authors": "Dimitra Giantsidi, Maurice Bailleu, Natacha Crooks, Pramod Bhatotia",
                    "abstract": "Distributed transaction processing is a fundamental building block for large-scale data management in the cloud. Given the threats of security violations in untrusted cloud environments, our work focuses on: How to design a distributed transactional KV store that achieves high-performance serializable transactions, while providing strong security properties?We introduce Treaty, a secure distributed transactional KV storage system that supports serializable ACID transactions while guaranteeing strong security properties: confidentiality, integrity, and freshness. Treaty leverages trusted execution environments (TEEs) to bootstrap its security properties, but it extends the trust provided by the limited enclave (volatile) memory region within a single node to build a secure (stateful) distributed transactional KV store over the untrusted storage, network and machines. To achieve this, Treaty embodies a secure two-phase commit protocol co-designed with a high-performance network library for TEEs. Further, Treaty ensures secure and crash-consistent persistency of committed transactions using a stabilization protocol. Our evaluation on a real hardware testbed based on the YCSB and TPC-C benchmarks shows that Treaty incurs reasonable overheads, while achieving strong security properties.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分布式事务处理是云中大规模数据管理的基础构件。鉴于不可信云环境中的安全违规威胁，我们的工作集中在:如何设计一个实现高性能可序列化事务的分布式事务KV store，同时提供强安全属性？我们引入了Treaty，这是一个安全的分布式事务性KV存储系统，它支持可串行化的ACID事务，同时保证强大的安全性:机密性、完整性和新鲜性。Treaty利用可信执行环境(TEEs)来引导其安全属性，但它扩展了由单个节点内的有限飞地(易失性)存储器区域提供的信任，以在不受信任的存储、网络和机器上构建安全的(有状态的)分布式事务KV存储。为了实现这一点，Treaty包含了一个安全的两阶段提交协议，该协议与一个用于tee的高性能网络库共同设计。此外，条约使用稳定协议确保提交事务的安全和崩溃一致性持久性。我们在基于YCSB和TPC-C基准的真实硬件测试床上的评估表明，该条约产生了合理的开销，同时实现了强大的安全属性。",
                    "title_zh": "条约:安全分布式交易"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00016",
                    "title": "CAROL: Confidence-Aware Resilience Model for Edge Federations",
                    "authors": "Shreshth Tuli, Giuliano Casale, Nicholas R. Jennings",
                    "abstract": "In recent years, the deployment of large-scale Inter-net of Things (IoT) applications has given rise to edge federations that seamlessly interconnect and leverage resources from multiple edge service providers. The requirement of supporting both latency-sensitive and compute-intensive IoT tasks necessitates service resilience, especially for the broker nodes in typical broker-worker deployment designs. Existing fault-tolerance or resilience schemes often lack robustness and generalization capability in non-stationary workload settings. This is typically due to the expensive periodic fine-tuning of models required to adapt them in dynamic scenarios. To address this, we present a confidence aware resilience model, CAROL, that utilizes a memory-efficient generative neural network to predict the Quality of Service (QoS) for a future state and a confidence score for each prediction. Thus, whenever a broker fails, we quickly recover the system by executing a local-search over the broker-worker topology space and optimize future QoS. The confidence score enables us to keep track of the prediction performance and run parsimonious neural network fine-tuning to avoid excessive overheads, further improving the QoS of the system. Experiments on a Raspberry-Pi based edge testbed with IoT benchmark applications show that CAROL outperforms state-of-the-art resilience schemes by reducing the energy consumption, deadline violation rates and resilience overheads by up to 16, 17 and 36 percent, respectively.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，大规模物联网(IoT)应用的部署催生了边缘联盟，这些联盟可以无缝互连和利用来自多个边缘服务提供商的资源。支持延迟敏感和计算密集型物联网任务的要求需要服务弹性，特别是对于典型代理-工作器部署设计中的代理节点。现有的容错或弹性方案在不稳定的工作负载设置中通常缺乏鲁棒性和泛化能力。这通常是因为需要对模型进行昂贵的周期性微调，以适应动态场景。为了解决这个问题，我们提出了一个置信度感知弹性模型CAROL，它利用一个内存高效的生成神经网络来预测未来状态的服务质量(QoS)以及每个预测的置信度得分。因此，每当代理失败时，我们通过在代理-工作器拓扑空间上执行本地搜索来快速恢复系统，并优化未来的QoS。置信度得分使我们能够跟踪预测性能，并运行节省的神经网络微调以避免过多的开销，从而进一步提高系统的QoS。在基于Raspberry-Pi的边缘测试床上进行的物联网基准应用实验表明，CAROL的性能优于最先进的弹性方案，能耗、期限违规率和弹性开销分别降低了16%、17%和36%。",
                    "title_zh": "CAROL:边缘联盟的信任感知弹性模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00017",
                    "title": "Cycle: Sustainable Off-Chain Payment Channel Network with Asynchronous Rebalancing",
                    "authors": "Zicong Hong, Song Guo, Rui Zhang, Peng Li, Yufeng Zhan, Wuhui Chen",
                    "abstract": "Payment channel network (PCN) is a promising off-chain technology for blockchain scalability, but it suffers from poor sustainability in practice. In other words, due to the imbalanced transfer in channels, the balance in one direction of channels gradually becomes exhausted until the PCN is rebalanced via a consensus-based rebalancing protocol, during which the involved channels must be suspended. This paper presents Cycle, the first off-chain protocol for a sustainable PCN. It not only keeps the PCN at a balanced level consistently but also avoids the channel freeze incurred by the rebalancing protocol, leading to minimum failed payments and sustained PCN service, respectively. Cycle achieves these benefits based on a novel idea of asynchronous rebalancing. During the normal off-chain running, the participants share the information about their payments and asynchronously rebalance the PCN following the principle that payments along circular channels can cancel each other out. To guarantee security, the protocol resolves the disputes resulting from network latency or malicious participants by a message mechanism for synchronization and a smart contract for arbitration. Moreover, to address the privacy concern during the information sharing, a truncated Laplace mechanism is designed to achieve differential privacy. Finally, we provide a proof-of-concept implementation in Ethereum, over which a real data-based simulation shows that Cycle satisfies 31% more payments than the state-of-the-art technique.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "支付通道网络(PCN)是一种很有前途的区块链可扩展性的链外技术，但在实践中可持续性较差。换句话说，由于信道中的不平衡传输，信道的一个方向上的平衡逐渐耗尽，直到PCN通过基于共识的再平衡协议被再平衡，在此期间，所涉及的信道必须被暂停。本文介绍了Cycle，第一个可持续PCN的离线协议。它不仅将PCN始终保持在一个平衡的水平，而且避免了由再平衡协议引起的信道冻结，分别导致最少的失败支付和持续的PCN服务。Cycle基于一种新颖的异步再平衡思想实现了这些好处。在正常的链外运行期间，参与者共享有关其支付的信息，并遵循循环渠道中的支付可以相互抵消的原则，异步重新平衡PCN。为了保证安全性，该协议通过消息同步机制和智能仲裁契约来解决由网络延迟或恶意参与者引起的争议。此外，为了解决信息共享过程中的隐私问题，设计了截断拉普拉斯机制来实现差分隐私。最后，我们提供了一个以太坊中的概念验证实现，基于真实数据的模拟表明，Cycle比最先进的技术多满足31%的支付。",
                    "title_zh": "循环:具有异步再平衡的可持续链外支付渠道网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00018",
                    "title": "Marlin: Two-Phase BFT with Linearity",
                    "authors": "Xiao Sui, Sisi Duan, Haibin Zhang",
                    "abstract": "As the first Byzantine fault-tolerant (BFT) protocol with linear communication complexity, HotStuff (PODC 2019) has received significant attention. HotStuff has three round-trips for both normal case operations and view change protocols. Follow-up studies attempt to reduce the number of phases for HotStuff. These protocols, however, all give up of one thing in return for another.This paper presents Marlin, a BFT protocol with linearity, having two phases for normal case operations and two or three phases for view changes. Marlin uses the same cryptographic tools as in HotStuff and introduces no additional assumptions. We implement a new and efficient Golang library for Marlin and HotStuff, showing Marlin outperforms HotStuff for both the common case and the view change.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为第一个具有线性通信复杂度的拜占庭容错(BFT)协议，HotStuff (PODC 2019)受到了极大的关注。HotStuff为正常情况操作和视图更改协议提供了三次往返。后续研究试图减少热敷阶段的数量。然而，这些协议都放弃一件事来换取另一件事。本文提出了Marlin，一种具有线性的BFT协议，具有用于正常情况操作的两个阶段和用于视图改变的两个或三个阶段。Marlin使用与HotStuff中相同的加密工具，并且没有引入额外的假设。我们为Marlin和HotStuff实现了一个新的高效的Golang库，表明Marlin在常见情况和视图变化方面都优于HotStuff。",
                    "title_zh": "马林:线性二相BFT"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00019",
                    "title": "ZugChain: Blockchain-Based Juridical Data Recording in Railway Systems",
                    "authors": "Signe Rüsch, Kai Bleeke, Ines Messadi, Stefan Schmidt, Andreas Krampf, Katharina Olze, Susanne Stahnke, Robert Schmid, Lukas Pirl, Roland Kittel, Andreas Polze, Marquart Franz, Matthias Müller, Leander Jehl, Rüdiger Kapitza",
                    "abstract": "In modern trains, a juridical recording unit logs events that occur during operation. This data is used to reconstruct the exact chain of events in case of failures and crashes. To ensure data recovery after an accident, the recorder is hardened against physical damage and secured against tampering; however, it is a single proprietary device and by no means indestructible.This paper presents ZugChain, a distributed, blockchain-based juridical recording unit that opportunistically utilizes on-train hardware. ZugChain offers high reliability via replication and tamper-resistance due to the nature of blockchains. It implements a permissioned blockchain based on a Byzantine fault-tolerant agreement protocol suitable for diverse communication systems. To utilize the logged data for advanced services, e. g., predictive maintenance, ZugChain securely and continuously exports traces to private data centers. We demonstrate ZugChain's feasibility with an implementation running on real train hardware, where we show that ZugChain orders data within 14 ms using at maximum 15 % of the total available shared CPU resources, thus fulfilling requirements of juridical recorders.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在现代列车中，司法记录单元记录运行中发生的事件。这些数据用于在出现故障和崩溃时重建事件的确切链。为了确保事故后的数据恢复，记录仪被加固以防止物理损坏并防止篡改；然而，它是一个单一的专有设备，绝不是坚不可摧的。本文介绍了ZugChain，一个分布式的，区块链为基础的司法记录单位，机会主义地利用列车上的硬件。由于区块链的性质，ZugChain通过复制和防篡改提供了高可靠性。它实现了一个基于拜占庭容错协议的许可区块链，适用于不同的通信系统。为了将记录的数据用于高级服务，例如预测性维护，ZugChain安全、持续地将跟踪数据输出到私有数据中心。我们通过在真实列车硬件上运行的实现来展示ZugChain的可行性，其中我们展示了ZugChain在14 ms内使用最多15 %的总可用共享CPU资源来排序数据，从而满足司法记录器的要求。",
                    "title_zh": "ZugChain:铁路系统中基于区块链的司法数据记录"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00020",
                    "title": "Strategic Safety-Critical Attacks Against an Advanced Driver Assistance System",
                    "authors": "Xugui Zhou, Anna Schmedding, Haotian Ren, Lishan Yang, Philip Schowitz, Evgenia Smirni, Homa Alemzadeh",
                    "abstract": "A growing number of vehicles are being transformed into semi-autonomous vehicles (Level 2 autonomy) by relying on advanced driver assistance systems (ADAS) to improve the driving experience. However, the increasing complexity and connectivity of ADAS expose the vehicles to safety-critical faults and attacks. This paper investigates the resilience of a widely-used ADAS against safety-critical attacks that target the control system at opportune times during different driving scenarios and cause accidents. Experimental results show that our proposed Context-Aware attacks can achieve an 83.4% success rate in causing hazards, 99.7% of which occur without any warnings. These results highlight the intolerance of ADAS to safety-critical attacks and the importance of timely interventions by human drivers or automated recovery mechanisms to prevent accidents.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "越来越多的车辆正在通过依赖高级驾驶辅助系统(ADAS)来改善驾驶体验，从而转变为半自动驾驶车辆(二级自主)。然而，ADAS日益增加的复杂性和连接性使车辆面临安全关键故障和攻击。本文研究了广泛使用的ADAS对安全关键攻击的恢复能力，这些攻击在不同的驾驶场景中在合适的时间针对控制系统并导致事故。实验结果表明，我们提出的上下文感知攻击在造成危险方面可以达到83.4%的成功率，其中99.7%在没有任何警告的情况下发生。这些结果突出了ADAS对安全关键攻击的不容忍，以及人类驾驶员或自动恢复机制及时干预以防止事故的重要性。",
                    "title_zh": "针对高级驾驶辅助系统的战略性安全关键攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00021",
                    "title": "Exploiting Temporal Data Diversity for Detecting Safety-critical Faults in AV Compute Systems",
                    "authors": "Saurabh Jha, Shengkun Cui, Timothy Tsai, Siva Kumar Sastry Hari, Michael B. Sullivan, Zbigniew T. Kalbarczyk, Stephen W. Keckler, Ravishankar K. Iyer",
                    "abstract": "Silent data corruption caused by random hardware faults in autonomous vehicle (AV) computational elements is a significant threat to vehicle safety. Previous research has explored design diversity, data diversity, and duplication techniques to detect such faults in other safety-critical domains. However, these are challenging to use for AVs in practice due to significant resource overhead and design complexity. We propose, DiverseAV, a low-cost data-diversity-based redundancy technique for detecting safety-critical random hardware faults in computational elements. DiverseAV introduces data-diversity between the redundant agents by exploiting the temporal semantic consistency available in the AV sensor data. DiverseAV is a black-box technique that offers a plug-and-play solution as it requires no knowledge of the internals of the AI agent responsible for executing driving decisions, requiring little to no modification to the agent itself for achieving high coverage of transient and permanent hardware faults. It is commercially viable because it avoids software modifications to agents that are costly in terms of development and testing time. Specifically, DiverseAV distributes the sensor data between the two software agents in a round-robin manner. As a result, the sensor data for two consecutive time steps are semantically similar in terms of their worldview but significantly different at the bit level, thus ensuring the state and data diversity between the two agents necessary for detecting faults. We demonstrate DiverseAV using an open-source self-driving AI agent which is controlling a car in an open-source world simulator.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由自主车辆(AV)计算元件中随机硬件故障引起的无声数据损坏是对车辆安全的重大威胁。先前的研究探索了设计多样性、数据多样性和复制技术，以检测其他安全关键领域中的此类故障。然而，由于巨大的资源开销和设计复杂性，这些在实践中用于AVs是具有挑战性的。我们提出，DiverseAV，一种低成本的基于数据多样性的冗余技术，用于检测计算元素中的安全关键随机硬件故障。DiverseAV通过利用AV传感器数据中可用的时间语义一致性，在冗余代理之间引入数据多样性。DiverseAV是一种黑盒技术，它提供了一种即插即用的解决方案，因为它不需要了解负责执行驾驶决策的AI代理的内部知识，只需要对代理本身进行很少或不需要修改，就可以实现瞬时和永久硬件故障的高覆盖率。它在商业上是可行的，因为它避免了在开发和测试时间方面昂贵的对代理的软件修改。具体来说，DiverseAV以循环方式在两个软件代理之间分发传感器数据。结果，两个连续时间步长的传感器数据在语义上就其世界观而言是相似的，但是在比特级别上是显著不同的，从而确保了检测故障所必需的两个代理之间的状态和数据多样性。我们使用开源的自动驾驶人工智能代理来演示DiverseAV，该代理正在开源的世界模拟器中控制汽车。",
                    "title_zh": "利用时间数据差异检测反病毒计算系统中的安全关键故障"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00022",
                    "title": "Arming IDS Researchers with a Robotic Arm Dataset",
                    "authors": "Arpan Gujarati, Zainab Saeed Wattoo, Maryam Raiyat Aliabadi, Sean Clark, Xiaoman Liu, Parisa Shiri, Amee Trivedi, Ruizhe Zhu, Jason Hein, Margo I. Seltzer",
                    "abstract": "Industry 4.0 is rapidly transforming traditional manufacturing practices. Smart manufacturing technologies that automate research and development using a combination of robotic arms and domain-specific cyber-physical systems are at the core of this transformation. Unfortunately, dependence on networked communication increases the risk of security attacks, which must be mitigated using either platforms that are secure by design or intrusion detection and prevention systems. We report on an ongoing project to design and develop intrusion detection systems (IDS) for the Hein Lab, a smart manufacturing research lab in the chemical sciences domain. Designing effective IDS requires large datasets and high-quality, domain-specific benchmarks, which are difficult to obtain. To address this gap, we present the Robotic Arm Dataset (RAD), which we collected at the Hein Lab over a three-month period. We also present our non-intrusive tracing framework RATracer, which can be retrofitted onto any existing Python-based automation pipeline, and two sets of preliminary analyses based on the command and power data in RAD.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "工业4.0正在迅速改变传统的制造实践。智能制造技术使用机械臂和特定领域的信息物理系统的组合来实现研发自动化，这是这一转型的核心。不幸的是，对网络通信的依赖增加了安全攻击的风险，必须使用设计安全的平台或入侵检测和预防系统来减轻这种风险。我们报告了一个正在进行的项目，为Hein实验室设计和开发入侵检测系统(IDS ),这是一个化学科学领域的智能制造研究实验室。设计有效的入侵检测系统需要大型数据集和高质量的、特定领域的基准，这些都很难获得。为了解决这一差距，我们提出了机械臂数据集(RAD)，它是我们在Hein实验室收集的，历时三个月。我们还展示了我们的非侵入式跟踪框架RATracer，它可以改进到任何现有的基于Python的自动化管道上，以及基于RAD中的命令和功率数据的两组初步分析。",
                    "title_zh": "用机械臂数据集武装IDS研究人员"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00023",
                    "title": "STBPU: A Reasonably Secure Branch Prediction Unit",
                    "authors": "Tao Zhang, Timothy Lesch, Kenneth Koltermann, Dmitry Evtyushkin",
                    "abstract": "Modern processors have suffered a deluge of threats exploiting branch instruction collisions inside the branch prediction unit (BPU), from eavesdropping on secret-related branch operations to triggering malicious speculative executions. Protecting branch predictors tends to be challenging from both security and performance perspectives. For example, partitioning or flushing BPU can stop certain collision-based exploits but only to a limited extent. Meanwhile, such mitigations negatively affect branch prediction accuracy and further CPU performance. This paper proposes Secret Token Branch Prediction Unit (STBPU), a secure BPU design to defend against collision-based transient execution attacks and BPU side channels while incurring minimal performance overhead. STBPU resolves the challenges above by customizing data representation inside BPU for each software entity requiring isolation. In addition, to prevent an attacker from using brute force techniques to trigger malicious branch instruction collisions, STBPU actively monitors the prediction-related events and preemptively changes BPU data representation.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2108.02156"
                    },
                    "abstract_zh": "现代处理器遭受了大量利用分支预测单元(BPU)内部的分支指令冲突的威胁，从窃听秘密相关的分支操作到触发恶意的推测性执行。从安全性和性能的角度来看，保护分支预测器往往具有挑战性。例如，分区或刷新BPU可以阻止某些基于冲突的利用，但仅限于有限的程度。同时，这种缓解对分支预测准确性和进一步的CPU性能产生负面影响。提出了秘密令牌分支预测单元(STBPU ),这是一种安全的BPU设计，可以抵御基于冲突的瞬时执行攻击和BPU边信道，同时产生最小的性能开销。STBPU通过在BPU内部为每个需要隔离的软件实体定制数据表示来解决上述挑战。此外，为了防止攻击者使用暴力技术来触发恶意的分支指令冲突，STBPU主动监控与预测相关的事件，并抢先改变BPU数据表示。",
                    "title_zh": "STBPU:一个相当安全的分支预测单元"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00024",
                    "title": "COMET: On-die and In-controller Collaborative Memory ECC Technique for Safer and Stronger Correction of DRAM Errors",
                    "authors": "Irina Alam, Puneet Gupta",
                    "abstract": "DRAM manufacturers have started adopting on-die error correcting coding (ECC) to deal with increasing error rates. The typical single error correcting (SEC) ECC on the memory die is coupled with a single-error correcting, double-error detecting (SECDED) ECC in the memory controller. Unfortunately, the on-die SEC can miscorrect double-bit errors (which would have been safely detected but uncorrected errors in conventional in-controller SECDED) resulting in triple bit errors more than 45% of the time. These are then miscorrected in the memory controller >55% of the time resulting in silent data corruption. We introduce COllaborative Memory ECC Technique (COMET), a novel method to efficiently design either the on-die or the in-controller ECC code, that, for the first time, will eliminate silent data corruption when a double-bit error happens within the DRAM. Further, we propose a collaboration mechanism between the on-die and in-controller ECC decoders that corrects most of the double-bit errors without adding any additional redundancy bits to either of the two codes. Overall, COMET can eliminate all double-bit error induced silent data corruptions and correct almost all (99.9997%) double-bit errors with negligible area, power, and performance impact.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "DRAM制造商已经开始采用片上纠错编码(ECC)来处理不断增加的错误率。存储器芯片上的典型单纠错(SEC) ECC与存储器控制器中的单纠错、双检错(SECDED) ECC相结合。不幸的是，片内SEC可能会错误纠正双位错误(在传统的片内SEC中可以安全地检测到这种错误，但无法纠正错误),导致超过45%的情况下出现三位错误。这些错误在内存控制器中的纠正率超过55%,从而导致静默数据损坏。我们引入了协作内存ECC技术(COMET ),这是一种高效设计片内或控制器内ECC代码的新方法，首次在DRAM内发生双位错误时消除静默数据损坏。此外，我们提出了片上和控制器内ECC解码器之间的协作机制，该机制可以纠正大多数双位错误，而无需向两个代码中的任何一个添加任何额外的冗余位。总的来说，COMET可以消除所有双位错误导致的静默数据损坏，并纠正几乎所有(99.9997%)双位错误，而对面积、功耗和性能的影响可以忽略不计。",
                    "title_zh": "COMET:片上和控制器内协作内存ECC技术，可更安全、更强大地纠正DRAM错误"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00025",
                    "title": "QuFI: a Quantum Fault Injector to Measure the Reliability of Qubits and Quantum Circuits",
                    "authors": "Daniel Oliveira, Edoardo Giusto, Emanuele Dri, Nadir Casciola, Betis Baheri, Qiang Guan, Bartolomeo Montrucchio, Paolo Rech",
                    "abstract": "Quantum computing is an up-and-coming technology that is expected to revolutionize the computation paradigm in the next few years. Qubits, the primary computing elements of quantum circuits, exploit the quantum physics proprieties to increase the parallelism and speed of computation drastically. Unfortunately, besides being intrinsically noisy, qubits have also been shown to be highly susceptible to external sources of faults, such as ionizing radiation. The latest discoveries highlight a much higher radiation sensitivity of qubits than traditional transistors and identify a much more complex fault model than bit-flip.We propose a framework to identify the quantum circuits sensitivity to radiation-induced faults and the probability for a fault in a qubit to propagate to the output. Based on the latest studies and radiation experiments performed on real quantum machines, we model the transient faults in a qubit as a phase shift with a parametrized magnitude. Additionally, our framework can inject multiple qubit faults, tuning the phase shift magnitude based on the proximity of the qubit to the particle strike location. As we show in the paper, the proposed fault injector is highly flexible, and it can be used on both quantum circuit simulators and real quantum machines. We report the finding of more than 285, 249, 536 injections on the Qiskit simulator and 53, 248 injections on real IBM machines. We consider three quantum algorithms and identify the faults and qubits that are more likely to impact the output. We also consider the fault propagation dependence on the circuit scale, showing that the reliability profile for some quantum algorithms is scale-dependent, with increased impact from radiation-induced faults as we increase the number of qubits. Finally, we also consider multi qubits faults, showing that they are much more critical than single faults. The fault injector and the data presented in this paper are available in a public repository to allow further analysis.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "量子计算是一项新兴技术，预计将在未来几年内彻底改变计算模式。量子比特是量子电路的主要计算元件，它利用量子物理特性来大幅提高计算的并行性和速度。不幸的是，除了内在的杂讯，量子位元也很容易受到外部错误来源的影响，例如游离辐射。最新发现强调了量子位比传统晶体管更高的辐射灵敏度，并识别了比比特翻转更复杂的故障模型。我们提出了一个框架来确定量子电路对辐射诱发故障的敏感性以及量子位中的故障传播到输出的概率。基于最新的研究和在真实量子机器上进行的辐射实验，我们将量子位中的瞬时故障建模为具有参数化幅度的相移。此外，我们的框架可以注入多个量子位故障，根据量子位与粒子撞击位置的接近程度调整相移幅度。正如我们在论文中所展示的，所提出的故障注入器是高度灵活的，它既可以在量子电路模拟器上使用，也可以在真实的量子机器上使用。我们报告了在Qiskit模拟器上超过285，249，536次注入和在真实IBM机器上超过53，248次注入的发现。我们考虑三种量子算法，并确定更有可能影响输出的错误和量子位。我们还考虑了故障传播对电路规模的依赖性，表明一些量子算法的可靠性曲线是规模依赖性的，随着我们增加量子位的数量，辐射引起的故障的影响也会增加。最后，我们还考虑了多量子位故障，表明它们比单个故障更严重。故障注入器和本文中介绍的数据可以在公共存储库中获得，以便进行进一步的分析。",
                    "title_zh": "曲飞:测量量子比特和量子电路可靠性的量子故障注入器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00026",
                    "title": "SEVulDet: A Semantics-Enhanced Learnable Vulnerability Detector",
                    "authors": "Zhiquan Tang, Qiao Hu, Yupeng Hu, Wenxin Kuang, Jiongyi Chen",
                    "abstract": "Recent years have seen increased attention to deep learning-based vulnerability detection frameworks that leverage neural networks to identify vulnerability patterns. Considerable efforts have been made; still, existing approaches are less ac-curate in practice. Prior works fail to comprehensively capture semantics from source code or adopt the appropriate design of neural networks. This paper presents SEVulDet, a Semantics-Enhanced learnable Vulnerability Detector that can accurately pinpoint vulnerability patterns by preserving path semantics into gadgets and learning from flexible-length codes. SEVulDet has two main characteristics: (i) SEVulDet employs a path-sensitive code slicing approach to extract sufficient path semantics and control flow logic into code gadgets. (ii) by inserting a spatial pyramidal pooling layer into the Convolutional Neural Network (CNN) with a well-designed multilayer attention mechanism, SEVulDet can handle gadgets of flexible-length semantics to avoid semantics loss incurred by traditional truncating or padding operations, and thus learn more potential vulnerability patterns. Comprehensive experimental results show that SEVulDet significantly outperforms classical static approaches and excels with state-of-the-art deep learning-based solutions by improving F1-measure to roughly 94.5%. Particularly, the elaborate design of the SEVulDet architecture helps us identify more real-world vulnerabilities than existing technologies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，人们越来越关注基于深度学习的漏洞检测框架，这些框架利用神经网络来识别漏洞模式。已经做出了相当大的努力；然而，现有的方法在实践中不够准确。先前的工作未能从源代码中全面捕获语义或采用适当的神经网络设计。本文介绍了SEVulDet，一种语义增强的可学习漏洞检测器，它可以通过将路径语义保存到小工具中并从可变长度代码中学习来准确定位漏洞模式。SEVulDet有两个主要特点:(i) SEVulDet采用路径敏感的代码切片方法，将足够的路径语义和控制流逻辑提取到代码小工具中。(ii)通过在卷积神经网络(CNN)中插入一个具有精心设计的多层注意机制的空间金字塔池层，SEVulDet可以处理灵活长度语义的小工具，以避免传统截断或填充操作导致的语义丢失，从而了解更多潜在的漏洞模式。综合实验结果表明，SEVulDet明显优于经典的静态方法，并通过将F1-measure提高到大约94.5%，优于基于深度学习的最新解决方案。特别是，SEVulDet体系结构的精心设计有助于我们识别比现有技术更多的真实漏洞。",
                    "title_zh": "SEVulDet:一种语义增强的可学习漏洞检测器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00027",
                    "title": "The Fault in Our Data Stars: Studying Mitigation Techniques against Faulty Training Data in Machine Learning Applications",
                    "authors": "Abraham Chan, Arpan Gujarati, Karthik Pattabiraman, Sathish Gopalakrishnan",
                    "abstract": "Machine learning (ML) has been adopted in many safety-critical applications like automated driving and medical diagnosis. Incorrect decisions by ML models can lead to catastrophic consequences, such as vehicle crashes and inappropriate medical procedures, thereby endangering our lives. The correct behaviour of a ML model is contingent upon the availability of well-labelled training data. However, obtaining large and high-quality training datasets for safety-critical applications is difficult, often resulting in the use of faulty training data.We compare the efficacy of five different error mitigation techniques, derived from a survey of more than 200 related articles, which are designed to tolerate noisy/faulty training data. We experimentally find that the error mitigation capabilities of these techniques vary across datasets, ML models, and different kinds of faults. We further find that ensemble learning offers the highest resilience among all the techniques across different configurations, followed by label smoothing.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "机器学习(ML)已经在许多安全关键应用中采用，如自动驾驶和医疗诊断。ML模型的错误决策会导致灾难性的后果，例如车辆碰撞和不适当的医疗程序，从而危及我们的生命。最大似然模型的正确行为取决于良好标记的训练数据的可用性。然而，为安全关键型应用获取大量高质量的训练数据集非常困难，常常导致使用错误的训练数据。我们比较了五种不同的错误缓解技术的有效性，这些技术来自对200多篇相关文章的调查，旨在容忍有噪声/错误的训练数据。我们通过实验发现，这些技术的错误缓解能力在数据集、ML模型和不同种类的错误之间有所不同。我们进一步发现，集成学习在不同配置的所有技术中提供了最高的弹性，其次是标签平滑。",
                    "title_zh": "我们的数据之星中的错误:研究机器学习应用中针对错误训练数据的缓解技术"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00028",
                    "title": "CFGExplainer: Explaining Graph Neural Network-Based Malware Classification from Control Flow Graphs",
                    "authors": "Jerome Dinal Herath, Priti Prabhakar Wakodikar, Ping Yang, Guanhua Yan",
                    "abstract": "With the ever increasing threat of malware, extensive research effort has been put on applying Deep Learning for malware classification tasks. Graph Neural Networks (GNNs) that process malware as Control Flow Graphs (CFGs) have shown great promise for malware classification. However, these models are viewed as black-boxes, which makes it hard to validate and identify malicious patterns. To that end, we propose CFG-Explainer, a deep learning based model for interpreting GNN-oriented malware classification results. CFGExplainer identifies a subgraph of the malware CFG that contributes most towards classification and provides insight into importance of the nodes (i.e., basic blocks) within it. To the best of our knowledge, CFGExplainer is the first work that explains GNN-based mal-ware classification. We compared CFGExplainer against three explainers, namely GNNExplainer, SubgraphX and PGExplainer, and showed that CFGExplainer is able to identify top equisized subgraphs with higher classification accuracy than the other three models.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着恶意软件威胁的不断增加，广泛的研究工作已经放在应用深度学习进行恶意软件分类任务上。将恶意软件处理为控制流图(CFG)的图形神经网络(gnn)在恶意软件分类方面显示出巨大的前景。然而，这些模型被视为黑盒，这使得很难验证和识别恶意模式。为此，我们提出了CFG-Explainer，一种基于深度学习的模型，用于解释面向GNN的恶意软件分类结果。CFGExplainer识别对分类贡献最大的恶意软件CFG的子图，并提供对其中节点(即基本块)重要性的洞察。据我们所知，CFGExplainer是第一部解释基于GNN的恶意软件分类的著作。我们将CFGExplainer与三个解释器进行了比较，即GNNExplainer、SubgraphX和PGExplainer，并表明CFGExplainer能够识别出比其他三个模型具有更高分类精度的顶级等大小子图。",
                    "title_zh": "从控制流图解释基于图形神经网络的恶意软件分类"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00029",
                    "title": "ComFASE: A Tool for Evaluating the Effects of V2V Communication Faults and Attacks on Automated Vehicles",
                    "authors": "Mateen Malik, Mehdi Maleki, Peter Folkesson, Behrooz Sangchoolie, Johan Karlsson",
                    "abstract": "This paper presents ComFASE, a communication fault and attack simulation engine. ComFASE is used to identify and evaluate potentially dangerous behaviours of interconnected automated vehicles in the presence of faults and attacks in wireless vehicular networks. ComFASE is built on top of OM-NET++ (a network simulator) and integrates SUMO (a traffic simulator) and Veins (a vehicular network simulator). The tool is flexible in modelling different types of faults and attacks and can be effectively used to study the interplay between safety and cybersecurity attributes by injecting cybersecurity attacks and evaluating their safety implications. To demonstrate the tool, we present results from a series of simulation experiments, where we injected delay and denial-of-service attacks on wireless messages exchanged between vehicles in a platooning application. The results show how different variants of attacks influence the platooning system in terms of collision incidents.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了一个通信故障和攻击模拟引擎ComFASE。ComFASE用于在无线车辆网络出现故障和攻击的情况下，识别和评估互连自动车辆的潜在危险行为。ComFASE建立在OM-NET++(一个网络模拟器)之上，集成了SUMO(一个流量模拟器)和静脉(一个车载网络模拟器)。该工具可以灵活地模拟不同类型的故障和攻击，并可通过注入网络安全攻击和评估其安全影响，有效地用于研究安全和网络安全属性之间的相互作用。为了演示该工具，我们展示了一系列模拟实验的结果，其中我们对队列应用程序中车辆之间交换的无线消息注入了延迟和拒绝服务攻击。结果显示了不同的攻击变体如何在冲突事件方面影响队列系统。",
                    "title_zh": "评估V2V通信故障和攻击对自动车辆影响的工具"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00030",
                    "title": "A Comprehensive, Longitudinal Study of Government DNS Deployment at Global Scale",
                    "authors": "Rebekah Houser, Shuai Hao, Chase Cotton, Haining Wang",
                    "abstract": "Within the Domain Name System (DNS), government domains form a particularly valuable part of the names-pace, representing trusted sources of information, vital services, and gateways for government personnel to engage in their duties. As the COVID-19 pandemic has unfolded, governments’ digital resources have become increasingly important to provide support to populations largely in isolation. The accessibility of these resources relies largely on the trustworthiness of the domains that represent them. In this paper, we conduct an extensive measurement study focused on the availability and legitimacy of DNS records in the authoritative nameservers of government domains for over 190 countries. Our measurements reveal that thousands of domains do not use replicated authoritative name-servers, as well as a substantial increase in the trend of more domains relying on a single third-party DNS services provider. We also find more than 1,000 domains vulnerable to hijacking due to defective delegations. Our work shows that although robust overall, the deployments of authoritative nameservers in government domains still contain a non-trivial number of configurations that do not meet RFC requirements, leading to poor performance and reduced reliability that may leave domains vulnerable to hijacking.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在域名系统(DNS)中，政府域名构成了域名空间中特别有价值的部分，代表了可信的信息源、重要的服务以及政府人员履行职责的网关。正如新冠肺炎疫情所展现的那样，政府的数字资源对于向基本上处于孤立状态的人口提供支持变得越来越重要。这些资源的可访问性很大程度上依赖于代表它们的域的可信度。在本文中，我们对190多个国家的政府域名权威域名服务器中DNS记录的可用性和合法性进行了广泛的测量研究。我们的测量显示，成千上万的域名不使用复制的权威域名服务器，并且越来越多的域名依赖单一的第三方DNS服务提供商。我们还发现，由于授权有缺陷，超过1000个域名容易遭到劫持。我们的工作表明，虽然总体上是稳健的，但政府域中权威名称服务器的部署仍然包含大量不符合RFC要求的配置，导致性能不佳和可靠性降低，这可能使域容易受到劫持。",
                    "title_zh": "全球范围内政府DNS部署的综合纵向研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00031",
                    "title": "GoldenEye: A Platform for Evaluating Emerging Numerical Data Formats in DNN Accelerators",
                    "authors": "Abdulrahman Mahmoud, Thierry Tambe, Tarek Aloui, David Brooks, Gu-Yeon Wei",
                    "abstract": "This paper presents GoldenEye, a functional simulator with fault injection capabilities for common and emerging numerical formats, implemented for the PyTorch deep learning framework. GoldenEye provides a unified framework for numerical format evaluation of DNNs, including traditional number systems such as fixed and floating point, as well as recent DNN-inspired formats such as block floating point and AdaptivFloat. Additionally, GoldenEye enables single- and multi- bit flips at various logical and functional points during a value’s lifetime for resiliency analysis, including for the first time attention to numerical values’ hardware metadata. This paper describes Golden-Eye’s technical design and implementation which make it an easy-to-use, extensible, versatile, and fast tool for dependability research and future DNN accelerator design. We showcase its utility with three case studies: a unifying platform for number system comparison and evaluation, a design-space exploration heuristic for data type selection, and fast DNN reliability analysis for different error models. GoldenEye is open-sourced and available at: https://github.com/ma3mool/goldeneye.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了GoldenEye，这是一个为PyTorch深度学习框架实现的功能模拟器，具有常见和新兴数字格式的故障注入能力。GoldenEye为DNN的数值格式评估提供了一个统一的框架，包括传统的数字系统，如定点和浮点，以及最近受DNN启发的格式，如块浮点和AdaptivFloat。此外，GoldenEye还支持在值的生命周期内，在各种逻辑和功能点进行单比特和多比特翻转，以进行弹性分析，包括首次关注数值的硬件元数据。本文描述了金眼的技术设计和实现，使其成为一个易于使用、可扩展、通用和快速的工具，用于可靠性研究和未来的DNN加速器设计。我们通过三个案例研究展示了它的实用性:一个用于数系比较和评估的统一平台，一个用于数据类型选择的设计空间探索启发式方法，以及用于不同错误模型的快速DNN可靠性分析。黄金眼是开源的，可在https://github.com/ma3mool/goldeneye.获得",
                    "title_zh": "黄金眼:评估DNN加速器中新兴数字数据格式的平台"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00032",
                    "title": "On the Price of Locality in Static Fast Rerouting",
                    "authors": "Klaus-Tycho Foerster, Juho Hirvonen, Yvonne-Anne Pignolet, Stefan Schmid, Gilles Trédan",
                    "abstract": "Modern communication networks feature fully decen-tralized flow rerouting mechanisms which allow them to quickly react to link failures. This paper revisits the fundamental algorithmic problem underlying such local fast rerouting mechanisms. Is it possible to achieve perfect resilience, i.e., to define local routing tables which preserve connectivity as long as the underlying network is still connected? Feigenbaum et al. [1] and Foerster et al. [2] showed that, unfortunately, it is impossible in general.This paper charts a more complete landscape of the feasibility of perfect resilience. We first show a perhaps surprisingly large price of locality in static fast rerouting mechanisms: even when source and destination remain connected by a linear number of link-disjoint paths after link failures, local rerouting algorithms cannot find any of them which leads to a disconnection on the routing level. This motivates us to study resilience in graphs which exclude certain dense minors, such as cliques or a complete bipartite graphs, and in particular, provide characterizations of the possibility of perfect resilience in different routing models. We provide further insights into the price of locality by showing impossibility results for few failures and investigate perfect resilience on Topology Zoo networks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代通信网络的特征是完全去中心化的流重新路由机制，这允许它们对链路故障做出快速反应。本文重新探讨了这种局部快速重路由机制的基本算法问题。是否有可能实现完美的弹性，即定义本地路由表，只要基础网络仍然连接，就保持连通性？Feigenbaum等人[1]和Foerster等人[2]表明，不幸的是，这在一般情况下是不可能的。本文更完整地展示了完美弹性的可行性。我们首先展示了在静态快速重路由机制中，局部性的代价可能惊人的大:即使当源和目的地在链路故障后通过线性数量的链路不相交路径保持连接时，本地重路由算法也不能找到它们中的任何一个，这导致了路由级的断开。这促使我们研究排除了某些稠密子图的图中的弹性，例如集团或完全二部图，特别是提供了不同路由模型中完美弹性的可能性的特征。我们通过展示少数故障的不可能性结果来提供对局部性价格的进一步洞察，并研究拓扑动物园网络上的完美弹性。",
                    "title_zh": "静态快速重路由中的局部性代价"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00033",
                    "title": "BLAP: Bluetooth Link Key Extraction and Page Blocking Attacks",
                    "authors": "Changseok Koh, Jonghoon Kwon, Junbeom Hur",
                    "abstract": "Secure Simple Pairing (SSP) and Link Manager Protocol (LMP) authentication are two main authentication mechanisms in Bluetooth specification. In this paper, we present two novel attacks, called link key extraction and page blocking attacks, breaking LMP authentication and SSP authentication, respectively. Link key extraction attack allows attackers to extract link keys of Bluetooth devices generated during the SSP procedure by exploiting Bluetooth HCI dump. Page blocking attacks by man-in-the-middle (MITM) attackers enforce Blue-tooth connections, enabling subsequent SSP downgrade attacks to bypass the SSP authentication challenge. In order to demonstrate the efficacy, we implement our attacks on various real-world devices and show that (1) a target link key is dumped into a log and extracted efficiently, possibly leading to the subsequent impersonation attack, and (2) malicious MITM connections can be established with 100% success rate, enabling subsequent SSP downgrade attack. We investigate the root causes for the vulnerabilities and present mitigations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全简单配对(SSP)和链路管理协议(LMP)认证是蓝牙规范中的两种主要认证机制。在本文中，我们提出了两种新的攻击，称为链接密钥提取和页面阻塞攻击，分别破坏LMP认证和SSP认证。链接密钥提取攻击允许攻击者通过利用蓝牙HCI转储来提取在SSP过程中生成的蓝牙设备的链接密钥。中间人(MITM)攻击者发起的页面阻塞攻击会强制实施蓝牙连接，使得后续的SSP降级攻击能够绕过SSP身份验证挑战。为了证明有效性，我们在各种真实设备上实施了我们的攻击，并表明(1)目标链接密钥被转储到日志中并被有效提取，这可能导致后续的假冒攻击，以及(2)恶意MITM连接可以以100%的成功率建立，从而允许后续的SSP降级攻击。我们调查了漏洞的根本原因并提出了缓解措施。",
                    "title_zh": "BLAP:蓝牙链接密钥提取和页面阻塞攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00034",
                    "title": "The Hazard Value: A Quantitative Network Connectivity Measure Accounting for Failures",
                    "authors": "Pieter Cuijpers, Stefan Schmid, Nicolas Schnepf, Jirí Srba",
                    "abstract": "To meet their stringent requirements in terms of performance and dependability, communication networks should be \"well connected\". While classic connectivity measures typically revolve around topological properties, e.g., related to cuts, these measures may not reflect well the degree to which a network is actually dependable. We introduce a more refined measure for network connectivity, the hazard value, which is developed to meet the needs of a real network operator. It accounts for crucial aspects affecting the dependability experienced in practice, including actual traffic patterns, distribution of failure probabilities, routing constraints, and alternatives for services with preferences therein. We analytically show that the hazard value fulfills several fundamental desirable properties that make it suitable for comparing different network topologies with one another, and for reasoning about how to efficiently enhance the robustness of a given network. We also present an optimised algorithm to compute the hazard value and an experimental evaluation against networks from the Internet Topology Zoo and classical datacenter topologies, such as fat trees and BCubes. This evaluation shows that the algorithm computes the hazard value within minutes for realistic networks, making it practically usable for network designers.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-03877336/file/resilience-axioms.pdf"
                    },
                    "abstract_zh": "为了满足他们在性能和可靠性方面的严格要求，通信网络应该“良好连接”。虽然经典的连通性测量通常围绕拓扑属性，例如与切割相关的拓扑属性，但是这些测量可能不能很好地反映网络实际可靠的程度。我们引入了一个更精确的网络连通性的度量，危险值，它是为了满足真实网络运营商的需求而开发的。它考虑了影响实践中所经历的可靠性的关键方面，包括实际的流量模式、故障概率的分布、路由约束以及其中具有偏好的服务的替代方案。我们通过分析表明，危险值满足几个基本的理想性质，使其适合于比较不同的网络拓扑结构，并适合于推理如何有效地增强给定网络的鲁棒性。我们还提出了一种计算危险值的优化算法，并对来自Internet拓扑动物园和经典数据中心拓扑(如胖树和BCubes)的网络进行了实验评估。该评估表明，该算法在几分钟内计算出真实网络的危险值，使其实际上可用于网络设计者。",
                    "title_zh": "危险值:考虑故障的定量网络连通性测量"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00035",
                    "title": "PassFlow: Guessing Passwords with Generative Flows",
                    "authors": "Giulio Pagnotta, Dorjan Hitaj, Fabio De Gaspari, Luigi V. Mancini",
                    "abstract": "Recent advances in generative machine learning models rekindled research interest in the area of password guessing. Data-driven password guessing approaches based on GANs, language models, and deep latent variable models have shown impressive generalization performance and offer compelling properties for the task of password guessing.This paper proposes PassFlow, a flow-based generative model approach to password guessing. Flow-based models allow for precise log-likelihood computation and optimization, which enables exact latent variable inference. Additionally, flow-based models provide meaningful latent space representation, which enables operations such as exploration of specific subspaces of the latent space and interpolation. We demonstrate the applicability of generative flows to the context of password guessing, departing from previous applications of flow-networks which are mainly limited to the continuous space of image generation. We show that PassFlow is able to outperform prior state-of-the-art GAN-based approaches in the password guessing task while using a training set that is orders of magnitudes smaller than that of prior art. Furthermore, a qualitative analysis of the generated samples shows that PassFlow can accurately model the distribution of the original passwords, with even non-matched samples closely resembling human-like passwords.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2105.06165"
                    },
                    "abstract_zh": "生成机器学习模型的最新进展重新点燃了密码猜测领域的研究兴趣。基于GANs、语言模型和深层潜在变量模型的数据驱动密码猜测方法已经显示出令人印象深刻的泛化性能，并且为密码猜测任务提供了引人注目的特性。提出了PassFlow，一种基于流的生成模型密码猜测方法。基于流量的模型允许精确的对数似然计算和优化，从而实现精确的潜在变量推断。此外，基于流的模型提供了有意义的潜在空间表示，这使得诸如潜在空间的特定子空间的探索和插值的操作成为可能。我们证明了生成流在密码猜测环境中的适用性，这与以前流网络的应用不同，以前的应用主要局限于图像生成的连续空间。我们表明，PassFlow在密码猜测任务中能够优于现有技术水平的基于GAN的方法，同时使用比现有技术小几个数量级的训练集。此外，对生成的样本的定性分析表明，PassFlow可以准确地模拟原始密码的分布，即使不匹配的样本也非常类似于类似人类的密码。",
                    "title_zh": "PassFlow:使用生成流猜测密码"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00036",
                    "title": "Active-MTSAD: Multivariate Time Series Anomaly Detection With Active Learning",
                    "authors": "Wenlu Wang, Pengfei Chen, Yibin Xu, Zilong He",
                    "abstract": "Time series anomaly detection is an important research topic in the field of intelligent operation and maintenance. When software systems are frequently updated with continuous integration and deployment, the distribution of KPI data will also change, and the accuracy of anomaly detection models will inevitably decrease. To tackle this problem, we propose an active anomaly detection framework named Active-MTSAD suitable for multi-dimensional time series, combining unsupervised anomaly detection and active learning. The active learning module introduces three feedback strategies, namely denominator penalty, negative penalty, and metric learning, to learn new anomalous patterns under new data distribution. In metric learning, we consider the difference between normal and abnormal samples in reconstruction error and latent space. We conduct extensive experiments on a large-scale public dataset and a real-world dataset coming from Tencent. The experimental results show that Active-MTSAD can still achieve excellent performance in real scenarios where the distribution changes with only 0.2% of labels.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "时间序列异常检测是智能运维领域的一个重要研究课题。当软件系统随着持续的集成和部署而频繁更新时，KPI数据的分布也会发生变化，异常检测模型的准确性必然会降低。针对这一问题，结合无监督异常检测和主动学习，提出了一种适用于多维时间序列的主动异常检测框架Active-MTSAD。主动学习模块引入了三种反馈策略，即分母惩罚、负惩罚和度量学习，以学习新数据分布下的新异常模式。在度量学习中，我们考虑正常样本和异常样本在重构误差和潜在空间上的差异。我们在大规模公共数据集和来自腾讯的真实数据集上进行了大量实验。实验结果表明，Active-MTSAD在分布仅发生0.2%变化的真实场景中仍能取得优异的性能。",
                    "title_zh": "主动学习的多元时间序列异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00037",
                    "title": "Predicting DRAM-Caused Node Unavailability in Hyper-Scale Clouds",
                    "authors": "Pengcheng Zhang, Yunong Wang, Xuhua Ma, Yaoheng Xu, Bin Yao, Xudong Zheng, Linquan Jiang",
                    "abstract": "DRAM faults are major hardware sources of cloud node unavailability. To enable early preventive actions and mitigate DRAM fault impacts, prior studies focus on predicting DRAM uncorrectable errors (UEs) that typically cause immediate node unavailability. In our cloud with over half a million nodes, we firstly observe that the correctable error storm (numerous CEs occur in a short period) dominates 56% DRAM-caused node unavailability (DCNU). Therefore, we propose to predict DCNU that takes account into both UEs and CE storms. Observing that DCNUs have strong relevance to temporal statistics and spatial patterns of CEs, we design novel spatio-temporal features to train the prediction model. Considering the model’s real effects cannot be evaluated by traditional metrics like F1-score, we propose a new metric NURR to quantify the node unavailability reduction and tune model hyperparameters with NURR. Our approach achieves over 40% better NURR than existing methods on historical data and runs stably in the production environment.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "DRAM故障是云节点不可用的主要硬件来源。为了实现早期预防措施并减轻DRAM故障的影响，先前的研究集中于预测通常导致立即节点不可用的DRAM不可纠正错误(UE)。在我们拥有超过50万个节点的云中，我们首先观察到可纠正的错误风暴(在短时间内发生大量计算事件)占据了56%的DRAM导致的节点不可用性(DCNU)。因此，我们建议预测考虑到UE和CE风暴的DCNU。观察到DCNUs与CEs的时间统计和空间模式有很强的相关性，我们设计了新的时空特征来训练预测模型。考虑到模型的实际效果不能用F1-score等传统指标来评价，我们提出了一种新的指标NURR来量化节点不可用率的降低，并用NURR来调整模型超参数。我们的方法在历史数据上获得了比现有方法高出40%以上的NURR，并且在生产环境中稳定运行。",
                    "title_zh": "预测超大规模云中DRAM导致的节点不可用性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00038",
                    "title": "Tool: An Efficient and Flexible Simulator for Byzantine Fault-Tolerant Protocols",
                    "authors": "Ping-Lun Wang, Tzu-Wei Chao, Chia-Chien Wu, Hsu-Chun Hsiao",
                    "abstract": "A Byzantine Fault-Tolerant (BFT) protocol protects a distributed system from faulty participants. To provide both liveness and safety, many such protocols assume they are dealing with a partially-synchronous network, which will eventually stabilize after a global stabilization time (GST). In a real-world network environment, however, there is no such guarantee of bounded transmission time for network packets. For this reason, even if a BFT protocol is mathematically proven to achieve both liveness and safety, its overall performance is difficult to analyze theoretically, especially if there are bad network conditions or adversarial behaviors. Accordingly, we propose a simulator for evaluating the performance of BFT protocols under various network conditions and attacks, and we implement it to empirically compare the performance of eight representative protocols. Experiment results show that our simulator can simulate 16 times as many nodes as an existing simulator supports (512 vs. 32), and it is over 500 times faster when simulating 32 nodes (38 milliseconds vs. 19.4 seconds).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "拜占庭容错(BFT)协议保护分布式系统免受错误参与者的影响。为了提供活性和安全性，许多这样的协议假设它们正在处理部分同步的网络，该网络将在全局稳定时间(GST)之后最终稳定。然而，在现实世界的网络环境中，网络数据包的有限传输时间没有这样的保证。由于这个原因，即使BFT协议在数学上被证明同时具有活性和安全性，它的整体性能也很难从理论上分析，尤其是在网络条件恶劣或存在敌对行为的情况下。因此，我们提出了一个模拟器，用于评估BFT协议在各种网络条件和攻击下的性能，并且我们实现了它来实验性地比较八个代表性协议的性能。实验结果表明，我们的模拟器可以模拟16倍于现有模拟器支持的节点数(512对32)，并且在模拟32个节点时(38毫秒对19.4秒)快了500多倍。",
                    "title_zh": "Tool:一个高效灵活的拜占庭容错协议模拟器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00039",
                    "title": "Invoke-Deobfuscation: AST-Based and Semantics-Preserving Deobfuscation for PowerShell Scripts",
                    "authors": "Huajun Chai, Lingyun Ying, Haixin Duan, Daren Zha",
                    "abstract": "In recent years, PowerShell has been widely used in cyber attacks and malicious PowerShell scripts can easily evade the detection of anti-virus software through obfuscation. Existing deobfuscation tools often fail to recover obfuscated scripts correctly due to imprecise obfuscation identification, improper recovery and wrong replacement. In this paper, we propose an AST-based and semantics-preserving deobfuscation approach, Invoke-Deobfuscation. It utilizes recoverable nodes of Abstract Syntax Tree to identify obfuscated pieces precisely, simulates the recovery process through Invoke function and variable tracing, and replaces obfuscated pieces in place to keep the original semantics. We build a large evaluation dataset containing 39,713 wild PowerShell scripts. Compared with the state-of-the-art tools, the experimental results show Invoke-Deobfuscation performs most efficiently. It recovers much more key information than others and significantly reduces samples’ obfuscation score, on average, by 46%. Moreover, 100% of Invoke-Deobfuscation’s results have the same network behavior as the original scripts.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，PowerShell被广泛应用于网络攻击中，恶意PowerShell脚本可以很容易地通过混淆来逃避杀毒软件的检测。现有的反混淆工具经常由于混淆识别不精确、恢复不当和替换错误而无法正确恢复混淆脚本。在本文中，我们提出了一种基于AST的语义保持去模糊方法，即Invoke-de obfusion。该算法利用抽象语法树的可恢复节点精确识别混淆片段，通过调用函数和变量追踪模拟恢复过程，并就地替换混淆片段以保持原始语义。我们构建了一个包含39，713个野生PowerShell脚本的大型评估数据集。实验结果表明，与目前最先进的工具相比，Invoke-de obfusion的执行效率最高。与其他方法相比，它可以恢复更多的关键信息，并显著降低样本的模糊分数，平均降低46%。此外，100%的Invoke-deobfusion结果与原始脚本具有相同的网络行为。",
                    "title_zh": "invoke-de obfusion:PowerShell脚本的基于AST且保持语义的de obfusion"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00040",
                    "title": "Exploiting monotonicity and symmetry for efficient simulation of highly dependable systems",
                    "authors": "Hoang Hai Nguyen, Kartik Palani, David M. Nicol",
                    "abstract": "Evaluation of highly dependable systems requires estimating the probability of a significant rare event under which the system fails to meet the requirement. To improve the estimation accuracy, advanced Monte Carlo simulation techniques such as importance sampling (IS) are commonly used. However, IS is known to misbehave under high dimension. As a result, the IS estimator can have a large relative error and underestimate the rare event probability. In this paper, we propose a novel IS method based on the idea of maximum weight minimization (MWM). Our method works by finding the sampling distribution that minimizes the maximum weight of a rare event sample. To alleviate the curse of dimensionality, we develop further heuristics based on two problem-specific structures, namely, monotonicity and symmetry. Using extensive examples from network reliability, stochastic flow analysis, cyber-security risk assessment, and fault tree analysis, we evaluate the performance of MWM, demonstrate its accuracy and scalability, and highlight applications where it outperforms state-of-the-art techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高度可靠系统的评估需要估计系统无法满足要求的重大罕见事件的概率。为了提高估计精度，通常使用先进的蒙特卡罗模拟技术，例如重要抽样(IS)。然而，众所周知，它在高维度下行为不良。因此，IS估计值可能具有较大的相对误差，并低估了罕见事件概率。在本文中，我们提出了一种新的基于最大重量最小化(MWM)思想的信息系统方法。我们的方法通过寻找使罕见事件样本的最大权重最小化的采样分布来工作。为了减轻维数灾难，我们基于两个特定于问题的结构，即单调性和对称性，开发了进一步的启发式算法。我们使用来自网络可靠性、随机流量分析、网络安全风险评估和故障树分析的大量示例，评估了MWM的性能，展示了其准确性和可扩展性，并重点介绍了其优于一流技术的应用。",
                    "title_zh": "利用单调性和对称性有效模拟高可靠性系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00041",
                    "title": "RAPMiner: A Generic Anomaly Localization Mechanism for CDN System with Multi-dimensional KPIs",
                    "authors": "Chang Liu, Yanwei Liu, Zhen Xu, Liang Dai",
                    "abstract": "As essential work in IT operations, anomaly localization, aiming to identify the affected scope of Internet infrastructure once an anomaly alarm occurs, is challenging due to the huge search space. The existing solutions usually show limited performances in the CDN scenario since they take the desirable assumptions that do not match with the practical anomaly pattern features. To address this issue, in this paper, we propose RAPMiner, which first uses a classification power-based redundant attribute deletion to prune the non-root cause attribute combinations, and then adopts an anomaly confidence-guided layer-by-layer top-down search to avoid searching for anomaly but non-root patterns. Both of them are effective in narrowing the search space. Experimental results show that RAPMiner can achieve comparable performance with the SOTA approach on the published Squeeze dataset according to F1-score and efficiency, as well as the best RC@k with stable parameter sensitivity on the RAPMD.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "异常定位是IT运营中的一项重要工作，其目的是在异常警报发生时确定互联网基础设施的影响范围，由于搜索空间巨大，因此具有挑战性。现有的解决方案通常在CDN场景中表现出有限的性能，因为它们采用了与实际异常模式特征不匹配的期望假设。为了解决这一问题，本文提出了RAPMiner算法，该算法首先使用基于分类能力的冗余属性删除来修剪非根原因属性组合，然后采用异常置信度引导的逐层自顶向下搜索来避免搜索异常但非根模式。两者都有效地缩小了搜索空间。实验结果表明，根据F1-score和效率，RAPMiner可以在已公布的Squeeze数据集上获得与SOTA方法相当的性能，并且在RAPMD上获得具有稳定参数敏感性的最佳RC@k。",
                    "title_zh": "RAPMiner:一种基于多维KPI的CDN系统通用异常定位机制"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00042",
                    "title": "Minimizing Noise in HyperLogLog-Based Spread Estimation of Multiple Flows",
                    "authors": "Dinhnguyen Dao, Rhongho Jang, Changhun Jung, David Mohaisen, DaeHun Nyang",
                    "abstract": "Cardinality estimation has become an essential building block of modern network monitoring systems due to the increasing concerns of cyberattacks (e.g., Denial-of-Service, worm, spammer, scanner, etc.). However, the ever-increasing attack scale and the diversity of patterns (i.e., flow size distribution) will produce a biased estimation of existing solutions if apply a monotonic hypothesis for network traffic. The most representative solution is virtual HyperLogLog (vHLL), which extended the proven HLL, a single element cardinality estimation solution, to a multi-tenant version using a memory random sharing and noise elimination approach. In this paper, we show that the assumption made by vHLL’s does not work for large-scale network traffic with diverse flow distributions. To resolve the issue, we propose a novel noise elimination method, called Rank Recovery-based Spread Estimator (RRSE), which is tolerant to both attack and normal traffic scenarios while using limited computation and storage. We show that our recovery function is more reliable than state-of-the-art approaches. Moreover, we implemented RRSE in a programmable switch to show the feasibility.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于对网络攻击(例如，拒绝服务、蠕虫、垃圾邮件发送者、扫描器等)的日益关注，基数估计已经成为现代网络监控系统的基本构件。).然而，如果对网络流量应用单调假设，不断增加的攻击规模和模式多样性(即，流大小分布)将产生对现有解决方案的有偏估计。最具代表性的解决方案是虚拟超对数(vHLL ),它使用内存随机共享和噪声消除方法，将成熟的单元素基数估计解决方案HLL扩展到多租户版本。在本文中，我们证明了vHLL的假设不适用于具有不同流量分布的大规模网络流量。为了解决这个问题，我们提出了一种新的噪声消除方法，称为基于秩恢复的扩展估计器(RRSE ),它可以容忍攻击和正常业务场景，同时使用有限的计算和存储。我们证明了我们的恢复函数比最先进的方法更可靠。此外，我们在一个可编程开关中实现了RRSE以证明其可行性。",
                    "title_zh": "最小化基于超对数的多流传播估计中的噪声"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00043",
                    "title": "L2Fuzz: Discovering Bluetooth L2CAP Vulnerabilities Using Stateful Fuzz Testing",
                    "authors": "Haram Park, Carlos Nkuba Kayembe, Seunghoon Woo, Heejo Lee",
                    "abstract": "Bluetooth Basic Rate/Enhanced Data Rate (BR/EDR) is a wireless technology used in billions of devices. Recently, several Bluetooth fuzzing studies have been conducted to detect vulnerabilities in Bluetooth devices, but they fall short of effectively generating malformed packets. In this paper, we propose L2FUZZ, a stateful fuzzer to detect vulnerabilities in Bluetooth BR/EDR Logical Link Control and Adaptation Protocol (L2CAP) layer. By selecting valid commands for each state and mutating only the core fields of packets, L2FUZZ can generate valid malformed packets that are less likely to be rejected by the target device. Our experimental results confirmed that: (1) L2FUZZ generates up to 46 times more malformed packets with a much less packet rejection ratio compared to the existing techniques, and (2) L2FUZZ detected five zero-day vulnerabilities from eight real-world Bluetooth devices.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2208.00110"
                    },
                    "abstract_zh": "蓝牙基本速率/增强数据速率(BR/EDR)是一种无线技术，用于数十亿台设备。最近，已经进行了几项蓝牙模糊化研究来检测蓝牙设备中的漏洞，但是它们未能有效地生成畸形分组。在本文中，我们提出了L2FUZZ，一个有状态的fuzzer来检测蓝牙BR/EDR逻辑链路控制和适配协议(L2CAP)层的漏洞。通过为每种状态选择有效的命令并只改变数据包的核心字段，L2FUZZ可以生成有效的格式错误的数据包，这些数据包不太可能被目标设备拒绝。我们的实验结果证实:(1)与现有技术相比，L2FUZZ生成高达46倍的畸形分组，而分组拒绝率低得多，以及(2) L2FUZZ从八个真实世界的蓝牙设备中检测到五个零日漏洞。",
                    "title_zh": "L2Fuzz:使用状态模糊测试发现蓝牙L2CAP漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00044",
                    "title": "NEC: Speaker Selective Cancellation via Neural Enhanced Ultrasound Shadowing",
                    "authors": "Hanqing Guo, Chenning Li, Lingkun Li, Zhichao Cao, Qiben Yan, Li Xiao",
                    "abstract": "In this paper, we propose NEC (Neural Enhanced Cancellation), a defense mechanism, which prevents unautho-rized microphones from capturing a target speaker’s voice. Compared with the existing scrambling-based audio cancellation approaches, NEC can selectively remove a target speaker’s voice from a mixed speech without causing interference to others. Specifically, for a target speaker, we design a Deep Neural Network (DNN) model to extract high-level speaker-specific but utterance-independent vocal features from his/her reference audios. When the microphone is recording, the DNN generates a shadow sound to cancel the target voice in real-time. Moreover, we modulate the audible shadow sound onto an ultrasound frequency, making it inaudible for humans. By leveraging the non-linearity of the microphone circuit, the microphone can accurately decode the shadow sound for target voice cancellation. We implement and evaluate NEC comprehensively with 8 smartphone microphones in different settings. The results show that NEC effectively mutes the target speaker at a microphone without interfering with other users’ normal conversations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们提出了NEC (Neural Enhanced Cancellation ),这是一种防御机制，可以防止未经授权的麦克风捕获目标说话人的语音。与现有的基于加扰的音频消除方法相比，NEC可以选择性地从混合语音中消除目标说话人的语音，而不会对他人造成干扰。具体来说，对于目标说话人，我们设计了一个深度神经网络(DNN)模型来从他/她的参考音频中提取特定于说话人但与话语无关的高级语音特征。麦克风录音时，DNN会产生阴影声音，实时抵消目标声音。此外，我们将可听见的阴影声音调制到超声波频率上，使人类听不见。通过利用麦克风电路的非线性，麦克风可以准确解码阴影声音，以消除目标声音。我们在不同的环境中使用8个智能手机麦克风全面实施和评估NEC。结果表明，NEC有效地使麦克风处的目标说话者静音，而不干扰其他用户的正常通话。",
                    "title_zh": "NEC:通过神经增强超声阴影的说话者选择性消除"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00045",
                    "title": "False Data Injection Attack Detection for Secure Distributed Demand Response in Smart Grids",
                    "authors": "Thusitha Dayaratne, Mahsa Salehi, Carsten Rudolph, Ariel Liebman",
                    "abstract": "Distributed demand response (DR) schemes for smart energy networks rely on data from various sources, many of them outside the network operator’s perimeter. Therefore, compromised inputs from false data injection attacks (FDIAs) can be detrimental to the expectations of stakeholders, pro-vide financial benefits to malicious actors, compromise the commercial viability of the scheme and have the potential to disrupt the energy supply. Due to the heterogeneity of data sources, FDIAs are arduous to prevent with standard security controls. Thus, detecting FDIAs is necessary to facilitate impact mitigations. However, FDIA detection in the residential DR context is arduous, given the inherent challenges such as the noisiness of residential demand, lack of labelled data in real-life settings, and variety and dynamicity of demand forecasts (e.g., weekdays vs weekend, different months/seasons). Addressing mentioned challenges, in this paper, we propose a data-driven unsupervised anomaly detection approach, named Clustering-based Spectral Residual (CSR), to detect false data injection attacks in smart grids’ DR. The CSR model is based on the popular k-means clustering and Spectral Residual method. The combination highlights the attack time slots, which increases the detection accuracy in our model. A supervised model is also proposed based on Convolutional Neural Network (CNN) to increase the detection accuracy in scenarios where label information is available. Using an energy consumption dataset from Austin, Texas, as a case study and through extensive experimental results, we show that our proposed CSR and CNN models outperform 25 widely used anomaly detection benchmarks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "智能能源网络的分布式需求响应(DR)方案依赖于各种来源的数据，其中许多都在网络运营商的边界之外。因此，来自虚假数据注入攻击(FDIAs)的受损输入可能会损害利益相关者的期望，为恶意行为者提供经济利益，损害方案的商业可行性，并有可能中断能源供应。由于数据源的异构性，使用标准的安全控制措施很难防止FDIAs。因此，检测FDIAs对于缓解影响是必要的。然而，住宅灾难恢复环境中的FDIA检测是艰巨的，因为存在固有的挑战，例如住宅需求的噪音、现实生活环境中标签数据的缺乏以及需求预测的多样性和动态性(例如，工作日与周末、不同月份/季节)。针对上述挑战，本文提出了一种数据驱动的无监督异常检测方法，称为基于聚类的谱残差(CSR ),用于检测智能电网灾难恢复中的虚假数据注入攻击。该组合突出了攻击时隙，这增加了我们模型中的检测准确性。还提出了一种基于卷积神经网络(CNN)的监督模型，以提高标签信息可用情况下的检测精度。使用德克萨斯州奥斯汀的能耗数据集作为案例研究，通过大量的实验结果，我们表明我们提出的CSR和CNN模型优于25个广泛使用的异常检测基准。",
                    "title_zh": "智能电网中安全分布式需求响应的虚假数据注入攻击检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00046",
                    "title": "Solution Bundles of Markov Performability Models through Adaptive Cross Approximation",
                    "authors": "Giulio Masetti, Leonardo Robol, Silvano Chiaradonna, Felicita Di Giandomenico",
                    "abstract": "A technique to approximate solution bundles, i.e., solutions of a parametric model where parameters are treated as independent variables instead of constants, is presented for Markov models. Analyses based on an approximated solution bundle are more efficient than those that solve the model for all combinations of parameters’ values separately. In this paper the idea is to properly adapt low rank tensor approximation techniques, and in particular Adaptive Cross Approximation, to the evaluation of performability attributes. Application on exemplary case studies confirms the advantages of the new solution technique with respect to solving the model for all time and parameters’ combinations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "针对马尔可夫模型提出了一种近似解束的技术，即参数模型的解，其中参数被视为独立变量而不是常数。基于近似解束的分析比针对参数值的所有组合分别求解模型的分析更有效。在本文中，想法是适当地调整低秩张量近似技术，特别是自适应交叉近似，以评估可执行性属性。典型案例研究的应用证实了新的求解技术在求解所有时间和参数组合的模型方面的优势。",
                    "title_zh": "基于自适应交叉逼近的马尔可夫可执行模型的解束"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00047",
                    "title": "Characterizing and Mitigating Anti-patterns of Alerts in Industrial Cloud Systems",
                    "authors": "Tianyi Yang, Jiacheng Shen, Yuxin Su, Xiaoxue Ren, Yongqiang Yang, Michael R. Lyu",
                    "abstract": "Alerts are crucial for requesting prompt human intervention upon cloud anomalies. The quality of alerts significantly affects the cloud reliability and the cloud provider’s business revenue. In practice, we observe on-call engineers being hindered from quickly locating and fixing faulty cloud services because of the vast existence of misleading, non-informative, non-actionable alerts. We call the ineffectiveness of alerts \"anti-patterns of alerts\". To better understand the anti-patterns of alerts and provide actionable measures to mitigate anti-patterns, in this paper, we conduct the first empirical study on the practices of mitigating anti-patterns of alerts in an industrial cloud system. We study the alert strategies and the alert processing procedure at Huawei Cloud, a leading cloud provider. Our study combines the quantitative analysis of millions of alerts in two years and a survey with eighteen experienced engineers. As a result, we summarized four individual anti-patterns and two collective anti-patterns of alerts. We also summarize four current reactions to mitigate the anti-patterns of alerts, and the general preventative guidelines for the configuration of alert strategy. Lastly, we propose to explore the automatic evaluation of the Quality of Alerts (QoA), including the indicativeness, precision, and handleability of alerts, as a future research direction that assists in the automatic detection of alerts’ anti-patterns. The findings of our study are valuable for optimizing cloud monitoring systems and improving the reliability of cloud services.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "警报对于在云异常时请求及时的人工干预是至关重要的。警报的质量会显著影响云的可靠性和云提供商的业务收入。在实践中，我们发现待命工程师无法快速定位和修复故障云服务，因为大量存在误导性、非信息性、不可操作的警报。我们将警报的无效性称为“警报的反模式”。为了更好地理解警报的反模式并提供可行的措施来减轻反模式，在本文中，我们对减轻工业云系统中警报的反模式的实践进行了首次实证研究。我们研究了领先的云提供商华为云的警报策略和警报处理流程。我们的研究结合了两年内数百万次警报的定量分析和对18名经验丰富的工程师的调查。因此，我们总结了四种单独的警报反模式和两种集体警报反模式。我们还总结了减轻警报反模式的四种当前反应，以及警报策略配置的一般预防准则。最后，我们建议探索警报质量(QoA)的自动评估，包括警报的指示性、精确性和可处理性，作为未来帮助自动检测警报反模式的研究方向。我们的研究结果对于优化云监控系统和提高云服务的可靠性具有重要价值。",
                    "title_zh": "表征和减轻工业云系统中警报的反模式"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00048",
                    "title": "Torpedo: A Fuzzing Framework for Discovering Adversarial Container Workloads",
                    "authors": "Kenton McDonough, Xing Gao, Shuai Wang, Haining Wang",
                    "abstract": "Containers enable a computing system to host multiple isolated applications, making more cost-efficient use of the available computing resources. However, exploiting shared computing resources, adversaries can launch various real-world attacks (e.g., denial-of-service attacks) inside containers. In this paper, we present TORPEDO, a fuzzing-based approach to detecting out-of-band workloads: such workloads could largely interfere the performance of colocated container instances on the same host, gaining extra unfair advantages on the system resources without being charged appropriately. TORPEDO mutates inputs of OS syscalls and simultaneously monitors the resource consumption of multiple container instances. It uses resource-guided heuristics to find inputs that maximize the difference in resource consumption between container instances and resource limits. We evaluate TORPEDO on widely-used containerization platforms and demonstrate that it can verify adversarial workloads that are manually discovered by existing research. More importantly, TORPEDO identifies several zero-day vulnerabilities that are not known to the public.",
                    "files": {
                        "openAccessPdf": "https://vtechworks.lib.vt.edu/bitstream/10919/104159/1/McDonough_KR_T_2021.pdf"
                    },
                    "abstract_zh": "容器使计算系统能够托管多个独立的应用程序，从而更加经济高效地利用可用的计算资源。然而，利用共享的计算资源，对手可以在容器内发起各种真实世界的攻击(例如，拒绝服务攻击)。在本文中，我们提出了鱼雷，一种基于模糊化的方法来检测带外工作负载:这种工作负载可能会在很大程度上干扰同一主机上共存的容器实例的性能，在没有适当收费的情况下获得额外的不公平的系统资源优势。鱼雷变异操作系统系统调用的输入，同时监控多个容器实例的资源消耗。它使用资源引导的试探法来寻找最大化容器实例和资源限制之间的资源消耗差异的输入。我们在广泛使用的集装箱化平台上评估了鱼雷，并证明它可以验证现有研究中人工发现的敌对工作负载。更重要的是，鱼雷识别了几个不为公众所知的零日漏洞。",
                    "title_zh": "鱼雷:一个发现敌对容器工作负载的模糊框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00049",
                    "title": "Back to the future: N-Versioning of Microservices",
                    "authors": "Antonio M. Espinoza, Riley Wood, Stephanie Forrest, Mohit Tiwari",
                    "abstract": "Microservices are the dominant architecture used to build internet-scale applications today. Being internet-facing, their most critical attack surfaces are the OWASP top 10 Web Application Security Risks. Many of the top 10 OWASP attack types—injection, cross site scripting, broken access control and security misconfigurations—have persisted for many years despite major investments in code analysis and secure development patterns. Because microservices decompose monolithic applications into components using clean APIs, they lend themselves to practical application of a classic security/resilience principle, N-versioning. The paper introduces RDDR, a principled approach for applying N-versioning to microservices to improve resilience to data leaks. RDDR applies N-versioning to vulnerable microservices, requiring minimal code changes and with low performance impact beyond the cost of replicating microservices. Our evaluation demonstrates RDDR mitigating vulnerabilities of the top 5 of the top 10 OWASP types by applying diversity and redundancy to individual microservices.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "微服务是当今用于构建互联网规模应用的主导架构。由于面向互联网，他们最重要的攻击面是OWASP十大Web应用程序安全风险。尽管在代码分析和安全开发模式方面进行了大量投资，但前10大OWASP攻击类型中的许多类型——注入、跨站点脚本、破坏访问控制和安全错误配置——已经持续了许多年。因为微服务使用干净的API将整体应用分解成组件，所以它们有助于经典安全性/弹性原则的实际应用，即N版本化。本文介绍了RDDR，这是一种将N版本化应用于微服务以提高数据泄漏恢复能力的原则性方法。RDDR将N版本管理应用于易受攻击的微服务，只需要最少的代码更改，并且对性能的影响低于复制微服务的成本。我们的评估表明，RDDR通过对单个微服务应用多样性和冗余性，缓解了前10种OWASP类型中的前5种漏洞。",
                    "title_zh": "回到未来:微服务的N版本化"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00050",
                    "title": "IoT Phantom-Delay Attacks: Demystifying and Exploiting IoT Timeout Behaviors",
                    "authors": "Chenglong Fu, Qiang Zeng, Haotian Chi, Xiaojiang Du, Siva Likitha Valluru",
                    "abstract": "This paper unveils a set of new attacks against Internet of Things (IoT) automation systems. We first propose two novel IoT attack primitives: Event Message Delay and Command Message Delay (event messages are generated by IoT devices to report device states, and command messages are used to control IoT devices). Our insight is that timeout detection in the TCP layer is decoupled from data protection in the Transport Layer Security (TLS) layer. As a result, even when a session is protected by TLS, its IoT event and/or command messages can still be significantly delayed without triggering alerts. It is worth highlighting that, by compromising/controlling one WiFi device in a smart environment, the attacker can delay the IoT messages of other non-compromised IoT devices; we thus call the attacks IoT Phantom-Delay Attacks. Our study shows the attack primitives can be used to build rich attacks and some of them can induce persistent effects. The presented attacks are very different from jamming. 1) Unlike jamming, our attacks do not discard any packets and thus do not trigger re-transmission. 2) Our attacks do not cause disconnection or timeout alerts. 3) Unlike reactive jamming, which usually relies on special hardware, our attacks can be launched from an ordinary WiFi device. Our evaluation involves 50 popular IoT devices and demonstrates that they are all vulnerable to the phantom-delay attacks. Finally, we discuss the countermeasures. We have contacted multiple IoT platforms regarding the vulnerable IoT timeout behaviors, and Google, Ring and SimpliSafe have acknowledged the problem.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文揭示了一系列针对物联网自动化系统的新攻击。我们首先提出两种新颖的物联网攻击原语:事件消息延迟和命令消息延迟(事件消息由物联网设备生成以报告设备状态，命令消息用于控制物联网设备)。我们认为TCP层的超时检测与传输层安全(TLS)层的数据保护是分离的。因此，即使会话受到TLS保护，其物联网事件和/或命令消息仍可能会显著延迟，而不会触发警报。值得强调的是，通过在智能环境中妥协/控制一个WiFi设备，攻击者可以延迟其他未妥协的物联网设备的物联网消息；因此，我们称这种攻击为物联网幻影延迟攻击。我们的研究表明，攻击原语可以用来构建丰富的攻击，其中一些攻击原语可以产生持久的效果。呈现的攻击与干扰非常不同。1)与干扰不同，我们的攻击不会丢弃任何数据包，因此不会触发重新传输。2)我们的攻击不会引起断线或超时警报。3)与通常依赖特殊硬件的反应式干扰不同，我们的攻击可以从普通的WiFi设备发起。我们的评估涉及50种流行的物联网设备，并表明它们都容易受到幻影延迟攻击。最后，我们讨论了对策。我们就易受攻击的物联网超时行为联系了多个物联网平台，Google、Ring和SimpliSafe都承认了这个问题。",
                    "title_zh": "物联网幻影延迟攻击:解密和利用物联网超时行为"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00051",
                    "title": "BFL: a Logic to Reason about Fault Trees",
                    "authors": "Stefano M. Nicoletti, Ernst Moritz Hahn, Mariëlle Stoelinga",
                    "abstract": "Safety-critical infrastructures must operate safely and reliably. Fault tree analysis is a widespread method used to assess risks in these systems: fault trees (FTs) are required — among others — by the Federal Aviation Authority, the Nuclear Regulatory Commission, in the ISO26262 standard for autonomous driving and for software development in aerospace systems. Although popular both in industry and academia, FTs lack a systematic way to formulate powerful and understandable analysis queries. In this paper, we aim to fill this gap and introduce Boolean Fault tree Logic (BFL), a logic to reason about FTs. BFL is a simple, yet expressive logic that supports easier formulation of complex scenarios and specification of FT properties. Alongside BFL, we present model checking algorithms based on binary decision diagrams (BDDs) to analyse specified properties in BFL, patterns and an algorithm to construct counterexamples. Finally, we propose a case-study application of BFL by analysing a COVID-19related FT.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2208.13424"
                    },
                    "abstract_zh": "安全关键基础设施必须安全可靠地运行。故障树分析是一种广泛用于评估这些系统中风险的方法:联邦航空管理局、核管理委员会、ISO26262自动驾驶和航空航天系统软件开发标准都要求使用故障树(ft)。尽管FTs在工业界和学术界都很流行，但是它缺乏一种系统的方法来表达强大的和可理解的分析查询。在本文中，我们旨在填补这一空白，并介绍布尔故障树逻辑(BFL)，一种逻辑推理的FTs。BFL是一种简单而富于表现力的逻辑，它支持复杂场景的更简单的公式化和财务交易属性的规范。除了BFL，我们还提出了基于二元决策图(BDDs)的模型检测算法，用于分析BFL中的特定属性、模式和构造反例的算法。最后，我们通过分析一个与COVID-19相关的FT，提出了BFL的一个案例研究应用。",
                    "title_zh": "BFL:对故障树进行推理的逻辑"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00052",
                    "title": "TimeDice: Schedulability-Preserving Priority Inversion for Mitigating Covert Timing Channels Between Real-time Partitions",
                    "authors": "Man-Ki Yoon, Jung-Eun Kim, Richard M. Bradford, Zhong Shao",
                    "abstract": "Timing predictability is a precondition for successful communication over a covert timing channel. Real-time systems are particularly vulnerable to timing channels because real-time applications can easily have temporal locality due to limited uncertainty in schedules. In this paper, we show that real-time applications can create hidden information flow even when the temporal isolation among the time partitions is strictly enforced. We then introduce an online algorithm that randomizes time-partition schedules to reduce the temporal locality, while guaranteeing the schedulability of, and thus the temporal isolation among, time partitions. We also present an analysis of the cost of the randomization on the responsiveness of real-time tasks. From an implementation on a Linux-based real-time operating system, we validate the analysis and evaluate the scheduling overhead as well as the impact on an experimental real-time system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "定时可预测性是在隐蔽定时信道上成功通信的先决条件。实时系统特别容易受到时间通道的影响，因为由于时间表的有限不确定性，实时应用程序很容易具有时间局部性。在本文中，我们证明了即使严格执行时间分区之间的时间隔离，实时应用程序也可以创建隐藏的信息流。然后，我们引入一个在线算法，该算法将时间分区调度随机化，以减少时间局部性，同时保证时间分区的可调度性，从而保证时间分区之间的时间隔离。我们还提出了对实时任务响应的随机化成本的分析。通过在基于Linux的实时操作系统上的实现，我们验证了分析并评估了调度开销以及对实验实时系统的影响。",
                    "title_zh": "TimeDice:减轻实时分区间隐蔽时间通道的可调度性保持优先级反转"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00053",
                    "title": "ERIC: An Efficient and Practical Software Obfuscation Framework",
                    "authors": "Alperen Bolat, Seyyid Hikmet Çelik, Ataberk Olgun, Oguz Ergin, Marco Ottavi",
                    "abstract": "Modern cloud computing systems distribute software executables over a network to keep the software sources, which are typically compiled in a security-critical cluster, secret. However, these executables are still vulnerable to reverse engineering techniques that can extract secret information from programs (e.g., an algorithm, cryptographic keys), violating the IP rights and potentially exposing the trade secrets of the software developer. Malicious parties can (i) statically analyze the disassembly of the executable (static analysis) or (ii) dynamically analyze the software by executing it on a controlled device and observe performance counter values or exploit side-channels to reverse engineer software (dynamic analysis).We develop ERIC, a new, efficient, and general software obfuscation framework. ERIC protects software against (i) static analysis, by making only an encrypted version of software executables available to the human eye, no matter how the software is distributed, and (ii) dynamic analysis, by guaranteeing that an encrypted executable can only be correctly decrypted and executed by a single authenticated device. ERIC comprises key hardware and software components to provide efficient software obfuscation support: (i) a hardware decryption engine (HDE) enables efficient decryption of encrypted hardware in the target device, (ii) the compiler can seamlessly encrypt software executables given only a unique device identifier. Both the hardware and software components are ISA-independent, making ERIC general. The key idea of ERIC is to use physical unclonable functions (PUFs), unique device identifiers, as secret keys in encrypting software executables. Malicious parties that cannot access the PUF in the target device cannot perform static or dynamic analyses on the encrypted binary.We develop ERIC’s prototype on an FPGA to evaluate it end-to-end. Our prototype extends RISC-V Rocket Chip with the hardware decryption engine (HDE) to minimize the overheads of software decryption. We augment the custom LLVM-based compiler to enable partial/full encryption of RISC-V executables. The HDE incurs minor FPGA resource overheads, it requires 2.63% more LUTs and 3.83% more flip-flops compared to the Rocket Chip baseline. LLVM-based software encryption increases compile time by 15.22% and the executable size by 1.59%. ERIC is publicly available and can be downloaded from https://github.com/kasirgalabs/ERIC.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代云计算系统通过网络分发软件可执行文件，以保持通常在安全关键集群中编译的软件源的秘密。然而，这些可执行程序仍然容易受到逆向工程技术的攻击，逆向工程技术可以从程序中提取秘密信息(例如，算法、密钥)，侵犯了IP权利，并且潜在地暴露了软件开发者的商业秘密。恶意方可以(I)静态地分析可执行文件的反汇编(静态分析),或者(ii)通过在受控设备上执行软件并观察性能计数器值来动态地分析软件，或者利用旁路来逆向工程软件(动态分析)。我们开发了ERIC，一个新的、高效的、通用的软件混淆框架。ERIC保护软件免受(I)静态分析，即无论软件是如何分发的，只有加密版本的软件可执行文件可供人眼使用，以及(ii)动态分析，即保证加密的可执行文件只能由单个经过身份验证的设备正确解密和执行。ERIC包括关键的硬件和软件组件，以提供有效的软件混淆支持:(I)硬件解密引擎(HDE)能够在目标设备中有效地解密加密的硬件，(ii)编译器可以无缝地加密软件可执行程序，只要给定唯一的设备标识符。硬件和软件组件都是独立于ISA的，这使得ERIC具有通用性。ERIC的核心思想是使用物理不可克隆函数(puf)，即唯一的设备标识符，作为加密软件可执行文件的密钥。无法访问目标设备中的PUF的恶意方无法对加密的二进制文件执行静态或动态分析。我们在FPGA上开发了ERIC的原型，以对其进行端到端评估。我们的原型使用硬件解密引擎(HDE)扩展RISC-V Rocket芯片，以最小化软件解密的开销。我们扩充了定制的基于LLVM的编译器，以支持RISC-V可执行文件的部分/全部加密。HDE会产生少量FPGA资源开销，与Rocket芯片基线相比，它需要多2.63%的lut和3.83%的触发器。基于LLVM的软件加密使编译时间增加了15.22%，可执行文件大小增加了1.59%。ERIC是公开可用的，可以从https://github.com/kasirgalabs/ERIC.下载",
                    "title_zh": "ERIC:一个高效实用的软件混淆框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00054",
                    "title": "Understanding RowHammer Under Reduced Wordline Voltage: An Experimental Study Using Real DRAM Devices",
                    "authors": "Abdullah Giray Yaglikçi, Haocong Luo, Geraldo F. de Oliviera, Ataberk Olgun, Minesh Patel, Jisung Park, Hasan Hassan, Jeremie S. Kim, Lois Orosa, Onur Mutlu",
                    "abstract": "RowHammer is a circuit-level DRAM vulnerability, where repeatedly activating and precharging a DRAM row, and thus alternating the voltage of a row’s wordline between low and high voltage levels, can cause bit flips in physically nearby rows. Recent DRAM chips are more vulnerable to RowHammer: with technology node scaling, the minimum number of activate-precharge cycles to induce a RowHammer bit flip reduces and the RowHammer bit error rate increases. Therefore, it is critical to develop effective and scalable approaches to protect modern DRAM systems against RowHammer. To enable such solutions, it is essential to develop a deeper understanding of the RowHammer vulnerability of modern DRAM chips. However, even though the voltage toggling on a wordline is a key determinant of RowHammer vulnerability, no prior work experimentally demonstrates the effect of wordline voltage (VPP) on the RowHammer vulnerability. Our work closes this gap in understanding.This is the first work to experimentally demonstrate on 272 real DRAM chips that lowering VPP reduces a DRAM chip’s RowHammer vulnerability. We show that lowering VPP 1) increases the number of activate-precharge cycles needed to induce a RowHammer bit flip by up to 85.8 % with an average of 7.4 % across all tested chips and 2) decreases the RowHammer bit error rate by up to 66.9 % with an average of 15.2 % across all tested chips. At the same time, reducing VPP marginally worsens a DRAM cell’s access latency, charge restoration, and data retention time within the guardbands of system-level nominal timing parameters for 208 out of 272 tested chips. We conclude that reducing VPP is a promising strategy for reducing a DRAM chip’s RowHammer vulnerability without requiring modifications to DRAM chips.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "RowHammer是电路级DRAM漏洞，其中重复激活和预充电DRAM行，并因此在低和高电压电平之间改变行的字线的电压，会导致物理上邻近的行中的位翻转。最近的DRAM芯片更容易受到RowHammer的攻击:随着技术节点规模的扩大，引发RowHammer位翻转的最小激活预充电周期数减少，RowHammer位错误率增加。因此，开发有效且可扩展的方法来保护现代DRAM系统免受RowHammer攻击是至关重要的。为了实现这种解决方案，有必要对现代DRAM芯片的RowHammer漏洞进行更深入的了解。然而，即使字线上的电压切换是行锤易损性的关键决定因素，先前的工作也没有实验性地证明字线电压(VPP)对行锤易损性的影响。我们的工作弥合了这种理解上的差距。这是首次在272个真实DRAM芯片上实验证明降低VPP可以减少DRAM芯片的RowHammer漏洞。我们表明，降低VPP 1)将引发行锤位翻转所需的激活预充电周期数增加了85.8 %，所有测试芯片的平均值为7.4 %，2)将行锤位错误率降低了66.9 %，所有测试芯片的平均值为15.2 %。同时，对于272个测试芯片中的208个，降低VPP略微恶化了DRAM单元的存取延迟、电荷恢复和系统级标称时序参数的保护带内的数据保持时间。我们的结论是，降低VPP是一种有前途的策略，用于降低DRAM芯片的RowHammer漏洞，而不需要修改DRAM芯片。",
                    "title_zh": "了解字线电压降低时的行锤现象:使用真实DRAM器件的实验研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00055",
                    "title": "KingFisher: Unveiling Insecurely Used Credentials in IoT-to-Mobile Communications",
                    "authors": "Yiwei Zhang, Siqi Ma, Juanru Li, Dawu Gu, Elisa Bertino",
                    "abstract": "Today users can access and/or control their IoT devices using mobile apps. Such interactions often rely on IoT-to-Mobile communication that supports direct data exchanges between IoT devices and smartphones. To guarantee mutual authentication and encrypted data transmission in IoT-to-Mobile communications while keeping lightweight implementation, IoT devices and smartphones often share credentials in advance with the help of a cloud server. Since these credentials impact communication security, in this paper we seek to understand how such sensitive materials are implemented. We design a set of analysis techniques and implement them in KingFisher, an analysis framework. KingFisher identifies shared credentials, tracks their uses, and examines violations against nine security properties that the implementation of credentials should satisfy. With an evaluation of eight real-world IoT solutions with more than 35 million deployed devices, KingFisher revealed that all these solutions involve insecurely used credentials, and are subject to privacy leakage or device hijacking.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，用户可以使用移动应用访问和/或控制他们的物联网设备。这种交互通常依赖于物联网到移动通信，支持物联网设备和智能手机之间的直接数据交换。为了保证物联网到移动通信中的相互认证和加密数据传输，同时保持轻量级实施，物联网设备和智能手机通常会在云服务器的帮助下提前共享凭据。由于这些凭证会影响通信安全性，因此在本文中，我们试图了解这些敏感材料是如何实现的。我们设计了一套分析技术，并在分析框架KingFisher中实现。KingFisher识别共享凭证，跟踪它们的使用，并检查违反凭证实现应该满足的九个安全属性的情况。通过对部署了超过3500万台设备的八个真实世界物联网解决方案的评估，KingFisher揭示了所有这些解决方案都涉及不安全使用的凭据，并且容易受到隐私泄露或设备劫持的影响。",
                    "title_zh": "翠鸟:揭开物联网到移动通信中不安全使用的凭证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00056",
                    "title": "WideLeak: How Over-the-Top Platforms Fail in Android",
                    "authors": "Gwendal Patat, Mohamed Sabt, Pierre-Alain Fouque",
                    "abstract": "Nowadays, most content providers rely on DRM (Digital Right Management) to protect media from illegal distribution. Becoming a major platform for streaming, Android provides its own DRM framework that does not comply with existing DRM standards. Thus, OTT (over-the-top) platforms need to adapt their apps to suit Android design, despite a fragmented ecosystem and little public documentation. Unfortunately, the security implications of how OTT apps leverage Widevine, the most popular Android DRM, have not been studied yet.In this paper, we report the first experimental study on the state of Widevine use in the wild. Our study explores OTT compliance with Widevine guidelines regarding asset protection and legacy phone support. With the evaluation of premium OTT apps, our experiments bring to light that most apps adopt weak and potentially vulnerable practices. We illustrate our findings by showing how to easily recover media content from many OTT apps, including Netflix.",
                    "files": {
                        "openAccessPdf": "https://hal-univ-rennes1.archives-ouvertes.fr/hal-03637107/file/wideleak.pdf"
                    },
                    "abstract_zh": "如今，大多数内容提供商依靠DRM(数字版权管理)来保护媒体免受非法分发。作为流媒体的主要平台，Android提供了自己的DRM框架，该框架不符合现有的DRM标准。因此，OTT (over-the-top)平台需要调整其应用程序以适应Android设计，尽管生态系统支离破碎，公共文档也很少。不幸的是，OTT应用如何利用最流行的Android DRM wide vine的安全影响尚未得到研究。在这篇文章中，我们报道了第一个关于野生野生葡萄使用状况的实验研究。我们的研究探讨了OTT是否符合Widevine关于资产保护和传统电话支持的指导方针。通过对优质OTT应用的评估，我们的实验揭示了大多数应用采用了薄弱和潜在易受攻击的做法。我们通过展示如何从包括网飞在内的许多OTT应用中轻松恢复媒体内容来说明我们的发现。",
                    "title_zh": "wide leak:Android中的高端平台是如何失败的"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00057",
                    "title": "Hardening In-memory Key-value Stores against ECC-uncorrectable Memory Errors",
                    "authors": "Tsuyoshi Shimomura, Hiroshi Yamada",
                    "abstract": "Memory errors that can be detected but cannot be fixed by error correction code (ECC) modules, called ECC-uncorrectable errors, have a severe impact on the availability of the datacenter applications. In-memory key-value stores (KVSes) suffer relatively more from ECC-uncorrectable errors compared with other applications because they typically allocate a large amount of memory and manage KVs and their running states in their address spaces. The standard way of recovery is the all-clean approach that reboots the damaged applications. This eliminates all the memory objects, causing a significant performance degradation of the in-memory KVSes. This paper presents a partial-surgery approach that forces in-memory KVSes to prune the damaged objects and reconstructs their internals by using undamaged ones. We prototyped our approach on memcached 1.4.39 and Redis 5.0.3, and conducted several experiments. The results show that the prototypes successfully recover from our injected memory errors and significantly outperform the conventional all-clean approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可以检测到但无法由纠错码(ECC)模块修复的内存错误称为ECC不可修复错误，会对数据中心应用程序的可用性产生严重影响。与其他应用程序相比，内存中的键值存储(kvse)更容易出现ECC不可纠正的错误，因为它们通常会分配大量内存，并管理KVs及其地址空间中的运行状态。标准的恢复方法是重新启动受损的应用程序。这消除了所有内存对象，导致内存KVSes的性能显著下降。本文提出了一种部分手术方法，强制内存KVSes修剪受损对象，并使用未受损对象重建其内部结构。我们在memcached 1.4.39和Redis 5.0.3上原型化了我们的方法，并进行了几次实验。结果表明，原型成功地从我们注入的内存错误中恢复，并明显优于传统的全清除方法。",
                    "title_zh": "针对ECC不可修复的内存错误强化内存中的键值存储"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00058",
                    "title": "Background Buster: Peeking through Virtual Backgrounds in Online Video Calls",
                    "authors": "Mohd Sabra, Anindya Maiti, Murtuza Jadliwala",
                    "abstract": "Video calling applications such as Zoom and Skype have become the preferred medium for both personal and professional communications. One feature in these applications that has gained prominence is the virtual background feature, which enables users to conceal their background by blending in a virtual image or video in place of the real background, thus providing users with background and contextual privacy. However, this feature is not robust enough, and depending on the target user’s activities, movement and accessories worn during the call, portions of the user’s background could leak which can then be reconstructed to reveal significant portions of the user’s real background, and other contextual information related to the real background. This paper conducts an investigative analysis of the background privacy provided by the virtual background feature in video calling applications by designing a novel background reconstruction framework, and using it to reveal users’ real background. By means a large dataset of call videos, collected from human subject participants and in the wild, a comprehensive evaluation of the proposed framework and related privacy attacks under a variety of different experimental parameters is then carried out. Results from these evaluations show that significant leakage of background information is feasible under certain conditions, rendering the feature ineffective in protecting privacy and giving users a false sense of security.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Zoom和Skype等视频通话应用程序已成为个人和专业通信的首选媒介。在这些应用中，已经获得显著地位的一个特征是虚拟背景特征，该特征使得用户能够通过混合虚拟图像或视频来代替真实背景来隐藏他们的背景，从而为用户提供背景和上下文隐私。然而，该特征不够健壮，并且取决于目标用户在呼叫期间的活动、移动和佩戴的配件，用户背景的部分可能泄露，然后可以重建该泄露以揭示用户真实背景的重要部分，以及与真实背景相关的其他上下文信息。通过设计一种新颖的背景重建框架，并使用它来揭示用户的真实背景，对视频通话应用中虚拟背景特征所提供的背景隐私进行了调查分析。通过从人类受试者参与者和在野外收集的呼叫视频的大数据集，然后在各种不同的实验参数下对所提出的框架和相关的隐私攻击进行综合评估。这些评估的结果表明，在某些条件下，背景信息的显著泄漏是可行的，使得该特征在保护隐私方面无效，并且给用户一种错误的安全感。",
                    "title_zh": "背景克星:在线视频通话中偷看虚拟背景"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00059",
                    "title": "SIMulation: Demystifying (Insecure) Cellular Network based One-Tap Authentication Services",
                    "authors": "Ziyi Zhou, Xing Han, Zeyuan Chen, Yuhong Nan, Juanru Li, Dawu Gu",
                    "abstract": "A recently emerged cellular network based One-Tap Authentication (OTAuth) scheme allows app users to quickly sign up or log in to their accounts conveniently: Mobile Network Operator (MNO) provided tokens instead of user passwords are used as identity credentials. After conducting a first in-depth security analysis, however, we have revealed several fundamental design flaws among popular OTAuth services, which allow an adversary to easily (1) perform unauthorized login and register new accounts as the victim, (2) illegally obtain identities of victims, and (3) interfere OTAuth services of legitimate apps. To further evaluate the impact of our identified issues, we propose a pipeline that integrates both static and dynamic analysis. We examined 1,025/894 Android/iOS apps, each app holding more than 100 million installations. We confirmed 396/398 Android/iOS apps are affected. Our research systematically reveals the threats against OTAuth services. Finally, we provide suggestions on how to mitigate these threats accordingly.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近出现的基于蜂窝网络的一键认证(OTAuth)方案允许应用程序用户快速注册或方便地登录他们的帐户:移动网络运营商(MNO)提供的令牌而不是用户密码被用作身份凭证。然而，在进行了第一次深入的安全分析后，我们发现了流行的OTAuth服务中的几个基本设计缺陷，这些缺陷允许对手轻松地(1)执行未经授权的登录并注册新帐户作为受害者，(2)非法获取受害者的身份，以及(3)干扰合法应用程序的OTAuth服务。为了进一步评估我们确定的问题的影响，我们提出了一个集成静态和动态分析的管道。我们检查了1，025/894个Android/iOS应用程序，每个应用程序都有超过1亿次安装。我们确认396/398个Android/iOS应用程序受到影响。我们的研究系统地揭示了对OTAuth服务的威胁。最后，我们就如何相应地减轻这些威胁提供了建议。",
                    "title_zh": "模拟:解密(不安全的)基于蜂窝网络的一键认证服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00060",
                    "title": "DisTA: Generic Dynamic Taint Tracking for Java-Based Distributed Systems",
                    "authors": "Dong Wang, Yu Gao, Wensheng Dou, Jun Wei",
                    "abstract": "Dynamic taint tracking is a powerful information flow analysis approach, which can be applied in many analysis scenarios, e.g., debugging, testing, and security vulnerability detection. Most dynamic taint tracking approaches are designed for standalone systems, and cannot support inter-node taint tracking in distributed systems. Few inter-node taint tracking approaches are designed for specific distributed systems, e.g., Apache Spark, and require specific modifications to different distributed systems.In this paper, we present DisTA, a generic dynamic taint tracking tool for Java-based distributed systems. By instrumenting common network communication modules in Java, DisTA can perform inter-node taint tracking for different distributed systems with little manual efforts. We evaluate DisTA on five large-scale real-world distributed systems, e.g., ZooKeeper and Yarn, and require only 10 LOC launch script modification on average. The experimental results show that DisTA can accurately track all inter-node taints with a relatively low overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "动态污点跟踪是一种强大的信息流分析方法，可应用于许多分析场景，如调试、测试和安全漏洞检测。大多数动态污点跟踪方法是为独立系统设计的，无法支持分布式系统中的节点间污点跟踪。很少有节点间污点跟踪方法是为特定的分布式系统设计的，例如Apache Spark，并且需要对不同的分布式系统进行特定的修改。在本文中，我们介绍了DisTA，一个用于基于Java的分布式系统的通用动态污点跟踪工具。通过在Java中检测常见的网络通信模块，DisTA只需很少的人工操作就可以为不同的分布式系统执行节点间污点跟踪。我们在ZooKeeper和Yarn等五个大规模真实世界分布式系统上评测DisTA，平均只需要10次LOC启动脚本修改。实验结果表明，DisTA能够以相对较低的开销准确跟踪所有节点间的污点。",
                    "title_zh": "DisTA:基于Java的分布式系统的通用动态污点跟踪"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00061",
                    "title": "How'd Security Benefit Reverse Engineers? : The Implication of Intel CET on Function Identification",
                    "authors": "Hyungseok Kim, Junoh Lee, Soomin Kim, Seungil Jung, Sang Kil Cha",
                    "abstract": "As CPU vendors introduce various hardware-assisted security features, modern compilers have started to produce binaries containing security-related instructions. Interestingly, such instructions tend to alter the shape of resulting binaries, which can potentially affect the effectiveness of binary analysis. This paper presents the first systematic study on the implication of the Intel CET (Control-flow Enforcement Technology) instructions on function identification. Our study finds that CET-relevant instructions provide useful, although limited, hints for function entries. Therefore, we devise a novel function identification algorithm that utilizes the usage patterns of CET instructions, and demonstrate a tool named FunSeeker that implements the idea. Our evaluation shows that FunSeeker significantly outperforms current state-of-the-art function identification tools in terms of both correctness and speed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着CPU供应商引入各种硬件辅助的安全特性，现代编译器已经开始产生包含安全相关指令的二进制文件。有趣的是，这样的指令往往会改变生成的二进制文件的形状，这可能会影响二进制分析的有效性。本文首次系统地研究了Intel CET(控制流执行技术)指令对函数识别的影响。我们的研究发现，CET相关的说明为函数条目提供了有用的，尽管有限的提示。因此，我们设计了一种新颖的利用CET指令使用模式的函数识别算法，并演示了一个名为FunSeeker的工具来实现这一思想。我们的评估表明，FunSeeker在正确性和速度方面明显优于当前最先进的函数识别工具。",
                    "title_zh": "安全性对逆向工程师有什么好处？英特尔CET对功能识别的启示"
                },
                {
                    "url": "https://doi.org/10.1109/DSN53405.2022.00062",
                    "title": "SAINTDroid: Scalable, Automated Incompatibility Detection for Android",
                    "authors": "Bruno Vieira Resende e Silva, Clay Stevens, Niloofar Mansoor, Witawas Srisa-an, Tingting Yu, Hamid Bagheri",
                    "abstract": "With the ever-increasing popularity of mobile devices over the last decade, mobile applications and the frameworks upon which they are built frequently change, leading to a confusing jumble of devices and applications utilizing differing features even within the same framework. For Android apps and devices—the largest such framework and marketplace— mismatches between the version of the app API installed on a device and the version targeted by the developers of an app running on that device can lead to run-time crashes, providing a poor user experience. This paper presents SAINTDroid, a holistic compatibility analysis approach that seamlessly examines both the application code and the framework code by gradually loading and analyzing classes as needed during the compatibility analysis to enable efficient and scalable identification of various types of crash-leading Android compatibility issues. We applied SAINTDroid to 3,590 real-world apps and compared the analysis results against the state-of-the-art techniques, which corroborates that SAINTDroid is up to 76% more successful in detecting compatibility issues while issuing significantly fewer false alarms. The experimental results also show that SAINTDroid is remarkably (up to 8.3 times and four times on average) faster than the state-of-the-art techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在过去十年中，随着移动设备的日益普及，移动应用和构建移动应用的框架频繁变化，导致即使在同一框架内也使用不同特征的设备和应用混乱混杂。对于Android应用和设备——最大的此类框架和市场——来说，设备上安装的应用API版本与该设备上运行的应用的开发者所针对的版本之间的不匹配可能会导致运行时崩溃，从而提供糟糕的用户体验。本文介绍了SAINTDroid，这是一种全面的兼容性分析方法，通过在兼容性分析期间根据需要逐步加载和分析类，无缝地检查应用程序代码和框架代码，以便高效和可扩展地识别各种类型的导致崩溃的Android兼容性问题。我们将SAINTDroid应用于3，590个真实世界的应用程序，并将分析结果与最先进的技术进行了比较，这证实了SAINTDroid在检测兼容性问题方面的成功率提高了76%，同时发出的错误警报明显减少。实验结果还表明，SAINTDroid明显快于现有技术(平均快8.3倍和4倍)。",
                    "title_zh": "SAINTDroid:适用于Android的可扩展自动不兼容检测"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2022w.html",
            "conf_title": "52nd DSN 2022: Baltimore, MD, USA - Workshops",
            "conf_url": "https://doi.org/10.1109/DSN-W54100.2022",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00011",
                    "title": "Stealthy Data Corruption Attack Against Road Traffic Congestion Avoidance Applications",
                    "authors": "Aawista Chaudhry, Talal Halabi, Mohammad Zulkernine",
                    "abstract": "Intelligent Transportation Systems (ITS) leverage open and real-time sharing of traffic data to enable more efficient transportation. However, the data exchanged over the vehicular network are easily corruptible via attacks known as misbehaviours. Misbehaviour detectors have been extensively developed but remain siloed and lack consideration of advanced attacks amalgamating multiple misbehaviours. These may be carried out as part of Advanced Persistent Threats. This paper presents a new approach to specifically designing stealthy data corruption attacks within ITS, and by extension in other data-reliant Cyber-Physical Systems. A Stackelberg security game is devised to model the actions of evasive attackers targeting congestion avoidance applications. The game is then solved to produce the optimal attack and defense strategies. The new stealthy attack achieves the intended long-term impact while improving evasion performance. This research direction exploring sophisticated attacks will allow to advance the design of robust misbehavior detection systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "智能交通系统(ITS)利用交通数据的开放和实时共享来实现更高效的交通。然而，通过车辆网络交换的数据很容易被称为不当行为的攻击破坏。不当行为检测器已经被广泛开发，但是仍然是孤立的，并且缺乏对混合多个不当行为的高级攻击的考虑。这些可能是作为高级持续威胁的一部分执行的。本文提出了一种新的方法，专门设计在智能交通系统，并通过扩展到其他数据依赖的网络物理系统中的隐形数据损坏攻击。设计了一个Stackelberg安全游戏来模拟针对拥塞避免应用的规避攻击者的行为。然后解决该游戏，以产生最佳的攻击和防御策略。新的隐形攻击实现了预期的长期影响，同时提高了规避性能。探索复杂攻击的这一研究方向将允许推进鲁棒的不当行为检测系统的设计。",
                    "title_zh": "针对道路交通拥堵避免应用的秘密数据破坏攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00012",
                    "title": "Certify the Uncertified: Towards Assessment of Virtualization for Mixed-criticality in the Automotive Domain",
                    "authors": "Marcello Cinque, Luigi De Simone, Andrea Marchetta",
                    "abstract": "Nowadays, a feature-rich automotive vehicle offers several technologies to assist the driver during his trip and guarantee an amusing infotainment system to the other passengers, too. Consolidating worlds at different criticalities is a welcomed challenge for car manufacturers that have recently tried to leverage virtualization technologies due to reduced maintenance, deployment, and shipping costs. For this reason, more and more mixed-criticality systems are emerging, trying to assure compliance with the ISO 26262 Road Vehicle Safety standard. In this short paper, we provide a preliminary investigation of the certification capabilities for Jailhouse, a popular open-source partitioning hypervisor. To this aim, we propose a testing methodology and showcase the results, pointing out when the software gets to a faulting state, deviating from its expected behavior. The ultimate goal is to picture the right direction for the hypervisor towards a potential certification process.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，功能丰富的汽车提供了多种技术来帮助司机在旅途中，并保证为其他乘客提供有趣的信息娱乐系统。对于最近试图利用虚拟化技术来降低维护、部署和运输成本的汽车制造商来说，整合不同关键程度的世界是一个受欢迎的挑战。由于这个原因，越来越多的混合临界系统正在出现，试图确保符合ISO 26262道路车辆安全标准。在这篇短文中，我们对Jailhouse的认证能力进行了初步调查，jail house是一种流行的开源分区管理程序。为此，我们提出了一种测试方法并展示了结果，指出了软件何时进入了错误状态，偏离了它的预期行为。最终目标是为虚拟机管理程序描绘一个潜在认证流程的正确方向。",
                    "title_zh": "认证未认证:汽车领域混合临界虚拟化评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00013",
                    "title": "Tiny Black Boxes: A nano-Drone Safety Architecture",
                    "authors": "Connor Sexton, Joseph Callenes",
                    "abstract": "As small-form factor drones grow more intelligent, they increasingly require more sophisticated capabilities to record sensor data and system state, ensuring safe and improved operation. Already regulations for black boxes, electronic data recorders (EDRs), for determining liabilities and improving the safety of large-form factor autonomous vehicles are becoming established. Conventional techniques use hardened memory storage units that conserve all sensor (visual) and system operational state; and N-way redundant models for detecting uncertainty in system operation. For small-form factor drones, which are highly limited by weight, power, and computational resources, these techniques become increasingly prohibitive. In this paper, we propose a safety architecture for resource constrained autonomous vehicles that enables the development of safer and more efficient nano-drone systems. The insight for the proposed safety architecture is that the regular structure of data-driven models used to control drones can be exploited to efficiently compress and identify key events that should be conserved in the EDR subsystem. We describe an implementation of the architecture, including hardware and software support and quantify the benefits of the approach. We show that the proposed techniques can increase that amount of recorded flight time by over 10x and reduce energy usage by over 10x for high resolution systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着小型无人机变得更加智能，它们越来越需要更复杂的功能来记录传感器数据和系统状态，以确保安全和改进的操作。关于黑匣子、电子数据记录器(EDRs)、确定责任和提高大型自主车辆安全性的法规已经开始建立。传统技术使用保存所有传感器(视觉)和系统操作状态的强化记忆存储单元；和N路冗余模型，用于检测系统运行中的不确定性。对于重量、功率和计算资源高度受限的小型无人机，这些技术变得越来越令人望而却步。在本文中，我们提出了一种用于资源受限的自主车辆的安全架构，该架构能够开发更安全、更高效的纳米无人机系统。所提出的安全架构的见解是，可以利用用于控制无人机的数据驱动模型的规则结构来有效地压缩和识别应该在EDR子系统中保存的关键事件。我们描述了该架构的实现，包括硬件和软件支持，并量化了该方法的好处。我们表明，对于高分辨率系统，所提出的技术可以将记录的飞行时间增加10倍以上，并将能耗降低10倍以上。",
                    "title_zh": "微型黑匣子:纳米无人机安全架构"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00014",
                    "title": "Alternative Route-Based Attacks in Metropolitan Traffic Systems",
                    "authors": "Sidney La Fontaine, Naveen Muralidhar, Michael Clifford, Tina Eliassi-Rad, Cristina Nita-Rotaru",
                    "abstract": "With the growing reliance on driving direction applications that dynamically account for live traffic updates, drivers are much more likely to act optimally, by taking the shortest path to their destination, and therefore more predictably. As city networks transition into being made up of connected and autonomous vehicles, autonomous driving pilots are even more likely to act optimally and predictably. The predictability that comes from acting optimally allows motivated attackers to manipulate driver(s) to travel chosen slower alternative routes by causing disruptions on road segments that are part of faster routes. A motivated attacker could use this method to cause a number of different harms such as forcing specific vehicles to take unnecessarily long routes, forcing all vehicles traveling between popular locations to follow a chosen route, or making vehicles travel specific road segments that the attacker chose, such as toll roads. In this work, we show the feasibility and practicality of conducting such attacks on several real traffic networks of major North American cities. We analyze several attack objectives under different attacker constraints and we demonstrated that an attacker could find an attack strategy in a matter of seconds.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着对动态考虑实时交通更新的驾驶方向应用程序的日益依赖，驾驶员更有可能采取最佳行动，通过最短路径到达目的地，因此更可预测。随着城市网络过渡到由联网和自动驾驶汽车组成，自动驾驶驾驶员甚至更有可能以最佳和可预测的方式行事。来自最佳行动的可预测性允许有动机的攻击者操纵驾驶员通过在作为快速路线的一部分的路段上造成中断来行驶所选择的较慢的替代路线。有动机的攻击者可以使用这种方法造成许多不同的伤害，例如迫使特定车辆走不必要的长路线，迫使所有在热门地点之间行驶的车辆遵循选定的路线，或者使车辆行驶攻击者选择的特定路段，例如收费公路。在这项工作中，我们展示了在北美主要城市的几个真实交通网络上进行这种攻击的可行性和实用性。我们分析了不同攻击者约束下的几个攻击目标，并证明了攻击者可以在几秒钟内找到攻击策略。",
                    "title_zh": "大都市交通系统中基于替代路由的攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00015",
                    "title": "Autonomous Attack Mitigation for Industrial Control Systems",
                    "authors": "John Mern, Kyle Hatch, Ryan Silva, Cameron Hickert, Tamim Sookoor, Mykel J. Kochenderfer",
                    "abstract": "Defending industrial control systems and other networks from cyber attack requires timely responses to alerts and threat intelligence. Decisions about how to respond involve coordinating actions across multiple nodes based on imperfect indicators of compromise while minimizing disruptions to network operations. Currently, playbooks are used to automate portions of a response process, but often leave complex decision-making to a human analyst. In this work, we present a deep reinforcement learning approach to autonomous response and recovery in large industrial control networks. We propose an attention-based neural architecture that is flexible to the size of the network under protection. To train and evaluate the autonomous defender agent, we present an industrial control network simulation environment suitable for reinforcement learning. Experiments show that the learned agent can effectively mitigate advanced attacks that progress with few observable signals over several months before execution. The proposed application of AI/ML techniques for security outperforms a fully automated playbook method in simulation, taking less disruptive actions while also defending more nodes on the network. The learned policy is also more robust to changes in attacker behavior than playbook approaches.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2111.02445"
                    },
                    "abstract_zh": "保护工业控制系统和其他网络免受网络攻击需要及时响应警报和威胁情报。关于如何响应的决策包括基于不完善的危害指标协调多个节点之间的行动，同时最小化对网络操作的中断。目前，剧本被用于自动化部分响应过程，但是通常将复杂的决策留给人类分析师。在这项工作中，我们提出了一种深度强化学习方法，用于大型工业控制网络中的自主响应和恢复。我们提出了一种基于注意力的神经架构，它可以灵活地适应受保护网络的规模。为了训练和评估自主防御代理，我们提出了一个适用于强化学习的工业控制网络仿真环境。实验表明，经过学习的代理可以有效地缓解高级攻击，这些攻击在执行前几个月内几乎没有可观察到的信号。提出的AI/ML技术在安全方面的应用在模拟中胜过完全自动化的剧本方法，采取更少的破坏性行动，同时还保护网络上更多的节点。与剧本方法相比，学习策略对于攻击者行为的改变也更加鲁棒。",
                    "title_zh": "工业控制系统的自主攻击缓解"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00016",
                    "title": "Federated Learning with Anomaly Client Detection and Decentralized Parameter Aggregation",
                    "authors": "Shu Liu, Yanlei Shang",
                    "abstract": "Federated learning is a framework for machine learning that is dedicated to data privacy protection. In federated learning, system cannot fully control the behavior of clients which can be faulty. These behaviors include sharing arbitrary faulty gradients and delaying the process of sharing due to Byzantine attacks or clients’ own software and hardware failures. In federated learning, the parameter server may also be faulty during gradient collection and aggregation, mainly including gradient-based training data inference and model parameter faulty update. The above problems may lead to reduced accuracy of federated learning model training, leakage of client privacy, etc. Existing research enhances the robustness of federated learning by exploiting the decentralization and immutability of Blockchain. For untrusted clients, most research is based on Byzantine fault tolerance to defend against clients indiscriminately, and may cause model accuracy reduction. In addition, most of the research focus on unencrypted gradients, and there is insufficient research on dealing with client anomalies in the case of gradient encryption. For untrusted parameter servers, existing research has problems in energy overhead and scalability. Aiming at the problems above, this paper studies the robustness of federated learning, and proposes a blockchain-based federated learning parameter update architecture PUS-FL. Through experiments simulating distributed machine learning on neural networks, we demonstrate that the anomaly detection algorithm of PUS-FL outperforms conventional gradient filters including geometric median, Multi-Krum and trimmed mean. In addition, our experiments also verify that the scalability-enhanced parameter aggregation consensus algorithm proposed in this paper(SE-PBFT) improves consensus scalability by reducing communication complexity.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "联邦学习是一个机器学习的框架，致力于数据隐私保护。在联合学习中，系统不能完全控制可能出错的客户端的行为。这些行为包括共享任意错误的梯度，以及由于拜占庭攻击或客户端自身的软硬件故障而延迟共享的过程。在联邦学习中，参数服务器在梯度收集和聚合过程中也可能出现故障，主要包括基于梯度的训练数据推断和模型参数故障更新。上述问题可能导致联合学习模型训练的准确性降低、客户端隐私泄露等。现有研究通过利用区块链的去中心化和不变性来增强联邦学习的鲁棒性。对于不受信任的客户端，大多数研究都是基于拜占庭容错来无差别地防御客户端，并可能导致模型准确性降低。此外，大部分研究集中在未加密的梯度上，在梯度加密的情况下处理客户端异常的研究不足。对于不可信参数服务器，现有研究在能量开销和可扩展性方面存在问题。针对上述问题，本文研究了联邦学习的鲁棒性，提出了一种基于区块链的联邦学习参数更新架构PUS-FL。通过在神经网络上模拟分布式机器学习的实验，我们证明了PUS-FL的异常检测算法优于传统的梯度滤波器，包括几何中值、多Krum和修剪均值。此外，我们的实验还验证了本文提出的可扩展性增强的参数聚合一致性算法(SE-PBFT)通过降低通信复杂度来提高一致性的可扩展性。",
                    "title_zh": "具有异常客户端检测和分散参数聚集的联合学习"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00017",
                    "title": "Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems",
                    "authors": "Xugui Zhou, Maxfield Kouzel, Homa Alemzadeh",
                    "abstract": "The growing complexity of Cyber-Physical Systems (CPS) and challenges in ensuring safety and security have led to the increasing use of deep learning methods for accurate and scalable anomaly detection. However, machine learning (ML) models often suffer from low performance in predicting unexpected data and are vulnerable to accidental or malicious perturbations. Although robustness testing of deep learning models has been extensively explored in applications such as image classification and speech recognition, less attention has been paid to ML-driven safety monitoring in CPS. This paper presents the preliminary results on evaluating the robustness of ML-based anomaly detection methods in safety-critical CPS against two types of accidental and malicious input perturbations, generated using a Gaussian-based noise model and the Fast Gradient Sign Method (FGSM). We test the hypothesis of whether integrating the domain knowledge (e.g., on unsafe system behavior) with the ML models can improve the robustness of anomaly detection without sacrificing accuracy and transparency. Experimental results with two case studies of Artificial Pancreas Systems (APS) for diabetes management show that ML-based safety monitors trained with domain knowledge can reduce on average up to 54.2% of robustness error and keep the average F1 scores high while improving transparency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络物理系统(CPS)日益增长的复杂性和确保安全的挑战导致深度学习方法越来越多地用于准确和可扩展的异常检测。然而，机器学习(ML)模型在预测意外数据时往往表现不佳，并且容易受到意外或恶意干扰的影响。尽管深度学习模型的鲁棒性测试已经在图像分类和语音识别等应用中得到广泛探索，但在CPS中对ML驱动的安全监控关注较少。本文介绍了在安全关键CPS中评估基于ML的异常检测方法的鲁棒性的初步结果，该方法针对两种类型的意外和恶意输入扰动，使用基于高斯的噪声模型和快速梯度符号方法(FGSM)产生。我们测试了将领域知识(例如，关于不安全系统行为的)与ML模型相结合是否可以在不牺牲准确性和透明性的情况下提高异常检测的鲁棒性的假设。对用于糖尿病管理的人工胰腺系统(APS)的两个案例研究的实验结果表明，利用领域知识训练的基于ML的安全监视器可以平均减少高达54.2%的鲁棒性误差，并且在提高透明度的同时保持较高的平均F1分数。",
                    "title_zh": "信息物理系统中数据和知识驱动的异常检测的鲁棒性测试"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00018",
                    "title": "On the impact of non-IID data on the performance and fairness of differentially private federated learning",
                    "authors": "Saba Amiri, Adam Belloum, Eric Nalisnick, Sander Klous, Leon Gommans",
                    "abstract": "Federated Learning enables distributed data holders to train a shared machine learning model on their collective data. It provides some measure of privacy by not requiring the data be pooled and centralized but still has been shown to be vulnerable to adversarial attacks. Differential Privacy provides rigorous guarantees and sufficient protection against adversarial attacks and has been widely employed in recent years to perform privacy preserving machine learning. One common trait in many of recent methods on federated learning and federated differentially private learning is the assumption of IID data, which in real world scenarios most certainly does not hold true. In this work, we empirically investigate the effect of non-IID data on node level on federated, differentially private, deep learning. We show the non-IID data to have a negative impact on both performance and fairness of the trained model and discuss the trade off between privacy, utility and fairness. Our results highlight the limits of common federated learning algorithms in a differentially private setting to provide robust, reliable results across underrepresented groups.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "联邦学习使分布式数据持有者能够在他们的集体数据上训练共享的机器学习模型。它通过不要求汇集和集中数据来提供一些隐私措施，但仍然显示出易受敌对攻击。差分隐私提供了严格的保证和足够的保护来对抗敌对攻击，并且近年来已经被广泛用于执行隐私保护机器学习。许多最近的关于联合学习和联合差分私人学习的方法的一个共同特征是IID数据的假设，这在现实世界场景中肯定不成立。在这项工作中，我们实证研究了非IID数据在节点级别上对联合、差分私有深度学习的影响。我们显示了非IID数据对训练模型的性能和公平性都有负面影响，并讨论了隐私、效用和公平性之间的权衡。我们的结果强调了普通联邦学习算法在不同私人设置中的局限性，以在代表性不足的群体中提供稳健、可靠的结果。",
                    "title_zh": "非IID数据对差异私有联合学习的绩效和公平性的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00019",
                    "title": "A Robust Framework for Adaptive Selection of Filter Ensembles to Detect Adversarial Inputs",
                    "authors": "Arunava Roy, Dipankar Dasgupta",
                    "abstract": "Existing defense strategies against adversarial attacks (AAs) on AI/ML are primarily focused on examining the input data streams using a wide variety of filtering techniques. For instance, input filters are used to remove noisy, misleading, and out-of-class inputs along with a variety of attacks on learning systems. However, a single filter may not be able to detect all types of AAs. To address this issue, in the current work, we propose a robust, transferable, distribution-independent, and cross-domain supported framework for selecting Adaptive Filter Ensembles (AFEs) to minimize the impact of data poisoning on learning systems. The optimal filter ensembles are determined through a Multi-Objective Bi-Level Programming Problem (MOBLPP) that provides a subset of diverse filter sequences, each exhibiting fair detection accuracy. The proposed framework of AFE is trained to model the pristine data distribution to identify the corrupted inputs and converges to the optimal AFE without vanishing gradients and mode collapses irrespective of input data distributions. We presented preliminary experiments to show the proposed defense outperforms the existing defenses in terms of robustness and accuracy.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现有的AI/ML对抗攻击的防御策略主要集中在使用各种过滤技术检查输入数据流。例如，输入过滤器被用来去除嘈杂的、误导的和非类别的输入，以及对学习系统的各种攻击。然而，单个过滤器可能无法检测所有类型的AAs。为了解决这个问题，在当前的工作中，我们提出了一个健壮的、可转移的、分布独立的、跨域支持的框架，用于选择自适应滤波器集成(AFE)以最小化数据中毒对学习系统的影响。通过多目标双层规划问题(MOBLPP)来确定最佳滤波器集合，该问题提供了不同滤波器序列的子集，每个滤波器序列表现出公平的检测精度。所提出的AFE框架被训练来模拟原始数据分布，以识别被破坏的输入，并且收敛到最优AFE，而没有消失梯度和模式崩溃，而与输入数据分布无关。我们提出了初步的实验，以显示提出的防御在鲁棒性和准确性方面优于现有的防御。",
                    "title_zh": "用于检测敌对输入的滤波器集成的自适应选择的鲁棒框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00020",
                    "title": "Towards Building Resilient Ensembles against Training Data Faults",
                    "authors": "Abraham Chan, Arpan Gujarati, Karthik Pattabiraman, Sathish Gopalakrishnan",
                    "abstract": "In this talk, we describe our approach to construct resilient ML ensembles against training data faults [1]. First, we demonstrate how ensembles tolerate faulty training data. Then, we show how we could use analytical modelling to help ML practitioners build resilient ensembles without the need for resource intensive fault injection experiments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本次演讲中，我们描述了我们针对训练数据错误构建弹性ML集成的方法[1]。首先，我们证明了集成如何容忍错误的训练数据。然后，我们展示了如何使用分析建模来帮助ML实践者构建弹性集成，而不需要资源密集型故障注入实验。",
                    "title_zh": "针对训练数据错误构建弹性集成"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00021",
                    "title": "General Probability in Coq",
                    "authors": "Avraham Shinnar, Barry M. Trager",
                    "abstract": "We have developed a general probability library in the Coq proof assistant intended for applications in machine learning and stochastic approximation. We will discuss design decisions and lessons learned.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们在Coq proof assistant中开发了一个通用概率库，旨在应用于机器学习和随机近似。我们将讨论设计决策和经验教训。",
                    "title_zh": "Coq中的一般概率"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00022",
                    "title": "Data-Centric Analysis of Compound Threats to Critical Infrastructure Control Systems",
                    "authors": "Sahiti Bommareddy, Benjamin Gilby, Maher Khan, Imes Chiu, Mathaios Panteli, John W. van de Lindt, Linton Wells, Yair Amir, Amy Babay",
                    "abstract": "Compound threats involving cyberattacks that are targeted in the aftermath of a natural disaster pose an important emerging threat for critical infrastructure. We introduce a novel compound threat model and data-centric framework for evaluating the resilience of power grid SCADA systems to such threats. We present a case study of a compound threat involving a hurricane and follow-on cyberattack on Oahu Hawaii and analyze the ability of existing SCADA architectures to withstand this threat model. We show that no existing architecture fully addresses this threat model, and demonstrate the importance of considering compound threats in planning system deployments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自然灾害后针对网络攻击的复合威胁对关键基础设施构成了新的重要威胁。我们介绍了一种新的复合威胁模型和以数据为中心的框架，用于评估电网SCADA系统对此类威胁的恢复能力。我们对夏威夷瓦胡岛的一次飓风和后续网络攻击的复合威胁进行了案例研究，并分析了现有SCADA架构抵御这种威胁模型的能力。我们表明，没有现有的架构完全解决这种威胁模型，并证明了在规划系统部署时考虑复合威胁的重要性。",
                    "title_zh": "对关键基础设施控制系统的复合威胁进行以数据为中心的分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00023",
                    "title": "Network Message Field Type Clustering for Reverse Engineering of Unknown Binary Protocols",
                    "authors": "Stephan Kleber, Frank Kargl, Milan Stute, Matthias Hollick",
                    "abstract": "Reverse engineering of unknown network protocols based on recorded traffic traces enables security analyses and debugging of undocumented network services. One important step in protocol reverse engineering is to determine data types of message fields. Existing approaches for binary protocols (1) lack comprehensive methods to interpret message content and determine the data types of discovered segments in a message and (2) assume the availability of context, which prevents the analysis of complex and lower-layer protocols. Overcoming these limitations, we propose the first generic method to analyze message field data types in unknown binary protocols by clustering of segments with the same data type. Our extensive evaluation shows that our method in most cases provides clustering of up to 100 % precision at reasonable recall. Particularly relevant for use in fuzzing and misbehavior detection, we increase the coverage of message bytes over the state-of-the-art to 87 % by almost a factor of 30. We provide an open-source implementation to allow follow-up works.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2301.03584"
                    },
                    "abstract_zh": "基于记录的流量跟踪对未知网络协议进行逆向工程，可以对未记录的网络服务进行安全分析和调试。协议逆向工程中的一个重要步骤是确定消息字段的数据类型。用于二进制协议的现有方法(1)缺乏全面的方法来解释消息内容和确定在消息中发现的段的数据类型，以及(2)假设上下文的可用性，这阻止了对复杂和较低层协议的分析。为了克服这些限制，我们提出了第一个通用方法，通过对具有相同数据类型的段进行聚类来分析未知二进制协议中的消息字段数据类型。我们广泛的评估表明，在大多数情况下，我们的方法在合理的召回率下提供高达100 %精度的聚类。特别适用于模糊和不当行为检测，我们将消息字节的覆盖率提高了近30倍，达到87 %。我们提供了一个开源的实现，以允许后续工作。",
                    "title_zh": "用于未知二进制协议逆向工程的网络消息字段类型聚类"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00024",
                    "title": "A Dataset of Linux Failure Data for Dependability Evaluation and Improvement",
                    "authors": "João R. Campos, Ernesto Costa, Marco Vieira",
                    "abstract": "Software systems are now used to execute critical tasks on a daily basis. As a result, unhandled or uncontrolled failures at runtime may lead to non-negligible risks or losses. To mitigate this, considerable effort and resources have been dedicated to assessing and improving the dependability of such systems. However, researching novel techniques to develop more dependable systems requires access to rich and detailed data. As data from real systems are not typically available, researchers often look for alternative processes, such as fault injection, to generate realistic synthetic data. As this requires considerable effort and expertise, researchers frequently rely on outdated datasets or develop simplified processes to collect data, eventually compromising the validation and development of their methods. This paper presents, discusses, and makes available a large failure dataset collected from an up-to-date Linux kernel through fault injection. It provides a detailed characterization of the target system by continuously monitoring hundreds of system metrics and various system logs throughout the experiments. Ultimately, the goal is to provide a reliable, well-defined, and properly generated dataset that can be used to research techniques to support the development of more dependable systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件系统现在被用来执行日常的关键任务。因此，运行时未处理或未控制的故障可能会导致不可忽视的风险或损失。为了减轻这种情况，已经投入了相当多的努力和资源来评估和提高这种系统的可靠性。然而，研究新技术以开发更可靠的系统需要访问丰富和详细的数据。由于来自真实系统的数据通常不可用，研究人员经常寻找替代过程，如故障注入，以生成真实的合成数据。由于这需要相当大的努力和专业知识，研究人员经常依赖过时的数据集或开发简化的过程来收集数据，最终损害了他们方法的验证和开发。本文介绍、讨论并提供了一个通过故障注入从最新的Linux内核中收集的大型故障数据集。通过在整个实验过程中持续监控数百个系统指标和各种系统日志，它提供了目标系统的详细特征。最终，目标是提供一个可靠的、定义良好的、正确生成的数据集，该数据集可用于研究支持更可靠系统开发的技术。",
                    "title_zh": "用于可信性评估和改进的Linux故障数据集"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00025",
                    "title": "Privacy Leakage Analysis for Colluding Smart Apps",
                    "authors": "Junzhe Wang, Lannan Luo",
                    "abstract": "The rapid proliferation of Internet-of-Things (IoT) has advanced the development of smart environments. By installing smart apps on IoT platforms, users can integrate IoT devices for convenient automation. As smart apps are exposed to a myriad of sensitive data from devices, one severe concern is about the privacy of these digitally augmented spaces. The recent work SAINT [1] has been proposed to detect sensitive data flows in individual smart apps using taint analysis. But it has high false positives and false negatives due to inappropriate consideration of taint seeds and taint sinks.One important security issue ignored by existing work is that the IoT platform supports parent-child smart apps. Their ability to communicate, however, has a negative effect on security. We call the parent-child smart apps colluding smart apps. Unfortunately, no tool exists to detect smart app collusion. We propose PDColA, which addresses the limitations of SAINT, and more importantly, can detect privacy leakages by colluding smart apps. The evaluation results show that PDColA achieves higher accuracies than SAINT in detecting privacy leakages by individual smart apps, and is effective to detect privacy leakages by colluding smart apps.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "物联网(IoT)的快速发展推动了智能环境的发展。通过在物联网平台上安装智能应用，用户可以集成物联网设备，实现便捷的自动化。随着智能应用暴露于来自设备的大量敏感数据，一个严重的问题是这些数字增强空间的隐私。最近的工作SAINT [1]提出使用污点分析来检测单个智能应用中的敏感数据流。但是由于对污点种子和污点接收器的不适当考虑，它具有很高的假阳性和假阴性。现有工作忽略的一个重要安全问题是，物联网平台支持亲子智能app。然而，它们的通信能力对安全性有负面影响。我们称亲子智能app为串通智能app。不幸的是，没有工具可以检测智能应用共谋。我们提出PDColA，它解决了SAINT的局限性，更重要的是，可以通过串通智能应用程序来检测隐私泄露。评估结果表明，PDColA在检测单个智能应用的隐私泄露方面比SAINT具有更高的准确率，在检测智能应用合谋的隐私泄露方面也是有效的。",
                    "title_zh": "合谋智能应用的隐私泄露分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00026",
                    "title": "A Practical Security Evaluation of a Moving Target Defence against Multi-Phase Cyberattacks",
                    "authors": "Tina Moghaddam, Minjune Kim, Jin-Hee Cho, Hyuk Lim, Terrence J. Moore, Frederica Free-Nelson, Dan Dongseong Kim",
                    "abstract": "Moving Target Defence (MTD) is a state-of-art defence mechanism as it proactively changes attack surfaces against cyberattacks. The theoretical security effectiveness of MTD techniques need to be validated with experimental evidence. Previous work in evaluating the effectiveness of virtual IP-shuffling MTD techniques mostly focused on the reconnaissance phase of cyberattacks, and used theoretical modelling or simulated and emulated networks to conduct the evaluation. These types of evaluations did not account for realistic network conditions or consider the effect on the attacker’s behaviour. In this paper, we present a practical evaluation of a virtual IP-shuffling MTD technique in a software define networking (SDN) testbed, with attacks based on the first three phases defined in the cyber kill chain, and consider a possible response by the attacker. This work considers two types of attackers: Dummy attacker and Adjusting attacker. A dummy attacker performs attacks consecutively with no knowledge or consideration about the MTD on the system, whereas an adjusting attacker is aware of the network using a time based MTD job management strategy and can adjust their approach accordingly. The effectiveness of attacks are analysed overall and across the three phases, and compared to the expectation. The results validate the effectiveness of the MTD technique, show its utility extends beyond just the reconnaissance phase, and demonstrate that the attacker can adjust their approach if they are aware of the MTD technique being used in order to increase their success rate.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "移动目标防御(MTD)是一种最先进的防御机制，因为它可以主动改变攻击面来抵御网络攻击。MTD技术的理论安全有效性需要实验证据来验证。在评估虚拟IP洗牌MTD技术的有效性方面，以前的工作主要集中在网络攻击的侦察阶段，并使用理论建模或模拟和仿真网络来进行评估。这些类型的评估没有考虑现实的网络条件，也没有考虑对攻击者行为的影响。在本文中，我们在软件定义网络(SDN)测试床中对虚拟IP洗牌MTD技术进行了实际评估，攻击基于网络杀伤链中定义的前三个阶段，并考虑了攻击者可能做出的响应。这项工作考虑了两种类型的攻击者:伪攻击者和调整攻击者。虚拟攻击者在不了解或不考虑系统上的MTD的情况下连续执行攻击，而调整攻击者知道网络使用基于时间的MTD作业管理策略，并可以相应地调整他们的方法。从整体和三个阶段分析攻击的有效性，并与预期进行比较。结果验证了MTD技术的有效性，显示了它的效用不仅仅局限于侦察阶段，并且证明了如果攻击者知道正在使用MTD技术，他们可以调整他们的方法以增加他们的成功率。",
                    "title_zh": "移动目标防御多阶段网络攻击的实用安全评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00027",
                    "title": "Repairing Security Vulnerabilities Using Pre-trained Programming Language Models",
                    "authors": "Kai Huang, Su Yang, Hongyu Sun, Chengyi Sun, Xuejun Li, Yuqing Zhang",
                    "abstract": "Repairing software bugs with automated solutions is a long-standing goal of researchers. Some of the latest automated program repair (APR) tools leverage natural language processing (NLP) techniques to repair software bugs. But natural languages (NL) and programming languages (PL) have significant differences, which leads to the fact that they may not be able to handle PL tasks well. Moreover, due to the difference between the vulnerability repair task and bug repair task, the performance of these tools on vulnerability repair is not yet known. To address these issues, we attempt to use large-scale pre-trained PL models (CodeBERT and GraphCodeBERT) for the vulnerability repair task based on the characteristics of PL and explore the real-world performance of the state-of-the-art data-driven approaches for vulnerability repair. The results show that using pre-trained PL models can better capture and process PL features and accomplish multi-line vulnerability repair. Specifically, our solution achieves advanced results (single-line repair accuracy 95.47%, multi-line repair accuracy 90.06%). These results outperform the state-of-the-art data-driven approaches and demonstrate that adding rich data-dependent features can help solve more complex code repair problems. Besides, we also discuss the previous work and our approach, pointing out some shortcomings and solutions we can work on in the future.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "用自动化解决方案修复软件bug是研究人员长久以来的目标。一些最新的自动程序修复(APR)工具利用自然语言处理(NLP)技术来修复软件缺陷。但是自然语言(NL)和编程语言(PL)有着显著的区别，这导致了它们可能无法很好地处理PL任务。此外，由于漏洞修复任务和缺陷修复任务之间的差异，这些工具在漏洞修复方面的性能尚不可知。为了解决这些问题，我们尝试使用大规模预训练的PL模型(CodeBERT和GraphCodeBERT)来完成基于PL特性的漏洞修复任务，并探索最新的数据驱动漏洞修复方法的真实性能。结果表明，使用预训练的PL模型可以更好地捕捉和处理PL特征，完成多线漏洞修复。具体来说，我们的解决方案实现了先进的结果(单线修复准确率95.47%，多线修复准确率90.06%)。这些结果优于最先进的数据驱动方法，并证明了添加丰富的数据相关功能可以帮助解决更复杂的代码修复问题。此外，我们还讨论了以前的工作和我们的方法，指出了一些不足之处和解决方案，我们可以在未来的工作。",
                    "title_zh": "使用预先训练的编程语言模型修复安全漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00028",
                    "title": "An Overview of Sybil Attack Detection Mechanisms in VFC",
                    "authors": "Haonan Yang, Yongchao Zhong, Bo Yang, Yiyu Yang, Zifeng Xu, Longjuan Wang, Yuqing Zhang",
                    "abstract": "Vehicular Fog Computing (VFC) has been proposed to address the security and response time issues of Vehicular Ad Hoc Networks (VANETs) in latency-sensitive vehicular network environments, due to the frequent interactions that VANETs need to have with cloud servers. However, the anonymity protection mechanism in VFC may cause the attacker to launch Sybil attacks by fabricating or creating multiple pseudonyms to spread false information in the network, which poses a severe security threat to the vehicle driving. Therefore, in this paper, we summarize different types of Sybil attack detection mechanisms in VFC for the first time, and provide a comprehensive comparison of these schemes. In addition, we also summarize the possible impacts of different types of Sybil attacks on VFC. Finally, we summarize challenges and prospects of future research on Sybil attack detection mechanisms in VFC.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于车载自组织网络需要与云服务器频繁交互，车载自组织网络(VANETs)在延迟敏感的车载网络环境中的安全性和响应时间问题已被提议采用车载雾计算(VFC)。然而，VFC的匿名保护机制可能会导致攻击者通过编造或创建多个假名在网络中传播虚假信息来发起Sybil攻击，对车辆行驶造成严重的安全威胁。因此，本文首次总结了VFC不同类型的Sybil攻击检测机制，并对这些方案进行了综合比较。此外，我们还总结了不同类型的Sybil攻击对VFC可能造成的影响。最后，总结了VFC Sybil攻击检测机制面临的挑战和对未来研究的展望。",
                    "title_zh": "VFC Sybil攻击检测机制概述"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00029",
                    "title": "A Chinese Multi-modal Relation Extraction Model for Internet Security of Finance",
                    "authors": "Qinghan Lai, Shuai Ding, Jinghao Gong, Jin'an Cui, Song Liu",
                    "abstract": "As the base of the whole economy and society, internet security of finance directly affects the overall development of the country. With the development of the Internet, it is essential to effectively extract the relation between financial entities from internet financial intelligence and build a financial security knowledge graph, which lays the foundation for monitoring of internet security of finance. For relation extraction of Chinese internet financial intelligence, the existing models are all based on single-modal text semantics ignoring the role of Chinese pictographic semantics, while the shape and structure of Chinese characters contains useful semantics. In addition, the pictographic semantic fusion method of Chinese text also needs to be improved for better performance. To solve these shortcomings, we propose a Chinese Multimodal Relation Extraction model (CMRE), which improves the relation extraction ability on the Chinese internet financial intelligence. In CMRE, we extract pictographic semantics based on Chinese character shape and structure. Furthermore, we design a novel multi-modal semantic fusion module based on improved Transformer to effectively fuse the text and pictographic semantics. Additionally, we design experiments on the Chinese literature dataset(Sanwen) to test the relation extraction capability of CMRE. Finally, we employ CMRE to extract relations between financial entities on the internet financial intelligence dataset(FinRE) to compare with other baseline models.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为整个经济和社会的基础，金融网络安全直接影响到国家的整体发展。随着互联网的发展，有效地从互联网金融情报中提取金融实体之间的关系，构建金融安全知识图谱，为金融互联网安全监控奠定基础是非常必要的。对于中文互联网金融情报的关系抽取，现有的模型都是基于单模态文本语义，忽略了中文象形语义的作用，而汉字的形状和结构包含有用的语义。此外，中文文本的象形语义融合方法也需要改进以获得更好的性能。针对这些不足，我们提出了中文多模态关系抽取模型(CMRE ),提高了中文互联网金融智能的关系抽取能力。在CMRE，我们根据汉字的形状和结构提取象形语义。此外，我们设计了一种基于改进Transformer的多模态语义融合模块，有效融合文本和象形语义。此外，我们在中文文献数据集(散文)上设计实验来测试CMRE的关系抽取能力。最后，我们采用CMRE提取互联网金融情报数据集(FinRE)上金融实体之间的关系，以与其他基线模型进行比较。",
                    "title_zh": "面向金融网络安全的中文多模态关系抽取模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00030",
                    "title": "SbrPBert: A BERT-Based Model for Accurate Security Bug Report Prediction",
                    "authors": "Xudong Cao, Tianwei Liu, Jiayuan Zhang, Mengyue Feng, Xin Zhang, Wanying Cao, Hongyu Sun, Yuqing Zhang",
                    "abstract": "Bidirectional Encoder Representation from Transformers (Bert) has achieved impressive performance in several Natural Language Processing (NLP) tasks. However, there has been limited investigation on its adaptation guidelines in specialized fields. Here we focus on the software security domain. Early identification of security-related reports in software bug reports is one of the essential means to prevent security accidents. However, the prediction of security bug reports (SBRs) is limited by the scarcity and imbalance of samples in this field and the complex characteristics of SBRs. So motivated, we constructed the largest dataset in this field and proposed a Security Bug Report Prediction Model Based on Bert (SbrPBert). By introducing a layer-based learning rate attenuation strategy and a fine-tuning method for freezing some layers, our model outperforms the baseline model on both our dataset and other small-sample datasets. This means the practical value of the model in BUG tracking systems or projects that lack samples. Moreover, our model has detected 56 hidden vulnerabilities through deployment on the Mozilla and RedHat projects so far.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "来自变压器的双向编码器表示(Bert)在几个自然语言处理(NLP)任务中取得了令人印象深刻的性能。然而，在专门领域对其适应指南的研究有限。这里我们关注软件安全领域。及早识别软件bug报告中的安全相关报告是预防安全事故的必要手段之一。然而，安全漏洞报告的预测受到该领域样本的稀缺性和不平衡性以及安全漏洞报告复杂特性的限制。因此，我们构建了该领域最大的数据集，并提出了基于Bert (SbrPBert)的安全漏洞报告预测模型。通过引入基于层的学习速率衰减策略和冻结某些层的微调方法，我们的模型在我们的数据集和其他小样本数据集上都优于基线模型。这意味着模型在缺少样本的BUG跟踪系统或项目中的实用价值。此外，通过在Mozilla和RedHat项目上的部署，我们的模型已经检测到56个隐藏的漏洞。",
                    "title_zh": "SbrPBert:一种基于Bert的精确安全缺陷报告预测模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00031",
                    "title": "SCUC-DSAC: A Data Sharing Access Control Model Based on Smart Contract and User Credit",
                    "authors": "Guangxia Xu, Li Wang",
                    "abstract": "In the context of today's big data era, there is an urgent need for data sharing in various industries. Traditional data sharing schemes are highly centralized and have problems such as single point of failure and data privacy leakage caused by the vulnerability of data storage systems to attackers, and there are also problems such as difficulty in determining data ownership, insufficient granularity of access control, and low transparency of data sharing process. In this paper, an access control model for data sharing based on smart contract and user credit (SCUC-DSAC) is proposed. Based on the consortium blockchain, the attribute-based access control strategy and user credit are combined to provide dynamic and fine-grained access control for users. The data in the model is encrypted and stored in the interstellar file system. The access authorization process is implemented in the smart contract to improve the transparency of the data sharing process. Theoretical and experimental analysis shows that this model meets the functional and security requirements in data sharing scenarios, and the performance of blockchain network is good.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在当今大数据时代的背景下，各行业迫切需要数据共享。传统的数据共享方案高度集中，存在数据存储系统对攻击者的脆弱性导致的单点故障和数据隐私泄露等问题，还存在数据所有权难以确定、访问控制粒度不够、数据共享过程透明度低等问题。提出了一种基于智能合同和用户信用的数据共享访问控制模型(SCUC-DSAC模型)。基于区块链联盟，将基于属性的访问控制策略和用户信用相结合，为用户提供动态的细粒度访问控制。模型中的数据被加密存储在星际文件系统中。智能合约中实现了访问授权过程，以提高数据共享过程的透明度。理论和实验分析表明，该模型满足数据共享场景下的功能和安全需求，区块链网络性能良好。",
                    "title_zh": "SCUC-DSAC:基于智能合同和用户信用的数据共享访问控制模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00032",
                    "title": "Vulnerability Dataset Construction Methods Applied To Vulnerability Detection: A Survey",
                    "authors": "Yuhao Lin, Ying Li, Mianxue Gu, Hongyu Sun, Qiuling Yue, Jinglu Hu, Chunjie Cao, Yuqing Zhang",
                    "abstract": "The increasing number of security vulnerabilities has become an important problem that needs to be solved urgently in the field of software security, which means that the current vulnerability mining technology still has great potential for development. However, most of the existing AI-based vulnerability detection methods focus on designing different AI models to improve the accuracy of vulnerability detection, ignoring the fundamental problems of data-driven AI-based algorithms: first, there is a lack of sufficient high-quality vulnerability data; second, there is no unified standardized construction method to meet the standardized evaluation of different vulnerability detection models. This all greatly limits security personnel’s in-depth research on vulnerabilities. In this survey, we review the current literature on building high-quality vulnerability datasets, aiming to investigate how state-of-the-art research has leveraged data mining and data processing techniques to generate vulnerability datasets to facilitate vulnerability discovery. We also identify the challenges of this new field and share our views on potential research directions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "日益增多的安全漏洞已经成为软件安全领域亟待解决的重要问题，这意味着当前的漏洞挖掘技术仍有很大的发展潜力。然而，现有的基于AI的漏洞检测方法大多侧重于设计不同的AI模型来提高漏洞检测的准确率，忽略了数据驱动的基于AI的算法的根本问题:一是缺乏足够的高质量漏洞数据；二是没有统一的标准化构建方法来满足不同漏洞检测模型的标准化评估。这都极大地限制了安全人员对漏洞的深入研究。在本次调查中，我们回顾了当前关于构建高质量漏洞数据集的文献，旨在调查最新研究如何利用数据挖掘和数据处理技术来生成漏洞数据集，以促进漏洞发现。我们还确定了这一新领域的挑战，并分享了我们对潜在研究方向的看法。",
                    "title_zh": "应用于漏洞检测的漏洞数据集构建方法综述"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00033",
                    "title": "Multi-authoritative Users Assured Data Deletion Scheme in Cloud Computing",
                    "authors": "Junfeng Tian, Ruxin Bai, Tianfeng Zhang",
                    "abstract": "With the rapid development of cloud storage technology, an increasing number of enterprises and users choose to store data in the cloud, which can reduce the local overhead and ensure safe storage, sharing, and deletion. In cloud storage, safe data deletion is a critical and challenging problem. This paper proposes an assured data deletion scheme based on multi-authoritative users in the semi-trusted cloud storage scenario (MAU-AD), which aims to realize the secure management of the key without introducing any trusted third party and achieve assured deletion of cloud data. MAU-AD uses access policy graphs to achieve fine-grained access control and data sharing. Besides, the data security is guaranteed by mutual restriction between authoritative users, and the system robustness is improved by multiple authoritative users jointly managing keys. In addition, the traceability of misconduct in the system can be realized by blockchain technology. Through simulation experiments and comparison with related schemes, MAU-AD is proven safe and effective, and it provides a novel application scenario for the assured deletion of cloud storage data.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着云存储技术的快速发展，越来越多的企业和用户选择将数据存储在云端，这样可以减少本地开销，保证数据的安全存储、共享和删除。在云存储中，安全的数据删除是一个关键且具有挑战性的问题。提出了一种半可信云存储场景下基于多权威用户的安全数据删除方案(MAU-AD ),目的是在不引入任何可信第三方的情况下实现密钥的安全管理，实现云数据的安全删除。MAU-AD使用访问策略图来实现细粒度的访问控制和数据共享。此外，权威用户之间的相互制约保证了数据的安全性，多个权威用户共同管理密钥提高了系统的健壮性。此外，通过区块链技术可以实现系统中不当行为的可追溯性。通过仿真实验和与相关方案的比较，证明了MAU-AD的安全性和有效性，为云存储数据的安全删除提供了一种新的应用场景。",
                    "title_zh": "云计算中多权威用户保证的数据删除方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00034",
                    "title": "A Two-Layer Soft-Voting Ensemble Learning Model For Network Intrusion Detection",
                    "authors": "Wenbin Yao, Longcan Hu, Yingying Hou, Xiaoyong Li",
                    "abstract": "Network intrusion detection is a real-time technology to protect the network from attack, which plays a major role in the server system and network security. However, network intrusion detection still faces multiple challenges, such as inconsistent data distribution between training and testing dataset, imbalanced data categories and low accuracy rate. To solve these problems, a two-layer soft-voting ensemble learning model with RF, lightGBM and XGBoost as base classifiers is proposed in this paper. Firstly, the model uses the adversarial validate algorithm to test the consistency of data distribution in training and testing dataset to determine whether the dataset needs re-splitting. Secondly, the model adopts the Synthetic Minority Oversampling Technique (SMOTE) to synthesize samples of minority classes, which helps improve the accuracy rate of minority classes. Finally, the experimental results show that the soft-voting ensemble learning model has a higher accuracy rate in both binary and multi-classification than other single models, which proves to be both feasible and efficient. In particular, the recall rate of DoS, ShellCode, Worms and Reconnaissance is significantly increased in multi-classification.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络入侵检测是一种保护网络免受攻击的实时技术，在服务器系统和网络安全中起着重要作用。然而，网络入侵检测仍然面临着多重挑战，如训练数据集和测试数据集之间的数据分布不一致、数据类别不均衡和准确率低。针对这些问题，提出了一种以RF、lightGBM和XGBoost为基分类器的两层软投票集成学习模型。首先，该模型使用对抗性验证算法来检验训练和测试数据集中数据分布的一致性，以确定数据集是否需要重新划分。其次，该模型采用合成少数过采样技术(SMOTE)合成少数类样本，有助于提高少数类的准确率。实验结果表明，软投票集成学习模型在二分类和多分类上都比其他单一模型具有更高的准确率，证明了该模型的可行性和有效性。特别是在多分类中，DoS、ShellCode、蠕虫和侦察的召回率显著提高。",
                    "title_zh": "网络入侵检测的两层软投票集成学习模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00035",
                    "title": "Machine Learning Analysis of Memory Images for Process Characterization and Malware Detection",
                    "authors": "Seth Lyles, Mark Desantis, John Donaldson, Micaela Gallegos, Hannah Nyholm, Claire Taylor, Kristine Monteith",
                    "abstract": "As signature-based malware detection techniques mature, malware authors have been forced to leave fewer footprints on target machines. Malicious activity can be conducted by chaining together benign, built-in functions in subversive ways. Because the functions are native to the host system, attackers can slip under the radar of signature filtering tools such as YARA. To address this challenge, we utilize the Volatility memory forensics framework to measure and characterize typical in-memory behavior, then observe the deviations from normal use that may indicate a compromise. We demonstrate that processes have characteristic memory footprints, and that machine learning models can flag malicious behavior as anomalous.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着基于签名的恶意软件检测技术的成熟，恶意软件作者被迫在目标机器上留下更少的足迹。恶意活动可以通过以颠覆性的方式将良性的内置功能链接在一起来进行。因为这些功能是主机系统固有的，所以攻击者可以躲过YARA等签名过滤工具的雷达。为了应对这一挑战，我们利用易失性内存取证框架来测量和表征典型的内存中行为，然后观察可能表明危害的正常使用的偏差。我们证明了进程具有特有的内存足迹，并且机器学习模型可以将恶意行为标记为异常。",
                    "title_zh": "用于进程表征和恶意软件检测的存储器图像的机器学习分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00036",
                    "title": "Blockchain-Based Incentive and Arbitrable Data Auditing Scheme",
                    "authors": "Junfeng Tian, Qianqian Song, Haoning Wang",
                    "abstract": "The private data possession of proof mechanism is an important means to ensure the security of cloud data. Using the private data possession of proof mechanism may cause disputes between users and cloud storage service providers. There is no credible proof to determine the wrong party, it will affect the public’s confidence in using cloud storage technology. Therefore, this paper designs an incentive and arbitrable data audit protocol based blockchain. This protocol uses the quadratic residue theorem to achieve efficient auditing. The smart contract is introduced as a fair arbitrator, the blockchain is used as a self-recording channel to provide credible proof for the contradiction between users and cloud storage service providers, avoid disputes and realize dispute-free arbitration. A set of reward and punishment measures are designed using power functions to restrain the malicious behavior of untrusted users and cloud storage service providers. Efficiency analysis and experiments show that the proposed scheme has lower computational and communication overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "私有数据占有证明机制是保证云数据安全的重要手段。使用私有数据占有证明机制可能会引起用户和云存储服务提供商之间的纠纷。没有可信的证明来确定错误的一方，会影响公众使用云存储技术的信心。因此，本文设计了一种基于区块链的激励性可仲裁数据审计协议。该协议使用二次剩余定理来实现高效审计。引入智能合同作为公平仲裁人，区块链作为自记录渠道，为用户与云存储服务提供商之间的矛盾提供可信证明，避免纠纷，实现无争议仲裁。利用幂函数设计了一套奖惩措施来约束不可信用户和云存储服务提供商的恶意行为。效率分析和实验表明，该方案具有较低的计算和通信开销。",
                    "title_zh": "基于区块链的激励和可仲裁数据审计方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00037",
                    "title": "A Comprehensive Dynamic Quality Assessment Method for Cyber Threat Intelligence",
                    "authors": "Menghan Wang, Libin Yang, Wei Lou",
                    "abstract": "Extraordinary growth of the Internet poses a great challenge for defending worldwide evolution of cyber attacks. Introducing cyber threat intelligence (CTI) is a promising approach for alleviating malicious attacks, which heavily relies on the quality of CTI themselves. However, most of current studies develop CTI quality assessment from the perspective of source or content separately, regardless of their availability in practical. In this paper, a dynamic method named CTIC to comprehensively assess CTI quality is proposed. Specifically, we propose a novel CTI feed assessing scheme by modeling the interactions of feeds as a correlation graph. An iterative algorithm is elaborated to depict the feed quality precisely. We design a CTI content assessing scheme together with a machine learning algorithm to score the availability of content from multi-dimensions. Experimental results on real data confirm our proposed mechanism can quantitatively as well as effectively assess CTI quality.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "互联网的迅猛发展给防御全球范围的网络攻击带来了巨大挑战。引入网络威胁情报(CTI)是缓解恶意攻击的一种有前途的方法，而恶意攻击在很大程度上依赖于CTI本身的质量。然而，目前大多数研究都是分别从来源或内容的角度进行CTI质量评估，而没有考虑它们在实践中的可用性。本文提出了一种综合评价CTI质量的动态方法——CTIC法。具体来说，我们提出了一种新的CTI feed评估方案，通过将feed的交互建模为一个相关图。详细阐述了精确描述饲料质量的迭代算法。我们设计了一个CTI内容评估方案和一个机器学习算法，从多维度对内容的可用性进行评分。真实数据上的实验结果证实了我们提出的机制可以有效地定量评估CTI质量。",
                    "title_zh": "网络威胁情报的综合动态质量评估方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00038",
                    "title": "DTC: A Dynamic Trusted Collaboration Architecture for Mobile Edge Computing",
                    "authors": "Ruizhong Du, Yan Gao",
                    "abstract": "Under mobile edge computing (MEC), collaborative computing is a new paradigm to optimize edge network load and server resource allocation. However, there are still issues such as resource imbalance and unreliable identity when collaborative nodes provide computing and caching services for computing devices. Therefore, an efficient and reliable MEC network should be established to manage these challenges. In this paper, a dynamic trusted collaboration scheme is proposed. Specifically, the transaction supervision of nodes in the MEC scenario is first realized through blockchain-based mobile edge computing (BMEC) technology. In BMEC, a management scheme is established laying the foundation for building a trusted MEC environment. Second, a collaborative model is designed. On this basis, it is formulated as an optimization problem based on computing, communication, caching, and energy consumption. The formulation problem is verified to be NP complete. Thus, an improved heuristic algorithm is adopted in this study to solve this problem. Ultimately, the experimental results demonstrate that DTC not only has good performance but also can effectively enhance the reliability of the MEC network compared with other cooperative schemes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在移动边缘计算(MEC)下，协同计算是优化边缘网络负载和服务器资源分配的新范式。然而，协作节点在为计算设备提供计算和缓存服务时，仍然存在资源不均衡和身份不可靠等问题。因此，应建立一个高效可靠的MEC网络来应对这些挑战。提出了一种动态可信协作方案。具体来说，MEC场景中节点的事务监管首先通过基于区块链的移动边缘计算(BMEC)技术实现。在BMEC，建立了一个管理方案，为构建可信MEC环境奠定了基础。其次，设计了一个协作模型。在此基础上，将其公式化为基于计算、通信、缓存和能量消耗的优化问题。公式问题被证明是NP完全的。因此，本研究采用一种改进的启发式算法来解决这个问题。实验结果表明，与其他协作方案相比，DTC不仅具有良好的性能，而且能有效提高MEC网络的可靠性。",
                    "title_zh": "DTC:一种面向移动边缘计算的动态可信协作架构"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00039",
                    "title": "VDBWGDL: Vulnerability Detection Based On Weight Graph And Deep Learning",
                    "authors": "Xin Zhang, Hongyu Sun, Zhipeng He, Mianxue Gu, Jingyu Feng, Yuqing Zhang",
                    "abstract": "Vulnerability detection has always been an essential part of maintaining information security, and the existing work can significantly improve the performance of vulnerability detection. However, due to the differences in representation forms and deep learning models, various methods still have some limitations. In order to overcome this defect, We propose a vulnerability detection method VDBWGDL, based on weight graphs and deep learning. Firstly, it accurately locates vulnerability-sensitive keywords and generates variant codes that satisfy vulnerability trigger logic and programmer programming style through code variant methods. Then, the control flow graph is sliced for vulnerable code keywords and program critical statements. The code block is converted into a vector containing rich semantic information and input into the weight map through the deep learning model. According to specific rules, different weights are set for each node. Finally, the similarity is obtained through the similarity comparison algorithm, and the suspected vulnerability is output according to different thresholds. VDBWGDL improves the accuracy and F1 value by 3.98% and 4.85% compared with four state-of-the-art models. The experimental results prove the effectiveness of VDBWGDL.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "漏洞检测一直是维护信息安全的重要组成部分，现有的工作可以显著提高漏洞检测的性能。然而，由于表现形式和深度学习模型的差异，各种方法仍然具有一定的局限性。为了克服这一缺陷，我们提出了一种基于权重图和深度学习的漏洞检测方法VDBWGDL。首先，通过代码变体方法，精确定位漏洞敏感关键词，生成满足漏洞触发逻辑和程序员编程风格的变体代码。然后，针对易受攻击的代码关键字和程序关键语句对控制流图进行切片。码块通过深度学习模型转换成包含丰富语义信息的向量，输入到权重图中。根据特定的规则，为每个节点设置不同的权重。最后通过相似度比较算法得到相似度，根据不同的阈值输出疑似漏洞。VDBWGDL与四种最先进的模型相比，精度和F1值分别提高了3.98%和4.85%。实验结果证明了VDBWGDL的有效性。",
                    "title_zh": "基于权重图和深度学习的漏洞检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W54100.2022.00040",
                    "title": "Dynamic Multipath Routing Mechanism for Multimedia Data Flow Scheduling Over Software Defined Networks",
                    "authors": "Jiawei Wu, Xiuquan Qiao, Huijuan Lu",
                    "abstract": "Due to the explosive growth of big data, driven by the pervasiveness of real-time multimedia applications, Software-defined Networks (SDNs) are expected to fully handle multimedia services with various quality of service (QoS) guarantees. Unlike traditional data applications (e.g., e-mail and file transfer), multimedia applications require diverse QoS guarantees to satisfy the user’s expectations. Currently, service providers still have difficulties in providing high quality video streaming due to the difficulty of scheduling efficiency and of end-to-end data delivery in the existing multipath algorithms. Moreover, existing multipath algorithms suffer from a significant transmission cost. To solve these problems, a Dynamic and Adaptive Multi-path Routing algorithm with respect to multiple constraints (DAMR) over SDN is proposed in this paper. The proposed approach leverages the Lagrangian Relaxation Algorithm (LRA) to find a feasible path that satisfies the desired QoS requirements. The DAMR takes several QoS routing constraints, such as end-to-end delay and bandwidth, into account in path selection. Compared with existing routing proposals, the DAMR makes efficient use of the latest global network state information achieved by the OpenFlow controller and it dynamically calculates the optimal routes according to the real-time status information of the link. Theoretical and simulation results show that our proposed DAMR algorithm is better than SPT and MCMPT in terms of packet loss ratio, throughput and end to end delay.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于大数据的爆炸式增长，以及实时多媒体应用的普及，软件定义网络(sdn)有望完全处理具有各种服务质量(QoS)保证的多媒体服务。与传统的数据应用(例如，电子邮件和文件传输)不同，多媒体应用需要不同的QoS保证来满足用户的期望。目前，由于现有多路径算法中调度效率和端到端数据传递的困难，服务提供商在提供高质量视频流方面仍然存在困难。此外，现有的多径算法承受着巨大的传输成本。针对这些问题，提出了一种SDN上多约束动态自适应多路径路由算法(DAMR)。所提出的方法利用拉格朗日松弛算法(LRA)来寻找满足期望QoS要求的可行路径。DAMR在路径选择中考虑了几个QoS路由约束，例如端到端延迟和带宽。与现有的路由方案相比，DAMR有效地利用了OpenFlow控制器获得的最新全球网络状态信息，并根据链路的实时状态信息动态计算最优路由。理论和仿真结果表明，我们提出的DAMR算法在丢包率、吞吐量和端到端时延方面都优于SPT和MCMPT算法。",
                    "title_zh": "用于软件定义网络上多媒体数据流调度的动态多路径路由机制"
                }
            ]
        }
    ],
    "2019": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2019.html",
            "conf_title": "49th DSN 2019: Portland, OR, USA",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8790390/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00016",
                    "title": "GreenFlag: Protecting 3D-Racetrack Memory from Shift Errors",
                    "authors": "Georgios Mappouras, Alireza Vahid, A. Robert Calderbank, Daniel J. Sorin",
                    "abstract": "Racetrack memory is an exciting emerging memory technology with the potential to offer far greater capacity and performance than other non-volatile memories. Racetrack memory has an unusual error model, though, which precludes the use of the typical error coding techniques used by architects. In this paper, we introduce GreenFlag, a coding scheme that combines a new construction for Varshamov-Tenegolts codes with specially crafted delimiter bits that are placed between each codeword. GreenFlag is the first coding scheme that is compatible with 3D racetrack, which has the benefit of very high density but the limitation of a single read/write port per track. Based on our implementation of encoding/decoding hardware, we analyze the trade-offs between latency, code length, and code rate; we then use this analysis to evaluate the viability of racetrack at each level of the memory hierarchy.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "赛道存储器是一种令人兴奋的新兴存储技术，有潜力提供比其他非易失性存储器更大的容量和性能。然而，赛道内存有一个不寻常的错误模型，它排除了架构师使用的典型错误编码技术。在本文中，我们介绍了GreenFlag，这是一种将Varshamov-Tenegolts码的新构造与放置在每个码字之间的特制分隔符位相结合的编码方案。GreenFlag是第一个与3D赛道兼容的编码方案，具有极高密度的优势，但每个赛道只有一个读/写端口。基于我们的编码/解码硬件实现，我们分析了延迟、码长和码率之间的权衡；然后，我们使用这种分析来评估赛道在记忆层级的每一层的生存能力。",
                    "title_zh": "GreenFlag:保护3D赛道内存免于移位错误"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00017",
                    "title": "Understanding and Modeling On-Die Error Correction in Modern DRAM: An Experimental Study Using Real Devices",
                    "authors": "Minesh Patel, Jeremie S. Kim, Hasan Hassan, Onur Mutlu",
                    "abstract": "Experimental characterization of DRAM errors is a powerful technique for understanding DRAM behavior and provides valuable insights for improving overall system performance, energy efficiency, and reliability. Unfortunately, recent DRAM technology scaling issues are forcing manufacturers to adopt on-die error-correction codes (ECC), which pose a significant challenge for DRAM error characterization studies by obfuscating raw error distributions using undocumented, proprietary, and opaque error-correction hardware. As we show in this work, errors observed in devices with on-die ECC no longer follow expected, well-studied distributions (e.g., lognormal retention times) but rather depend on the particular ECC scheme used.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "DRAM错误的实验表征是用于理解DRAM行为的强大技术，并且为改善整体系统性能、能量效率和可靠性提供了有价值的见解。不幸的是，最近的DRAM技术缩放问题正迫使制造商采用片内纠错码(ECC)，这通过使用未记录的、专有的和不透明的纠错硬件混淆原始错误分布，对DRAM错误表征研究构成了重大挑战。正如我们在这项工作中所展示的，在具有片上ECC的器件中观察到的误差不再遵循预期的、经过充分研究的分布(例如，对数正态保持时间)，而是取决于所使用的特定ECC方案。",
                    "title_zh": "理解和模拟现代DRAM中的片内纠错:使用真实器件的实验研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00018",
                    "title": "Demystifying Soft Error Assessment Strategies on ARM CPUs: Microarchitectural Fault Injection vs. Neutron Beam Experiments",
                    "authors": "Athanasios Chatzidimitriou, Pablo Bodmann, George Papadimitriou, Dimitris Gizopoulos, Paolo Rech",
                    "abstract": "Fault injection in early microarchitecture-level simulation CPU models and beam experiments on the final physical CPU chip are two established methodologies to access the soft error reliability of a microprocessor at different stages of its design flow. Beam experiments, on one hand, estimate the devices expected soft error rate in realistic physical conditions by exposing it to accelerated particles fluxes. Fault injection in microarchitectural models of the processor, on the other hand, provides deep insights on faults propagation through the entire system stack, including the operating system. Combining beam experiments and fault injection data can deliver deep insights about the devices expected reliability when deployed in the field. However, it is yet largely unclear if the fault injection error rates can be compared to those reported by beam experiments and how this comparison can lead to informed soft error protection decisions in early stages of the system design.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "早期微体系结构级模拟CPU模型中的故障注入和最终物理CPU芯片上的beam实验是在微处理器设计流程的不同阶段评估微处理器软错误可靠性的两种既定方法。一方面，束实验通过将器件暴露于加速粒子流来估计器件在实际物理条件下的预期软错误率。另一方面，处理器微体系结构模型中的故障注入可以深入了解故障在整个系统堆栈(包括操作系统)中的传播情况。结合射束实验和故障注入数据，可以深入了解设备在现场部署时的预期可靠性。然而，目前尚不清楚故障注入错误率是否可以与beam实验报告的错误率进行比较，以及这种比较如何在系统设计的早期阶段做出明智的软错误保护决策。",
                    "title_zh": "揭开ARM处理器软错误评估策略的神秘面纱:微体系结构故障注入与中子束实验"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00019",
                    "title": "A Multiversion Programming Inspired Approach to Detecting Audio Adversarial Examples",
                    "authors": "Qiang Zeng, Jianhai Su, Chenglong Fu, Golam Kayas, Lannan Luo, Xiaojiang Du, Chiu C. Tan, Jie Wu",
                    "abstract": "Adversarial examples (AEs) are crafted by adding human-imperceptible perturbations to inputs such that a machine-learning based classifier incorrectly labels them. They have become a severe threat to the trustworthiness of machine learning. While AEs in the image domain have been well studied, audio AEs are less investigated. Recently, multiple techniques are proposed to generate audio AEs, which makes countermeasures against them urgent. Our experiments show that, given an audio AE, the transcription results by Automatic Speech Recognition (ASR) systems differ significantly (that is, poor transferability), as different ASR systems use different architectures, parameters, and training datasets. Based on this fact and inspired by Multiversion Programming, we propose a novel audio AE detection approach MVP-Ears, which utilizes the diverse off-the-shelf ASRs to determine whether an audio is an AE. We build the largest audio AE dataset to our knowledge, and the evaluation shows that the detection accuracy reaches 99.88%. While transferable audio AEs are difficult to generate at this moment, they may become a reality in future. We further adapt the idea above to proactively train the detection system for coping with transferable audio AEs. Thus, the proactive detection system is one giant step ahead of attackers working on transferable AEs.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1812.10199"
                    },
                    "abstract_zh": "通过向输入添加人类察觉不到的扰动，使得基于机器学习的分类器错误地标记它们，来制作对立示例(AEs)。它们已经成为机器学习可信度的严重威胁。虽然图像域中的AEs已得到充分研究，但音频AEs研究较少。最近，提出了多种技术来产生音频AEs，这使得针对它们的对策变得迫切。我们的实验表明，给定一个音频AE，自动语音识别(ASR)系统的转录结果显著不同(即，可转移性差)，因为不同的ASR系统使用不同的架构、参数和训练数据集。基于这一事实，并受多版本编程的启发，我们提出了一种新的音频AE检测方法MVP-Ears，该方法利用各种现成的ASR来确定音频是否是AE。我们建立了我们所知的最大的音频声发射数据集，评估表明，检测准确率达到99.88%。虽然目前很难产生可传输的音频AEs，但它们可能会在未来成为现实。我们进一步调整上述想法，以主动训练检测系统来应对可转移音频AE。因此，主动检测系统比研究可转移AEs的攻击者领先了一大步。",
                    "title_zh": "一种受多版本程序设计启发的检测音频对立示例的方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00020",
                    "title": "Classifying Malware Represented as Control Flow Graphs using Deep Graph Convolutional Neural Network",
                    "authors": "Jiaqi Yan, Guanhua Yan, Dong Jin",
                    "abstract": "Malware have been one of the biggest cyber threats in the digital world for a long time. Existing machine learning based malware classification methods rely on handcrafted features extracted from raw binary files or disassembled code. The diversity of such features created has made it hard to build generic malware classification systems that work effectively across different operational environments. To strike a balance between generality and performance, we explore new machine learning techniques to classify malware programs represented as their control flow graphs (CFGs). To overcome the drawbacks of existing malware analysis methods using inefficient and nonadaptive graph matching techniques, in this work, we build a new system that uses deep graph convolutional neural network to embed structural information inherent in CFGs for effective yet efficient malware classification. We use two large independent datasets that contain more than 20K malware samples to evaluate our proposed system and the experimental results show that it can classify CFG-represented malware programs with performance comparable to those of the state-of-the-art methods applied on handcrafted malware features.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "长期以来，恶意软件一直是数字世界中最大的网络威胁之一。现有的基于机器学习的恶意软件分类方法依赖于从原始二进制文件或反汇编代码中提取的手工特征。所创建的这种特征的多样性使得很难构建跨不同操作环境有效工作的通用恶意软件分类系统。为了在通用性和性能之间取得平衡，我们探索了新的机器学习技术来分类恶意软件程序，用它们的控制流图(CFG)来表示。为了克服现有的恶意软件分析方法使用低效和非适应性图匹配技术的缺点，在这项工作中，我们建立了一个新的系统，该系统使用深度图卷积神经网络来嵌入CFG中固有的结构信息，用于有效而高效的恶意软件分类。我们使用两个包含超过20K个恶意软件样本的大型独立数据集来评估我们提出的系统，实验结果表明，它可以分类以CFG为代表的恶意软件程序，其性能与应用于手工制作的恶意软件特征的最新方法相当。",
                    "title_zh": "使用深度图卷积神经网络对表示为控制流图的恶意软件进行分类"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00021",
                    "title": "ZK-GanDef: A GAN Based Zero Knowledge Adversarial Training Defense for Neural Networks",
                    "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah",
                    "abstract": "Neural Network classifiers have been used successfully in a wide range of applications. However, their underlying assumption of attack free environment has been defied by adversarial examples. Researchers tried to develop defenses; however, existing approaches are still far from providing effective solutions to this evolving problem. In this paper, we design a generative adversarial net (GAN) based zero knowledge adversarial training defense, dubbed ZK-GanDef, which does not consume adversarial examples during training. Therefore, ZK-GanDef is not only efficient in training but also adaptive to new adversarial examples. This advantage comes at the cost of small degradation in test accuracy compared to full knowledge approaches. Our experiments show that ZK-GanDef enhances test accuracy on adversarial examples by up-to 49.17% compared to zero knowledge approaches. More importantly, its test accuracy is close to that of the state-of-the-art full knowledge approaches (maximum degradation of 8.46%), while taking much less training time.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1904.08516"
                    },
                    "abstract_zh": "神经网络分类器已经被成功地用于广泛的应用中。然而，他们潜在的无攻击环境的假设已经被对抗的例子所挑战。研究人员试图开发防御手段；然而，现有的方法还远远不能为这个不断发展的问题提供有效的解决方案。本文设计了一种基于生成对抗网的零知识对抗训练防御方法，称为ZK-甘德夫，该方法在训练过程中不消耗对抗样本。因此，ZK-甘德夫不仅训练效率高，而且能适应新的对抗实例。与全知识方法相比，这种优势的代价是测试精度略有下降。我们的实验表明，与零知识方法相比，ZK-甘德夫算法在对立例子上的测试准确率提高了49.17%。更重要的是，它的测试精度接近最先进的全知识方法(最大降级8.46%)，同时花费的训练时间少得多。",
                    "title_zh": "ZK-甘德夫:基于甘的神经网络零知识对抗训练防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00022",
                    "title": "Efficient Treatment of Uncertainty in System Reliability Analysis using Importance Measures",
                    "authors": "Hananeh Aliee, Faramarz Khosravi, Jürgen Teich",
                    "abstract": "The reliability of today's electronic products suffers from a growing variability of failure and ageing effects. In this paper, we investigate a technique for the efficient derivation of uncertainty distributions of system reliability. We assume that a system is composed of unreliable components whose reliabilities are modeled as probability distributions. Existing Monte Carlo (MC) simulation-based techniques, which iteratively select a sample from the probability distributions of the components, often suffer from high execution time and/or poor coverage of the sample space. To avoid the costly re-evaluation of a system reliability during MC simulation, we propose to employ the Taylor expansion of the system reliability function. Moreover, we propose a stratified sampling technique which is based on the fact that the contribution (or importance) of the components on the uncertainty of their system may not be equivalent. This technique finely/coarsely stratifies the probability distribution of the components with high/low contribution. The experimental results show that the proposed technique is more efficient and provides more accurate results compared to previously proposed techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当今电子产品的可靠性受到故障和老化效应日益增加的影响。在本文中，我们研究了一种有效地推导系统可靠性不确定性分布的技术。我们假设一个系统由不可靠的部件组成，这些部件的可靠性被建模为概率分布。现有的基于蒙特卡罗(MC)模拟的技术，从成分的概率分布中迭代地选择样本，经常遭受高执行时间和/或样本空间的不良覆盖。为了避免在MC模拟过程中对系统可靠性进行昂贵的重新评估，我们建议采用系统可靠性函数的泰勒展开式。此外，我们提出了一种分层抽样技术，它是基于这样一个事实，即部件对其系统不确定性的贡献(或重要性)可能不相等。这种技术对具有高/低贡献的分量的概率分布进行精细/粗略分层。实验结果表明，与先前提出的技术相比，所提出的技术更有效，并且提供了更准确的结果。",
                    "title_zh": "利用重要度有效处理系统可靠性分析中的不确定性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00023",
                    "title": "Extensions of Network Reliability Analysis",
                    "authors": "Hoang Hai Nguyen, Kartik Palani, David M. Nicol",
                    "abstract": "Network reliability studies properties of networks subjected to random failures of their components. It has been widely adopted to modeling and analyzing real-world problems across different domains, such as circuit design, genomics, databases, information propagation, network security, and many others. Two practical situations that usually arise from such problems are (i) the correlation between component failures and (ii) the uncertainty in failure probabilities. Previous work captured correlations by modeling component reliability using general Boolean expression of Bernoulli random variables. This paper extends such a model to address the second problem, where we investigate the use of Beta distributions to capture the variance of uncertainty. We call this new formalism the Beta uncertain graph. We study the reliability polynomials of Beta uncertain graphs as multivariate polynomials of Beta random variables and demonstrate the use of the model on two realistic examples. We also observe that the reliability distribution of a monotone Beta uncertain graph can be approximated by a Beta distribution, usually with high accuracy. Numerical results from Monte Carlo simulation of an approximation scheme and from two case studies strongly support this observation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络可靠性研究的是网络在其组件发生随机故障时的特性。它已被广泛用于建模和分析不同领域的现实问题，如电路设计、基因组学、数据库、信息传播、网络安全等。这类问题通常产生的两种实际情况是(I)部件失效之间的相关性和(ii)失效概率的不确定性。先前的工作通过使用伯努利随机变量的一般布尔表达式来建模组件可靠性，从而捕获相关性。本文扩展了这样一个模型来解决第二个问题，其中我们研究了使用贝塔分布来捕捉不确定性的方差。我们把这种新的形式称为贝塔不确定图。我们将贝塔不确定图的可靠性多项式作为贝塔随机变量的多元多项式来研究，并在两个实际例子上演示了该模型的使用。我们还观察到，单调Beta不确定图的可靠性分布可以用Beta分布来近似，通常精度很高。一个近似方案的蒙特卡罗模拟和两个案例研究的数值结果有力地支持了这一观察。",
                    "title_zh": "网络可靠性分析的扩展"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00024",
                    "title": "An Online Approach to Estimate Parameters of Phase-Type Distributions",
                    "authors": "Peter Buchholz, Iryna Dohndorf, Jan Kriege",
                    "abstract": "The traditional expectation-maximization (EM) algorithm is a general purpose algorithm for maximum likelihood estimation in problems with incomplete data. Several variants of the algorithm exist to estimate the parameters of phase-type distributions (PHDs), a widely used class of distributions in performance and dependability modeling. EM algorithms are typical offline algorithms because they improve the likelihood function by iteratively running through a fixed sample. Nowadays data can be generated online in most systems such that offline algorithms seem to be outdated in this environment. This paper proposes an online EM algorithm for parameter estimation of PHDs. In contrast to the offline version, the online variant adds data immediately when it becomes available and includes no iteration. Different variants of the algorithms are proposed that exploit the specific structure of subclasses of PHDs like hyperexponential, hyper-Erlang or acyclic PHDs. The algorithm furthermore incorporates current methods to detect drifts or change points in a data stream and estimates a new PHD whenever such a behavior has been identified. Thus, the resulting distributions can be applied for online model prediction and for the generation of inhomogeneous PHDs as an extension of inhomogeneous Poisson processes. Numerical experiments with artificial and measured data streams show the applicability of the approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传统的期望最大化(EM)算法是不完全数据问题中最大似然估计的通用算法。存在该算法的几种变体来估计相位型分布(PHDs)的参数，相位型分布是在性能和可靠性建模中广泛使用的一类分布。EM算法是典型的离线算法，因为它们通过迭代运行固定样本来改进似然函数。如今，数据可以在大多数系统中在线生成，因此离线算法在这种环境下似乎已经过时。本文提出了一种在线EM算法用于博士学位论文的参数估计。与离线版本相比，在线版本在数据可用时会立即添加数据，并且不包含迭代。提出了算法的不同变体，其利用了博士子类的特定结构，如超指数、超埃尔兰或非循环博士。此外，该算法结合了当前的方法来检测数据流中的漂移或变化点，并且每当识别出这种行为时就估计新的PHD。因此，得到的分布可以应用于在线模型预测和作为非均匀泊松过程的扩展的非均匀博士的生成。对人工数据流和实测数据流的数值实验表明了该方法的适用性。",
                    "title_zh": "一种在线估计相位型分布参数的方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00025",
                    "title": "ML-Based Fault Injection for Autonomous Vehicles: A Case for Bayesian Fault Injection",
                    "authors": "Saurabh Jha, Subho S. Banerjee, Timothy Tsai, Siva Kumar Sastry Hari, Michael B. Sullivan, Zbigniew T. Kalbarczyk, Stephen W. Keckler, Ravishankar K. Iyer",
                    "abstract": "The safety and resilience of fully autonomous vehicles (AVs) are of significant concern, as exemplified by several headline-making accidents. While AV development today involves verification, validation, and testing, end-to-end assessment of AV systems under accidental faults in realistic driving scenarios has been largely unexplored. This paper presents DriveFI, a machine learning-based fault injection engine, which can mine situations and faults that maximally impact AV safety, as demonstrated on two industry-grade AV technology stacks (from NVIDIA and Baidu). For example, DriveFI found 561 safety-critical faults in less than 4 hours. In comparison, random injection experiments executed over several weeks could not find any safety-critical faults.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1907.01051"
                    },
                    "abstract_zh": "正如几起头条新闻事故所证明的那样，完全自动驾驶汽车(AVs)的安全性和弹性受到了极大的关注。虽然今天的AV开发包括验证、确认和测试，但是在真实驾驶场景中的意外故障下的AV系统的端到端评估在很大程度上还没有被探索。本文介绍了基于机器学习的故障注入引擎DriveFI，它可以挖掘最大程度影响AV安全的情况和故障，如在两个行业级AV技术栈(来自NVIDIA和百度)上演示的那样。例如，DriveFI在不到4小时内发现了561个安全关键故障。相比之下，在几周内执行的随机注射实验无法发现任何安全关键故障。",
                    "title_zh": "基于最大似然的自主车辆故障注入:贝叶斯故障注入案例"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00026",
                    "title": "Deep Validation: Toward Detecting Real-World Corner Cases for Deep Neural Networks",
                    "authors": "Weibin Wu, Hui Xu, Sanqiang Zhong, Michael R. Lyu, Irwin King",
                    "abstract": "The exceptional performance of Deep neural networks (DNNs) encourages their deployment in safety-and dependability-critical systems. However, DNNs often demonstrate erroneous behaviors in real-world corner cases. Existing countermeasures center on improving the testing and bug-fixing practice. Unfortunately, building a bug-free DNN-based system is almost impossible currently due to its black-box nature, so anomaly detection is imperative in practice. Motivated by the idea of data validation in a traditional program, we propose and implement Deep Validation, a novel framework for detecting real-world error-inducing corner cases in a DNN-based system during runtime. We model the specifications of DNNs by resorting to their training data and cast checking input validity of DNNs as the problem of discrepancy estimation. Deep Validation achieves excellent detection results against various corner case scenarios across three popular datasets. Consequently, Deep Validation greatly complements existing efforts and is a crucial step toward building safe and dependable DNN-based systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "深度神经网络(DNNs)的卓越性能鼓励其在安全和可靠性关键系统中的部署。然而，dnn在现实世界的极端情况下经常表现出错误的行为。现有的对策集中在改进测试和缺陷修复实践上。不幸的是，构建一个无错误的基于DNN的系统目前几乎是不可能的，因为它的黑盒性质，所以异常检测在实践中是必不可少的。受传统程序中数据验证思想的启发，我们提出并实现了深度验证，这是一个新的框架，用于在运行时检测基于DNN的系统中真实世界的错误诱导拐角情况。我们通过依赖于DNNs的训练数据来建模DNNs的规范，并将检查DNNs的输入有效性视为差异估计的问题。深度验证针对三个流行数据集的各种极限情况场景实现了出色的检测结果。因此，深度验证极大地补充了现有的工作，是构建安全可靠的基于DNN的系统的关键一步。",
                    "title_zh": "深度验证:为深度神经网络检测真实世界的极限情况"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00027",
                    "title": "SOTER: A Runtime Assurance Framework for Programming Safe Robotics Systems",
                    "authors": "Ankush Desai, Shromona Ghosh, Sanjit A. Seshia, Natarajan Shankar, Ashish Tiwari",
                    "abstract": "The recent drive towards achieving greater autonomy and intelligence in robotics has led to high levels of complexity. Autonomous robots increasingly depend on third-party off-the-shelf components and complex machine-learning techniques. This trend makes it challenging to provide strong design-time certification of correct operation. To address these challenges, we present SOTER, a robotics programming framework with two key components: (1) a programming language for implementing and testing high-level reactive robotics software, and (2) an integrated runtime assurance (RTA) system that helps enable the use of uncertified components, while still providing safety guarantees. SOTER provides language primitives to declaratively construct a RTA module consisting of an advanced, high-performance controller (uncertified), a safe, lower-performance controller (certified), and the desired safety specification. The framework provides a formal guarantee that a well-formed RTA module always satisfies the safety specification, without completely sacrificing performance by using higher performance uncertified components whenever safe. SOTER allows the complex robotics software stack to be constructed as a composition of RTA modules, where each uncertified component is protected using a RTA module. To demonstrate the efficacy of our framework, we consider a real-world case-study of building a safe drone surveillance system. Our experiments both in simulation and on actual drones show that the SOTER-enabled RTA ensures the safety of the system, including when untrusted third-party components have bugs or deviate from the desired behavior.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1808.07921"
                    },
                    "abstract_zh": "最近在机器人领域实现更大的自主性和智能的驱动力导致了高度的复杂性。自主机器人越来越依赖第三方现成的组件和复杂的机器学习技术。这种趋势使得提供强有力的设计时正确操作认证变得非常困难。为了应对这些挑战，我们提出了SOTER，这是一个机器人编程框架，具有两个关键组件:(1)用于实现和测试高级反应式机器人软件的编程语言，以及(2)集成的运行时保证(RTA)系统，该系统有助于支持使用未经认证的组件，同时仍提供安全保证。SOTER提供语言原语来声明性地构建RTA模块，该模块由高级高性能控制器(未经认证)、安全低性能控制器(经过认证)和所需的安全规范组成。该框架提供了一个正式的保证，即一个结构良好的RTA模块总是满足安全规范，而不会通过在安全的情况下使用更高性能的未经认证的组件来完全牺牲性能。SOTER允许将复杂的机器人软件堆栈构建为RTA模块的组合，其中每个未经认证的组件都使用RTA模块进行保护。为了证明我们框架的有效性，我们考虑一个构建安全无人机监控系统的真实案例研究。我们在模拟和实际无人机上的实验表明，支持SOTER的RTA确保了系统的安全性，包括当不受信任的第三方组件出现错误或偏离预期行为时。",
                    "title_zh": "SOTER:安全机器人系统编程的运行时保证框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00028",
                    "title": "OneFile: A Wait-Free Persistent Transactional Memory",
                    "authors": "Pedro Ramalhete, Andreia Correia, Pascal Felber, Nachshon Cohen",
                    "abstract": "A persistent transactional memory (PTM) library provides an easy-to-use interface to programmers for using byte-addressable non-volatile memory (NVM). Previously proposed PTMs have, so far, been blocking. We present OneFile, the first wait-free PTM with integrated wait-free memory reclamation. We have designed and implemented two variants of the OneFile, one with lock-free progress and the other with bounded wait-free progress. We additionally present software transactional memory (STM) implementations of the lock-free and wait-free algorithms targeting volatile memory. Each of our PTMs and STMs is implemented as a single C++ file with ~1,000 lines of code, making them versatile to use. Equipped with these PTMs and STMs, non-expert developers can design and implement their own lock-free and wait-free data structures on NVM, thus making lock-free programming accessible to common software developers.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/7886745/files/OneFile-zenodo.pdf"
                    },
                    "abstract_zh": "持久事务内存(PTM)库为程序员使用字节可寻址非易失性内存(NVM)提供了易于使用的接口。到目前为止，以前提出的PTM一直是阻塞的。我们推出了OneFile，这是首款集成了无等待内存回收的无等待PTM。我们已经设计并实现了OneFile的两个变体，一个是无锁进程，另一个是有限制的无等待进程。此外，我们还介绍了针对易失性内存的无锁和无等待算法的软件事务内存(STM)实现。我们的每个PTM和STM都是作为一个C++文件实现的，包含大约1，000行代码，这使它们具有多种用途。有了这些PTM和STM，非专业开发人员可以在NVM上设计和实现他们自己的无锁和无等待数据结构，从而使普通软件开发人员也可以进行无锁编程。",
                    "title_zh": "一个文件:一个无等待的持久事务存储器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00029",
                    "title": "Sparkle: Speculative Deterministic Concurrency Control for Partially Replicated Transactional Stores",
                    "authors": "Zhongmiao Li, Paolo Romano, Peter Van Roy",
                    "abstract": "The last few decades have witnessed the unprecedented growth of large-scale online services. Distributed data storage systems, which are the fundamental building blocks of large-scale online services, are faced with a number of challenging, and often antagonistic, requirements. On the one hand, many distributed data storage systems have shifted away from weak consistency and embraced strong, transactional, semantics in order to tame the ever growing complexity of modern applications. On the other hand, the need for storing sheer amount of data and serving geo-dispersed clients with low latency has driven modern data storage systems to adopt partial replication techniques, often applied to geo-distributed infrastructures. Unfortunately, when employed in the geo-distributed and/or partial replicated settings, state of the art approaches to enforce transactional consistency suffer from severe bottlenecks that strongly hinder their efficiency. This dissertation investigates the use of speculative techniques to enhance performance of partially replicated transactional data stores, with a focus on geo-distributed platforms. With the term speculation, in this dissertation, we refer to the possibility of exposing the updates produced by uncommitted transactions to other transactions and/or to external clients in order to enhance performance. We apply speculation techniques to two fundamental approaches to develop replicated transactional data stores, namely Deferred Update Replication (DUR) and State Machine Replication (SMR). In DUR-based systems, transactions are firstly executed in a node and then propagated to other nodes for a global verification phase, during which pre-commit locks have to be held on data items updated by transactions. The global verification phase can throttle system throughput, especially when there is high conflict. We tackle this problem by introducing Speculative Transaction Replication (STR), a DUR protocol that exploits speculative reads to enhance performance of geo-distributed, partially replicated transactional data stores. The use of speculative reads greatly reduces the ‘effective duration’ of pre-commit locks, thus removing one of the key bottlenecks of DUR-based protocols. However, the indiscriminate use of speculative reads can expose applications to concurrency anomalies that can compromise their correctness in subtle ways. We tackle this issue by introducing Speculative Snapshot Isolation (SPSI), an extension of Snapshot Isolation (SI), which specifies desirable atomicity and isolation guarantees that must hold when using speculative processing techniques. In a nutshell, SPSI guarantees that, applications designed to operate using SI can safely execute atop STR, sheltering programmers from complex concurrency anomalies and source code modification. Our experimental study shows that STR, thanks to the use of speculative reads, yields up to 11× throughput improvements over state-of-the-art approaches that do not adopt speculative techniques. In SMR-based systems, transactions first undergo an ordering phase, then replicas have to guarantee that the result of transaction execution is equivalent to a serial execution according to the produced order from the ordering phase. To ensure this guarantee, existing approaches use a single-thread to execute or serialize transactions, which severely limits throughput especially given the current architectural trend towards massively parallel multi-core processors. This limitation is tackled through the introduction of SPARKLE. SPARKLE is an innovative deterministic concurrency control designed for Partially-Replicated State Machines (PRSMs). SPARKLE untaps the potential parallelism of modern multi-core systems through the use of speculative technique and by avoiding inherently non-scalable designs that rely on a single thread for either executing or scheduling transactions. The key contribution of SPARKLE is a set of techniques that can greatly minimize the frequency of misspeculations and the cost associated with correcting them. Our evaluation shows that SPARKLE achieves up to one order of magnitude throughput gains when compared to state of the art systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "过去几十年见证了大规模在线服务的空前增长。分布式数据存储系统是大规模在线服务的基本构件，它面临着许多挑战性的、通常是对抗性的需求。一方面，许多分布式数据存储系统已经从弱一致性转向强事务性语义，以便驯服现代应用程序不断增长的复杂性。另一方面，存储大量数据和以低延迟服务于地理上分散的客户端的需求已经驱使现代数据存储系统采用部分复制技术，通常应用于地理上分散的基础设施。不幸的是，当在地理分布的和/或部分复制的环境中使用时，实施事务一致性的现有技术方法遭受严重的瓶颈，这严重阻碍了它们的效率。本文研究了使用推测技术来提高部分复制事务数据存储的性能，重点是地理分布式平台。在本文中，推测一词指的是将未提交事务产生的更新暴露给其他事务和/或外部客户端以提高性能的可能性。我们将推测技术应用于开发复制事务数据存储的两种基本方法，即延迟更新复制(DUR)和状态机复制(SMR)。在基于DUR的系统中，事务首先在一个节点中执行，然后传播到其他节点进行全局验证，在此期间，必须对事务更新的数据项持有预提交锁。全局验证阶段可能会抑制系统吞吐量，尤其是当存在高冲突时。我们通过引入推测性事务复制(STR)来解决这个问题，STR是一种DUR协议，它利用推测性读取来增强地理分布的部分复制的事务性数据存储的性能。推测性读取的使用大大减少了预提交锁的“有效持续时间”，从而消除了基于DUR的协议的一个关键瓶颈。然而，不加选择地使用推测性读取会使应用程序暴露于并发异常，这可能会以微妙的方式损害它们的正确性。我们通过引入推测性快照隔离(SPSI)来解决这个问题，这是快照隔离(SI)的一个扩展，它指定了在使用推测性处理技术时必须保持的理想的原子性和隔离保证。简而言之，SPSI保证，设计为使用SI运行的应用程序可以安全地在STR上执行，保护程序员免受复杂的并发异常和源代码修改的影响。我们的实验研究表明，由于使用了推测性读取，STR的吞吐量比没有采用推测性技术的最先进方法提高了11倍。在基于SMR的系统中，事务首先经历一个排序阶段，然后副本必须保证事务执行的结果等同于根据排序阶段产生的顺序的串行执行。为了确保这种保证，现有的方法使用单线程来执行或序列化事务，这严重限制了吞吐量，尤其是在当前架构趋向于大规模并行多核处理器的情况下。这个限制是通过引入火花来解决的。SPARKLE是一种创新的确定性并发控制，专为部分复制状态机(PRSMs)设计。SPARKLE通过使用推测性技术以及避免依赖单线程执行或调度事务的固有不可扩展设计，挖掘了现代多核系统的潜在并行性。SPARKLE的主要贡献是一套技术，可以极大地减少错误推测的频率和与纠正它们相关的成本。我们的评估显示，与最先进的系统相比，SPARKLE实现了高达一个数量级的吞吐量增益。",
                    "title_zh": "Sparkle:部分复制事务存储的推测性确定性并发控制"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00030",
                    "title": "White-Box Atomic Multicast",
                    "authors": "Alexey Gotsman, Anatole Lefort, Gregory V. Chockler",
                    "abstract": "Atomic multicast is a communication primitive that delivers messages to multiple groups of processes according to some total order, with each group receiving the projection of the total order onto messages addressed to it. To be scalable, atomic multicast needs to be genuine, meaning that only the destination processes of a message should participate in ordering it. In this paper we propose a novel genuine atomic multicast protocol that in the absence of failures takes as low as 3 message delays to deliver a message when no other messages are multicast concurrently to its destination groups, and 5 message delays in the presence of concurrency. This improves the latencies of both the fault-tolerant version of classical Skeen's multicast protocol (6 or 12 message delays, depending on concurrency) and its recent improvement by Coelho et al. (4 or 8 message delays). To achieve such low latencies, we depart from the typical way of guaranteeing fault-tolerance by replicating each group with Paxos. Instead, we weave Paxos and Skeen's protocol together into a single coherent protocol, exploiting opportunities for white-box optimisations. We experimentally demonstrate that the superior theoretical characteristics of our protocol are reflected in practical performance pay-offs.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-03880004/file/multicast-dsn19.pdf"
                    },
                    "abstract_zh": "原子多播是一种通信原语，它根据某个总顺序将消息传递给多组进程，每组都接收总顺序在发往它的消息上的投影。为了具有可伸缩性，原子多播需要是真实的，这意味着只有消息的目的地进程应该参与对它的排序。在本文中，我们提出了一个新颖的真正的原子多播协议，在没有失败的情况下，当没有其他消息被并发地多播到它的目的地组时，只需要3个消息延迟来传递一个消息，而在存在并发的情况下，只需要5个消息延迟。这改善了经典Skeen多播协议的容错版本的延迟(6或12个消息延迟，取决于并发性)和Coelho等人最近的改进(4或8个消息延迟)。为了实现如此低的延迟，我们通过用Paxos复制每个组来偏离保证容错的典型方式。相反，我们将Paxos和Skeen的协议编织成一个单一的一致协议，利用白盒优化的机会。我们通过实验证明，我们的协议的优越的理论特性反映在实际的性能代价。",
                    "title_zh": "白盒原子多播"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00031",
                    "title": "Fault Tolerance Through Redundant Execution on COTS Multicores: Exploring Trade-Offs",
                    "authors": "Yanyan Shen, Gernot Heiser, Kevin Elphinstone",
                    "abstract": "High availability and integrity are paramount in systems deployed in life-and mission-critical scenarios. Such fault-tolerance can be achieved through redundant co-execution (RCoE) on replicated hardware, now cheaply available with multicore processors. RCoE replicates almost all software, including OS kernel, drivers, and applications, achieving a sphere of replication that covers everything except the minimal interfaces to non-replicated peripherals. We complement our original, loosely-coupled RCoE with a closely-coupled version that improves transparency of replication to application code, and investigate the functionality, performance and vulnerability trade-offs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在生命和任务关键场景中部署的系统中，高可用性和完整性至关重要。这种容错能力可以通过复制硬件上的冗余协同执行(RCoE)来实现，现在多核处理器可以廉价获得。RCoE复制几乎所有的软件，包括操作系统内核、驱动程序和应用程序，实现了一个覆盖所有内容的复制范围，除了到非复制外围设备的最小接口。我们用一个紧密耦合的版本来补充我们原来松散耦合的RCoE，该版本提高了应用程序代码复制的透明度，并研究了功能、性能和漏洞的权衡。",
                    "title_zh": "通过COTS多核上的冗余执行实现容错:探索折衷"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00032",
                    "title": "ParaMedic: Heterogeneous Parallel Error Correction",
                    "authors": "Sam Ainsworth, Timothy M. Jones",
                    "abstract": "Processor error detection can be reduced in cost significantly by exploiting the parallelism that exists in a repeated copy of an execution, which may not exist in the original code, to split up the redundant work on a large number of small, highly efficient cores. However, such schemes don't provide a method for automatic error recovery. We develop ParaMedic, an architecture to allow efficient automatic correction of errors detected in a system by using parallel heterogeneous cores, to provide a full fail-safe system that does not propagate errors to other systems, and can recover without manual intervention. This uses logging to roll back any computation that occurred after a detected error, along with a set of techniques to provide error-checking parallelism while still preventing the escape of incorrect processor values in multicore environments, where ordering of individual processors' logs is not enough to be able to roll back execution. Across a set of single and multi-threaded benchmarks, we achieve 3.1% and 1.5% overhead respectively, compared with 1.9% and 1% for error detection alone.",
                    "files": {
                        "openAccessPdf": "https://www.repository.cam.ac.uk/bitstream/1810/291240/2/dsn-accepted.pdf"
                    },
                    "abstract_zh": "通过利用执行的重复副本中存在的并行性(原始代码中可能不存在)，将冗余工作分解到大量小型高效内核上，可以显著降低处理器错误检测的成本。然而，这种方案没有提供自动错误恢复的方法。我们开发了一种架构，它允许通过使用并行异构内核有效地自动纠正系统中检测到的错误，以提供一个完整的故障安全系统，该系统不会将错误传播到其他系统，并且可以在没有手动干预的情况下进行恢复。这使用日志记录来回滚在检测到错误后发生的任何计算，以及一组技术来提供错误检查并行性，同时仍然防止多核环境中错误处理器值的逸出，在多核环境中，单个处理器日志的排序不足以回滚执行。在一组单线程和多线程基准测试中，我们分别实现了3.1%和1.5%的开销，而单独进行错误检测时，开销分别为1.9%和1%。",
                    "title_zh": "护理人员:异构并行纠错"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00033",
                    "title": "gem5-Approxilyzer: An Open-Source Tool for Application-Level Soft Error Analysis",
                    "authors": "Radha Venkatagiri, Khalique Ahmed, Abdulrahman Mahmoud, Sasa Misailovic, Darko Marinov, Christopher W. Fletcher, Sarita V. Adve",
                    "abstract": "Modern systems are increasingly susceptible to soft errors in the field and traditional redundancy-based mitigation techniques are too expensive to protect against all errors. Recent techniques, such as approximate computing and various low-cost resilience mechanisms, intelligently trade off inaccuracy in program output for better energy, performance, and resiliency overhead. A fundamental requirement for realizing the full potential of these techniques is a thorough understanding of how applications react to errors. Approxilyzer is a state-of-the-art tool that enables an accurate, efficient, and comprehensive analysis of how errors in almost all dynamic instructions in a program's execution affect the quality of the final program output. While useful, its adoption is limited by its implementation using the proprietary Simics infrastructure and the SPARC ISA. We present gem5-Approxilyzer, a re-implementation of Approxilyzer using the open-source gem5 simulator. gem5-Approxilyzer can be extended to different ISAs, starting with x86 in this work. We show that gem5-Approxilyzer is both efficient (up to two orders of magnitude reduction in error injections over a naive campaign) and accurate (average 92% for our experiments) in predicting the program's output quality in the presence of errors. We also compare the error profiles of five workloads under x86 and SPARC to further motivate the need for a tool like gem5-Approxilyzer.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代系统越来越容易受到现场软错误的影响，传统的基于冗余的缓解技术过于昂贵，无法防范所有错误。最近的技术，如近似计算和各种低成本弹性机制，智能地权衡程序输出中的不准确性，以获得更好的能量、性能和弹性开销。实现这些技术的全部潜力的一个基本要求是彻底理解应用程序如何对错误做出反应。Approxilyzer是一个最先进的工具，它能够准确、高效和全面地分析程序执行中几乎所有动态指令中的错误如何影响最终程序输出的质量。虽然有用，但它的采用受到使用专有Simics基础设施和SPARC ISA的实现的限制。我们介绍了gem5-approxiliyzer，它是使用开源gem 5模拟器对approxiliyzer的重新实现。ge M5-approxiliyzer可以扩展到不同的isa，本文从x86开始。我们证明了在存在错误的情况下，在预测程序的输出质量方面，ge M5-approxiliyzer是高效的(在简单的活动中，错误注入减少了两个数量级)和准确的(在我们的实验中平均为92%)。我们还比较了x86和SPARC下五个工作负载的错误概况，以进一步激发对gem5-Approxilyzer等工具的需求。",
                    "title_zh": "gem 5-approxiliyzer:一个用于应用级软错误分析的开源工具"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00034",
                    "title": "Your IoTs Are (Not) Mine: On the Remote Binding Between IoT Devices and Users",
                    "authors": "Jiongyi Chen, Chaoshun Zuo, Wenrui Diao, Shuaike Dong, Qingchuan Zhao, Menghan Sun, Zhiqiang Lin, Yinqian Zhang, Kehuan Zhang",
                    "abstract": "Nowadays, IoT clouds are increasingly deployed to facilitate users to manage and control their IoT devices. Unlike the traditional cloud services with communication between a client and a server, IoT cloud architectures involve three parties: the IoT device, the user, and the cloud. Before a user can remotely access her IoT device, remote communication between them is bootstrapped through the cloud. However, the security implications of such a unique process in IoT are less understood today. In this paper, we report the first step towards systematic analyses of IoT remote binding. To better understand the problem, we describe the life cycle of remote binding with a state-machine model which helps us demystify the complexity in various designs and systematically explore the attack surfaces. With the evaluation of 10 real-world remote binding solutions, our study brings to light questionable practices in the designs of authentication and authorization, including inappropriate use of device IDs, weak device authentication, and weak cloud-side access control, as well as the impact of the discovered problems, which could cause sensitive user data leak, persistent denial-ofservice, connection disruption, and even stealthy device control.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，物联网云越来越多地被部署来方便用户管理和控制他们的物联网设备。与客户端和服务器之间通信的传统云服务不同，物联网云架构涉及三方:物联网设备、用户和云。在用户可以远程访问她的物联网设备之前，他们之间的远程通信是通过云引导的。然而，物联网中这种独特过程的安全含义如今却鲜为人知。在本文中，我们报告了系统分析物联网远程绑定的第一步。为了更好地理解这个问题，我们用一个状态机模型来描述远程绑定的生命周期，这有助于我们揭开各种设计中的复杂性，并系统地探索攻击面。通过对10个真实世界远程绑定解决方案的评估，我们的研究揭示了身份验证和授权设计中的可疑做法，包括设备id的不当使用、薄弱的设备身份验证和薄弱的云端访问控制，以及所发现问题的影响，这些问题可能导致敏感用户数据泄漏、持续拒绝服务、连接中断，甚至隐形设备控制。",
                    "title_zh": "你的物联网(不是)我的:物联网设备与用户的远程绑定"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00035",
                    "title": "BenchIoT: A Security Benchmark for the Internet of Things",
                    "authors": "Naif Saleh Almakhdhub, Abraham A. Clements, Mathias Payer, Saurabh Bagchi",
                    "abstract": "Attacks against IoT systems are increasing at an alarming pace. Many IoT systems are and will be built using low-cost micro-controllers (IoT-uCs). Different security mechanisms have been proposed for IoT-uCs with different trade-offs. To guarantee a realistic and practical evaluation, the constrained resources of IoT-uCs require that defenses must be evaluated with respect to not only security, but performance, memory, and energy as well. Evaluating security mechanisms for IoT-uCs is limited by the lack of realistic benchmarks and evaluation frameworks. This burdens researchers with the task of developing not only the proposed defenses but applications on which to evaluate them. As a result, security evaluation for IoT-uCs is limited and ad-hoc. A sound benchmarking suite is essential to enable robust and comparable evaluations of security techniques on IoT-uCs. This paper introduces BenchIoT, a benchmark suite and evaluation framework to address pressing challenges and limitations for evaluating IoT-uCs security. The evaluation framework enables automatic evaluation of 14 metrics covering security, performance, memory usage, and energy consumption. The BenchIoT benchmarks provide a curated set of five real-world IoT applications that cover both IoT-uCs with and without an OS. We demonstrate BenchIoT's ability by evaluating three defense mechanisms. All benchmarks and the evaluation framework is open sourced and available to the research community.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "针对物联网系统的攻击正以惊人的速度增加。许多物联网系统正在并将使用低成本微控制器(IoT-uCs)构建。针对物联网统一通信系统，已经提出了不同的安全机制，具有不同的权衡。为了保证评估的现实性和实用性，物联网统一通信系统的有限资源要求防御系统不仅要考虑安全性，还要考虑性能、内存和能源。评估物联网统一通信系统的安全机制受到缺乏现实基准和评估框架的限制。这使得研究人员不仅要开发拟议的防御措施，还要开发评估这些措施的应用程序。因此，物联网统一通信系统的安全评估是有限的和临时的。一套完善的基准测试套件对于在物联网统一通信系统上对安全技术进行可靠和可比的评估至关重要。本文介绍BenchIoT，这是一个基准测试套件和评估框架，旨在解决评估IoT-uCs安全性的紧迫挑战和限制。该评估框架支持自动评估涵盖安全性、性能、内存使用和能耗的14项指标。BenchIoT基准测试提供了五个真实世界的物联网应用，涵盖了有操作系统和无操作系统的物联网-统一通信系统。我们通过评估三种防御机制来展示BenchIoT的能力。所有基准和评估框架都是开源的，可供研究社区使用。",
                    "title_zh": "BenchIoT:物联网安全基准"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00036",
                    "title": "Exploiting Memory Corruption Vulnerabilities in Connman for IoT Devices",
                    "authors": "K. Virgil English, Islam Obaidat, Meera Sridhar",
                    "abstract": "In the recent past, there has been a rapid increase in attacks on consumer Internet-of-Things (IoT) devices. Several attacks currently focus on easy targets for exploitation, such as weak configurations (weak default passwords). However, with governments, industries, and organizations proposing new laws and regulations to reduce and prevent such easy targets in the IoT space, attackers will move to more subtle exploits in these devices. Memory corruption vulnerabilities are a significant class of vulnerabilities in software security through which attackers can gain control of the entire system. Numerous memory corruption vulnerabilities have been found in IoT firmware already deployed in the consumer market. This paper presents an approach for exploiting stack-based buffer-overflow attacks in IoT firmware, to hijack the device remotely. To show the feasibility of this approach, we demonstrate exploiting a common network software application, Connman, used widely in IoT firmware such as Samsung smart TVs. A series of experiments are reported on, including: crashing and executing arbitrary code in the targeted software application in a controlled environment, adopting the attacks in uncontrolled environments (with standard software defenses such as W⊕X and ASLR enabled), and installing publicly available IoT firmware that uses this software application on a Raspberry Pi. The presented exploits demonstrate the ease in which an adversary can control IoT devices.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近，针对消费者物联网(IoT)设备的攻击迅速增加。目前有几种攻击集中在容易被利用的目标上，例如弱配置(弱默认密码)。然而，随着政府、行业和组织提出新的法律法规来减少和防止物联网领域中如此容易的目标，攻击者将转向更微妙的利用这些设备。内存损坏漏洞是软件安全中的一类重要漏洞，攻击者可以通过它控制整个系统。已经在消费市场部署的物联网固件中发现了大量内存损坏漏洞。提出了一种利用物联网固件中基于堆栈的缓冲区溢出攻击来远程劫持设备的方法。为了展示这种方法的可行性，我们展示了开发一种常见的网络软件应用程序Connman，该应用程序广泛用于三星智能电视等物联网固件中。报告了一系列实验，包括:在受控环境中崩溃和执行目标软件应用程序中的任意代码，在非受控环境中采用攻击(启用W⊕X和ASLR等标准软件防御)，以及在Raspberry Pi上安装使用该软件应用程序的公共可用物联网固件。所展示的漏洞展示了对手可以轻松控制物联网设备。",
                    "title_zh": "利用物联网设备Connman中的内存损坏漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00037",
                    "title": "Rigorous, Effortless and Timely Assessment of Cellular Network Changes",
                    "authors": "Ajay Mahimkar, Zihui Ge, Sanjeev Ahuja, Shomik Pathak, Nauman Shafi",
                    "abstract": "Cellular service providers continuously deploy changes in their network in the form of new software releases, service feature introductions, configuration changes, equipment re-homes, firmware upgrades, and topology modifications. It is important to carefully assess the impact of these changes on service performance to validate expected behaviors and take mitigation actions in a timely fashion in case of any unexpected degradation. The diverse nature of the network changes, complex interactions across different layers of the cellular network, and the rapid evolution of the network make it challenging to accurately conduct the assessment. In this paper, we present the design and implementation of our system that enables rigorous, effortless and timely assessment of performance around network changes. We share our lessons learned from the deployment in an operational cellular network over the last eight years.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "蜂窝服务提供商以新软件发布、服务功能引入、配置变更、设备重置、固件升级和拓扑修改的形式不断地在他们的网络中部署变更。重要的是要仔细评估这些变化对服务性能的影响，以验证预期的行为，并在出现任何意外降级时及时采取缓解措施。网络变化的多样性、蜂窝网络不同层之间的复杂交互以及网络的快速发展使得准确进行评估变得非常困难。在本文中，我们介绍了我们的系统的设计和实现，该系统能够对网络变化进行严格、轻松和及时的性能评估。我们分享了过去八年来在运营蜂窝网络中的部署经验。",
                    "title_zh": "对蜂窝网络变化进行严格、轻松和及时的评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00038",
                    "title": "An Eventually Perfect Failure Detector for Networks of Arbitrary Topology Connected with ADD Channels Using Time-To-Live Values",
                    "authors": "Karla Vargas, Sergio Rajsbaum",
                    "abstract": "We present an implementation of an eventually perfect failure detector in an arbitrarily connected, partitionable network. We assume ADD channels: for each one there exist constants K, D, not known to the processes, such that for every K consecutive messages sent in one direction, at least one is delivered within time D. The best previous implementation used messages of bounded size, but exponential in n, the number of nodes. The main contribution of this paper is a novel use of time-to-live values in the design of failure detectors, obtaining a flexible implementation that uses messages of size O(n log n)",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了一个在任意连接、可划分网络中的最终完美故障检测器的实现。我们假设添加信道:对于每一个信道，存在进程未知的常数K，D，使得对于在一个方向上发送的每K个连续消息，至少一个在时间D内被传递。本文的主要贡献是在故障检测器的设计中新颖地使用了生存时间值，获得了使用大小为O(n log n)的消息的灵活实现",
                    "title_zh": "一种最终完美的故障检测器，适用于使用生存时间值的添加通道连接的任意拓扑网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00039",
                    "title": "Bonsai: Efficient Fast Failover Routing Using Small Arborescences",
                    "authors": "Klaus-Tycho Foerster, Andrzej Kamisinski, Yvonne-Anne Pignolet, Stefan Schmid, Gilles Trédan",
                    "abstract": "To provide high availability despite link failures, many modern communication networks feature fast failover mechanisms in the data plane, which operates orders of magnitude faster than the control plane. While the configuration of highly resilient data planes is known to be a difficult combinatorial problem, over the last years, much progress has been made in the design of algorithms which provably guarantee connectivity even under many concurrent link failures. However, while these algorithms provide connectivity, the resulting routes after failures can be very long, which in turn can harm performance. In this paper, we propose, analyze, and evaluate methods for fast failover algorithms which account for the quality of the routes after failures, in addition to connectivity. In particular, we revisit the existing approach to cover the to-be-protected network with arc-disjoint spanning arborescences to define alternative routes to the destination, aiming to keep the stretch imposed by these trees low (hence the name of our method: Bonsai). We show that the underlying problem is NP-hard on general topologies and present lower bound results that are tight for various topologies, for any class of fast failover algorithms. We also present heuristics for general networks and demonstrate their performance benefits in extensive simulations. Finally, we show that failover algorithms using low-stretch arborescences, as a side effect, can provide connectivity under more general failure models than usually considered in the literature.",
                    "files": {
                        "openAccessPdf": "https://hal.laas.fr/hal-03049100/file/dsn2019.pdf"
                    },
                    "abstract_zh": "为了在链路故障的情况下提供高可用性，许多现代通信网络在数据平面中采用快速故障转移机制，其运行速度比控制平面快几个数量级。虽然已知高弹性数据平面的配置是一个困难的组合问题，但在过去几年中，在算法设计方面已经取得了很大进展，这些算法甚至在许多并发链路故障的情况下也能保证连通性。然而，虽然这些算法提供了连接性，但是故障后产生的路由可能会非常长，这反过来会损害性能。在本文中，我们提出、分析和评估了快速故障转移算法的方法，这些算法除了考虑连通性之外，还考虑了故障后的路由质量。特别是，我们重新审视了现有的方法，用弧不相交的生成树状结构覆盖要保护的网络，以定义到达目的地的替代路径，旨在保持这些树施加的伸展较低(因此我们的方法的名称为Bonsai)。我们证明了基本问题在一般拓扑结构上是NP-hard的，并且给出了对于各种拓扑结构、对于任何类别的快速故障转移算法都是严格的下界结果。我们还提出了一般网络的启发式算法，并在广泛的模拟中展示了它们的性能优势。最后，我们表明，作为副作用，使用低伸展树状结构的故障转移算法可以在比文献中通常考虑的更一般的故障模型下提供连接。",
                    "title_zh": "Bonsai:使用小型树状结构的高效快速故障转移路由"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00040",
                    "title": "SATIN: A Secure and Trustworthy Asynchronous Introspection on Multi-Core ARM Processors",
                    "authors": "Shengye Wan, Jianhua Sun, Kun Sun, Ning Zhang, Qi Li",
                    "abstract": "On ARM processors with TrustZone security extension, asynchronous introspection mechanisms have been developed in the secure world to detect security policy violations in the normal world. These mechanisms provide security protection via passively checking the normal world snapshot. However, since previous secure world checking solutions require to suspend the entire rich OS, asynchronous introspection has not been widely adopted in the real world. Given a multi-core ARM system that can execute the two worlds simultaneously on different cores, secure world introspection can check the rich OS without suspension. However, we identify a new normal-world evasion attack that can defeat the asynchronous introspection by removing the attacking traces in parallel from one core when the security checking is performing on another core. We perform a systematic study on this attack and present its efficiency against existing asynchronous introspection mechanisms. As the countermeasure, we propose a secure and trustworthy asynchronous introspection mechanism called SATIN, which can efficiently detect the evasion attacks by increasing the attackers' evasion time cost and decreasing the defender's execution time under a safe limit. We implement a prototype on an ARM development board and the experimental results show that SATIN can effectively prevent evasion attacks on multi-core systems with a minor system overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在具有TrustZone安全扩展的ARM处理器上，安全领域已经开发了异步自省机制来检测正常领域中的安全策略违规。这些机制通过被动检查正常世界快照来提供安全保护。然而，由于以前的安全世界检查解决方案需要暂停整个富操作系统，异步自省在现实世界中还没有被广泛采用。给定一个可以在不同内核上同时执行两个世界的多核ARM系统，安全世界自省可以在不暂停的情况下检查丰富的操作系统。然而，我们发现了一种新的正常世界规避攻击，当安全检查在另一个核心上执行时，它可以通过从一个核心并行删除攻击痕迹来击败异步自省。我们对这种攻击进行了系统的研究，并针对现有的异步自省机制展示了它的效率。作为对策，我们提出了一种安全可信的异步自省机制SATIN，通过增加攻击者的规避时间成本和在安全范围内减少防御者的执行时间，可以有效地检测规避攻击。我们在ARM开发板上实现了一个原型系统，实验结果表明SATIN可以有效地防止对多核系统的规避攻击，并且系统开销较小。",
                    "title_zh": "SATIN:多核ARM处理器上安全可信的异步自检"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00041",
                    "title": "DeviceVeil: Robust Authentication for Individual USB Devices Using Physical Unclonable Functions",
                    "authors": "Kuniyasu Suzaki, Yohei Hori, Kazukuni Kobara, Mohammad Mannan",
                    "abstract": "The Universal Serial Bus (USB) supports a diverse and wide-ranging set of device types. To enable ease of use, USB devices are automatically detected and classified by common operating systems, without any authentication. This trust-by-default design principle can be easily exploited, and led to numerous attacks in the past (e.g., Stuxnet, BadUSB, BadAndroid), specifically targeting high-value organizations. Administrators' efforts to prevent these attacks may also be threatened by unscrupulous users who may insert any USB device, or malicious users (inside attackers) who may try to circumvent OS/kernel-enforced protection mechanisms (e.g., via OS replacement). The root causes of USB attacks appear to be the lack of robust authentication of individual USB devices and inadequate tamper-proofing of the solution mechanism itself. We propose DeviceVeil to address these limitations. To authenticate individual USB devices, we utilize the tamper-proof feature of Physical Unclonable Functions (PUFs); PUFs extract unique features from physical characteristics of an integrated circuit (IC) at a reasonable cost (less than 1 USD). To make our authentication mechanism robust, we implement it as a small hypervisor, and protect it by a novel combination of security technologies available in commodity PCs, e.g., Trusted Platform Module (TPM), customized secure boot, and virtualization support. The OS disk image with all user data is encrypted by a key sealed in TPM and can be decrypted by the hypervisor only. Customized secure boot allows the loading of the legitimate hypervisor and OS kernel only. The hypervisor enables pre-OS authentication to protect the trust-by-default OS from USB attacks. The chain of trust continues from power-on to the insertion of a USB device and disallows all illegitimate USB devices. DeviceVeil's PUF authentication takes about 1.7 seconds during device insertion.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通用串行总线(USB)支持多种多样的设备类型。为了便于使用，通用操作系统会自动检测USB设备并对其进行分类，无需任何身份验证。这种默认信任的设计原则很容易被利用，并在过去导致了许多专门针对高价值组织的攻击(例如，Stuxnet、BadUSB、BadAndroid)。管理员防止这些攻击的努力也可能受到可能插入任何USB设备的不道德用户或可能试图规避操作系统/内核强制保护机制(例如，通过操作系统替换)的恶意用户(内部攻击者)的威胁。USB攻击的根本原因似乎是缺乏对单个USB设备的可靠认证，以及解决方案机制本身的防篡改能力不足。我们提出DeviceVeil来解决这些限制。为了认证单个USB设备，我们利用物理不可克隆功能(puf)的防篡改特性；puf以合理的成本(低于1美元)从集成电路(IC)的物理特性中提取独特的特征。为了使我们的身份验证机制更加强大，我们将其作为一个小型虚拟机管理程序来实施，并通过商用电脑中可用的安全技术的新颖组合来保护它，例如可信平台模块(TPM)、定制安全引导和虚拟化支持。包含所有用户数据的操作系统磁盘映像由密封在TPM中的密钥加密，并且只能由虚拟机管理程序解密。定制的安全引导只允许加载合法的虚拟机管理程序和操作系统内核。虚拟机管理程序支持预操作系统身份验证，以保护默认信任的操作系统免受USB攻击。信任链从通电开始一直延续到插入USB设备，并且不允许所有非法的USB设备。DeviceVeil的PUF认证在设备插入期间需要大约1.7秒。",
                    "title_zh": "DeviceVeil:使用物理不可克隆功能对单个USB设备进行可靠的认证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00042",
                    "title": "Multilayer ROP Protection Via Microarchitectural Units Available in Commodity Hardware",
                    "authors": "Mateus Tymburibá, Hugo Sousa, Fernando Magno Quintão Pereira",
                    "abstract": "This paper presents a multilayer protection approach to guard programs against Return-Oriented Programming (ROP) attacks. Upper layers validate most of a program's control flow at a low computational cost; thus, not compromising runtime. Lower layers provide strong enforcement guarantees to handle more suspicious flows; thus, enhancing security. Our multilayer system combines techniques already described in the literature with verifications that we introduce in this paper. We argue that modern versions of x86 processors already provide the microarchitectural units necessary to implement our technique. We demonstrate the effectiveness of our multilayer protection on a extensive suite of benchmarks, which includes: SPEC CPU2006; the three most popular web browsers; 209 benchmarks distributed with LLVM and four well-known systems shown to be vulnerable to ROP exploits. Our experiments indicate that we can protect programs with almost no overhead in practice, allying the good performance of lightweight security techniques with the high dependability of heavyweight approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "提出了一种多层保护方法来保护程序免受面向返回编程(ROP)的攻击。上层以较低的计算成本验证程序的大部分控制流；因此，不会影响运行时间。较低层提供强有力的执行保证来处理更多的可疑流；从而增强安全性。我们的多层系统结合了文献中已经描述的技术和我们在本文中介绍的验证。我们认为现代版本的x86处理器已经提供了实现我们的技术所必需的微体系结构单元。我们在一系列广泛的基准测试中展示了我们的多层保护的有效性，包括:SPEC CPU2006三种最流行的网络浏览器；与LLVM和四个著名系统一起分发的209个基准测试表明易受ROP攻击。我们的实验表明，通过将轻量级安全技术的良好性能与重量级方法的高可靠性结合起来，我们可以在实践中几乎没有开销的情况下保护程序。",
                    "title_zh": "通过商用硬件中可用的微体系结构单元提供多层ROP保护"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00043",
                    "title": "Deploying Intrusion-Tolerant SCADA for the Power Grid",
                    "authors": "Amy Babay, John L. Schultz, Thomas Tantillo, Samuel Beckley, Eamon Jordan, Kevin Ruddell, Kevin Jordan, Yair Amir",
                    "abstract": "While there has been considerable research on making power grid Supervisory Control and Data Acquisition (SCADA) systems resilient to attacks, the problem of transitioning these technologies into deployed SCADA systems remains largely unaddressed. We describe our experience and lessons learned in deploying an intrusion-tolerant SCADA system in two realistic environments: a red team experiment in 2017 and a power plant test deployment in 2018. These experiences resulted in technical lessons related to developing an intrusion-tolerant system with a real deployable application, preparing a system for deployment in a hostile environment, and supporting protocol assumptions in that hostile environment. We also discuss some meta-lessons regarding the cultural aspects of transitioning academic research into practice in the power industry.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然在使电网监控和数据采集(SCADA)系统对攻击具有弹性方面已经有了相当多的研究，但是将这些技术转变成已部署的SCADA系统的问题在很大程度上仍然没有解决。我们描述了我们在两个现实环境中部署入侵容忍SCADA系统的经验和教训:2017年的红队实验和2018年的电厂测试部署。这些经验带来了与开发具有真正可部署应用程序的入侵容忍系统、准备在敌对环境中部署系统以及在该敌对环境中支持协议假设相关的技术教训。我们还讨论了一些关于在电力行业将学术研究转化为实践的文化方面的元课程。",
                    "title_zh": "为电网部署可容忍入侵的SCADA"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00044",
                    "title": "Reaching Data Confidentiality and Model Accountability on the CalTrain",
                    "authors": "Zhongshu Gu, Hani Jamjoom, Dong Su, Heqing Huang, Jialong Zhang, Tengfei Ma, Dimitrios Pendarakis, Ian M. Molloy",
                    "abstract": "Distributed collaborative learning (DCL) paradigms enable building joint machine learning models from distrusted multi-party participants. Data confidentiality is guaranteed by retaining private training data on each participant's local infrastructure. However, this approach makes today's DCL design fundamentally vulnerable to data poisoning and backdoor attacks. It limits DCL's model accountability, which is key to backtracking problematic training data instances and their responsible contributors. In this paper, we introduce CALTRAIN, a centralized collaborative learning system that simultaneously achieves data confidentiality and model accountability. CALTRAIN enforces isolated computation via secure enclaves on centrally aggregated training data to guarantee data confidentiality. To support building accountable learning models, we securely maintain the links between training instances and their contributors. Our evaluation shows that the models generated by CALTRAIN can achieve the same prediction accuracy when compared to the models trained in non-protected environments. We also demonstrate that when malicious training participants tend to implant backdoors during model training, CALTRAIN can accurately and precisely discover the poisoned or mislabeled training data that lead to the runtime mispredictions.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1812.03230"
                    },
                    "abstract_zh": "分布式协作学习(DCL)范例能够从不信任的多方参与者构建联合机器学习模型。通过在每个参与者的本地基础设施上保留私人培训数据来保证数据的机密性。然而，这种方法使得今天的DCL设计在根本上容易受到数据中毒和后门攻击。它限制了DCL的模型责任，而模型责任是回溯有问题的训练数据实例及其负责贡献者的关键。在本文中，我们介绍了CALTRAIN，这是一个集中式的协作学习系统，它同时实现了数据保密性和模型责任性。CALTRAIN通过集中汇总的培训数据上的安全飞地实施隔离计算，以保证数据机密性。为了支持建立负责任的学习模型，我们安全地维护培训实例及其参与者之间的联系。我们的评估表明，与在非保护环境中训练的模型相比，由CALTRAIN生成的模型可以实现相同的预测精度。我们还证明，当恶意训练参与者倾向于在模型训练期间植入后门时，CALTRAIN可以准确地发现导致运行时错误预测的中毒或错误标记的训练数据。",
                    "title_zh": "在CalTrain上实现数据保密和模型问责"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00045",
                    "title": "Tell Me More Than Just Assembly! Reversing Cyber-Physical Execution Semantics of Embedded IoT Controller Software Binaries",
                    "authors": "Pengfei Sun, Luis Garcia, Saman A. Zonouz",
                    "abstract": "The safety of critical cyber-physical IoT devices hinges on the security of their embedded software that implements control algorithms for monitoring and control of the associated physical processes, e.g., robotics and drones. Reverse engineering of the corresponding embedded controller software binaries enables their security analysis by extracting high-level, domain-specific, and cyber-physical execution semantic information from executables. We present MISMO, a domain-specific reverse engineering framework for embedded binary code in emerging cyber-physical IoT control application domains. The reverse engineering outcomes can be used for firmware vulnerability assessment, memory forensics analysis, targeted memory data attacks, or binary patching for dynamic selective memory protection (e.g., important control algorithm parameters). MISMO performs semantic-matching at an algorithmic level that can help with the understanding of any possible cyber-physical security flaws. MISMO compares low-level binary symbolic values and high-level algorithmic expressions to extract domain-specific semantic information for the binary's code and data. MISMO enables a finer-grained understanding of the controller by identifying the specific control and state estimation algorithms used. We evaluated MISMO on 2,263 popular firmware binaries by 30 commercial vendors from 6 application domains including drones, self-driving cars, smart homes, robotics, 3D printers, and the Linux kernel controllers. The results show that MISMO can accurately extract the algorithm-level semantics of the embedded binary code and data regions. We discovered a zero-day vulnerability in the Linux kernel controllers versions 3.13 and above.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "关键的网络物理物联网设备的安全性取决于其嵌入式软件的安全性，该软件实施控制算法来监控和控制相关的物理过程，例如机器人和无人机。相应嵌入式控制器软件二进制文件的逆向工程通过从可执行文件中提取高级、特定领域和网络物理执行语义信息来支持其安全性分析。我们提出了MISMO，这是一个针对新兴信息物理物联网控制应用领域的嵌入式二进制代码的特定领域逆向工程框架。逆向工程结果可用于固件脆弱性评估、存储器取证分析、有针对性的存储器数据攻击或用于动态选择性存储器保护的二进制修补(例如，重要的控制算法参数)。MISMO在算法层面执行语义匹配，这有助于理解任何可能的网络物理安全缺陷。MISMO比较低级二进制符号值和高级算法表达式，以提取二进制代码和数据的特定于领域的语义信息。MISMO通过识别所使用的特定控制和状态估计算法，能够更好地理解控制器。我们在来自6个应用领域的30家商业供应商的2，263个流行的固件二进制文件上评估了MISMO，包括无人机、自动驾驶汽车、智能家居、机器人、3D打印机和Linux内核控制器。结果表明，MISMO能够准确提取嵌入式二进制代码和数据区域的算法级语义。我们在Linux内核控制器版本3.13及更高版本中发现了一个零日漏洞。",
                    "title_zh": "告诉我不仅仅是组装！逆转嵌入式物联网控制器软件二进制文件的信息物理执行语义"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00046",
                    "title": "Exploiting Latency and Error Tolerance of GPGPU Applications for an Energy-Efficient DRAM",
                    "authors": "Haonan Wang, Adwait Jog",
                    "abstract": "Memory (DRAM) energy consumption is one of the major scalability bottlenecks for almost all computing systems, including throughput machines such as Graphics Processing Units (GPUs). A large fraction of DRAM dynamic energy is spent on fetching the data bits from a DRAM page (row) to a small-sized hardware structure called as the row buffer. The data access from this row buffer is much less expensive in terms of energy and latency. Hence, it is preferred to reuse the buffered data as much as possible before activating another row and bringing its data to these row buffers. Our thorough characterization of several GPGPU applications shows that these row buffers are poorly utilized leading to sub-optimal energy consumption. To address this, we propose a novel memory scheduling for GPUs that exploits latency and error tolerance properties of GPGPU applications to reduce row energy by 44% on average.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内存(DRAM)能耗是几乎所有计算系统的主要可扩展性瓶颈之一，包括图形处理单元(GPU)等吞吐机器。DRAM动态能量的很大一部分花费在从DRAM页面(行)获取数据位到称为行缓冲器的小型硬件结构上。从这个行缓冲器的数据访问在能量和延迟方面要便宜得多。因此，在激活另一行并将其数据带到这些行缓冲器之前，最好尽可能多地重用缓冲的数据。我们对几个GPGPU应用程序的彻底表征表明，这些行缓冲区未得到充分利用，导致了次优的能耗。为了解决这一问题，我们提出了一种新的GPU内存调度方法，该方法利用GPGPU应用程序的延迟和容错属性，平均减少44%的行能量。",
                    "title_zh": "利用GPGPU应用的延迟和容错性实现高能效DRAM"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00047",
                    "title": "Leveraging Transverse Reads to Correct Alignment Faults in Domain Wall Memories",
                    "authors": "Sébastien Ollivier, Donald Kline Jr., Kawsher A. Roxy, Rami G. Melhem, Sanjukta Bhanja, Alex K. Jones",
                    "abstract": "Spintronic domain wall memories (DWMs) are prone to alignment faults, which cannot be protected by traditional error correction techniques. To solve this problem, we propose a new technique called derived error correction coding (DECC). We construct metadata from the data and shift state of the DWM, on demand, using a novel transverse read (TR). TR reads in an orthogonal direction to the DWM access point and can determine the number of ones in a DWM. Errors in the metadata correspond to shift-faults in the DWM. Rather than storing the metadata, it is created on-demand and protected by storing parity bits. Repairing the metadata with ECC allows restoration of DWM alignment and ensures correct operation. Through these techniques, our shift-aware error correction approaches provide a lifetime of over 15 years with a similar performance, while reducing area and energy by 370% and 52%, versus the state-of-the-art, for a 32-bit nanowire.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自旋电子畴壁存储器(dwm)容易出现对准错误，这是传统纠错技术所不能保护的。为了解决这个问题，我们提出了一种新技术，称为派生纠错编码(DECC)。我们从数据中构造元数据，并使用一种新颖的横向读取(TR)按需转换DWM的状态。TR在与DWM接入点正交的方向上读取，并可以确定DWM中1的数量。元数据中的错误对应于DWM中的移位故障。它不是存储元数据，而是按需创建并通过存储奇偶校验位来保护。使用ECC修复元数据允许恢复DWM对齐并确保正确操作。通过这些技术，我们的移位感知纠错方法提供了超过15年的寿命和类似的性能，同时与最先进的32位纳米线相比，面积和能耗分别减少了370%和52%。",
                    "title_zh": "利用横向读取来校正畴壁存储器中的对准错误"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00048",
                    "title": "SuDoku: Tolerating High-Rate of Transient Failures for Enabling Scalable STTRAM",
                    "authors": "Prashant J. Nair, Bahar Asgari, Moinuddin K. Qureshi",
                    "abstract": "Conventionally, systems have relied on technology scaling to provide smaller cells, which helps in increasing the capacity of on-chip and off-chip structures. Unfortunately, scaling technology to smaller nodes causes increased susceptibility to faults. We study the problem of efficiently tolerating transient failures using scalable Spin-Transfer Torque RAM (STTRAM) as an example. At smaller feature sizes, the energy required to flip a STTRAM cell reduces, which makes these cells more susceptible to random failures caused by thermal noise. Such failures can be tolerated by periodic scrubbing and provisioning each line with Error Correction Code (ECC). However, to tolerate the desired bit-error-rate, the cache needs ECC-6 (six bit error correction) per line, incurring impractical storage overheads. Ideally, we want to tolerate these faults without relying on multi-bit ECC. We propose SuDoku, a design that provisions each line with ECC-1 and a strong error detection code, and relies on a region-based RAID-4 to perform correction of multi-bit errors. Unfortunately, simply having such a RAID-4 based architecture is ineffective at tolerating a high-rate of transient faults and provides an MTTF in the order of only a few seconds. We describe a novel data resurrection scheme that can repair multiple faulty lines in a RAID-4 region to increase the MTTF to several hours. We propose an extension of SuDoku, which hashes a given line into two regions of RAID-4 to significantly enhance reliability and increase the MTTF to trillions of hours. Our evaluations show that SuDoku provides 874x higher reliability than ECC-6, incurs 30% less storage than ECC-6, and performs within 0.1% of an ideal fault-free baseline.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传统上，系统依赖于技术缩放来提供更小的单元，这有助于增加片上和片外结构的容量。不幸的是，将技术扩展到更小的节点会增加出错的可能性。我们以可扩展自旋转移矩RAM (STTRAM)为例，研究了有效容忍瞬时故障的问题。在较小的特征尺寸下，翻转STTRAM单元所需的能量减少，这使得这些单元更容易受到由热噪声引起的随机故障的影响。通过定期清理和为每条线路提供纠错码(ECC ),可以容忍这种故障。然而，为了容忍期望的误码率，高速缓存需要每行ECC-6(六位纠错),导致不切实际的存储开销。理想情况下，我们希望在不依赖多位ECC的情况下容忍这些故障。我们提出了SuDoku，这是一种为每一行提供ECC-1和强大的错误检测代码的设计，并依靠基于区域的RAID-4来执行多位错误的纠正。不幸的是，简单地拥有这样的基于RAID-4的架构在容忍高速率的瞬时故障方面是无效的，并且仅提供了几秒量级的MTTF。我们描述了一种新颖的数据复活方案，它可以修复RAID-4区域中的多条故障线路，从而将MTTF增加到几个小时。我们提出了数独的扩展，它将给定的行散列到RAID-4的两个区域，以显著增强可靠性，并将MTTF增加到数万亿小时。我们的评估表明，SuDoku的可靠性比ECC-6高874倍，存储量比ECC-6少30%，性能与理想的无故障基准相差不到0.1%。",
                    "title_zh": "数独:容忍高瞬时故障率以实现可伸缩的STTRAM"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00049",
                    "title": "NeXUS: Practical and Secure Access Control on Untrusted Storage Platforms using Client-Side SGX",
                    "authors": "Judicael Briand Djoko, Jack Lange, Adam J. Lee",
                    "abstract": "With the rising popularity of file-sharing services such as Google Drive and Dropbox in the workflows of individuals and corporations alike, the protection of client-outsourced data from unauthorized access or tampering remains a major security concern. Existing cryptographic solutions to this problem typically require server-side support, involve non-trivial key management on the part of users, and suffer from severe re-encryption penalties upon access revocations. This combination of performance overheads and management burdens makes this class of solutions undesirable in situations where performant, platform-agnostic, dynamic sharing of user content is required. We present NEXUS, a stackable filesystem that leverages trusted hardware to provide confidentiality and integrity for user files stored on untrusted platforms. NEXUS is explicitly designed to balance security, portability, and performance: it supports dynamic sharing of protected volumes on any platform exposing a file access API without requiring server-side support, enables the use of fine-grained access control policies to allow for selective sharing, and avoids the key revocation and file re-encryption overheads associated with other cryptographic approaches to access control. This combination of features is made possible by the use of a client-side Intel SGX enclave that is used to protect and share NEXUS volumes, ensuring that cryptographic keys never leave enclave memory and obviating the need to reencrypt files upon revocation of access rights. We implemented a NEXUS prototype that runs on top of the AFS filesystem and show that it incurs ×2 overhead for a variety of common file and database operations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着Google Drive和Dropbox等文件共享服务在个人和企业工作流中的日益流行，保护客户外包的数据免受未经授权的访问或篡改仍然是一个主要的安全问题。针对该问题的现有加密解决方案通常需要服务器端支持，涉及用户方的重要密钥管理，并且在访问撤销时遭受严重的重新加密惩罚。这种性能开销和管理负担的组合使得这类解决方案在需要高性能、平台无关、动态共享用户内容的情况下不理想。我们介绍NEXUS，一个可堆叠的文件系统，它利用可信硬件为存储在不可信平台上的用户文件提供机密性和完整性。NEXUS旨在平衡安全性、可移植性和性能:它支持在任何公开文件访问API的平台上动态共享受保护的卷，而无需服务器端支持，支持使用细粒度的访问控制策略来实现选择性共享，并避免了与其他加密访问控制方法相关的密钥撤销和文件重新加密开销。通过使用客户端英特尔SGX enclave来保护和共享NEXUS卷，确保加密密钥永远不会离开enclave内存，并且无需在撤销访问权限时重新加密文件，从而使这种功能组合成为可能。我们实现了一个运行在AFS文件系统之上的NEXUS原型，并表明对于各种常见的文件和数据库操作，它会产生×2的开销。",
                    "title_zh": "NeXUS:使用客户端SGX对不受信任的存储平台进行实用、安全的访问控制"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00050",
                    "title": "TEE-Perf: A Profiler for Trusted Execution Environments",
                    "authors": "Maurice Bailleu, Donald Dragoti, Pramod Bhatotia, Christof Fetzer",
                    "abstract": "We introduce TEE-PERF, an architecture-and platform-independent performance measurement tool for trusted execution environments (TEEs). More specifically, TEE-PERF supports method-level profiling for unmodified multithreaded applications, without relying on any architecture-specific hardware features (e.g. Intel VTune Amplifier), or without requiring platform-dependent kernel features (e.g. Linux perf). Moreover, TEE-PERF provides accurate profiling measurements since it traces the entire process execution without employing instruction pointer sampling. Thus, TEE-PERF does not suffer from sampling frequency bias, which can occur with threads scheduled to align to the sampling frequency. We have implemented TEE-P ERF with an easy to use interface, and integrated it with Flame Graphs to visualize the performance bottlenecks. We have evaluated TEE-PERF based on the Phoenix multithreaded benchmark suite and real-world applications (RocksDB, SPDK, etc.), and compared it with Linux perf. Our experimental evaluation shows that TEE-PERF incurs low profiling overheads, while providing accurate profile measurements to identify and optimize the application bottlenecks in the context of TEEs. TEE-PERF is publicly available.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们介绍了TEE-PERF，一个用于可信执行环境(TEEs)的独立于架构和平台的性能测量工具。更具体地说，TEE-PERF支持对未经修改的多线程应用进行方法级评测，不依赖任何特定于架构的硬件特性(如英特尔VTune Amplifier)，也不需要依赖于平台的内核特性(如Linux perf)。此外，TEE-PERF提供了准确的分析测量，因为它跟踪整个过程的执行，而不采用指令指针采样。因此，TEE-PERF不会受到采样频率偏差的影响，这种偏差会在线程调度为与采样频率一致时发生。我们已经实现了TEE-P ERF，它有一个易于使用的接口，并且集成了火焰图来可视化性能瓶颈。我们基于凤凰多线程基准测试套件和真实应用(RocksDB、SPDK等)对TEE-PERF进行了评估。)，并与Linux perf进行了对比。我们的实验评估表明，TEE-PERF产生较低的分析开销，同时提供准确的分析测量，以识别和优化TEE环境中的应用瓶颈。蒂-PERF是公开的。",
                    "title_zh": "TEE-Perf:可信执行环境的剖析器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00051",
                    "title": "EPA-RIMM : An Efficient, Performance-Aware Runtime Integrity Measurement Mechanism for Modern Server Platforms",
                    "authors": "Brian Delgado, Tejaswini Vibhute, John Fastabend, Karen L. Karavanic",
                    "abstract": "Detecting unexpected changes in a system's runtime environment is critical to resilience. A repurposing of System Management Mode (SMM) for runtime security inspections has been proposed, due to SMM's high privilege and protected memory. However, key challenges prevent SMM's adoption for this purpose in production-level environments: the possibility of severe performance impacts, semantic gaps between SMM and host software, high overheads, overly broad access permissions, and lack of flexibility. We introduce a Runtime Integrity Measurement framework, EPA-RIMM, for both native Linux and Xen platforms, that includes several novel features to solve these challenges. EPA-RIMM decomposes large measurements to control perturbation and leverages the SMI Transfer Monitor (STM) to bridge the semantic gap between hypervisors and SMM, as well as restrict the measurement agent's accesses. We present a design and implementation for a concurrent approach that allows EPA-RIMM to utilize all cores in SMM, dramatically increasing measurement throughput and reducing application perturbation. Our Linux and Xen prototype results show that EPA-RIMM meets performance goals while continuously monitoring code and data for signs of attack, and that it is effective at detecting a number of recent exploits.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "检测系统运行时环境中的意外变化对于恢复能力至关重要。由于SMM的高特权和受保护的存储器，已经提出了用于运行时安全检查的系统管理模式(SMM)的再利用。然而，主要挑战阻止了SMM在生产级环境中采用这一目的:严重性能影响的可能性，SMM和主机软件之间的语义差距，高开销，过于广泛的访问权限，以及缺乏灵活性。我们为原生Linux和Xen平台引入了一个运行时完整性度量框架EPA-RIMM，它包含了几个解决这些挑战的新特性。EPA-RIMM分解大型测量以控制扰动，并利用SMI Transfer Monitor (STM)来弥合虚拟机管理程序和SMM之间的语义鸿沟，以及限制测量代理的访问。我们介绍了一种并行方法的设计和实现，该方法允许EPA-RIMM利用SMM的所有内核，从而显著提高测量吞吐量并减少应用程序干扰。我们的Linux和Xen原型结果表明，EPA-RIMM在持续监控代码和数据的攻击迹象的同时，满足了性能目标，并且能够有效地检测大量最近的攻击。",
                    "title_zh": "EPA-RIMM:一种高效、性能敏感的现代服务器平台运行时完整性测量机制"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00052",
                    "title": "Pseudo-Honeypot: Toward Efficient and Scalable Spam Sniffer",
                    "authors": "Yihe Zhang, Hao Zhang, Xu Yuan, Nian-Feng Tzeng",
                    "abstract": "Honeypot-based spammer gathering solutions usually lack attribute variability, deployment flexibility, and network scalability, deemed as their common drawbacks. This paper explores pseudo-honeypot, a novel honeypot-like system to overcome such drawbacks, for efficient and scalable spammer sniffing. The pseudo-honeypot takes advantage of user diversity and selects normal accounts, with attributes that have the higher potential of attracting spammers, as the parasitic bodies. By harnessing such category of users, pseudo-honeypot can monitor their streaming posts and behavioral patterns transparently. When compared with its traditional honeypot counterpart, the proposed solution offers the substantial advantages of attribute variability, deployment flexibility, network scalability, and system portability. Meanwhile, it offers a novel method to collect the social network dataset that has a higher probability of including spams and spammers, without being noticed by advanced spammers. We take the Twitter social network as an example to exhibit its system design, including pseudo-honeypot nodes selection, monitoring, feature extraction, ground truth labeling, and learning-based classification. Through experiments, we demonstrate the efficiency of pseudo-honeypot in terms of spams and spammers gathering. In particular, we confirm our solution can garner spammers at least 19 times faster than the state-of-the-art honeypot-based counterpart.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于蜜罐的垃圾邮件收集解决方案通常缺乏属性可变性、部署灵活性和网络可扩展性，这被认为是它们的共同缺点。本文探讨伪蜜罐，一种新颖的类似蜜罐的系统来克服这些缺点，用于高效和可扩展的垃圾邮件嗅探。伪蜜罐利用用户多样性，选择具有更高吸引垃圾邮件发送者潜力的属性的正常账户作为寄生体。通过利用这类用户，伪蜜罐可以透明地监控他们的流帖子和行为模式。与传统的蜜罐解决方案相比，所提出的解决方案提供了属性可变性、部署灵活性、网络可扩展性和系统可移植性的实质性优势。同时，它提供了一种新的方法来收集社交网络数据集，该数据集有较高的概率包含垃圾邮件和垃圾邮件发送者，而不会被高级垃圾邮件发送者注意到。我们以Twitter社交网络为例展示了其系统设计，包括伪蜜罐节点选择、监控、特征提取、地面真实标记和基于学习的分类。通过实验，我们证明了伪蜜罐在垃圾邮件和垃圾邮件发送者收集方面的效率。特别是，我们确认我们的解决方案比最先进的基于蜜罐的解决方案至少快19倍。",
                    "title_zh": "伪蜜罐:高效可扩展的垃圾邮件嗅探器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00053",
                    "title": "Controller-Oblivious Dynamic Access Control in Software-Defined Networks",
                    "authors": "Steven R. Gomez, Samuel Jero, Richard Skowyra, Jason Martin, Patrick Sullivan, David Bigelow, Zachary Ellenbogen, Bryan C. Ward, Hamed Okhravi, James W. Landry",
                    "abstract": "Conventional network access control approaches are static (e.g., user roles in Active Directory), coarse-grained (e.g., 802.1x), or both (e.g., VLANs). Such systems are unable to meaningfully stop or hinder motivated attackers seeking to spread throughout an enterprise network. To address this threat, we present Dynamic Flow Isolation (DFI), a novel architecture for supporting dynamic, fine-grained access control policies enforced in a Software-Defined Network (SDN). These policies can emit and revoke specific access control rules automatically in response to network events like users logging off, letting the network adaptively reduce unnecessary reachability that could be potentially leveraged by attackers. DFI is oblivious to the SDN controller implementation and processes new packets prior to the controller, making DFI's access control resilient to a malicious or faulty controller or its applications. We implemented DFI for OpenFlow networks and demonstrated it on an enterprise SDN testbed with around 100 end hosts and servers. Finally, we evaluated the performance of DFI and how it enables a novel policy, which is otherwise difficult to enforce, that protects against a surrogate of the recent NotPetya malware in an infection scenario. We found that the threat was most limited in its ability to spread using our policy, which automatically restricted network flows over the course of the attack, compared to no access control or a static role-based policy.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传统的网络访问控制方法是静态的(例如，活动目录中的用户角色)、粗粒度的(例如，802.1x)或两者兼而有之(例如，VLANs)。这种系统不能有意义地阻止或阻碍有动机的攻击者寻求在整个企业网络中传播。为了应对这一威胁，我们提出了动态流隔离(DFI)，这是一种支持在软件定义网络(SDN)中实施动态细粒度访问控制策略的新型架构。这些策略可以自动发出和撤销特定的访问控制规则，以响应用户注销等网络事件，让网络自适应地减少可能被攻击者利用的不必要的可达性。DFI不理会SDN控制器实施，并在控制器之前处理新数据包，使DFI的访问控制能够抵御恶意或故障控制器或其应用程序。我们为OpenFlow网络实施了DFI，并在一个拥有大约100台终端主机和服务器的企业SDN试验床上进行了演示。最后，我们评估了DFI的性能，以及它如何实现一种新的策略，这种策略在其他情况下很难实施，可以在感染场景中防止最近的NotPetya恶意软件的替代。我们发现，与没有访问控制或基于角色的静态策略相比，使用我们的策略可以在攻击过程中自动限制网络流量，从而最大限度地限制威胁的传播能力。",
                    "title_zh": "软件定义网络中控制器无关的动态访问控制"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00054",
                    "title": "BorderPatrol: Securing BYOD using Fine-Grained Contextual Information",
                    "authors": "Onur Zungur, Guillermo Suarez-Tangil, Gianluca Stringhini, Manuel Egele",
                    "abstract": "Companies adopt Bring Your Own Device (BYOD) policies extensively, for both convenience and cost management. The compelling way of putting private and business related applications (apps) on the same device leads to the widespread usage of employee owned devices to access sensitive company data and services. Such practices create a security risk as a legitimate app may send business-sensitive data to third party servers through detrimental app functions or packaged libraries. In this paper, we propose BorderPatrol, a system for extracting contextual data that businesses can leverage to enforce access control in BYOD-enabled corporate networks through fine-grained policies. BorderPatrol extracts contextual information, which is the stack trace of the app function that generated the network traffic, on provisioned user devices and transfers this data in IP headers to enforce desired policies at network routers. BorderPatrol provides a way to selectively prevent undesired functionalities, such as analytics activities or advertisements, and help enforce information dissemination policies of the company while leaving other functions of the app intact. Using 2,000 apps, we demonstrate that BorderPatrol is effective in preventing packets which originate from previously identified analytics and advertisement libraries from leaving the network premises. In addition, we show BorderPatrol's capability in selectively preventing undesirable app functions using case studies.",
                    "files": {
                        "openAccessPdf": "https://kclpure.kcl.ac.uk/portal/files/109600840/2019dsn_bpatrol.pdf"
                    },
                    "abstract_zh": "为了方便和成本管理，公司广泛采用自带设备(BYOD)政策。将私人和业务相关的应用程序(app)放在同一台设备上的引人注目的方式，导致员工广泛使用自己的设备来访问敏感的公司数据和服务。这种做法会带来安全风险，因为合法的应用程序可能会通过有害的应用程序功能或打包的库将业务敏感数据发送到第三方服务器。在本文中，我们提出了BorderPatrol，这是一个用于提取上下文数据的系统，企业可以利用它通过细粒度的策略在支持BYOD的企业网络中实施访问控制。BorderPatrol提取上下文信息(生成网络流量的应用程序功能的堆栈跟踪),并在IP报头中传输这些数据，以在网络路由器上实施所需的策略。BorderPatrol提供了一种有选择地阻止不需要的功能(如分析活动或广告)的方法，并有助于执行公司的信息传播政策，同时保持应用程序的其他功能不变。通过使用2，000个应用，我们证明了BorderPatrol可以有效地阻止来自之前识别的分析和广告库的数据包离开网络。此外，我们通过案例研究展示了BorderPatrol选择性阻止不良应用程序功能的能力。",
                    "title_zh": "BorderPatrol:使用细粒度上下文信息保护BYOD"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00055",
                    "title": "Characterizing and Understanding HPC Job Failures Over The 2K-Day Life of IBM BlueGene/Q System",
                    "authors": "Sheng Di, Hanqi Guo, Eric Pershey, Marc Snir, Franck Cappello",
                    "abstract": "An in-depth understanding of the failure features of HPC jobs in a supercomputer is critical to the large-scale system maintenance and improvement of the service quality for users. In this paper, we investigate the features of hundreds of thousands of jobs in one of the most powerful supercomputers, the IBM Blue Gene/Q Mira, based on 2001 days of observations with a total of over 32.44 billion core-hours. We study the impact of the system's events on the jobs' execution in order to understand the system's reliability from the perspective of jobs and users. The characterization involves a joint analysis based on multiple data sources, including the reliability, availability, and serviceability (RAS) log; job scheduling log; the log regarding each job's physical execution tasks; and the I/O behavior log. We present 22 valuable takeaways based on our in-depth analysis. For instance, 99,245 job failures are reported in the job-scheduling log, a large majority (99.4%) of which are due to user behavior (such as bugs in code, wrong configuration, or misoperations). The job failures are correlated with multiple metrics and attributes, such as users/projects and job execution structure (number of tasks, scale, and core-hours). The best-fitting distributions of a failed job's execution length (or interruption interval) include Weibull, Pareto, inverse Gaussian, and Erlang/exponential, depending on the types of errors (i.e., exit codes). The RAS events affecting job executions exhibit a high correlation with users and core-hours and have a strong locality feature. In terms of the failed jobs, our similarity-based event-filtering analysis indicates that the mean time to interruption is about 3.5 days.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "深入了解超级计算机HPC作业的故障特征，对于大规模系统维护和提高用户服务质量至关重要。在本文中，我们基于2001天总计超过324.4亿个核心小时的观察，研究了最强大的超级计算机之一IBM Blue Gene/Q Mira中成千上万个作业的特征。我们研究系统事件对作业执行的影响，以便从作业和用户的角度理解系统的可靠性。表征涉及基于多个数据源的联合分析，包括可靠性、可用性和可服务性(RAS)日志；作业计划日志；关于每个作业的物理执行任务的日志；和I/O行为日志。基于我们的深入分析，我们提出了22个有价值的要点。例如，在作业调度日志中报告了99，245个作业失败，其中大部分(99.4%)是由于用户行为(例如代码中的错误、错误的配置或误操作)。作业失败与多个指标和属性相关，例如用户/项目和作业执行结构(任务数量、规模和核心小时)。根据错误类型(即退出代码)，失败作业的执行长度(或中断间隔)的最佳分布包括威布尔分布、帕累托分布、逆高斯分布和埃尔兰/指数分布。影响作业执行的RAS事件表现出与用户和核心时间的高度相关性，并且具有很强的局部性特征。对于失败的作业，我们基于相似性的事件过滤分析表明，平均中断时间约为3.5天。",
                    "title_zh": "描述和理解IBM BlueGene/Q系统2K天生命周期中的HPC作业失败"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00056",
                    "title": "Detecting \"0-Day\" Vulnerability: An Empirical Study of Secret Security Patch in OSS",
                    "authors": "Xinda Wang, Kun Sun, Archer L. Batcheller, Sushil Jajodia",
                    "abstract": "Security patches in open source software (OSS) not only provide security fixes to identified vulnerabilities, but also make the vulnerable code public to the attackers. Therefore, armored attackers may misuse this information to launch N-day attacks on unpatched OSS versions. The best practice for preventing this type of N-day attacks is to keep upgrading the software to the latest version in no time. However, due to the concerns on reputation and easy software development management, software vendors may choose to secretly patch their vulnerabilities in a new version without reporting them to CVE or even providing any explicit description in their change logs. When those secretly patched vulnerabilities are being identified by armored attackers, they can be turned into powerful \"0-day\" attacks, which can be exploited to compromise not only unpatched version of the same software, but also similar types of OSS (e.g., SSL libraries) that may contain the same vulnerability due to code clone or similar design/implementation logic. Therefore, it is critical to identify secret security patches and downgrade the risk of those \"0-day\" attacks to at least \"n-day\" attacks. In this paper, we develop a defense system and implement a toolset to automatically identify secret security patches in open source software. To distinguish security patches from other patches, we first build a security patch database that contains more than 4700 security patches mapping to the records in CVE list. Next, we identify a set of features to help distinguish security patches from non-security ones using machine learning approaches. Finally, we use code clone identification mechanisms to discover similar patches or vulnerabilities in similar types of OSS. The experimental results show our approach can achieve good detection performance. A case study on OpenSSL, LibreSSL, and BoringSSL discovers 12 secret security patches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "开源软件中的安全补丁不仅为已识别的漏洞提供安全修复，还会向攻击者公开易受攻击的代码。因此，装甲攻击者可能会滥用这些信息，对未打补丁的OSS版本发起N天攻击。防止这种N天攻击的最佳实践是立即将软件升级到最新版本。然而，出于对声誉和软件开发管理简便性的考虑，软件供应商可能会选择在新版本中秘密修补其漏洞，而不向CVE报告，甚至不在其变更日志中提供任何明确的描述。当这些秘密修补的漏洞被伪装的攻击者识别时，它们可以变成强大的“0天”攻击，这些攻击不仅可以被利用来危害相同软件的未修补版本，还可以危害由于代码克隆或类似的设计/实现逻辑而可能包含相同漏洞的类似类型的操作系统(例如，SSL库)。因此，确定秘密的安全补丁并将那些“0天”攻击的风险降低到至少“n天”攻击是至关重要的。在本文中，我们开发了一个防御系统，并实现了一个工具集来自动识别开源软件中的秘密安全补丁。为了将安全补丁与其他补丁区分开来，我们首先构建了一个安全补丁数据库，其中包含4700多个安全补丁，这些安全补丁映射到CVE列表中的记录。接下来，我们使用机器学习方法来识别一组特征，以帮助区分安全补丁和非安全补丁。最后，我们使用代码克隆识别机制来发现相似类型操作系统中的相似补丁或漏洞。实验结果表明，该方法能够获得良好的检测性能。对OpenSSL、LibreSSL和BoringSSL的案例研究发现了12个秘密安全补丁。",
                    "title_zh": "检测“0天”漏洞:OSS秘密安全补丁的实证研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00057",
                    "title": "Where Are You Taking Me? Behavioral Analysis of Open DNS Resolvers",
                    "authors": "Jeman Park, Aminollah Khormali, Manar Mohaisen, Aziz Mohaisen",
                    "abstract": "Open DNS resolvers are resolvers that perform recursive resolution on behalf of any user. They can be exploited by adversaries because they are open to the public and require no authorization to use. Therefore, it is important to understand the state of open resolvers to gauge their potentially negative impact on the security and stability of the Internet. In this study, we conducted a comprehensive probing over the entire IPv4 address space and found that more than 3 million open resolvers still exist in the wild. Moreover, we found that many of them work in a way that deviates from the standard. More importantly, we found that many open resolvers answer queries with the incorrect, even malicious, responses. Contrasting to results obtained in 2013, we found that while the number of open resolvers has decreased significantly, the number of resolvers providing incorrect responses is almost the same, while the number of open resolvers providing malicious responses has increased, highlighting the prevalence of their threat.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "开放DNS解析器是代表任何用户执行递归解析的解析器。它们可以被对手利用，因为它们对公众开放并且不需要授权就可以使用。因此，了解开放解析器的状态以评估它们对互联网的安全性和稳定性的潜在负面影响是很重要的。在这项研究中，我们对整个IPv4地址空间进行了全面的探测，发现仍有超过300万个开放式解析器存在于网络中。此外，我们发现他们中的许多人的工作方式偏离了标准。更重要的是，我们发现许多开放解析器用不正确的、甚至是恶意的响应来回答查询。与2013年获得的结果相比，我们发现尽管开放解析器的数量显著减少，但提供错误响应的解析器数量几乎相同，而提供恶意响应的开放解析器数量有所增加，这凸显了其威胁的普遍性。",
                    "title_zh": "你要带我去哪里？开放式DNS解析器的行为分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00058",
                    "title": "POLaR: Per-Allocation Object Layout Randomization",
                    "authors": "Jonghwan Kim, DaeHee Jang, Yunjong Jeong, Brent ByungHoon Kang",
                    "abstract": "Object Layout Randomization (OLR) is a memory randomization approach that makes unpredictable in-object memory layout by shuffling and relocating each member fields of the object. This defense approach has significant security effect for mitigating various types of memory error attacks. However, the current state-of-the-art enforces OLR while compile time. It makes diversified object layout for each binary, but the layout remains equal across the execution. This approach can be effective in case the program binary is hidden from attackers. However, there are several limitations: (i) the security efficacy is built with the premise that the binary is safely undisclosed from adversaries, (ii) the randomized object layout is identical across multiple executions, and (iii) the programmer should manually specify which objects should be affected by OLR. In this paper, we introduce Per-allocation Object Layout Randomization(POLaR): the first dynamic approach of OLR suited for public binaries. The randomization mechanism of POLaR is applied at runtime, and the randomization makes unique object layout even for the same type of instances. As a result, POLaR achieves two previously unmet security primitives. (i) The randomization does not break upon the exposure of the binary. (ii) Repeating the same attack does not result in deterministic behavior. In addition, we also implemented the TaintClass framework based on DFSan project to optimize/automate the target object selection process. To show the efficacy of POLaR, we use several public open-source software and SPEC2006 benchmark suites.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对象布局随机化(OLR)是一种内存随机化方法，它通过打乱和重新定位对象的每个成员字段来实现不可预测的对象内内存布局。这种防御方法对于减轻各种类型的存储器错误攻击具有显著的安全效果。然而，当前的最新技术在编译时执行OLR。它为每个二进制文件创建了多样化的对象布局，但是在执行过程中布局保持不变。这种方法在程序二进制对攻击者隐藏的情况下是有效的。然而，有几个限制:(I)安全功效是建立在二进制文件不被对手安全地公开的前提下的，(ii)随机对象布局在多次执行中是相同的，以及(iii)程序员应该手动指定哪些对象应该受到OLR的影响。在本文中，我们介绍了每分配对象布局随机化(POLaR):第一个适用于公共二进制文件的动态OLR方法。POLaR的随机化机制是在运行时应用的，随机化使得即使是同一类型的实例也有独特的对象布局。因此，POLaR实现了两个以前没有实现的安全原语。(I)随机化在二进制暴露时不会中断。(ii)重复相同的攻击不会导致确定性行为。此外，我们还基于DFSan项目实现了TaintClass框架，以优化/自动化目标对象选择过程。为了展示POLaR的功效，我们使用了几个公共开源软件和SPEC2006基准测试套件。",
                    "title_zh": "极轴:每分配对象布局随机化"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00059",
                    "title": "The Strength of Weak Randomization: Easily Deployable, Efficiently Searchable Encryption with Minimal Leakage",
                    "authors": "David Pouliot, Scott Griffy, Charles V. Wright",
                    "abstract": "Efficiently searchable and easily deployable encryption schemes enable an untrusted, legacy service such as a relational database engine to perform searches over encrypted data. The ease with which such schemes can be deployed on top of existing services makes them especially appealing in operational environments where encryption is needed but it is not feasible to replace large infrastructure components like databases or document management systems. Unfortunately all previously known approaches for efficiently searchable and easily deployable encryption are vulnerable to inference attacks where an adversary can use knowledge of the distribution of the data to recover the plaintext with high probability. We present a new efficiently searchable, easily deployable database encryption scheme that is provably secure against inference attacks even when used with real, low-entropy data. We implemented our constructions in Haskell and tested databases up to 10 million records showing our construction properly balances security, deployability and performance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高效可搜索且易于部署的加密方案使不受信任的传统服务(如关系数据库引擎)能够对加密数据执行搜索。此类方案易于部署在现有服务之上，这使得它们在需要加密但无法取代大型基础设施组件(如数据库或文档管理系统)的操作环境中尤其具有吸引力。不幸的是，所有先前已知的用于有效搜索和容易部署的加密的方法都容易受到推断攻击，其中对手可以使用数据分布的知识以高概率恢复明文。我们提出了一种新的高效可搜索的、易于部署的数据库加密方案，即使在使用真实的低熵数据时，该方案也能抵抗推理攻击。我们在Haskell中实现了我们的构造，并测试了多达1000万条记录的数据库，表明我们的构造恰当地平衡了安全性、可部署性和性能。",
                    "title_zh": "弱随机化的优势:易于部署、高效搜索、泄漏最小的加密"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00060",
                    "title": "HeapTherapy+: Efficient Handling of (Almost) All Heap Vulnerabilities Using Targeted Calling-Context Encoding",
                    "authors": "Qiang Zeng, Golam Kayas, Emil Mohammed, Lannan Luo, Xiaojiang Du, Junghwan Rhee",
                    "abstract": "Exploitation of heap vulnerabilities has been on the rise, leading to many devastating attacks. Conventional heap patch generation is a lengthy procedure requiring intensive manual efforts. Worse, fresh patches tend to harm system dependability, hence deterring users from deploying them. We propose a heap patching system HEAPTHERAPY+ that simultaneously has the following prominent advantages: (1) generating patches without manual efforts; (2) installing patches without altering the code (so called code-less patching); (3) handling various heap vulnerability types; (4) imposing a very low overhead; and (5) no dependency on specific heap allocators. As a separate contribution, we propose targeted calling context encoding, which is a suite of algorithms for optimizing calling context encoding, an important technique with applications in many areas. The system properly combines heavyweight offline attack analysis with lightweight online defense generation, and provides a new countermeasure against heap attacks. The evaluation shows that the system is effective and efficient.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对堆漏洞的利用一直在增加，导致了许多毁灭性的攻击。传统的堆补丁生成是一个冗长的过程，需要大量的人工工作。更糟糕的是，新的补丁往往会损害系统的可靠性，从而阻止用户部署它们。我们提出了一种堆修补系统HEAPTHERAPY+,它同时具有以下突出的优点:(1)无需人工努力就能生成补丁；(2)在不改变代码的情况下安装补丁(所谓的无代码补丁)；(3)处理各种堆漏洞类型；(4)施加非常低的开销；以及(5)不依赖于特定的堆分配器。作为一个单独的贡献，我们提出了目标呼叫上下文编码，这是一套优化呼叫上下文编码的算法，这是一项在许多领域都有应用的重要技术。该系统将重量级离线攻击分析和轻量级在线防御生成恰当地结合起来，提供了一种新的堆攻击对策。评估表明该系统是有效的。",
                    "title_zh": "HeapTherapy+:使用目标调用上下文编码有效处理(几乎)所有堆漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00061",
                    "title": "FabZK: Supporting Privacy-Preserving, Auditable Smart Contracts in Hyperledger Fabric",
                    "authors": "Hui Kang, Ting Dai, Nerla Jean-Louis, Shu Tao, Xiaohui Gu",
                    "abstract": "On a Blockchain network, transaction data are exposed to all participants. To preserve privacy and confidentiality in transactions, while still maintaining data immutability, we design and implement FabZK. FabZK conceals transaction details on a shared ledger by storing only encrypted data from each transaction (e.g., payment amount), and by anonymizing the transactional relationship (e.g., payer and payee) between members in a Blockchain network. It achieves both privacy and auditability by supporting verifiable Pedersen commitments and constructing zero-knowledge proofs. FabZK is implemented as an extension to the open source Hyperledger Fabric. It provides APIs to easily enable data privacy in both client code and chaincode. It also supports on-demand, automated auditing based on encrypted data. Our evaluation shows that FabZK offers strong privacy-preserving capabilities, while delivering reasonable performance for the applications developed based on its framework.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在区块链网络上，交易数据对所有参与者公开。为了保护交易中的隐私和机密性，同时仍然保持数据的不变性，我们设计并实现了FabZK。FabZK通过仅存储每笔交易的加密数据(例如，支付金额)，以及通过匿名化区块链网络中成员之间的交易关系(例如，付款人和收款人)，来隐藏共享账本上的交易细节。它通过支持可验证的Pedersen承诺和构造零知识证明来实现隐私性和可审计性。FabZK是作为开源Hyperledger Fabric的扩展实现的。它提供了API来轻松地在客户端代码和链代码中启用数据隐私。它还支持基于加密数据的按需自动审计。我们的评估表明，FabZK提供了强大的隐私保护功能，同时为基于其框架开发的应用程序提供了合理的性能。",
                    "title_zh": "FabZK:在Hyperledger Fabric中支持隐私保护、可审计的智能合同"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00062",
                    "title": "Fast Predictive Repair in Erasure-Coded Storage",
                    "authors": "Zhirong Shen, Xiaolu Li, Patrick P. C. Lee",
                    "abstract": "Erasure coding offers a storage-efficient redundancy mechanism for maintaining data availability guarantees in large-scale storage clusters, yet it also incurs high performance overhead in failure repair. Recent developments in accurate disk failure prediction allow soon-to-fail (STF) nodes to be repaired in advance, thereby opening new opportunities for accelerating failure repair in erasure-coded storage. To this end, we present a fast predictive repair solution called FastPR, which carefully couples two repair methods, namely migration (i.e., relocating the chunks of an STF node) and reconstruction (i.e., decoding the chunks of an STF node through erasure coding), so as to fully parallelize the repair operation across the storage cluster. FastPR solves a bipartite maximum matching problem and schedules both migration and reconstruction in a parallel fashion. We show that FastPR significantly reduces the repair time over the baseline repair approaches via mathematical analysis, large-scale simulation, and Amazon EC2 experiments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "擦除编码提供了一种存储高效的冗余机制，用于维护大规模存储集群中的数据可用性保证，但它也导致了故障修复方面的高性能开销。在准确的磁盘故障预测方面的最新发展允许提前修复即将发生故障(STF)的节点，从而为加速擦除编码存储中的故障修复提供了新的机会。为此，我们提出了一种称为FastPR的快速预测修复解决方案，它仔细耦合了两种修复方法，即迁移(即重新定位STF节点的块)和重建(即通过擦除编码解码STF节点的块)，以便在存储集群上完全并行化修复操作。FastPR解决了一个双向最大匹配问题，并以并行方式调度迁移和重建。通过数学分析、大规模模拟和Amazon EC2实验，我们发现FastPR比基线修复方法显著减少了修复时间。",
                    "title_zh": "擦除编码存储中的快速预测修复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00063",
                    "title": "SBFT: A Scalable and Decentralized Trust Infrastructure",
                    "authors": "Guy Golan-Gueta, Ittai Abraham, Shelly Grossman, Dahlia Malkhi, Benny Pinkas, Michael K. Reiter, Dragos-Adrian Seredinschi, Orr Tamir, Alin Tomescu",
                    "abstract": "SBFT is a state of the art Byzantine fault tolerant state machine replication system that addresses the challenges of scalability, decentralization and global geo-replication. SBFT is optimized for decentralization and is experimentally evaluated on a deployment of more than 200 active replicas withstanding a malicious adversary controlling f=64 replicas. Our experiments show how the different algorithmic ingredients of SBFT contribute to its performance and scalability. The results show that SBFT simultaneously provides almost 2x better throughput and about 1.5x better latency relative to a highly optimized system that implements the PBFT protocol. To achieve this performance improvement, SBFT uses a combination of four ingredients: using collectors and threshold signatures to reduce communication to linear, using an optimistic fast path, reducing client communication and utilizing redundant servers for the fast path. SBFT is the first system to implement a correct dual-mode view change protocol that allows to efficiently run either an optimistic fast path or a fallback slow path without incurring a view change to switch between modes.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1804.01626"
                    },
                    "abstract_zh": "SBFT是最先进的拜占庭容错状态机复制系统，解决了可扩展性、分散化和全局地理复制的挑战。SBFT针对去中心化进行了优化，并在超过200个活动副本的部署上进行实验性评估，以抵御控制f=64个副本的恶意对手。我们的实验显示了SBFT的不同算法成分如何对其性能和可伸缩性做出贡献。结果显示，相对于实施PBFT协议的高度优化系统，SBFT同时提供了几乎2倍的吞吐量和大约1.5倍的延迟。为了实现这种性能改进，SBFT使用了四种成分的组合:使用收集器和阈值签名来将通信减少到线性，使用乐观快速路径，减少客户端通信，以及将冗余服务器用于快速路径。SBFT是第一个实现正确的双模式视图改变协议的系统，该协议允许有效地运行乐观快速路径或后退慢速路径，而不会导致视图改变以在模式之间切换。",
                    "title_zh": "SBFT:一个可扩展的分散式信任基础设施"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00064",
                    "title": "UChecker: Automatically Detecting PHP-Based Unrestricted File Upload Vulnerabilities",
                    "authors": "Jin Huang, Yu Li, Junjie Zhang, Rui Dai",
                    "abstract": "Unrestricted file upload vulnerabilities enable attackers to upload and execute malicious scripts in web servers. We have built a system, namely UChecker, to effectively and automatically detect such vulnerabilities in PHP server-side web applications. Towards this end, UChecker first interprets abstract syntax trees (AST) of program source code to perform symbolic execution. It then models vulnerabilities using SMT constraints and further leverages an SMT solver to verify the satisfiability of these constraints. UChecker features a novel vulnerability-oriented locality analysis algorithm to reduce the workload of symbolic execution, an AST-driven symbolic execution engine with compact data structures, and rules to translate PHP-based constraints into SMT-based constraints by mitigating their semantic gaps. Experiments based on real-world examples have demonstrated that UChecker has accomplished a high detection accuracy. In addition, it detected three vulnerable PHP scripts that are previously unknown.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "不受限制的文件上传漏洞使得攻击者能够在web服务器中上传和执行恶意脚本。我们已经建立了一个系统，即UChecker，可以有效地自动检测PHP服务器端web应用程序中的此类漏洞。为此，UChecker首先解释程序源代码的抽象语法树(AST)来执行符号执行。然后，它使用SMT约束对漏洞进行建模，并进一步利用SMT求解器来验证这些约束的可满足性。UChecker提供了一种新颖的面向漏洞的局部性分析算法，以减少符号执行的工作量；一个AST驱动的符号执行引擎，具有紧凑的数据结构；以及一些规则，通过减少语义差距，将基于PHP的约束转换为基于SMT的约束。基于真实世界的例子的实验已经表明，UChecker已经实现了高检测精度。此外，它还检测到三个以前未知的易受攻击的PHP脚本。",
                    "title_zh": "UChecker:自动检测基于PHP的无限制文件上传漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00065",
                    "title": "PrivAnalyzer: Measuring the Efficacy of Linux Privilege Use",
                    "authors": "John Criswell, Jie Zhou, Spyridoula Gravani, Xiaoyu Hu",
                    "abstract": "Operating systems such as Linux break the power of the root user into separate privileges (which Linux calls capabilities) and give processes the ability to enable privileges only when needed and to discard them permanently when the program no longer needs them. However, there is no method of measuring how well the use of such facilities reduces the risk of privilege escalation attacks if the program has a vulnerability. This paper presents PrivAnalyzer, an automated tool that measures how effectively programs use Linux privileges. PrivAnalyzer consists of three components: 1) AutoPriv, an existing LLVM-based C/C++ compiler which uses static analysis to transform a program that uses Linux privileges into a program that safely removes them when no longer needed, 2) ChronoPriv, a new LLVM C/C++ compiler pass that performs dynamic analysis to determine for how long a program retains various privileges, and 3) ROSA, a new bounded model checker that can model the damage a program can do at each program point if an attacker can exploit the program and abuse its privileges. We use PrivAnalyzer to determine how long five privileged open source programs retain the ability to cause serious damage to a system and find that merely transforming a program to drop privileges does not significantly improve security. However, we find that simple refactoring can considerably increase the efficacy of Linux privileges. In two programs that we refactored, we reduced the percentage of execution in which a device file can be read and written from 97% and 88% to 4% and 1%, respectively.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "诸如Linux之类的操作系统将根用户的权力分解成单独的特权(Linux称之为能力),并赋予进程仅在需要时才启用特权的能力，以及在程序不再需要特权时永久丢弃特权的能力。但是，如果程序存在漏洞，则无法衡量使用这种工具在多大程度上降低了特权提升攻击的风险。本文介绍了PrivAnalyzer，这是一个测量程序使用Linux特权的效率的自动化工具。PrivAnalyzer由三个组件组成:1) AutoPriv，一个现有的基于LLVM的C/C++编译器，它使用静态分析将使用Linux特权的程序转换为在不再需要时安全删除它们的程序，2) ChronoPriv，一个新的LLVM C/C++编译器，它执行动态分析以确定程序保留各种特权的时间，以及3) ROSA，一个新的有界模型检查器，如果攻击者可以利用程序并滥用其特权，它可以模拟程序在每个程序点可能造成的损害。我们使用PrivAnalyzer来确定五个有特权的开源程序保留对系统造成严重破坏的能力的时间，并发现仅仅将程序转换为放弃特权并不能显著提高安全性。然而，我们发现简单的重构可以大大提高Linux特权的功效。在我们重构的两个程序中，我们将设备文件可读写的执行百分比分别从97%和88%降低到4%和1%。",
                    "title_zh": "PrivAnalyzer:测量Linux特权使用的功效"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00066",
                    "title": "1dVul: Discovering 1-Day Vulnerabilities through Binary Patches",
                    "authors": "Jiaqi Peng, Feng Li, Bingchang Liu, Lili Xu, Binghong Liu, Kai Chen, Wei Huo",
                    "abstract": "Discovering 1-day vulnerabilities in binary patches is worthwhile but challenging. One of the key difficulties lies in generating inputs that could reach the patched code snippet while making the unpatched program crash. In this paper, we named it as a target-oriented input generation problem or a ToIG problem for clarity. Existing solutions for the ToIG problem either suffer from path explosion or may get stuck by complex checks. In the paper, we present a new solution to improve the efficiency of ToIG which leverage a combination of a distance-based directed fuzzing mechanism and a dominator-based directed symbolic execution mechanism. To demonstrate its efficiency, we design and implement 1dVul, a tool for 1-day vulnerability discovering at binary-level, based on the solution. Demonstrations show that 1dVul has successfully generated inputs for 130 targets from a total of 209 patch targets identified from applications in DARPA Cyber Grant Challenge, while the state-of-the-art solutions AFLGo and Driller can only reach 99 and 107 targets, respectively, within the same limited time budget. Further-more, 1dVul runs 2.2X and 3.6X faster than AFLGo and Driller, respectively, and has confirmed 96 vulnerabilities from the unpatched programs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "发现二进制补丁中的1天漏洞是值得的，但具有挑战性。一个关键的困难在于生成的输入可以到达打补丁的代码片段，同时使未打补丁的程序崩溃。在本文中，为清晰起见，我们将其命名为面向目标的输入生成问题或ToIG问题。ToIG问题的现有解决方案要么遭遇路径爆炸，要么可能被复杂的检查卡住。在本文中，我们提出了一种新的解决方案来提高ToIG的效率，该方案结合了基于距离的定向模糊机制和基于支配者的定向符号执行机制。为了证明其有效性，我们基于该解决方案设计并实现了一个二进制级别的一日漏洞发现工具1dVul。演示表明，1dVul已从DARPA网络资助挑战赛申请中确定的总共209个补丁目标中成功生成了130个目标的输入，而在相同的有限时间预算内，最先进的解决方案AFLGo和Driller只能分别达到99个和107个目标。此外，1dVul的运行速度分别比AFLGo和Driller快2.2倍和3.6倍，并已确认来自未打补丁程序的96个漏洞。",
                    "title_zh": "1dVul:通过二进制补丁发现1天漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00067",
                    "title": "Revisiting Client Puzzles for State Exhaustion Attacks Resilience",
                    "authors": "Mohammad A. Noureddine, Ahmed M. Fawaz, Amanda Hsu, Cody Guldner, Sameer Vijay, Tamer Basar, William H. Sanders",
                    "abstract": "In this paper, we address the challenges facing the adoption of client puzzles as a means to protect the TCP connection establishment channel from state exhaustion DDoS attacks. We model the problem of selecting the puzzle difficulties as a Stackelberg game with the server as the leader and the clients as the followers and obtain the equilibrium solution for the puzzle difficulty. We then present an implementation of client puzzles inside the TCP stack of the Linux 4.13.0 kernel. We evaluate the performance of our implementation and the obtained solution against a range of attacks through reproducible experiments on the DETER testbed. Our results show that client puzzles are effective at boosting the tolerance of the TCP handshake channel to state exhaustion DDoS attacks by rate limiting malicious attackers while allocating resources for legitimate clients.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1807.11892"
                    },
                    "abstract_zh": "在本文中，我们解决了采用客户端难题作为保护TCP连接建立通道免受状态耗尽DDoS攻击的手段所面临的挑战。我们将难题难度的选择问题建模为一个Stackelberg博弈，服务器作为领导者，客户端作为跟随者，得到了难题难度的均衡解。然后，我们展示了Linux 4.13.0内核的TCP栈中客户端谜题的实现。我们通过在DETER测试床上的可重复实验来评估我们的实现和所获得的解决方案针对一系列攻击的性能。我们的结果表明，客户端难题通过在为合法客户端分配资源的同时限制恶意攻击者的速率，有效地提高了TCP握手信道对状态耗尽DDoS攻击的容忍度。",
                    "title_zh": "重新审视状态耗尽攻击弹性的客户端难题"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00068",
                    "title": "Robust Anomaly Detection on Unreliable Data",
                    "authors": "Zilong Zhao, Sophie Cerf, Robert Birke, Bogdan Robu, Sara Bouchenak, Sonia Ben Mokhtar, Lydia Y. Chen",
                    "abstract": "Classification algorithms have been widely adopted to detect anomalies for various systems, e.g., IoT and cloud, under the common assumption that the data source is clean, i.e., features and labels are correctly set. However, data collected from the field can be unreliable due to careless annotations or malicious data transformation for incorrect anomaly detection. In this paper, we present a two-layer learning framework for robust anomaly detection (RAD) in the presence of unreliable anomaly labels. The first layer of quality model filters the suspicious data, where the second layer of classification model detects the anomaly types. We specifically focus on two use cases, (i) detecting 10 classes of IoT attacks and (ii) predicting 4 classes of task failures of big data jobs. Our evaluation results show that RAD can robustly improve the accuracy of anomaly detection, to reach up to 98% for IoT device attacks (i.e., +11%) and up to 83% for cloud task failures (i.e., +20%), under a significant percentage of altered anomaly labels. Index Terms—Unreliable Data; Anomaly Detection; Failures; Attacks; Machine Learning",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-02056558/file/dsn2019.pdf"
                    },
                    "abstract_zh": "在数据源是干净的，即特征和标签被正确设置的共同假设下，分类算法已经被广泛采用来检测各种系统(例如，物联网和云)的异常。然而，从现场收集的数据可能不可靠，这是由于粗心的注释或恶意的数据转换导致不正确的异常检测。在本文中，我们提出了一个两层的学习框架，用于在存在不可靠异常标签的情况下进行稳健的异常检测。第一层质量模型过滤可疑数据，第二层分类模型检测异常类型。我们特别关注两个用例，(I)检测10类物联网攻击，以及(ii)预测大数据作业的4类任务失败。我们的评估结果表明，RAD可以稳健地提高异常检测的准确性，在大量更改异常标签的情况下，对物联网设备攻击的准确率高达98%(即+11%)，对云任务失败的准确率高达83%(即+20%)。索引术语——不可靠的数据；异常检测；失败；攻击；机器学习",
                    "title_zh": "不可靠数据上的稳健异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2019.00069",
                    "title": "Pupillography as Indicator of Programmers' Mental Effort and Cognitive Overload",
                    "authors": "Ricardo Couceiro, Gonçalo Duarte, João Durães, João Castelhano, Catarina Duarte, César A. D. Teixeira, Miguel Castelo-Branco, Paulo Carvalho, Henrique Madeira",
                    "abstract": "Our research explores a recent paradigm called Biofeedback Augmented Software Engineering (BASE) that introduces a strong new element in the software development process: the programmers' biofeedback. In this Practical Experience Report we present the results of an experiment to evaluate the possibility of using pupillography to gather biofeedback from the programmers. The idea is to use pupillography to get meta information about the programmers' cognitive and emotional states (stress, attention, mental effort level, cognitive overload,...) during code development to identify conditions that may precipitate programmers making bugs or bugs escaping human attention, and tag the corresponding code locations in the software under development to provide online warnings to the programmer or identify code snippets that will need more intensive testing. The experiments evaluate the use of pupillography as cognitive load predictor, compare the results with the mental effort perceived by programmers using NASATLX, and discuss different possibilities for the use of pupillography as biofeedback sensor in real software development scenarios.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们的研究探索了一种称为生物反馈增强软件工程(BASE)的最新范式，它在软件开发过程中引入了一个强大的新元素:程序员的生物反馈。在这份实践经验报告中，我们展示了一项实验的结果，以评估使用瞳孔描记法从程序员那里收集生物反馈的可能性。这个想法是使用瞳孔描记法来获得关于程序员的认知和情绪状态的元信息(压力，注意力，脑力劳动水平，认知超载，...)在代码开发期间识别可能促使程序员制造错误或逃避人类注意的错误的条件，并在开发中的软件中标记相应的代码位置，以向程序员提供在线警告或识别将需要更密集测试的代码片段。实验评估了使用瞳孔描记法作为认知负荷预测器，将结果与使用NASATLX的程序员感知的脑力劳动进行比较，并讨论了在实际软件开发场景中使用瞳孔描记法作为生物反馈传感器的不同可能性。",
                    "title_zh": "作为程序员脑力劳动和认知超负荷指标的瞳孔描记法"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2019w.html",
            "conf_title": "49th DSN 2019: Portland, OR, USA - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8792946/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00009",
                    "title": "Enhancing Information Sharing and Visualization Capabilities in Security Data Analytic Platforms",
                    "authors": "Gustavo Gonzalez Granadillo, Mario Faiella, Ibéria Medeiros, Rui Azevedo, Susana Gonzalez Zarzosa",
                    "abstract": "Collecting and processing Open Source Intelligence (OSINT) data is becoming a fundamental approach for obtaining cybersecurity threat information and awareness. Different types of useful information and Indicators of Compromise (IoCs) are obtained from OSINT sources, which keep security analysts updated about new and possible threats against the IT infrastructures they protect. However, skimming through various news feeds is a time consuming process and a source of all kinds of information (sometimes unuseful and not related to the monitored infrastructure) for any security analyst. Based on these shortcomings, we propose a Context-Aware OSINT Platform as a tool for enhancing visualization and information sharing capabilities in security data analytic platforms. The tool is not only able to collect OSINT data, but also to process it and filter only the relevant parts, thus enriching the attributes of the detected data, and consequently, decreasing the amount of information and the time required to analyze and act upon.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "收集和处理开源情报(OSINT)数据正在成为获取网络安全威胁信息和意识的基本方法。不同类型的有用信息和危害指标(IOC)从OSINT来源获得，这使安全分析师能够及时了解他们所保护的IT基础架构面临的新的和可能的威胁。然而，对于任何安全分析师来说，浏览各种新闻提要都是一个耗时的过程，并且是各种信息的来源(有时是无用的，并且与受监控的基础架构无关)。基于这些缺点，我们提出了一个上下文感知的OSINT平台，作为增强安全数据分析平台的可视化和信息共享能力的工具。该工具不仅能够收集新的数据，而且能够对其进行处理并仅过滤相关部分，从而丰富检测到的数据的属性，并因此减少分析和采取行动所需的信息量和时间。",
                    "title_zh": "增强安全数据分析平台的信息共享和可视化能力"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00010",
                    "title": "Design of a Classification Model for a Twitter-Based Streaming Threat Monitor",
                    "authors": "Fernando Alves, Pedro Miguel Ferreira, Alysson Bessani",
                    "abstract": "Receiving timely and relevant security information is crucial to maintaining a high-security level on an IT infrastructure. This information can be extracted from Open Source Intelligence published daily by users, security companies, and hackers. In particular, Twitter has become an information hub for obtaining cutting edge information about many subjects, including cybersecurity. This work discusses the design of a classifier model for a Twitter-based threat monitor for generating a summary of the threat landscape related to a given monitored IT infrastructure. Since the classifier is a crucial element of the processing pipeline that constitutes the threat monitor, its architecture, topology and hyper-parameters must be properly selected to achieve high true positive and true negative classification rates. Our experimental work considered two architectural approaches: a single model for the whole IT infrastructure or an ensemble of models, one for each of several parts of the infrastructure. Within this scope we tested one linear (support vector machine) and one non-linear (multi-layer perceptron) modelling technique. Finally, several model design variables, hyper-parameters and learning parameters were selected by grid-search.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "及时接收相关的安全信息对于维护IT基础架构的高安全性至关重要。这些信息可以从用户、安全公司和黑客每天发布的开源情报中提取。特别是，Twitter已经成为获取包括网络安全在内的许多主题的前沿信息的信息中心。这项工作讨论了基于Twitter的威胁监视器的分类器模型的设计，用于生成与给定的受监视IT基础架构相关的威胁情况摘要。由于分类器是构成威胁监视器的处理管道的关键元素，因此必须正确选择其架构、拓扑和超参数，以实现高的真阳性和真阴性分类率。我们的实验工作考虑了两种架构方法:整个IT基础设施的单一模型或模型集合，基础设施的几个部分各有一个模型。在这个范围内，我们测试了一种线性(支持向量机)和一种非线性(多层感知器)建模技术。最后，通过网格搜索选择了几个模型设计变量、超参数和学习参数。",
                    "title_zh": "基于Twitter的流式威胁监视器的分类模型设计"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00011",
                    "title": "System Misuse Detection Via Informed Behavior Clustering and Modeling",
                    "authors": "Linara Adilova, Livin Natious, Siming Chen, Olivier Thonnard, Michael Kamp",
                    "abstract": "One of the main tasks of cybersecurity is recognizing malicious interactions with an arbitrary system. Currently, the logging information from each interaction can be collected in almost unrestricted amounts, but identification of attacks requires a lot of effort and time of security experts.We propose an approach for identifying fraud activity through modeling normal behavior in interactions with a system via machine learning methods, in particular LSTM neural networks. In order to enrich the modeling with system specific knowledge, we propose to use an interactive visual interface that allows security experts to identify semantically meaningful clusters of interactions. These clusters incorporate domain knowledge and lead to more precise behavior modeling via informed machine learning. We evaluate the proposed approach on a dataset containing logs of interactions with an administrative interface of login and security server. Our empirical results indicate that the informed modeling is capable of capturing normal behavior, which can then be used to detect abnormal behavior.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1907.00874"
                    },
                    "abstract_zh": "网络安全的主要任务之一是识别与任意系统的恶意交互。目前，可以收集几乎无限量的来自每个交互的日志信息，但是识别攻击需要安全专家的大量努力和时间。我们提出了一种通过机器学习方法，特别是LSTM神经网络，对与系统交互的正常行为进行建模来识别欺诈活动的方法。为了用系统特定的知识丰富建模，我们建议使用一个交互式的可视界面，它允许安全专家识别语义上有意义的交互集群。这些集群整合了领域知识，并通过知情的机器学习实现更精确的行为建模。我们在包含与登录和安全服务器的管理界面的交互日志的数据集上评估了所提出的方法。我们的实证结果表明，知情建模能够捕捉正常行为，然后可以用于检测异常行为。",
                    "title_zh": "通过知情行为聚类和建模进行系统误用检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00012",
                    "title": "Adversarial Video Captioning",
                    "authors": "Suman Kalyan Adari, Washington Garcia, Kevin R. B. Butler",
                    "abstract": "In recent years, developments in the field of computer vision have allowed deep learning-based techniques to surpass human-level performance. However, these advances have also culminated in the advent of adversarial machine learning techniques, capable of launching targeted image captioning attacks that easily fool deep learning models. Although attacks in the image domain are well studied, little work has been done in the video domain. In this paper, we show it is possible to extend prior attacks in the image domain to the video captioning task, without heavily affecting the video's playback quality. We demonstrate our attack against a state-of-the-art video captioning model, by extending a prior image captioning attack known as Show and Fool. To the best of our knowledge, this is the first successful method for targeted attacks against a video captioning model, which is able to inject 'subliminal' perturbations into the video stream, and force the model to output a chosen caption with up to 0.981 cosine similarity, achieving near-perfect similarity to chosen target captions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，计算机视觉领域的发展已经允许基于深度学习的技术超越人类水平的性能。然而，这些进步也最终导致了对抗性机器学习技术的出现，这些技术能够发起有针对性的图像字幕攻击，轻松欺骗深度学习模型。尽管在图像领域的攻击已经得到了很好的研究，但是在视频领域的研究却很少。在本文中，我们展示了将图像域中的先前攻击扩展到视频字幕任务是可能的，而不会严重影响视频的回放质量。我们通过扩展先前被称为“表演和愚弄”的图像字幕攻击来展示我们对最先进的视频字幕模型的攻击。据我们所知，这是第一个针对视频字幕模型的目标攻击的成功方法，它能够将“潜意识”扰动注入视频流，并迫使模型输出具有高达0.981余弦相似性的选定字幕，实现与选定目标字幕的近乎完美的相似性。",
                    "title_zh": "对抗性视频字幕"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00014",
                    "title": "Malware Evasion Attack and Defense",
                    "authors": "Yonghong Huang, Utkarsh Verma, Celeste Fralick, Gabriel Infante-Lopez, Brajesh Kumar, Carl Woodward",
                    "abstract": "Machine learning (ML) classifiers are vulnerable to adversarial examples. An adversarial example is an input sample which is slightly modified to induce misclassification in an ML classifier. In this work, we investigate white-box and grey-box evasion attacks to an ML-based malware detector and conduct performance evaluations in a real-world setting. We compare the defense approaches in mitigating the attacks. We propose a framework for deploying grey-box and black-box attacks to malware detection systems.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1904.05747"
                    },
                    "abstract_zh": "机器学习(ML)分类器容易受到对立例子的攻击。一个相反的例子是一个输入样本，它被稍微修改以引起ML分类器中的错误分类。在本文中，我们研究了基于ML的恶意软件检测器的白盒和灰盒规避攻击，并在真实环境中进行了性能评估。我们比较了减轻攻击的防御方法。我们提出了一个将灰盒和黑盒攻击部署到恶意软件检测系统的框架。",
                    "title_zh": "恶意软件规避攻击和防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00015",
                    "title": "Mixed Strategy Game Model Against Data Poisoning Attacks",
                    "authors": "Yifan Ou, Reza Samavi",
                    "abstract": "In this paper we use game theory to model poisoning attack scenarios. We prove the non-existence of pure strategy Nash Equilibrium in the attacker and defender game. We then propose a mixed extension of our game model and an algorithm to approximate the Nash Equilibrium strategy for the defender. We then demonstrate the effectiveness of the mixed defence strategy generated by the algorithm, in an experiment.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1906.02872"
                    },
                    "abstract_zh": "在本文中，我们使用博弈论来模拟中毒攻击场景。我们证明了攻击者和防御者博弈中纯策略纳什均衡的不存在性。然后，我们提出了一个混合扩展的博弈模型和一个算法来逼近防守方的纳什均衡策略。然后，我们在实验中证明了该算法产生的混合防御策略的有效性。",
                    "title_zh": "对抗数据中毒攻击的混合策略博弈模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00016",
                    "title": "NV-DNN: Towards Fault-Tolerant DNN Systems with N-Version Programming",
                    "authors": "Hui Xu, Zhuangbin Chen, Weibin Wu, Zhi Jin, Sy-Yen Kuo, Michael R. Lyu",
                    "abstract": "Employing deep learning algorithms in real-world applications becomes a trend. However, a bottleneck that impedes their further adoption in safety-critical systems is the reliability issue. It is challenging to develop reliable neural network models as the theory of deep learning has not yet been well-established and neural network models are very sensitive to data perturbations. Inspired by the classic paradigm of N-version programming for fault tolerance, this paper investigates the feasibility of developing fault-tolerant deep learning systems through model redundancy. We hypothesize that if we train several simplex models independently, these models are unlikely to produce erroneous results for the same test cases. In this way, we can design a fault-tolerant system whose output is determined by all these models cooperatively. We propose several independence factors that can be introduced for generating multiple versions of neural network models, including training, network, and data. Experimental results on MNIST and CIFAR-10 both verify that our approach can improve the fault-tolerant ability of a deep learning system. Particularly, independent data for training plays the most significant role in generating multiple models sharing the least mutual faults.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在现实世界的应用中采用深度学习算法成为一种趋势。然而，阻碍其在安全关键系统中进一步采用的瓶颈是可靠性问题。开发可靠的神经网络模型具有挑战性，因为深度学习的理论尚未完全建立，并且神经网络模型对数据扰动非常敏感。受经典的N版本容错编程范式的启发，本文研究了通过模型冗余开发容错深度学习系统的可行性。我们假设，如果我们独立地训练几个单纯形模型，这些模型不太可能对相同的测试用例产生错误的结果。这样，我们可以设计一个容错系统，其输出由所有这些模型共同决定。我们提出了几个独立的因素，可以引入生成多个版本的神经网络模型，包括训练，网络和数据。在MNIST和CIFAR-10上的实验结果都验证了该方法能够提高深度学习系统的容错能力。特别地，用于训练的独立数据在生成共享最少相互错误的多个模型中起着最重要的作用。",
                    "title_zh": "NV-DNN:用N版本程序设计实现容错DNN系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00017",
                    "title": "N-Version Machine Learning Models for Safety Critical Systems",
                    "authors": "Fumio Machida",
                    "abstract": "Quality control of machine learning systems is a fundamental challenge in industries to provide intelligent services or products using machine learning. While recent advances in machine learning algorithms substantially improve the performance of intelligent tasks such as object recognition, their outputs are essentially stochastic and very sensitive to input data. Such an output uncertainty is a big obstacle to ensure the quality of safety critical applications like autonomous vehicle and hence architectural design to mitigate the impact of error output becomes a great importance. In this paper, we propose N-version machine learning architecture that aims to improve system reliability against probabilistic outputs of individual machine learning modules. The key idea of this architecture is exploiting two kinds of diversities; input diversity and model diversity. Our study first formally defines these diversity metrics and analytically shows the improved reliability by N-version machine learning architecture. Since we treat a machine learning module as a black-box, the proposed architecture and the reliability property are generally applicable to any machine learning algorithms and applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "机器学习系统的质量控制是使用机器学习提供智能服务或产品的行业中的一个基本挑战。虽然机器学习算法的最新进展大大提高了智能任务(如对象识别)的性能，但它们的输出本质上是随机的，并且对输入数据非常敏感。这种输出不确定性是确保自动驾驶汽车等安全关键应用质量的一大障碍，因此减轻错误输出影响的架构设计变得非常重要。在本文中，我们提出了N版本的机器学习架构，旨在提高系统的可靠性对个别机器学习模块的概率输出。该架构的核心思想是利用两种多样性；输入多样性和模型多样性。我们的研究首先正式定义了这些多样性度量，并分析性地显示了N版本机器学习架构提高的可靠性。因为我们将机器学习模块视为黑盒，所以所提出的架构和可靠性属性通常适用于任何机器学习算法和应用。",
                    "title_zh": "安全关键系统的n版本机器学习模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00018",
                    "title": "Novelty Detection via Network Saliency in Visual-Based Deep Learning",
                    "authors": "Valerie Chen, Man-Ki Yoon, Zhong Shao",
                    "abstract": "Machine-learning driven safety-critical autonomous systems, such as self-driving cars, must be able to detect situations where its trained model is not able to make a trustworthy prediction. Often viewed as a black-box, it is non-obvious to determine when a model will make a safe decision and when it will make an erroneous, perhaps life-threatening one. Prior work on novelty detection deal with highly structured data and do not translate well to dynamic, real-world situations. This paper proposes a multi-step framework for the detection of novel scenarios in vision-based autonomous systems by leveraging information learned by the trained prediction model and a new image similarity metric. We demonstrate the efficacy of this method through experiments on a real-world driving dataset as well as on our in-house indoor racing environment.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1906.03685"
                    },
                    "abstract_zh": "机器学习驱动的安全关键自主系统，如自动驾驶汽车，必须能够检测其训练模型无法做出可信预测的情况。通常被视为一个黑箱，确定一个模型什么时候会做出安全的决策，什么时候会做出错误的，甚至可能危及生命的决策是不明显的。先前关于新颖性检测的工作处理高度结构化的数据，且不能很好地转化为动态的真实世界的情况。本文提出了一个多步骤框架，用于在基于视觉的自主系统中检测新场景，该框架利用了由训练的预测模型和新的图像相似性度量学习到的信息。我们通过在真实世界驾驶数据集和我们的内部室内赛车环境上的实验证明了这种方法的有效性。",
                    "title_zh": "基于视觉的深度学习中基于网络显著性的新颖性检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00020",
                    "title": "Using Intuition from Empirical Properties to Simplify Adversarial Training Defense",
                    "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah",
                    "abstract": "Due to the surprisingly good representation power of complex distributions, neural network (NN) classifiers are widely used in many tasks which include natural language processing, computer vision and cyber security. In recent works, people noticed the existence of adversarial examples. These adversarial examples break the NN classifiers' underlying assumption that the environment is attack free and can easily mislead fully trained NN classifier without noticeable changes. Among defensive methods, adversarial training is a popular choice. However, original adversarial training with single-step adversarial examples (Single-Adv) can not defend against iterative adversarial examples. Although adversarial training with iterative adversarial examples (Iter-Adv) can defend against iterative adversarial examples, it consumes too much computational power and hence is not scalable. In this paper, we analyze Iter-Adv techniques and identify two of their empirical properties. Based on these properties, we propose modifications which enhance Single-Adv to perform competitively as Iter-Adv. Through preliminary evaluation, we show that the proposed method enhances the test accuracy of state-of-the-art (SOTA) Single-Adv defensive method against iterative adversarial examples by up to 16.93% while reducing its training cost by 28.75%.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1906.11729"
                    },
                    "abstract_zh": "由于复杂分布令人惊讶的良好表示能力，神经网络分类器被广泛应用于许多任务，包括自然语言处理、计算机视觉和网络安全。在最近的作品中，人们注意到了对立例子的存在。这些对立的例子打破了神经网络分类器的基本假设，即环境是不受攻击的，并且可以容易地误导完全训练的神经网络分类器而没有明显的变化。在防守方法中，对抗性训练是一种受欢迎的选择。然而，使用单步对抗示例的原始对抗训练(Single-Adv)无法防御迭代对抗示例。虽然使用迭代对抗示例的对抗训练(Iter-Adv)可以防御迭代对抗示例，但是它消耗了太多的计算能力，因此不可扩展。在本文中，我们分析了Iter-Adv技术，并确定了它们的两个经验性质。基于这些性质，我们提出了增强Single-Adv与Iter-Adv竞争性能的修改。通过初步评估，我们表明所提出的方法将最先进的(SOTA) Single-Adv防御方法对迭代对抗示例的测试精度提高了16.93%，同时降低了28.75%的训练成本。",
                    "title_zh": "利用来自经验性质的直觉来简化对抗性训练辩护"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00021",
                    "title": "Component-Level ASIL Decomposition for Automotive Architectures",
                    "authors": "Alessandro Frigerio, Bart Vermeulen, Kees Goossens",
                    "abstract": "The Automotive industry is evolving towards a more electronics-assisted driving and self-driving functionality. The addition of complex subsystems has a great impact on the current vehicle architectures, leading to safety concerns. In this work we present a technique that follows the ISO 26262: Road Vehicles - Functional Safety standard to introduce redundancy in the architecture by using ASIL decomposition, and perform a safety analysis of the modelled system. A three-layer model is used to describe the application, the resources, and the physical space of the vehicle. In this paper we introduce novel model transformations to replicate parts of the application following ASIL decomposition rules. Finally, we perform a cost analysis and a probabilistic fault tree analysis on the architecture, making a comparison between different possible solutions. The advantages of these techniques, such as traceability and scalability, are shown by modelling and analysing the lateral control application of a real truck platooning system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "汽车行业正朝着更具电子辅助驾驶和自动驾驶功能的方向发展。复杂子系统的增加对当前的车辆架构有很大的影响，导致安全问题。在这项工作中，我们提出了一种遵循ISO 26262:道路车辆-功能安全标准的技术，通过使用ASIL分解在架构中引入冗余，并对模拟系统进行安全分析。三层模型用于描述应用程序、资源和车辆的物理空间。在本文中，我们引入了新的模型转换来复制应用程序中遵循ASIL分解规则的部分。最后，我们对架构进行成本分析和概率故障树分析，比较不同的可能解决方案。这些技术的优点，如可追溯性和可扩展性，通过建模和分析一个真实的卡车队列系统的横向控制应用来显示。",
                    "title_zh": "汽车架构的组件级ASIL分解"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00022",
                    "title": "Autonomous Maneuver Coordination Via Vehicular Communication",
                    "authors": "Wenbo Xu, Alexander Willecke, Martin Wegner, Lars C. Wolf, Rüdiger Kapitza",
                    "abstract": "Autonomous vehicles can make local decisions based on the perception of their environments. However, individual decisions do not always result in the most efficient solution from a global point of view, because of a lack of coordination. To improve the traffic efficiency, multiple autonomous vehicles can be orchestrated in a spontaneous group. This is achieved by a recently proposed Maneuver Coordination service utilizing the vehicular communication. Vehicles equipped with the Maneuver Coordination service can share their planned driving trajectories with others close to them, detect potential conflicts and negotiate a new plan of trajectories. If the negotiation is successful, the vehicles can end up with a cooperative and more efficient joint plan, compared to the individual plans. In this work, we extend the Maneuver Coordination service by designing a coordination protocol for the negotiation. Our protocol can ensure an agreement and prevent conflicting maneuver changes. The negotiation procedure also takes potential network failures into account and keeps the impact of such failures at a relatively low level. We tested our approach on a V2X simulation framework. The evaluation results of a lane-join scenario show that the coordinated plan after negotiation has 50% less accumulated time loss compared to the default right-of-way rules.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动驾驶汽车可以根据对环境的感知做出局部决策。然而，由于缺乏协调，从全球角度来看，单个决定并不总能产生最有效的解决方案。为了提高交通效率，可以将多辆自动驾驶车辆组织成一个自发的小组。这是通过最近提出的利用车辆通信的机动协调服务来实现的。配备了机动协调服务的车辆可以与附近的其他车辆共享其计划的驾驶轨迹，检测潜在的冲突并协商新的轨迹计划。如果协商成功，车辆最终可以得到一个合作的、比单个计划更有效的联合计划。在这项工作中，我们通过为协商设计一个协调协议来扩展机动协调服务。我们的协议可以确保一个协议，并防止冲突的机动变化。协商过程还考虑了潜在的网络故障，并将这种故障的影响保持在相对较低的水平。我们在V2X模拟框架上测试了我们的方法。车道加入场景的评估结果表明，与默认的通行权规则相比，协商后的协调计划的累计时间损失减少了50%。",
                    "title_zh": "经由车辆通信的自主机动协调"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00023",
                    "title": "Reliability-Driven Task Assignment in Vehicular Crowdsourcing: A Matching Game",
                    "authors": "Talal Halabi, Mohammad Zulkernine",
                    "abstract": "Vehicular crowdsourcing is an emerging mobile sensing-based paradigm in which a service platform manages the allocation of data collection and processing tasks to vehicles according to their itinerary, expected response time, and optimal reward. However, selfish or malicious vehicles may take advantage of the platform to maximize their profit or even attack the deployed sensing applications and compromise their decisions by transmitting unreliable data, which can degrade the quality of delivered services and negatively affect the platform reward and reputation. In this paper, we design a task assignment mechanism for vehicular crowdsourcing based on vehicles' reliability to protect the platform from such threats. First, a beta reputation system is adopted for probabilistic reliability assessment according to vehicles' behavior. Then, a new multi-dimensional task assignment problem, which proves to be NP-complete, is modeled as a many-to-one matching game between the platform and vehicles by defining reliability and reward-based preference functions. Finally, a distributed matching algorithm that aims at maximizing the platform reward by assigning the tasks to reliable participants is presented. The mechanism also achieves privacy-preservability by enabling vehicles to engage in the task allocation process without necessarily unveiling their sensitive information. Results show that the proposed mechanism increases the quality of crowdsourcing services by assigning the tasks to reliable and benign vehicles, and adheres to the scalability requirements of the system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "车辆众包是一种新兴的基于移动传感的范式，其中服务平台根据车辆的行程、预期响应时间和最佳回报管理数据收集和处理任务的分配。然而，自私或恶意的车辆可能会利用平台来最大化其利润，甚至攻击部署的传感应用，并通过传输不可靠的数据来损害其决策，这可能会降低所提供服务的质量，并对平台的回报和声誉产生负面影响。本文设计了一种基于车辆可靠性的车辆众包任务分配机制，以保护平台免受此类威胁。首先，根据车辆行为采用beta信誉系统进行概率可靠性评估。然后，通过定义可靠性和基于奖励的偏好函数，将一个新的多维任务分配问题建模为平台和车辆之间的多对一匹配博弈，该问题被证明是NP完全的。最后，提出了一种分布式匹配算法，通过将任务分配给可靠的参与者来最大化平台回报。该机制还通过使车辆能够参与任务分配过程而不必暴露其敏感信息来实现隐私保护。结果表明，该机制通过将任务分配给可靠和良性的车辆，提高了众包服务的质量，并符合系统的可扩展性要求。",
                    "title_zh": "车辆众包中可靠性驱动的任务分配:匹配博弈"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00024",
                    "title": "Predictive Runtime Simulation for Building Trust in Cooperative Autonomous Systems",
                    "authors": "Emilia Cioroaica, Daniel Schneider, Hanna AlZughbi, Jan Reich, Rasmus Adler, Tobias Braun",
                    "abstract": "Future autonomous systems will also be cooperative systems. They will interact with each other, with traffic infrastructure, with cloud services and with other systems. In such an open ecosystem trust is of fundamental importance, because cooperation between systems is key for many innovation applications and services. Without an adequate notion of trust, as well as means to maintain and use it, the full potential of autonomous systems thus cannot be unlocked. In this paper, we discuss what constitutes trust in autonomous cooperative systems and sketch out a corresponding multifaceted notion of trust. We then go on to discuss a predictive runtime simulation approach as a building block for trust and elaborate on means to secure this approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "未来的自治系统也将是合作系统。它们将相互交互，与交通基础设施交互，与云服务交互，与其他系统交互。在这样一个开放的生态系统中，信任至关重要，因为系统之间的合作是许多创新应用和服务的关键。没有足够的信任概念，以及维护和使用信任的手段，自治系统的全部潜力就无法释放。在本文中，我们讨论了自治协作系统中的信任是由什么构成的，并勾画出一个相应的多方面的信任概念。然后，我们继续讨论预测性运行时模拟方法作为信任的构建模块，并详细说明保护这种方法的方法。",
                    "title_zh": "协作自治系统中建立信任的预测运行时模拟"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2019.00025",
                    "title": "Enabling Security Checking of Automotive ECUs with Formal CSP Models",
                    "authors": "John Heneghan, Siraj Ahmed Shaikh, Jeremy W. Bryans, Madeline Cheah, Paul Wooderson",
                    "abstract": "This paper presents an approach, using the process-algebra CSP, that aims to support systematic security testing of ECU components. An example use case regarding Over-The-Air software updates demonstrates the potential of our approach. Initial results confirm application code implemented in a typical automotive development environment can be translated into machine-readable format for the FDR refinement checker to formally verify security functions and identify any existing security flaws. Although still early stage work, the potential contribution towards automatically model-checking ECU components and, by composing several CSP models, larger systems is encouraging.",
                    "files": {
                        "openAccessPdf": "https://pure.coventry.ac.uk/ws/files/28235259/Binder1.pdf"
                    },
                    "abstract_zh": "本文提出了一种方法，使用进程代数CSP，旨在支持ECU组件的系统安全测试。一个关于无线软件更新的用例展示了我们方法的潜力。初步结果证实，在典型的汽车开发环境中实现的应用代码可以被翻译成机器可读的格式，以便FDR精化检查器正式验证安全功能并识别任何现有的安全缺陷。尽管仍处于早期阶段，但对自动模型检查ECU组件的潜在贡献，以及通过组成几个CSP模型，更大的系统是令人鼓舞的。",
                    "title_zh": "支持使用正式CSP模型对汽车ECU进行安全检查"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2019s.html",
            "conf_title": "49th DSN 2019: Portland, OR, USA - Supplemental Volume",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8792825/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00006",
                    "title": "Automatically Validating the Effectiveness of Software Diversity Schemes",
                    "authors": "Daniel M. Kelly, Christopher C. Wellons, Joel Coffman, Andrew S. Gearhart",
                    "abstract": "Software diversity promises to invert the current balance of power in cybersecurity by preventing exploit reuse. Nevertheless, the comparative evaluation of diversity techniques has received scant attention. In ongoing work, we use the DARPA Cyber Grand Challenge (CGC) environment to assess the effectiveness of diversifying compilers in mitigating exploits. Our approach provides a quantitative comparison of diversity strategies and demonstrates wide variation in their effectiveness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件多样性有望通过防止漏洞重用来逆转当前网络安全中的力量平衡。然而，多样性技术的比较评估很少受到关注。在正在进行的工作中，我们使用DARPA网络大挑战(CGC)环境来评估多样化编译器在减少利用方面的有效性。我们的方法提供了多样性战略的定量比较，并证明了其有效性的广泛差异。",
                    "title_zh": "自动验证软件多样性方案的有效性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00007",
                    "title": "Privacy-Preserving Deep Learning Computation for Geo-Distributed Medical Big-Data Platforms",
                    "authors": "Joohyung Jeon, Junhui Kim, Joongheon Kim, Kwangsoo Kim, Aziz Mohaisen, Jong-Kook Kim",
                    "abstract": "This paper proposes a distributed deep learning framework for privacy-preserving medical data training. In order to avoid patients' data leakage in medical platforms, the hidden layers in the deep learning framework are separated and where the first layer is kept in platform and others layers are kept in a centralized server. Whereas keeping the original patients' data in local platforms maintain their privacy, utilizing the server for subsequent layers improves learning performance by using all data from each platform during training.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2001.02932"
                    },
                    "abstract_zh": "提出了一种用于隐私保护医学数据训练的分布式深度学习框架。为了避免医疗平台中患者的数据泄露，深度学习框架中的隐藏层被分离，其中第一层保存在平台中，其他层保存在中央服务器中。尽管将原始患者数据保存在本地平台中维护了他们的隐私，但是通过在训练期间使用来自每个平台的所有数据，将服务器用于后续层提高了学习性能。",
                    "title_zh": "面向地理分布式医疗大数据平台的隐私保护深度学习计算"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00008",
                    "title": "A Quantitative Approach for Medical Imaging Device Security Assessment",
                    "authors": "Pingchuan Ma, Zhiqiang Wang, Xiali Hei, Xiaoxiang Zou, Jianyi Zhang, Qixu Liu, Xin Lyu, Zihan Zhuo",
                    "abstract": "Medical imaging devices play a fundamental role in e-health, and threats to them can endanger patients' privacy and safety. Government agencies in many countries have issued guidance for pre-and post-market security management. However, these methods suffer from bias and low efficiency. In this paper, we design a list of criteria and propose a Fuzzy Analytic Hierarchy Process-based model for fine-grained security assessment of medical imaging devices. Finally, a case study is presented to illustrate the steps involved in our model.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "医疗成像设备在电子医疗中发挥着重要作用，对它们的威胁会危及患者的隐私和安全。许多国家的政府机构发布了上市前和上市后安全管理指南。然而，这些方法存在偏差且效率低。在本文中，我们设计了一系列标准，并提出了一个基于模糊层次分析法的医学成像设备细粒度安全评估模型。最后，给出了一个案例研究来说明我们的模型所涉及的步骤。",
                    "title_zh": "医学影像设备安全性评估的定量方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00009",
                    "title": "The STAR-Guardian Network for the Protection of Long-Life Cyber-Physical Systems",
                    "authors": "Algirdas V. Avizienis, Rimas Avizienis, Audrius V. Avizienis",
                    "abstract": "The first processor to detect errors and to initiate recovery of a computing system was the TARP (Test-And-Repair-Processor) of the JPL-STAR (Self-Testing-And-Repairing) computer. The STAR-Guardian (SG) is a successor of the TARP. The SG is a network of Guard processors that provides fault tolerance services to closed cyber-physical systems with long life requirements, called Clients. The architecture of the SG is summarized and the properties of the SG that offer advantages in the protection of Clients are identified.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "第一个检测错误并开始恢复计算系统的处理器是JPL星(自我测试和修复)计算机的TARP(测试和修复处理器)。STAR-Guardian是TARP的继任者。SG是一个警卫处理器网络，为具有长寿命要求的封闭网络物理系统(称为客户端)提供容错服务。总结了SG的体系结构，并确定了在保护客户端方面具有优势的SG的属性。",
                    "title_zh": "用于保护长寿命网络物理系统的恒星守护者网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00010",
                    "title": "Privacy and Security of Connected Vehicles in Intelligent Transportation System",
                    "authors": "Alireza Jolfaei, Krishna Kant",
                    "abstract": "The paper considers data security and privacy issues in intelligent transportation systems which involve data streams coming out from individual vehicles to road side units. In this environment, there are issues in regards to the scalability of key management and computation limitations at the edge of the network. To address these issues, we suggest the formation of groups in the vehicular layer, where a group leader is assigned to communicate with group members and the road side unit. We propose a lightweight permutation mechanism for preserving the confidentiality and privacy of sensory data.",
                    "files": {
                        "openAccessPdf": "https://researchonline.federation.edu.au/vital/access/services/Download/vital:14230/SOURCE1"
                    },
                    "abstract_zh": "本文考虑了智能交通系统中的数据安全和隐私问题，涉及到从单个车辆到路边单元的数据流。在这种环境中，存在关于密钥管理的可扩展性和网络边缘的计算限制的问题。为了解决这些问题，我们建议在车辆层组建小组，其中指派一名组长与小组成员和路侧单位进行沟通。我们提出了一种轻量级的置换机制来保护感觉数据的机密性和隐私性。",
                    "title_zh": "智能交通系统中互联车辆的隐私和安全"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00011",
                    "title": "Towards Cognitive Security Defense from Data",
                    "authors": "Marcello Cinque, Domenico Cotroneo, Antonio Pecchia",
                    "abstract": "IT organizations rely on a variety of independent security monitors and data sources to develop situational awareness for detecting and responding to security incidents. In spite of the advances in Security Information and Event Management (SIEM) for handling monitoring data in production environments, computer defense still depends on many cognitive human processes. In this context, having machines doing part of the cognitive work in lieu of humans is by now a real necessity. We present our framework towards the vision of cognitive SIEM, its building components and ongoing work on the topic.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "IT组织依靠各种独立的安全监视器和数据源来发展态势感知能力，以检测和响应安全事件。尽管安全信息和事件管理(SIEM)在处理生产环境中的监控数据方面取得了进步，但计算机防御仍然依赖于许多认知人类过程。在这种背景下，让机器代替人类做部分认知工作是一种现实的需要。我们将向认知SIEM的愿景、其构建组件和正在进行的工作展示我们的框架。",
                    "title_zh": "从数据走向认知安全防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00012",
                    "title": "Towards Predicting the Impact of Roll-Forward Failure Recovery for HPC Applications",
                    "authors": "Bo Fang, Jieyang Chen, Karthik Pattabiraman, Matei Ripeanu, Sriram Krishnamoorthy",
                    "abstract": "The roll-forward recovery schemes on HPC systems implicitly trade off faster time to solution for higher risk: as it usually performs a probabilistic repair, this may cause further failures such as SDCs. It is essential for users to be able to reason about the impact of a particular repair exercised by the scheme. Towards this goal, we identify two research questions aiming to determine the outcome of a repair either at the failure point or at the end of the execution. For the former, we propose a promising hybrid approach that combines machine learning and error propagation analysis techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "HPC系统上的前滚恢复方案隐含地以更快的解决时间换取更高的风险:由于它通常执行概率性修复，这可能导致进一步的故障，如SDCs。对于用户来说，能够对该方案实施的特定修复的影响进行推理是至关重要的。为此，我们确定了两个研究问题，旨在确定修复在故障点或执行结束时的结果。对于前者，我们提出了一个有前途的混合方法，结合机器学习和错误传播分析技术。",
                    "title_zh": "预测前滚故障恢复对HPC应用程序的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00013",
                    "title": "SDN-Based IP Shuffling Moving Target Defense with Multiple SDN Controllers",
                    "authors": "Jargalsaikhan Narantuya, Seunghyun Yoon, Hyuk Lim, Jin-Hee Cho, Dong Seong Kim, Terrence J. Moore, Frederica Free-Nelson",
                    "abstract": "Conventional SDN-based MTD techniques have been mainly developed with a single SDN controller which exposes a single point of failure as well as raises a scalability issue for large-scale networks in achieving both security and performance. The use of multiple SDN controllers has been proposed to ensure both performance and security of SDN-based MTD systems for large-scale networks; however, the effect of using multiple SDN controllers has not been investigated in the state-of-the-art research. In this paper, we propose the SDN based MTD architecture using multiple SDN controllers and validate their security effect (i.e., attack success probability) by implementing an IP shuffling MTD in a testbed using ONOS SDN controllers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传统的基于SDN的MTD技术主要是利用单个SDN控制器开发的，这暴露了单个故障点，并且在实现安全性和性能方面提出了大规模网络的可扩展性问题。已经提出使用多个SDN控制器来确保用于大规模网络的基于SDN的MTD系统的性能和安全性；然而，使用多个SDN控制器的效果尚未在最新研究中进行调查。在本文中，我们提出了使用多个SDN控制器的基于SDN的MTD架构，并通过在使用ONOS SDN控制器的测试床中实现IP洗牌MTD来验证其安全效果(即，攻击成功概率)。",
                    "title_zh": "基于SDN的多SDN控制器IP洗牌移动目标防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00014",
                    "title": "Consistent BFT Performance for Blockchains",
                    "authors": "Mohammad M. Jalalzai, Costas Busch, Golden G. Richard III",
                    "abstract": "There have been numerous solutions to improve the message complexity of Byzantine Fault Tolerant (BFT) protocols. Unfortunately, these solutions do not guarantee consistent performance and fall back to quadratic message complexity if a certain threshold of node failures is encountered in the network. Furthermore, reliance on a single primary to forward a proposed blockchain block to all replicas in the network can provide a potential attack vector, in which the primary can create discrepancies among histories of honest replicas. This results in increased latency during the view change (denial of service). Therefore, we propose a BFT-based protocol that guarantees consistent performance and shifts the reliance from a single primary to broadcast a candidate block to a sub-committee of replicas.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "已经有许多解决方案来改善拜占庭容错(BFT)协议的消息复杂性。不幸的是，这些解决方案不能保证一致的性能，并且如果在网络中遇到一定阈值的节点故障，则退回到二次消息复杂度。此外，依赖单个主设备将建议的区块链块转发给网络中的所有复制品会提供潜在的攻击媒介，其中主设备会在诚实复制品的历史中产生差异。这导致视图更改期间的延迟增加(拒绝服务)。因此，我们提出了一个基于BFT的协议，它保证了一致的性能，并将对单个主节点广播候选块的依赖转移到副本的子委员会。",
                    "title_zh": "区块链始终如一的BFT表现"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00015",
                    "title": "Bayesian Neural Network Based Encrypted Traffic Classification using Initial Handshake Packets",
                    "authors": "Jiwon Yang, Jargalsaikhan Narantuya, Hyuk Lim",
                    "abstract": "Traffic classification has garnered significant attention from researchers owing to its applicability in a wide range of network management systems. The identification and categorization of network traffic are usually based on various parameters such as the port numbers, payload signatures, and statistical features. These methods face difficulty in classifying encrypted traffic flows for secure communication. We propose a novel payload-based classification that exploits unencrypted handshake packets, which are exchanged between the end hosts for transport layer security establishment. We use Bayesian neural network as the classifier, which takes cipher suite, compression method, and TLS extension information of the handshake packets as the inputs. We conducted comparative experiments to show that the proposed method outperforms other traditional payload-based classifiers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于流量分类在广泛的网络管理系统中的适用性，它引起了研究者的极大关注。网络流量的识别和分类通常基于各种参数，如端口号、有效负载签名和统计特征。这些方法在分类用于安全通信的加密业务流时面临困难。我们提出了一种新的基于有效载荷的分类方法，该方法利用了未加密的握手包，这些握手包在终端主机之间进行交换，以建立传输层安全性。我们使用贝叶斯神经网络作为分类器，它以密码组、压缩方法和握手包的TLS扩展信息作为输入。我们进行了对比实验，以表明所提出的方法优于其他传统的基于有效载荷的分类器。",
                    "title_zh": "使用初始握手包的基于贝叶斯神经网络的加密流量分类"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00016",
                    "title": "P4AIG: Circuit-Level Verification of P4 Programs",
                    "authors": "Mohammad A. Noureddine, Amanda Hsu, Matthew Caesar, Fadi A. Zaraket, William H. Sanders",
                    "abstract": "In this work, we set out to develop P4 AIG, a tool for the static verification of programmable data planes using sequential circuit analysis. P4 AIG targets P4 programs by treating them as hardware pipelines rather than software programs. P4 AIG allows for the circuit-level treatment of P4 programs, a feature not available for traditional software verification techniques. We believe that P4 AIG will exploit the nature of P4 programs to achieve higher scalability in verification.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在这项工作中，我们着手开发P4 AIG，一个利用时序电路分析对可编程数据平面进行静态验证的工具。P4 AIG将P4项目视为硬件管道而非软件程序。P4 AIG允许P4程序的电路级处理，这是传统软件验证技术所不具备的特性。我们相信，P4 AIG将利用P4项目的性质来实现更高的验证可扩展性。",
                    "title_zh": "P4AIG:P4程序的电路级验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00017",
                    "title": "Short-Liveness of Error Propagation in Kernel Can Improve Operating Systems Availability",
                    "authors": "Manabu Sugimoto, Takafumi Kubota, Kenji Kono",
                    "abstract": "The reliability of operating systems is crucial to achieving high availability of computer systems. Unfortunately, Linux, a widely used operating system, is far from bug-free. Some recent studies point out error propagation is very short in the kernel and thus most data in the kernel are not corrupt even when a failure occurs. This paper explores the possibility of exploiting the property of \"short-liveness\" of error propagation in the kernel to improve the operating system availability. Our novel design of the memory management scheme allows us to recover the kernel by removing inconsistent data structures corrupted during error propagations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "操作系统的可靠性对于实现计算机系统的高可用性至关重要。不幸的是，Linux，一个广泛使用的操作系统，远非没有错误。最近的一些研究指出，内核中的错误传播非常短，因此即使发生故障，内核中的大多数数据也不会损坏。本文探讨了利用内核中错误传播的“短活性”特性来提高操作系统可用性的可能性。我们的内存管理方案的新颖设计允许我们通过移除在错误传播期间损坏的不一致的数据结构来恢复内核。",
                    "title_zh": "内核中错误传播的短活性可以提高操作系统的可用性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00018",
                    "title": "Towards a Bayesian Approach for Assessing Fault Tolerance of Deep Neural Networks",
                    "authors": "Subho S. Banerjee, James Cyriac, Saurabh Jha, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer",
                    "abstract": "This paper presents Bayesian Deep Learning based Fault Injection (BDLFI), a novel methodology for fault injection in neural networks (NNs) and more generally differentiable programs. BDLFI uses (1) Bayesian Deep Learning to model the propagation of faults, and (2) Markov Chain Monte Carlo inference to quantify the effect of faults on the outputs of a NN. We demonstrate BDLFI on two representative networks and present our results that challenge pre-existing results in the field.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了基于贝叶斯深度学习的故障注入(BDLFI)，这是一种用于神经网络(NNs)和更一般的可微分程序中的故障注入的新方法。BDLFI使用(1)贝叶斯深度学习来模拟故障的传播，以及(2)马尔可夫链蒙特卡罗推断来量化故障对神经网络输出的影响。我们在两个有代表性的网络上演示了BDLFI，并展示了我们的结果，挑战了该领域中已有的结果。",
                    "title_zh": "评估深度神经网络容错性的贝叶斯方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00019",
                    "title": "Retrospectively Documenting SAFEGUARD's Possession of the Overarching Properties",
                    "authors": "Mallory Suzanne Graydon",
                    "abstract": "Software-intensive aviation and space systems are typically developed in accordance with recognized development process, safety analysis, and software development standards such as RTCA DO-178C and SAE ARP 4754A. In 2015, the FAA invited selected participants to a workshop on streamlining assurance processes [1]. This resulted in the assembly of a working group that has drafted a set of Overarching Properties (OPs) for the airworthiness approval of airborne systems. The completion of this draft raises a question: How should applicants demonstrate satisfaction of the OPs? To define and assess a candidate answer, we have prepared retrospective documentation showing that a specimen software system possesses the OPs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件密集型航空和航天系统通常根据公认的开发过程、安全分析和软件开发标准(如RTCA DO-178C和SAE ARP 4754A)进行开发。2015年，美国联邦航空局邀请选定的参与者参加关于简化保证流程的研讨会[1]。这导致了一个工作组的成立，该工作组已经为机载系统的适航性批准起草了一套总体特性(OPs)。这份初稿完成后，提出了一个问题:申请人应如何证明对老年退休金计划感到满意？为了定义和评估一个候选答案，我们准备了回顾性的文档，表明一个样本软件系统拥有OPs。",
                    "title_zh": "追溯性地记录保障措施对支配性财产的占有"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00020",
                    "title": "On the Trend of Resilience for GPU-Dense Systems",
                    "authors": "Kyushick Lee, Michael B. Sullivan, Siva Kumar Sastry Hari, Timothy Tsai, Stephen W. Keckler, Mattan Erez",
                    "abstract": "Emerging high-performance computing (HPC) systems show a tendency towards heterogeneous nodes that are dense with accelerators such as GPUs. They offer higher computational power at lower energy and cost than homogeneous CPU-only nodes. While an accelerator-rich machine reduces the total number of compute nodes required to achieve a performance target, a single node becomes susceptible to accelerator failures as well as sharing intra-node resources with many accelerators. Such failures must be recovered by end-to-end resilience schemes such as checkpoint-restart. However, preserving a large amount of local state within accelerators for checkpointing incurs significant overhead. This trend reveals a new challenge for the resilience in accelerator-dense systems. We study its impact in multi-level checkpointing systems and with burst buffers. We quantify the system-level efficiency for resilience, sweeping the failure rate, system scale, and GPU density. Our multi-level checkpoint-restart model shows that the efficiency begins to drop at a 16:1 GPU-to-CPU ratio in a 3.6 EFLOP system and a ratio of 64:1 degrades overall system efficiency by 5%. Furthermore, we quantify the system-level impact of possible design considerations for the resilience in GPU-dense systems to mitigate this challenge.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "新兴的高性能计算(HPC)系统显示出向异构节点发展的趋势，这些异构节点密集分布着GPU等加速器。与同构的纯CPU节点相比，它们以更低的能耗和成本提供了更高的计算能力。虽然加速器丰富的机器减少了实现性能目标所需的计算节点总数，但是单个节点容易受到加速器故障的影响，并且与许多加速器共享节点内资源。这种故障必须通过端到端弹性方案(如检查点重启)来恢复。然而，在加速器中为检查点保存大量的本地状态会导致巨大的开销。这一趋势揭示了加速器密集型系统的弹性面临的新挑战。我们研究了它在多级检查点系统和突发缓冲区中的影响。我们量化了弹性的系统级效率，包括故障率、系统规模和GPU密度。我们的多级检查点重启模型显示，在3.6 EFLOP系统中，当GPU与CPU的比率为16:1时，效率开始下降，当比率为64:1时，整体系统效率下降5%。此外，我们量化了GPU密集型系统中弹性的可能设计考虑因素的系统级影响，以缓解这一挑战。",
                    "title_zh": "GPU密集型系统的弹性趋势研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00021",
                    "title": "On the Estimation of Complex Circuits Functional Failure Rate by Machine Learning Techniques",
                    "authors": "Thomas Lange, Aneesh Balakrishnan, Maximilien Glorieux, Dan Alexandrescu, Luca Sterpone",
                    "abstract": "De-Rating or Vulnerability Factors are a major feature of failure analysis efforts mandated by today's Functional Safety requirements. Determining the Functional De-Rating of sequential logic cells typically requires computationally intensive fault-injection simulation campaigns. In this paper a new approach is proposed which uses Machine Learning to estimate the Functional De-Rating of individual flip-flops and thus, optimising and enhancing fault injection efforts. Therefore, first, a set of per-instance features is described and extracted through an analysis approach combining static elements (cell properties, circuit structure, synthesis attributes) and dynamic elements (signal activity). Second, reference data is obtained through first-principles fault simulation approaches. Finally, one part of the reference dataset is used to train the Machine Learning algorithm and the remaining is used to validate and benchmark the accuracy of the trained tool. The intended goal is to obtain a trained model able to provide accurate per-instance Functional De-Rating data for the full list of circuit instances, an objective that is difficult to reach using classical methods. The presented methodology is accompanied by a practical example to determine the performance of various Machine Learning models for different training sizes.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2002.09945"
                    },
                    "abstract_zh": "降额或易损性因素是当今功能安全要求规定的故障分析工作的主要特征。确定时序逻辑单元的功能降额通常需要计算密集型故障注入模拟活动。在本文中，提出了一种新的方法，该方法使用机器学习来估计单个触发器的功能降额，从而优化和增强故障注入工作。因此，首先，通过结合静态元素(单元属性、电路结构、合成属性)和动态元素(信号活动)的分析方法来描述和提取一组每个实例的特征。第二，通过第一原理故障模拟方法获得参考数据。最后，参考数据集的一部分用于训练机器学习算法，剩余部分用于验证和测试训练工具的准确性。预期目标是获得一个经过训练的模型，能够为电路实例的完整列表提供准确的每个实例的功能降额数据，这是使用经典方法难以达到的目标。所提出的方法附有一个实际例子，以确定不同训练规模的各种机器学习模型的性能。",
                    "title_zh": "基于机器学习技术的复杂电路功能失效率估计"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S.2019.00022",
                    "title": "Generation of Stressmarks for Early Stage Soft-Error Modeling",
                    "authors": "Karthik Swaminathan, Ramon Bertran, Hans M. Jacobson, Prabhakar Kudva, Pradip Bose",
                    "abstract": "Early-stage Soft-Error Rate (SER) vulnerability modeling and estimation is essential for all types of processing platforms, ranging from embedded/IoT processors to server-class systems, to ensure reliable and deterministic operation. The objective of such modeling is to provide inputs to designers on the addition of protection features, such as latch hardening, parity protection, ECC and redundancy techniques, for achieving RAS targets without significantly impacting the overall processor area and power. This calls for a systematic methodology, starting from the latch level and moving up to the micro-architecture and architecture level of abstraction. In this paper, we present a methodology that characterizes processor vulnerability and define a metric to effectively quantify this vulnerability. Based on these characterizations, we propose techniques to generate synthetic stressmarks that maximize SER vulnerability for a given processor configuration. We carry out an exploration of these stressmarks across different operating corners for a state-of-the-art POWERTM ISA-based server-class processor. In comparison to single instruction microbenchmarks as well as real workloads from the SPEC-2017 benchmark suite, our stressmarks demonstrate up to 16X increase in vulnerability in terms of our proposed metric.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "从嵌入式/物联网处理器到服务器级系统，早期软错误率(SER)漏洞建模和评估对于所有类型的处理平台至关重要，以确保可靠和确定性的操作。这种建模的目的是向设计者提供关于增加保护功能的输入，例如锁存强化、奇偶保护、ECC和冗余技术，以实现RAS目标，而不会显著影响整体处理器面积和功率。这需要一个系统的方法，从闩锁级别开始，向上移动到微架构和抽象架构级别。在本文中，我们提出了一种表征处理器漏洞的方法，并定义了一种有效量化这种漏洞的度量标准。基于这些特征，我们提出了生成合成应力标记的技术，该合成应力标记对于给定的处理器配置最大化SER脆弱性。我们针对最新的基于POWERTM ISA的服务器级处理器，在不同的操作环境中对这些应力标记进行了探索。与单指令微基准测试以及SPEC-2017基准测试套件中的真实工作负载相比，我们的压力测试表明，根据我们提出的指标，漏洞增加了16倍。",
                    "title_zh": "用于早期软错误建模的应力标记的生成"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2019i.html",
            "conf_title": "49th DSN (Industry Track) 2019: Portland, OR, USA",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8793211/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-Industry.2019.00007",
                    "title": "Detecting Failures of Neural Machine Translation in the Absence of Reference Translations",
                    "authors": "Wenyu Wang, Wujie Zheng, Dian Liu, Changrong Zhang, Qinsong Zeng, Yuetang Deng, Wei Yang, Pinjia He, Tao Xie",
                    "abstract": "Despite getting widely adopted recently, a Neural Machine Translation (NMT) system is often found to produce translation failures in the outputs. Developers have been relying on in-house system testing for quality assurance of NMT. This testing methodology requires human-constructed reference translations as the ground truth (test oracle) for example natural language inputs. The testing methodology has shown benefits of quickly enhancing an NMT system in early development stages. However, in industrial settings, it is desirable to detect translation failures without reliance on reference translations for enabling further improvements on translation quality in both industrial development and production environments. Aiming for a practical and scalable solution to such demand in the industrial settings, in this paper, we propose a new approach for automatically identifying translation failures without requiring reference translations for a translation task. Our approach focuses on a property of natural language translation that can be checked systematically by using information from both the test inputs (i.e., the texts to be translated) and the test outputs (i.e., the translations under inspection) of the NMT system. Our evaluation conducted on real-world datasets shows that our approach can effectively detect property violations as translation failures. By deploying our approach in the translation service of WeChat (a messenger app with more than one billion monthly active users), we show that our approach is both practical and scalable in the industrial settings.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管最近被广泛采用，神经机器翻译(NMT)系统经常被发现在输出中产生翻译失败。开发人员一直依靠内部系统测试来保证NMT的质量。这种测试方法需要人工构建的参考翻译作为基础事实(测试oracle ),例如自然语言输入。测试方法显示了在早期开发阶段快速增强NMT系统的好处。然而，在工业环境中，希望在不依赖参考翻译的情况下检测翻译失败，以便能够在工业开发和生产环境中进一步提高翻译质量。针对工业环境中的这种需求，本文提出了一种不需要参考译文就能自动识别翻译错误的新方法。我们的方法集中于自然语言翻译的一个属性，该属性可以通过使用来自NMT系统的测试输入(即，要翻译的文本)和测试输出(即，被检查的翻译)的信息来系统地检查。我们在真实数据集上进行的评估表明，我们的方法可以有效地检测作为翻译失败的属性违反。通过在微信的翻译服务中部署我们的方法，我们表明我们的方法在工业环境中既实用又可扩展。",
                    "title_zh": "在没有参考翻译的情况下检测神经机器翻译的失败"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-Industry.2019.00008",
                    "title": "A Parser for Deep Packet Inspection of IEC-104: A Practical Solution for Industrial Applications",
                    "authors": "Justyna J. Chromik, Anne Remke, Boudewijn R. Haverkort, Gerard Geist",
                    "abstract": "We present a practical solution for deep packet inspection for IEC-104 SCADA traffic, which can be used in monitoring approaches to ensure the dependable operation of critical systems. We re-implement an outdated parser and extend it to also parse the content of individual IEC-104 packets and to extract information relevant for monitoring and securing the physical processes being controlled. The deep packet inspection framework Spicy was used for the implementation, which allows for easy extensibility in the future. To illustrate the feasibility of the proposed solution, the throughput obtained when using the parser in combination with the monitoring tool Zeek has been evaluated for traces of different lengths. The traces have been captured in an operating electrical distribution field station with a single RTU.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们为IEC-104 SCADA流量提供了一种实用的深度数据包检测解决方案，可用于监控方法，以确保关键系统的可靠运行。我们重新实现了一个过时的解析器，并对其进行了扩展，以解析单个IEC-104数据包的内容，并提取与监控和保护受控物理过程相关的信息。该实施使用了深度数据包检测框架Spicy，这为将来的扩展提供了便利。为了说明所提出的解决方案的可行性，结合使用解析器和监控工具Zeek时获得的吞吐量已经针对不同长度的跟踪进行了评估。这些痕迹是在一个运行中的配电现场站用一个RTU捕获的。",
                    "title_zh": "IEC-104深度包检测解析器:工业应用的实用解决方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-Industry.2019.00009",
                    "title": "Detecting Attacks Against Safety-Critical ADAS Based on In-Vehicle Network Message Patterns",
                    "authors": "Christopher Gutierrez, Marcio Juliato, Shabbir Ahmed, Manoj R. Sastry",
                    "abstract": "Vehicles on the road today are Internet-enabled devices, providing navigation, safety, and entertainment to passengers. It is possible for an attacker to compromise these devices to gain remote access to the in-vehicle network, allowing control of the vehicle. To detect the presence of masqueraded messages, we propose a Message Time-series Intrusion Detection System (MTS IDS), which is based on the principle that ADAS messages exhibit regular (benign) patterns.We demonstrate the feasibility of detecting masquerade injection attacks that attempt to negatively influence Advanced Driver-assistance Systems such as Adaptive Cruise Control (ACC) and Lane Centering Systems (LCS). Our results show a MTS IDS detects masquerade messages against ACC and LCS ADAS systems with F1-scores of 0.9889 and 0.98705, respectively. While no computing system can be completely secure, these results can help increase resilience of ADAS and autonomous vehicles against masquerading attacks, and therefore improve road and passenger safety.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "今天行驶在路上的车辆是支持互联网的设备，为乘客提供导航、安全和娱乐。攻击者有可能损害这些设备以获得对车载网络的远程访问，从而控制车辆。为了检测伪装消息的存在，我们提出了一个消息时间序列入侵检测系统(MTS IDS ),该系统基于ADAS消息显示规则(良性)模式的原理。我们证明了检测伪装注入攻击的可行性，伪装注入攻击试图对高级驾驶员辅助系统产生负面影响，如自适应巡航控制(ACC)和车道居中系统(LCS)。我们的结果显示MTS IDS针对ACC和LCS ADAS系统检测伪装消息，F1分数分别为0.9889和0.98705。虽然没有一个计算系统是完全安全的，但这些结果有助于提高ADAS和自动驾驶汽车抵御伪装攻击的能力，从而提高道路和乘客的安全。",
                    "title_zh": "基于车载网络消息模式的安全关键ADAS攻击检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-Industry.2019.00010",
                    "title": "LAB to SOC: Robust Features for Dynamic Malware Detection",
                    "authors": "Matilda Rhode, Lewis Tuson, Pete Burnap, Kevin Jones",
                    "abstract": "Machine learning models regularly achieve more than 95% accuracy in academic literature for dynamic malware detection problems, but the samples providing the data for these models are rarely shared publicly. This not only creates a benchmarking problem for academic and industry practitioners but could fail to reveal the hidden bias of machine learning models towards data from a particular source. This paper simulates \"lab\" experiments with several filetypes, machine learning algorithms, and features tested using data from two sources to probe the robustness of these models across different test sets. The first source is the same as the training data, the second is a commercial malware dataset provided by an organisation's advanced malware detection methods. These preliminary results indicate that for Windows executable files, widely used API call features are less robust than behavioural metrics such as CPU usage, RAM use, and packets received and transmitted, which give greater consistency in predictive accuracy rates across the different test sets.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在动态恶意软件检测问题的学术文献中，机器学习模型通常可以达到95%以上的准确率，但为这些模型提供数据的样本很少公开共享。这不仅给学术和行业从业者带来了一个基准问题，而且可能无法揭示机器学习模型对特定来源数据的隐藏偏见。本文使用来自两个来源的数据模拟了几个文件类型、机器学习算法和功能的“实验室”实验，以探索这些模型在不同测试集上的健壮性。第一个来源与训练数据相同，第二个来源是由组织的高级恶意软件检测方法提供的商业恶意软件数据集。这些初步结果表明，对于Windows可执行文件，广泛使用的API调用功能不如CPU使用、RAM使用以及接收和传输的数据包等行为指标强大，这些指标在不同测试集的预测准确率方面具有更高的一致性。",
                    "title_zh": "实验室到SOC:强大的动态恶意软件检测功能"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-Industry.2019.00011",
                    "title": "Characterizing and Modeling Reliability of Declustered RAID for HPC Storage Systems",
                    "authors": "Zhi Qiao, Shuwen Liang, Song Fu, Hsing-Bung Chen, Bradley W. Settlemyer",
                    "abstract": "Declustered RAID aims to enhance the recovery performance of storage by shuffling data and parity blocks among all disks (including spares) in a RAID group. All drives in the RAID group participate in data reconstruction. The idea of declustered RAID is promising. However, the performance and reliability of declustered RAIDs in real-world High-Performance Computing (HPC) storage environments have not been thoroughly studied and well understood. With the popularity of the ZFS file system and software RAID used in production data centers, in this paper, we extensively evaluate declustered RAID with regard to the performance of RAID recovery comparing with ZFS RAIDZ. Furthermore, we formally analyze the reliability of declustered RAID in terms of the mean-time-to-data-loss (MTTDL) and discover that improved recovery performance leads to higher storage reliability compared with the traditional RAID.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分散式RAID旨在通过在RAID组中的所有磁盘(包括备用磁盘)之间转移数据和奇偶校验块来增强存储的恢复性能。RAID组中的所有驱动器都参与数据重建。分散突袭的想法很有希望。然而，现实世界的高性能计算(HPC)存储环境中的去集群RAIDs的性能和可靠性还没有被彻底研究和很好理解。随着ZFS文件系统和软件RAID在生产数据中心的普及，在本文中，我们针对RAID恢复性能与ZFS RAIDZ进行了广泛的评估。此外，我们从平均数据丢失时间(MTTDL)的角度对去集群RAID的可靠性进行了形式化分析，发现与传统RAID相比，恢复性能的提高带来了更高的存储可靠性。",
                    "title_zh": "面向高性能计算存储系统的分簇RAID的可靠性表征与建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-Industry.2019.00012",
                    "title": "System Restore in a Multi-cloud Data Pipeline Platform",
                    "authors": "Long Wang, Harigovind V. Ramasamy, Valentina Salapura, Robin Arnold, Xu Wang, Senthil Bakthavachalam, Phil Coulthard, Lee Suprenant, John Timm, Denis Ricard, Richard E. Harper, Ahut Gupta",
                    "abstract": "Data pipeline platforms hosting big data analytics can span multiple clouds. Backup and restore service is typically applied to deal with data corruptions in such platforms. This paper proposes a novel approach to providing consistency to the restored state of a multi-cloud data pipeline platform from its backups, and also presents the performance of the approach demonstrated in a dry run test.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "托管大数据分析的数据管道平台可以跨越多个云。备份和恢复服务通常用于处理这种平台中的数据损坏。本文提出了一种新的方法来为从备份中恢复的多云数据管道平台的状态提供一致性，并介绍了在模拟运行测试中演示的该方法的性能。",
                    "title_zh": "多云数据管道平台中的系统恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-Industry.2019.00013",
                    "title": "Neferion: Time Bound, Fail-Safe and Deterministic Propagation of Network Connectivity Policies Across Large Multi-datacenter Networks",
                    "authors": "Giridhar Appaji Nag Yasa, Neeraj Bisht, Aftab Ahmad Ansari, V. Prasad Reddy Idamakanti, Santhosh Tangudu",
                    "abstract": "Network connectivity policies dictate network communication between virtual instances in a cloud networking environment. Any change to these policies needs to be deterministic (a version of policy needs to be uniformly applied across the network), time-bound (needs to be completed or rolled back in case of failures within a defined SLA) and fail-safe against erroneous policies (application of a faulty policy should not block all communication across the network). Network partitions, inter-geographic network latencies, hardware failures and operator errors pose major challenges to continuous policy update propagation in a deterministic, time-bound and fail-safe manner. In this paper, we describe a new system for controlled propagation of service configurations across large networks called NEFERION. Neferion provides deterministic guarantees in face of network partitions, host server and/or controller downtime by employing gossip membership protocol across the network nodes for local ascertainment of cluster state.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络连接策略规定了云网络环境中虚拟实例之间的网络通信。对这些策略的任何更改都必须是确定性的(一个版本的策略需要在整个网络中统一应用)、有时间限制的(需要在定义的SLA内出现故障时完成或回滚)以及针对错误策略的故障安全(错误策略的应用不应阻止整个网络中的所有通信)。网络分区、地理间网络延迟、硬件故障和操作员错误对以确定的、有时间限制的和故障安全的方式持续传播策略更新提出了重大挑战。在本文中，我们描述了一个新的系统，用于跨大型网络的服务配置的受控传播，称为NEFERION。面对网络分区、主机服务器和/或控制器停机，Neferion通过在网络节点间采用gossip成员协议来本地确定集群状态，从而提供确定性保证。",
                    "title_zh": "Neferion:跨大型多数据中心网络的网络连接策略的限时、故障安全和确定性传播"
                }
            ]
        }
    ],
    "2015": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2015.html",
            "conf_title": "DSN 2015: Rio de Janeiro, Brazil",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7265894/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN.2015.22",
                    "title": "Leveraging State Information for Automated Attack Discovery in Transport Protocol Implementations",
                    "authors": "Samuel Jero, Hyojeong Lee, Cristina Nita-Rotaru",
                    "abstract": "We present a new method for finding attacks in unmodified transport protocol implementations using the specification of the protocol state machine to reduce the search space of possible attacks. Such reduction is obtained by appling malicious actions to all packets of the same type observed in the same state instead of applying them to individual packets. Our method requires knowledge of the packet formats and protocol state machine. We demonstrate our approach by developing SNAKE, a tool that automatically finds performance and resource exhaustion attacks on unmodified transport protocol implementations. SNAKE utilizes virtualization to run unmodified implementations in their intended environments and network emulation to create the network topology. SNAKE was able to find 9 attacks on 2 transport protocols, 5 of which we believe to be unknown in the literature.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了一种在未修改的传输协议实现中发现攻击的新方法，该方法使用协议状态机的规范来减少可能攻击的搜索空间。这种减少是通过将恶意动作应用于在相同状态下观察到的相同类型的所有分组而不是将它们应用于单个分组来获得的。我们的方法需要数据包格式和协议状态机的知识。我们通过开发SNAKE来演示我们的方法，SNAKE是一个工具，它可以自动发现对未修改的传输协议实现的性能和资源耗尽攻击。SNAKE利用虚拟化在目标环境中运行未经修改的实现，并利用网络仿真来创建网络拓扑。SNAKE能够发现对2种传输协议的9种攻击，其中5种我们认为在文献中是未知的。",
                    "title_zh": "在传输协议实现中利用状态信息进行自动攻击发现"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.20",
                    "title": "Δ-Encoding: Practical Encoded Processing",
                    "authors": "Dmitrii Kuvaiskii, Christof Fetzer",
                    "abstract": "Transient and permanent errors in memory and CPUs occur with alarming frequency. Although most of these errors are masked at the hardware level or result in crashes, a non-negligible number of them leads to Silent Data Corruptions (SDCs), i.e., incorrect results of computations. Safety-critical programs require a very high level of confidence that such faults are detected and not propagated to the outside. Unfortunately, state-of-the-art fault detection techniques generally assume a limited Single Event Upset fault model, concentrating only on transient faults. We present ∆-encoding: a software-only approach to detect hardware faults with very high probability. ∆-encoding makes no assumptions on the rate and type of faults. Our approach combines AN codes and duplicated instructions to harden programs against transient and permanent hardware errors. Our evaluation shows that ∆-encoding detects 99.997% of all injected errors with performance slowdown of 2–4 times.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内存和CPU中的瞬时和永久错误以惊人的频率出现。尽管这些错误中的大部分在硬件级别被掩盖或导致崩溃，但其中不可忽略的数量会导致静默数据破坏(SDC)，即不正确的计算结果。安全关键程序需要非常高的置信度来检测此类故障，并且不会传播到外部。不幸的是，现有的故障检测技术通常假设有限的单事件翻转故障模型，仅集中于瞬时故障。我们提出了∑-编码:一种纯软件的方法，以非常高的概率检测硬件故障。∑-编码对故障率和类型不做任何假设。我们的方法结合了一个代码和重复的指令来强化程序，防止暂时和永久的硬件错误。我们的评估显示,∑-编码检测到99.997%的注入错误，性能下降2-4倍。",
                    "title_zh": "δ编码:实际编码处理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.50",
                    "title": "Measuring and Understanding Extreme-Scale Application Resilience: A Field Study of 5, 000, 000 HPC Application Runs",
                    "authors": "Catello Di Martino, William Kramer, Zbigniew Kalbarczyk, Ravishankar K. Iyer",
                    "abstract": "This paper presents an in-depth characterization of the resiliency of more than 5 million HPC application runs completed during the first 518 production days of Blue Waters, a 13.1 petaflop Cray hybrid supercomputer. Unlike past work, we measure the impact of system errors and failures on user applications, i.e., the compiled programs launched by user jobs that can execute across one or more XE (CPU) or XK (CPU+GPU) nodes. The characterization is performed by means of a joint analysis of several data sources, which include workload and error/failure logs. In order to relate system errors and failures to the executed applications, we developed LogDiver, a tool to automate the data pre-processing and metric computation. Some of the lessons learned in this study include: i) while about 1.53% of applications fail due to system problems, the failed applications contribute to about 9% of the production node hours executed in the measured period, i.e., the system consumes computing resources, and system-related issues represent a potentially significant energy cost for the work lost, ii) there is a dramatic increase in the application failure probability when executing full-scale applications: 20x (from 0.008 to 0.162) when scaling XE applications from 10,000 to 22,000 nodes, and 6x (from 0.02 to 0.129) when scaling GPU/hybrid applications from 2000 to 4224 nodes, and iii) the resiliency of hybrid applications is impaired by the lack of adequate error detection capabilities in hybrid nodes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文深入描述了Blue Waters(一台13.1 petaflop Cray混合超级计算机)前518个生产日内完成的500多万次HPC应用运行的弹性。与过去的工作不同，我们测量系统错误和故障对用户应用程序的影响，即由用户作业启动的编译后的程序，这些程序可以在一个或多个XE (CPU)或XK (CPU+GPU)节点上执行。通过对几个数据源(包括工作负载和错误/故障日志)的联合分析来进行表征。为了将系统错误和故障与执行的应用程序相关联，我们开发了LogDiver，这是一个自动化数据预处理和度量计算的工具。在该研究中获得的一些经验教训包括:I)虽然大约1.53%的应用由于系统问题而失败，但是失败的应用贡献了在测量的周期中执行的大约9%的生产节点时间，即，系统消耗计算资源，并且系统相关的问题代表了工作损失的潜在的显著能量成本， ii)执行完整规模的应用程序时，应用程序故障概率会大幅增加:当XE应用程序从10，000个节点扩展到22，000个节点时，故障概率会增加20倍(从0.008到0.162)，当GPU/混合应用程序从2000个节点扩展到4224个节点时，故障概率会增加6倍(从0.02到0.129)，以及iii)混合节点中缺乏足够的错误检测功能会削弱混合应用程序的弹性。",
                    "title_zh": "测量和理解超大规模应用程序的弹性:对5，000，000个HPC应用程序运行的现场研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.52",
                    "title": "Understanding and Exploiting Spatial Properties of System Failures on Extreme-Scale HPC Systems",
                    "authors": "Saurabh Gupta, Devesh Tiwari, Christopher Jantzi, James H. Rogers, Don Maxwell",
                    "abstract": "As we approach exascale, the scientific simulations are expected to experience more interruptions due to increased system failures. Designing better HPC resilience techniques requires understanding the key characteristics of system failures on these systems. While temporal properties of system failures on HPC systems have been well-investigated, there is limited understanding about the spatial characteristics of system failures and its impact on the resilience mechanisms. Therefore, we examine the spatial characteristics and behavior of system failures. We investigate the interaction between spatial and temporal characteristics of failures and its implications for system operations and resilience mechanisms on large-scale HPC systems. We show that system failures have \"spatial locality\" at different granularity in the system, study impact of different failure-types, and investigate the correlation among different failure-types. Finally, we propose a novel scheme that exploits the spatial locality in failures to improve application and system performance. Our evaluation shows that the proposed scheme significantly improves the system performance in a dynamic and production-level HPC system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着我们接近亿亿次级，由于系统故障增加，科学模拟预计将经历更多中断。设计更好的HPC弹性技术需要了解这些系统上系统故障的关键特征。虽然已经对HPC系统上系统故障的时间特性进行了充分的研究，但是对系统故障的空间特性及其对弹性机制的影响的理解有限。因此，我们检查系统故障的空间特征和行为。我们研究了故障的空间和时间特征之间的相互作用及其对大规模HPC系统的系统操作和恢复机制的影响。我们证明了系统故障在系统的不同粒度上具有“空间局部性”，研究了不同故障类型的影响，并考察了不同故障类型之间的相关性。最后，我们提出了一种新的方案，利用故障中的空间局部性来提高应用和系统性能。我们的评估表明，所提出的方案显著提高了动态生产级HPC系统的系统性能。",
                    "title_zh": "理解和利用超大规模高性能计算系统故障的空间特性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.14",
                    "title": "Detection of Early-Stage Enterprise Infection by Mining Large-Scale Log Data",
                    "authors": "Alina Oprea, Zhou Li, Ting-Fang Yen, Sang H. Chin, Sumayah A. Alrwais",
                    "abstract": "Recent years have seen the rise of sophisticated attacks including advanced persistent threats (APT) which pose severe risks to organizations and governments. Additionally, new malware strains appear at a higher rate than ever before. Since many of these malware evade existing security products, traditional defenses deployed by enterprises today often fail at detecting infections at an early stage. We address the problem of detecting early-stage APT infection by proposing a new framework based on belief propagation inspired from graph theory. We demonstrate that our techniques perform well on two large datasets. We achieve high accuracy on two months of DNS logs released by Los Alamos National Lab (LANL), which include APT infection attacks simulated by LANL domain experts. We also apply our algorithms to 38TB of web proxy logs collected at the border of a large enterprise and identify hundreds of malicious domains overlooked by state-of-the-art security products.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1411.5005"
                    },
                    "abstract_zh": "近年来，包括高级持续威胁(APT)在内的复杂攻击不断增加，给组织和政府带来了严重的风险。此外，新的恶意软件以前所未有的速度出现。由于许多这些恶意软件避开了现有的安全产品，因此当今企业部署的传统防御措施通常无法在早期检测到感染。我们通过提出一个基于受图论启发的信念传播的新框架来解决检测早期APT感染的问题。我们证明了我们的技术在两个大型数据集上表现良好。我们在洛斯阿拉莫斯国家实验室(LANL)发布的两个月的DNS日志上实现了高准确性，其中包括由LANL领域专家模拟的APT感染攻击。我们还将我们的算法应用于在大型企业边界收集的38TB web代理日志，并识别出数百个被最先进的安全产品忽略的恶意域。",
                    "title_zh": "通过挖掘大规模日志数据检测早期企业感染"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.34",
                    "title": "LEAPS: Detecting Camouflaged Attacks with Statistical Learning Guided by Program Analysis",
                    "authors": "Zhongshu Gu, Kexin Pei, Qifan Wang, Luo Si, Xiangyu Zhang, Dongyan Xu",
                    "abstract": "Currently cyber infrastructures are facing increasingly stealthy attacks that implant malicious payloads under the cover of benign programs. Existing attack detection approaches based on statistical learning methods may generate misleading decision boundaries when processing noisy data with such a mixture of benign and malicious behaviors. On the other hand, attack detection based on formal program analysis may lack completeness or adaptivity when modelling attack behaviors. In light of these limitations, we have developed LEAPS, an attack detection system based on supervised statistical learning to classify benign and malicious system events. Furthermore, we leverage control flow graphs inferred from the system event logs to enable automatic pruning of the training data, which leads to a more accurate classification model when applied to the testing data. Our extensive evaluation shows that, compared with pure statistical learning models, LEAPS achieves consistently higher accuracy when detecting real-world camouflaged attacks with benign program cover-up.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "目前，网络基础设施正面临越来越多的隐蔽攻击，这些攻击在良性程序的掩护下植入恶意有效载荷。现有的基于统计学习方法的攻击检测方法在处理具有这种良性和恶意行为混合的噪声数据时可能产生误导的决策边界。另一方面，当对攻击行为建模时，基于形式程序分析的攻击检测可能缺乏完整性或适应性。鉴于这些限制，我们开发了LEAPS，这是一种基于监督统计学习的攻击检测系统，用于对良性和恶意系统事件进行分类。此外，我们利用从系统事件日志推断的控制流图来实现训练数据的自动修剪，这在应用于测试数据时导致更准确的分类模型。我们的大量评估表明，与纯统计学习模型相比，LEAPS在检测具有良性程序掩盖的真实世界伪装攻击时，始终获得更高的准确性。",
                    "title_zh": "LEAPS:用程序分析指导的统计学习检测伪装攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.40",
                    "title": "OnionBots: Subverting Privacy Infrastructure for Cyber Attacks",
                    "authors": "Amirali Sanatinia, Guevara Noubir",
                    "abstract": "Over the last decade botnets survived by adopting a sequence of increasingly sophisticated strategies to evade detection and take overs, and to monetize their infrastructure. At the same time, the success of privacy infrastructures such as Tor opened the door to illegal activities, including botnets, ransomware, and a marketplace for drugs and contraband. We contend that the next waves of botnets will extensively attempt to subvert privacy infrastructure and cryptographic mechanisms. In this work we propose to preemptively investigate the design and mitigation of such botnets. We first, introduce OnionBots, what we believe will be the next generation of resilient, stealthy botnets. OnionBots use privacy infrastructures for cyber attacks by completely decoupling their operation from the infected host IP address and by carrying traffic that does not leak information about its source, destination, and nature. Such bots live symbiotically within the privacy infrastructures to evade detection, measurement, scale estimation, observation, and in general all IP-based current mitigation techniques. Furthermore, we show that with an adequate self-healing network maintenance scheme, that is simple to implement, OnionBots can achieve a low diameter and a low degree and be robust to partitioning under node deletions. We develop a mitigation technique, called SOAP, that neutralizes the nodes of the basic OnionBots. In light of the potential of such botnets, we believe that the research community should proactively develop detection and mitigation methods to thwart OnionBots, potentially making adjustments to privacy infrastructure.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1501.03378"
                    },
                    "abstract_zh": "在过去的十年中，僵尸网络通过采用一系列日益复杂的策略来逃避检测和收购，并将其基础设施货币化而得以生存。与此同时，Tor等隐私基础设施的成功为非法活动打开了大门，包括僵尸网络、勒索软件以及毒品和违禁品市场。我们认为，下一波僵尸网络将广泛地试图颠覆隐私基础设施和加密机制。在这项工作中，我们建议先发制人地调查这种僵尸网络的设计和缓解。我们首先介绍OnionBots，我们认为它将是下一代有弹性的隐形僵尸网络。OnionBots使用隐私基础设施进行网络攻击，方法是将其操作与受感染的主机IP地址完全分离，并传输不会泄露其来源、目的地和性质信息的流量。这种机器人在隐私基础设施中共生共存，以逃避检测、测量、规模估计、观察，以及通常所有基于IP的当前缓解技术。此外，我们还证明了在一个适当的自愈网络维护方案下，OnionBots可以实现低直径和低度，并且在节点删除的情况下对分区具有鲁棒性。我们开发了一种缓解技术，称为SOAP，它中和了基本OnionBots的节点。鉴于此类僵尸网络的潜力，我们认为研究社区应该主动开发检测和缓解方法来阻止OnionBots，从而可能对隐私基础架构进行调整。",
                    "title_zh": "OnionBots:为网络攻击颠覆隐私基础设施"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.32",
                    "title": "A Statistical Approach for Timed Reachability in AADL Models",
                    "authors": "Harold Bruintjes, Joost-Pieter Katoen, David Lesens",
                    "abstract": "We introduce a simulator (slimsim) for a subset of AADL extended with formalized behavioral semantics for nominal and error models. The simulator allows to perform probabilistic analysis using the Monte Carlo method, on linear-hybrid, stochastic models, which describe a combination of nominal and error behaviors of hard- and software components. The tool supports the use of different strategies, which control the behavior of the simulator when dealing with various forms of non-determinism. The simulator is tested using benchmarks of the COMPASS toolset, as well as a case study by Airbus Defense and Space.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们介绍了一个模拟器(slimsim ),它是用名义模型和错误模型的形式化行为语义扩展的AADL子集。模拟器允许使用蒙特卡罗方法对线性混合随机模型进行概率分析，该模型描述了硬件和软件组件的标称和错误行为的组合。该工具支持使用不同的策略，这些策略在处理各种形式的不确定性时控制模拟器的行为。模拟器使用COMPASS工具集的基准测试，以及空中客车防务和航天公司的案例研究。",
                    "title_zh": "AADL模型中时间可达性的统计方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.29",
                    "title": "Scalable Analysis of Fault Trees with Dynamic Features",
                    "authors": "Jan Krcál, Pavel Krcál",
                    "abstract": "Fault trees constitute one of the essential formalisms for static safety analysis of various industrial systems. Dynamic fault trees (DFT) enrich the formalism by time-dependent behavior, e.g., repairs or functional dependencies. Analysis of DFT is so far limited to substantially smaller models than those required for, e.g., nuclear power plants. We propose a fault tree formalism that combines both static and dynamic features, called SD fault trees. It gives the user the freedom to express each equipment failure either statically, without modelling temporal information, or dynamically, allowing repairs and other timed interdependencies. We introduce an analysis algorithm for an important subclass of SD fault trees. The algorithm (1) scales similarly to static algorithms and (2) allows for a more realistic analysis compared to static algorithms as it takes into account temporal interdependencies. Finally, we demonstrate the applicability of the method by an experimental evaluation on fault trees of nuclear power plants.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "故障树是各种工业系统静态安全分析的基本形式之一。动态故障树(DFT)通过依赖于时间的行为，例如修理或功能依赖，丰富了形式主义。迄今为止，DFT的分析仅限于比核电厂所需模型小得多的模型。我们提出了一种结合静态和动态特征的故障树形式，称为SD故障树。它让用户可以自由地表示每个设备故障，或者是静态的，不需要建模时间信息，或者是动态的，允许修理和其他时间相关性。我们介绍了一种分析算法的一个重要子类的SD故障树。该算法(1)与静态算法类似地扩展，并且(2)与静态算法相比，由于考虑了时间上的相互依赖性，因此允许更真实的分析。最后，通过对核电厂故障树的实验评估，验证了该方法的适用性。",
                    "title_zh": "具有动态特征的故障树可扩展分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.21",
                    "title": "The Power of Evil Choices in Bloom Filters",
                    "authors": "Thomas Gerbet, Amrit Kumar, Cédric Lauradoux",
                    "abstract": "A Bloom filter is a probabilistic hash-based data structure extensively used in software including online security applications. This paper raises the following important question: Are Bloom filters correctly designed in a security context? The answer is no and the reasons are multiple: bad choices of parameters, lack of adversary models and misused hash functions. Indeed, developers truncate cryptographic digests without a second thought on the security implications. This work constructs adversary models for Bloom filters and illustrates attacks on three applications, namely SCRAPY web spider, BITLY DABLOOMS spam filter and SQUID cache proxy. As a general impact, filters are forced to systematically exhibit worst-case behavior. One of the reasons being that Bloom filter parameters are always computed in the average case. We compute the worst-case parameters in adversarial settings, show how to securely and efficiently use cryptographic hash functions and propose several other countermeasures to mitigate our attacks.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01082158v2/file/RR-8627.pdf"
                    },
                    "abstract_zh": "布隆过滤器是广泛用于包括在线安全应用在内的软件中的基于概率散列的数据结构。本文提出了以下重要问题:Bloom过滤器在安全环境中设计正确吗？答案是否定的，原因是多方面的:错误的参数选择、缺乏对手模型和误用哈希函数。事实上，开发人员在没有考虑安全隐患的情况下就截断了加密摘要。该工作构建了Bloom过滤器的对手模型，并举例说明了对三种应用程序的攻击，即SCRAPY web spider、BITLY dab brows垃圾邮件过滤器和SQUID缓存代理。作为一般影响，滤波器被迫系统地表现出最坏情况的行为。原因之一是布隆过滤器参数总是在平均情况下计算的。我们计算了敌对环境中的最坏情况参数，展示了如何安全有效地使用加密哈希函数，并提出了几种其他对策来减轻我们的攻击。",
                    "title_zh": "《布鲁姆过滤器》中邪恶选择的力量"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.17",
                    "title": "Secure Dynamic Software Loading and Execution Using Cross Component Verification",
                    "authors": "Byungho Min, Vijay Varadharajan",
                    "abstract": "In this paper, we propose a cross verification mechanism for secure execution and dynamic component loading. Our mechanism is based on a combination of code signing and same-origin policy, and it blocks several types of attacks from drive-by download attacks to malicious component loadings such as DLL hijacking, DLL side-loading, binary hijacking, typical DLL injection and loading of newly installed malware components, even when malicious components have valid digital signatures. Considering modern malware often uses stolen private keys to sign its binaries and bypass code signing mechanism, we believe the proposed mechanism can significantly improve the security of modern computing platforms. In addition, the proposed mechanism protects proprietary software components so that unauthorised use of such components cannot occur. We have implemented a prototype for Microsoft Windows 7 and XP SP3, and evaluated application execution and dynamic component loading behaviour under our security mechanism. The proposed mechanism is general, and can be applied to other major computing platforms including Android, Linux and Mac OS X.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了一种安全执行和动态组件加载的交叉验证机制。我们的机制基于代码签名和同源策略的组合，并且它阻止几种类型的攻击，从驱动下载攻击到恶意组件加载，例如DLL劫持、DLL侧加载、二进制劫持、典型的DLL注入和新安装的恶意组件的加载，即使恶意组件具有有效的数字签名。考虑到现代恶意软件通常使用窃取的私钥对其二进制文件进行签名，并绕过代码签名机制，我们认为所提出的机制可以显著提高现代计算平台的安全性。此外，所提出的机制保护专有软件组件，从而不会发生对这些组件的未授权使用。我们已经为微软Windows 7和XP SP3实现了一个原型，并在我们的安全机制下评估了应用执行和动态组件加载行为。所提出的机制是通用的，可以应用于包括Android、Linux和Mac OS X在内的其他主流计算平台。",
                    "title_zh": "使用交叉组件验证的安全动态软件加载和执行"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.12",
                    "title": "Parallax: Implicit Code Integrity Verification Using Return-Oriented Programming",
                    "authors": "Dennis Andriesse, Herbert Bos, Asia Slowinska",
                    "abstract": "Parallax is a novel self-contained code integrity verification approach, that protects instructions by overlapping Return-Oriented Programming (ROP) gadgets with them. Our technique implicitly verifies integrity by translating selected code (verification code) into ROP code which uses gadgets scattered over the binary. Tampering with the protected instructions destroys the gadgets they contain, so that the verification code fails, thereby preventing the adversary from using the modified binary. Unlike prior solutions, Parallax does not rely on code checksumming, so it is not vulnerable to instruction cache modification attacks which affect checksumming techniques. Further, unlike previous algorithms which withstand such attacks, Parallax does not compute hashes of the execution state, and can thus protect code with non-deterministic state. Parallax limits performance overhead to the verification code, while the protected code executes at its normal speed. This allows us to protect performance-critical code, and confine the slowdown to other code regions. Our experiments show that Parallax can protect up to 90% of code bytes, including most control flow instructions, with a performance overhead of under 4%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Parallax是一种新颖的自包含代码完整性验证方法，它通过重叠面向返回的编程(ROP)小工具来保护指令。我们的技术通过将选定的代码(验证码)翻译成ROP代码来隐式验证完整性，ROP代码使用分散在二进制文件中的小工具。篡改受保护的指令会破坏它们包含的小工具，因此验证码会失效，从而防止对手使用修改后的二进制代码。与先前的解决方案不同，视差不依赖于代码校验和，因此它不容易受到影响校验和技术的指令高速缓存修改攻击。此外，与经受住这种攻击的先前算法不同，视差不计算执行状态的散列，因此可以保护具有不确定状态的代码。Parallax限制了验证码的性能开销，而受保护的代码以正常速度执行。这允许我们保护性能关键的代码，并将速度减慢限制在其他代码区域。我们的实验表明，Parallax可以保护高达90%的代码字节，包括大多数控制流指令，性能开销低于4%。",
                    "title_zh": "Parallax:使用面向返回编程的隐式代码完整性验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.19",
                    "title": "TIP-Code: A Three Independent Parity Code to Tolerate Triple Disk Failures with Optimal Update Complextiy",
                    "authors": "Yongzhe Zhang, Chentao Wu, Jie Li, Minyi Guo",
                    "abstract": "With the rapid expansion of data storages and the increasing risk of data failures, triple Disk Failure Tolerant arrays (3DFTs) become popular and widely used. They achieve high fault tolerance via erasure codes. One class of erasure codes called Maximum Distance Separable (MDS) codes, which aims to offer data protection with minimal storage overhead, is a typical choice to enhance the reliability of storage systems. However, existing 3DFTs based on MDS codes are inefficient in terms of update complexity, which results in poor write performance. In this paper, we present an efficient MDS coding scheme called TIP-code, which is purely based on XOR operations and can tolerate triple disk failures. It uses three independent parities (horizontal, diagonal and anti-diagonal parities), and offers optimal update complexity. To demonstrate the effectiveness of TIP-code, we conduct several quantitative analysis and experiments. The results show that, compared to typical MDS codes for 3DFTs (i.e., Cauchy-RS and STAR codes), TIP-code improves the single write performance by up to 46.6%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着数据存储的快速扩展和数据故障风险的增加，三磁盘容错阵列(3DFTs)变得流行和广泛使用。它们通过擦除代码实现高容错性。一类被称为最大距离可分(MDS)码的擦除码旨在以最小的存储开销提供数据保护，是增强存储系统可靠性的典型选择。然而，现有的基于MDS码的3DFTs在更新复杂度方面是低效的，这导致了较差的写入性能。本文提出了一种高效的MDS编码方案，称为TIP-code，它完全基于异或运算，可以容忍三重磁盘故障。它使用三个独立的奇偶校验(水平、对角和反对角奇偶校验)，并提供最佳的更新复杂性。为了证明TIP-code的有效性，我们进行了一些定量分析和实验。结果显示，与用于3DFTs的典型MDS码(即，柯西-RS和STAR码)相比，TIP码将单次写入性能提高了高达46.6%。",
                    "title_zh": "TIP-Code:三个独立的奇偶校验码，以最佳的更新复杂度容忍三个磁盘故障"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.24",
                    "title": "Enabling Efficient and Reliable Transition from Replication to Erasure Coding for Clustered File Systems",
                    "authors": "Runhui Li, Yuchong Hu, Patrick P. C. Lee",
                    "abstract": "To balance performance and storage efficiency, modern clustered file systems often first store data with replication, followed by encoding the replicated data with erasure coding. We argue that the commonly used random replication does not take into account erasure coding in its design, thereby raising both performance and availability issues in the subsequent encoding operation. We propose encoding-aware replication, which carefully places the replicas so as to (i) eliminate cross-rack downloads of data blocks during the encoding operation, (ii) preserve availability without data relocation after the encoding operation, and (iii) maintain load balancing across replicas as in random replication before the encoding operation. We conduct extensive HDFS-based testbed experiments and discrete-event simulations, and demonstrate the performance gains of encoding-aware replication over random replication.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了平衡性能和存储效率，现代集群文件系统通常首先使用复制来存储数据，然后使用擦除编码来编码复制的数据。我们认为，常用的随机复制在其设计中没有考虑擦除编码，从而在随后的编码操作中提出了性能和可用性问题。我们提出编码感知复制，它仔细地放置副本，以便(I)在编码操作期间消除数据块的跨机架下载，(ii)在编码操作之后保持可用性而不重新定位数据，以及(iii)在编码操作之前保持副本之间的负载平衡，就像在随机复制中一样。我们进行了大量基于HDFS的测试床实验和离散事件模拟，并展示了编码感知复制相对于随机复制的性能增益。",
                    "title_zh": "实现群集文件系统从复制到擦除编码的高效、可靠过渡"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.51",
                    "title": "Grouping-Based Elastic Striping with Hotness Awareness for Improving SSD RAID Performance",
                    "authors": "Yubiao Pan, Yongkun Li, Yinlong Xu, Zhipeng Li",
                    "abstract": "RAID provides a good option to provide device-level fault tolerance. Conventional RAID usually updates parities with read-modify-write or read-reconstruct-write, which may introduce a lot of extra I/Os and thus significantly degrade SSD RAID performance. The recently proposed elastic striping scheme reconstructs new stripes with updated new data chunks without updating old parity chunks. However, it necessitates RAID-level garbage collection which may incur a very high cost. In this paper, we propose a hotness-aware caching scheme to buffer incoming writes and categorize data chunks in buffers into multiple groups according to their hotness values. We then propose a grouping-based elastic striping scheme to separately write data chunks in different groups into SSDs. We deployed the proposed schemes on a RAID-5 array composed of eight commercial SSDs, and experimental results show that compared to elastic striping, our scheme reduces 26% -- 65% of chunk writes to SSDs, and also reduces the average response time by 17.2% -- 63.9%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "RAID为提供设备级容错提供了一个很好的选择。传统RAID通常使用读取-修改-写入或读取-重建-写入来更新奇偶校验，这可能会引入大量额外的I/o，从而显著降低SSD RAID性能。最近提出的弹性条带化方案用更新的新数据块重建新条带，而不更新旧的奇偶校验块。然而，它需要RAID级别的垃圾收集，这可能会导致非常高的成本。在本文中，我们提出了一种热度感知的缓存方案来缓冲传入的写操作，并根据热度值将缓冲区中的数据块分为多个组。然后，我们提出了一种基于分组的弹性条带化方案，将不同组中的数据块分别写入固态硬盘。我们在一个由8个商用固态硬盘组成的RAID-5阵列上部署了所提出的方案，实验结果表明，与弹性条带化相比，我们的方案减少了26% - 65%的固态硬盘块写入，并且平均响应时间减少了17.2% - 63.9%。",
                    "title_zh": "具有热度感知功能的基于分组的弹性条带化可提高SSD RAID性能"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.13",
                    "title": "Joza: Hybrid Taint Inference for Defeating Web Application SQL Injection Attacks",
                    "authors": "Abbas Naderi-Afooshteh, Anh Nguyen-Tuong, Mandana Bagheri-Marzijarani, Jason D. Hiser, Jack W. Davidson",
                    "abstract": "Despite years of research on taint-tracking techniques to detect SQL injection attacks, taint tracking is rarely used in practice because it suffers from high performance overhead, intrusive instrumentation, and other deployment issues. Taint inference techniques address these shortcomings by obviating the need to track the flow of data during program execution by inferring markings based on either the program's input (negative taint inference), or the program itself (positive taint inference). We show that existing taint inference techniques are insecure by developing new attacks that exploit inherent weaknesses of the inferencing process. To address these exposed weaknesses, we developed Joza, a novel hybrid taint inference approach that exploits the complementary nature of negative and positive taint inference to mitigate their respective weaknesses. Our evaluation shows that Joza prevents real-world SQL injection attacks, exhibits no false positives, incurs low performance overhead (4%), and is easy to deploy.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管多年来一直在研究污点跟踪技术来检测SQL注入攻击，但污点跟踪很少在实践中使用，因为它存在高性能开销、侵入性检测和其他部署问题。污点推理技术通过基于程序的输入(负面污点推理)或程序本身(正面污点推理)来推断标记，从而消除了在程序执行期间跟踪数据流的需要，从而解决了这些缺点。我们通过开发利用推理过程的固有弱点的新攻击来表明现有污点推理技术是不安全的。为了解决这些暴露的弱点，我们开发了Joza，这是一种新的混合污点推理方法，它利用负面和正面污点推理的互补性来减轻它们各自的弱点。我们的评估表明，Joza可以防止现实世界中的SQL注入攻击，不会出现误报，性能开销低(4%)，并且易于部署。",
                    "title_zh": "Joza:战胜Web应用程序SQL注入攻击的混合污点推理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.18",
                    "title": "Private Browsing Mode Not Really That Private: Dealing with Privacy Breach Caused by Browser Extensions",
                    "authors": "Bin Zhao, Peng Liu",
                    "abstract": "Private Browsing Mode (PBM) is widely supported by all major commodity web browsers. However, browser extensions can greatly undermine PBM. In this paper, we propose an approach to comprehensively identify and stop privacy breaches under PBM caused by browser extensions. Our approach is primarily based on run-time behavior tracking. We combine dynamic analysis and symbolic execution to represent extensions' behavior to identify privacy breaches in PBM caused by extensions. Our analysis shows that many extensions have not fulfilled PBM's guidelines on handling private browsing data. To the best of our knowledge, our approach also provides the first work to stop privacy breaches through instrumentation. We implemented a prototype SoPB on top of Firefox and evaluated it with 1,912 extensions. The results show that our approach can effectively identify and stop privacy breaches under PBM caused by extensions, with almost negligible performance impact.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "私有浏览模式(PBM)被所有主要的商用web浏览器广泛支持。然而，浏览器扩展会大大削弱PBM。在本文中，我们提出了一种方法来全面识别和阻止PBM下由浏览器扩展引起的隐私泄露。我们的方法主要基于运行时行为跟踪。我们结合动态分析和符号执行来表示扩展的行为，以识别在PBM由扩展引起的隐私泄露。我们的分析表明，许多扩展没有满足PBM关于处理私人浏览数据的指导方针。据我们所知，我们的方法还提供了第一个通过仪器来阻止隐私泄露的工作。我们在Firefox上实现了一个原型SoPB，并用1，912个扩展对其进行了评估。结果表明，我们的方法可以有效地识别和阻止PBM下由扩展引起的隐私泄露，而性能影响几乎可以忽略不计。",
                    "title_zh": "隐私浏览模式并没有那么隐私:处理由浏览器扩展引起的隐私泄露"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.26",
                    "title": "Test-Based Interoperability Certification for Web Services",
                    "authors": "Ivano Alessandro Elia, Nuno Laranjeiro, Marco Vieira",
                    "abstract": "Web Services are designed with the key goal of providing interoperable application-to-application interaction, regardless of the platforms involved. Although experience shows that interoperability is difficult to achieve, developers still have limited tools to assess the interoperability of their services and, to the best of our knowledge, none able to support end-to-end interoperability certification. In this paper, we lay the foundations of an interoperability certification process for Web services, which allows testing the interoperability level of a given Web service and also identifying possible interoperability issues. In practice, the process can be used by developers or providers to certify a given web service for interoperability, ensuring successful interaction with client-side platforms. We show the effectiveness of the process by conducting a large experimental evaluation to certify five different implementations of the services specified by the TPC-App benchmark, and about 2500 synthetic generated services.client-side platforms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "设计Web服务的主要目标是提供可互操作的应用程序到应用程序的交互，而不考虑所涉及的平台。尽管经验表明互操作性很难实现，但是开发人员仍然只有有限的工具来评估他们的服务的互操作性，而且据我们所知，没有一个工具能够支持端到端的互操作性认证。在本文中，我们为Web服务的互操作性认证过程奠定了基础，该过程允许测试给定Web服务的互操作性级别，并识别可能的互操作性问题。在实践中，开发人员或提供商可以使用该流程来验证给定web服务的互操作性，确保与客户端平台的成功交互。我们通过进行大规模实验性评估来证明TPC-App基准指定的服务的五种不同实现，以及大约2500个合成生成的服务，从而展示了该过程的有效性。",
                    "title_zh": "基于测试的Web服务互操作性认证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.37",
                    "title": "Understanding the Dark Side of Big Data Clusters: An Analysis beyond Failures",
                    "authors": "Andrea Rosà, Lydia Y. Chen, Walter Binder",
                    "abstract": "Motivated by the high system complexity of today's datacenters, a large body of related studies tries to understand workloads and resource utilization in datacenters. However, there is little work on exploring unsuccessful job and task executions. In this paper, we study three types of unsuccessful executions in traces of a Google datacenter, namely fail, kill, and eviction. The objective of our analysis is to identify their resource waste, impacts on application performance, and root causes. We first quantitatively show their strong negative impact on CPU, RAM, and DISK usage and on task slowdown. We analyze patterns of unsuccessful jobs and tasks, particularly focusing on their interdependency. Moreover, we uncover their root causes by inspecting key workload and system attributes such as machine locality and concurrency level. Our results help in the design of low-latency and fault-tolerant big-data systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "受当今数据中心高度系统复杂性的推动，大量相关研究试图了解数据中心的工作负载和资源利用率。然而，很少有工作探索不成功的工作和任务的执行。在本文中，我们研究了Google数据中心痕迹中三种不成功的执行，即失败、终止和驱逐。我们分析的目标是确定他们的资源浪费、对应用程序性能的影响以及根本原因。我们首先从数量上展示了它们对CPU、RAM和磁盘使用以及任务变慢的强烈负面影响。我们分析不成功的工作和任务的模式，特别关注它们的相互依赖性。此外，我们通过检查关键工作负载和系统属性(如机器位置和并发级别)来揭示其根本原因。我们的结果有助于设计低延迟和容错的大数据系统。",
                    "title_zh": "了解大数据集群的阴暗面:超越失败的分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.46",
                    "title": "Improving Reliability with Dynamic Syndrome Allocation in Intelligent Software Defined Data Centers",
                    "authors": "Ulya Bayram, Dwight Divine, Pin Zhou, Eric William Davis Rozier",
                    "abstract": "We propose new algorithms for implementing a software-defined data center (SDDC) to improve the dependability of storage systems without the addition of new hardware. We define the construction of a system that can predict its future resource requirements and act on these predictions to allocate overprovisioned resources to improve reliability. We introduce algorithms for implementing a smart SDDC (SSDDC) that characterizes user I/O transactions (writes and deletes), and use these models to predict the level of overprovisioning within a system, overbooking excess resources to improve reliability, while mitigating the impact on quality of service. We compare several implementations of our methods experimentally, and discuss methods for improving the fault-tolerance of our S2DDC, present experimental results showcasing our ability to improve system reliability showing the decrease in expected annual block loss due to disk failures and latent sector errors, and highlight the benefit of dependence based usage models in estimating overprovisioning.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了实现软件定义的数据中心(SDDC)的新算法，以在不增加新硬件的情况下提高存储系统的可靠性。我们定义了一个系统的构造，该系统可以预测其未来的资源需求，并根据这些预测来分配过度供应的资源以提高可靠性。我们介绍了用于实现智能SDDC (SSDDC)的算法，该算法可以描述用户I/O事务(写入和删除)的特征，并使用这些模型来预测系统内的过度配置水平，超额预订多余的资源以提高可靠性，同时减轻对服务质量的影响。我们通过实验比较了我们的方法的几种实现，并讨论了提高我们的S2DDC的容错能力的方法，展示了我们提高系统可靠性的能力的实验结果，显示了由于磁盘故障和潜在扇区错误导致的预期年度块丢失的减少，并强调了基于依赖性的使用模型在估计过度配置方面的优势。",
                    "title_zh": "在智能软件定义的数据中心中通过动态校正子分配提高可靠性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.53",
                    "title": "Experiences with Building Disaster Recovery for Enterprise-Class Clouds",
                    "authors": "Long Wang, Harigovind V. Ramasamy, Richard E. Harper, Mahesh Viswanathan, Edmond Plattier",
                    "abstract": "The ability to recover from disasters is an important requirement for many enterprises. With enterprise-class workloads increasingly hosted on the cloud, cloud customers have come to expect disaster recovery (DR) as a necessary feature from cloud platforms. This paper identifies key challenges in providing DR as a service on enterprise cloud platforms, and portrays DR solutions for a managed cloud platform. In particular, we present the reference architecture for DR solutions, and describe our practical experiences in providing a portfolio of DR solutions for the cloud platform. The solutions cover diverse target recovery sites, such as an equivalent cloud site, a dedicated recovery site, and a customer-owned site. From the experiences, we provide insights into and lessons on implementing DR for enterprise-class clouds.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "从灾难中恢复的能力是许多企业的一项重要要求。随着越来越多的企业级工作负载在云上托管，云客户开始期望灾难恢复(DR)成为云平台的必要功能。本白皮书确定了在企业云平台上提供灾难恢复即服务的主要挑战，并描述了托管云平台的灾难恢复解决方案。特别是，我们展示了灾难恢复解决方案的参考体系结构，并描述了我们在为云平台提供灾难恢复解决方案组合方面的实践经验。这些解决方案涵盖了不同的目标恢复站点，例如等效的云站点、专用恢复站点和客户拥有的站点。根据这些经验，我们提供了关于为企业级云实施灾难恢复的见解和教训。",
                    "title_zh": "为企业级云构建灾难恢复的经验"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.27",
                    "title": "FloodGuard: A DoS Attack Prevention Extension in Software-Defined Networks",
                    "authors": "Haopei Wang, Lei Xu, Guofei Gu",
                    "abstract": "This paper addresses one serious SDN-specific attack, i.e., data-to-control plane saturation attack, which overloads the infrastructure of SDN networks. In this attack, an attacker can produce a large amount of table-miss packet_in messages to consume resources in both control plane and data plane. To mitigate this security threat, we introduce an efficient, lightweight and protocol-independent defense framework for SDN networks. Our solution, called FloodGuard, contains two new techniques/modules: proactive flow rule analyzer and packet migration. To preserve network policy enforcement, proactive flow rule analyzer dynamically derives proactive flow rules by reasoning the runtime logic of the SDN/OpenFlow controller and its applications. To protect the controller from being overloaded, packet migration temporarily caches the flooding packets and submits them to the OpenFlow controller using rate limit and round-robin scheduling. We evaluate FloodGuard through a prototype implementation tested in both software and hardware environments. The results show that FloodGuard is effective with adding only minor overhead into the entire SDN/OpenFlow infrastructure.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了一种严重的SDN专用攻击，即数据到控制平面饱和攻击，这种攻击使SDN网络的基础设施过载。在这种攻击中，攻击者可以产生大量表丢失packet_in消息，以消耗控制平面和数据平面中的资源。为了减轻这种安全威胁，我们为SDN网络引入了一种高效、轻量级且独立于协议的防御框架。我们的解决方案称为FloodGuard，包含两种新技术/模块:主动流规则分析器和数据包迁移。为了保持网络策略的实施，主动流规则分析器通过推理SDN/OpenFlow控制器及其应用程序的运行时逻辑来动态导出主动流规则。为了防止控制器过载，数据包迁移会临时缓存泛洪数据包，并使用速率限制和循环调度将它们提交给OpenFlow控制器。我们通过在软件和硬件环境中测试的原型实现来评估FloodGuard。结果表明，FloodGuard是有效的，只需在整个SDN/OpenFlow基础设施中增加少量开销。",
                    "title_zh": "FloodGuard:软件定义网络中的DoS攻击防御扩展"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.48",
                    "title": "Enhancing Software Dependability and Security with Hardware Supported Instruction Address Space Randomization",
                    "authors": "Seung-Hun Kim, Lei Xu, Ziyi Liu, Zhiqiang Lin, Won Woo Ro, Weidong Shi",
                    "abstract": "We present a micro-architecture based lightweight framework to enhance dependability and security of software against code reuse attack. Different from the prior hardware based approaches for mitigating code reuse attacks, our solution is based on software diversity and instruction level control flow randomization. Generally, software based instruction location randomization (ILR) using binary emulator as a mediation layer has been shown to be effective for thwarting code reuse attacks like return oriented programming (ROP). However, our in-depth studies show that straightforward and naive implementation of ILR at the micro-architecture level will incur major performance deficiencies in terms of instruction fetch and cache utilization. For example, straightforward implementation of ILR increases the first level instruction cache miss rates on average by more than 9 times for a set of SPEC CPU2006 benchmarks. To address these issues, we present a novel micro-architecture design that can support native execution of control flow randomized software binary while at the same time preserve the performance of instruction fetch and efficient use of on-chip caches. The proposed design is evaluated by extending cycle based x86 architecture simulator, XIOSim with validated power simulation. Performance evaluation on SPEC CPU2006 benchmarks shows an average speedup of 1.63 times compared to the hardware implementation of ILR. Using the proposed approach, direct execution of ILR software incurs only 2.1% IPC performance slowdown with a very small hardware overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了一个基于微体系结构的轻量级框架来增强软件的可靠性和安全性，以抵御代码重用攻击。不同于先前基于硬件的减轻代码重用攻击的方法，我们的解决方案基于软件多样性和指令级控制流随机化。一般来说，使用二进制仿真器作为中介层的基于软件的指令位置随机化(ILR)已经被证明对于阻止代码重用攻击(如面向返回的编程(ROP ))是有效的。然而，我们的深入研究表明，在微体系结构级别直接而简单地实现ILR将导致指令提取和缓存利用方面的重大性能缺陷。例如，对于一组SPEC CPU2006基准测试，ILR的直接实施将一级指令缓存缺失率平均提高了9倍以上。为了解决这些问题，我们提出了一种新颖的微架构设计，它可以支持控制流随机化软件二进制文件的本地执行，同时保持取指令的性能和片上高速缓存的有效使用。使用基于扩展周期的x86体系结构仿真器XIOSim和经验证的功耗仿真对所提出的设计进行评估。在SPEC CPU2006基准上的性能评估显示，与ILR的硬件实现相比，平均加速比是1.63倍。使用所提出的方法，直接执行ILR软件仅导致2.1%的IPC性能降低，并且具有非常小的硬件开销。",
                    "title_zh": "通过硬件支持的指令地址空间随机化增强软件可靠性和安全性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.60",
                    "title": "Hide & Share: Landmark-Based Similarity for Private KNN Computation",
                    "authors": "Davide Frey, Rachid Guerraoui, Anne-Marie Kermarrec, Antoine Rault, François Taïani, Jingjing Wang",
                    "abstract": "—Computing k-nearest-neighbor graphs constitutes a fundamental operation in a variety of data-mining applications. As a prominent example, user-based collaborative-ﬁltering pro- vides recommendations by identifying the items appreciated by the closest neighbors of a target user. As this kind of applications evolve, they will require KNN algorithms to operate on more and more sensitive data. This has prompted researchers to propose decentralized peer-to-peer KNN solutions that avoid concentrating all information in the hands of one central organization. Un- fortunately, such decentralized solutions remain vulnerable to malicious peers that attempt to collect and exploit information on participating users. In this paper, we seek to overcome this limitation by proposing H&S (Hide & Share), a novel landmark-based similarity mechanism for decentralized KNN computation. Landmarks allow users (and the associated peers) to estimate how close they lay to one another without disclosing their individual proﬁles. We evaluate H&S in the context of a user-based collaborative- ﬁltering recommender with publicly available traces from existing recommendation systems. We show that although landmark- based similarity does disturb similarity values (to ensure privacy), the quality of the recommendations is not as signiﬁcantly ham- pered. We also show that the mere fact of disturbing similarity values turns out to be an asset because it prevents a malicious user from performing a proﬁle reconstruction attack against other users, thus reinforcing users’ privacy. Finally, we provide a formal privacy guarantee by computing an upper bound on the amount of information revealed by H&S about a user’s proﬁle.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "—计算k-最近邻图是各种数据挖掘应用程序中的基本操作。一个突出的例子是，基于用户的协同过滤通过识别目标用户最近的邻居喜欢的项目来提供推荐。随着这类应用的发展，它们将需要KNN算法来处理越来越多的敏感数据。这促使研究人员提出分散的点对点KNN解决方案，避免将所有信息集中在一个中央组织手中。不幸的是，这种分散的解决方案仍然容易受到试图收集和利用参与用户信息的恶意对等体的攻击。在本文中，我们试图通过提出H&S (Hide & Share)来克服这一限制，这是一种用于分散KNN计算的新的基于标志点的相似性机制。地标允许用户(和相关联的对等体)估计他们彼此之间的距离，而不暴露他们的个人档案。我们在基于用户的协同过滤推荐系统的背景下评估H&S，该推荐系统具有来自现有推荐系统的公开可用的踪迹。我们表明，尽管基于地标的相似性确实会干扰相似性值(以确保隐私)，但推荐的质量不会受到显著影响。我们还表明，干扰相似性值这一事实本身就是一项资产，因为它可以防止恶意用户对其他用户进行剖面重建攻击，从而加强用户的隐私。最后，我们通过计算H&S披露的关于用户个人资料的信息量上限，提供正式的隐私保证。",
                    "title_zh": "隐藏和共享:基于标志点的相似性的私人KNN计算"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.31",
                    "title": "Energy Resilience Modelling for Smart Houses",
                    "authors": "Hamed Ghasemieh, Boudewijn R. Haverkort, Marijn R. Jongerden, Anne Remke",
                    "abstract": "The use of renewable energy in houses and neighbourhoods is very much governed by national legislation and has recently led to enormous changes in the energy market and poses a serious threat to the stability of the grid at peak production times. One of the approaches towards a more balanced grid is, e.g., taken by the German government by subsidizing local storage for solar power. While the main interest of the energy operator and the government is to balance the grid, thereby ensuring its stability, the main interest of the client is twofold: the total cost for electricity should be as low as possible and the house should be as resilient as possible in the presence of power outages. Using local battery storage can help to overcome the effects of power outages. However, the resulting resilience highly depends on the battery usage strategy employed by the controller, taking into account the state of charge of the battery. We present a Hybrid Petri net model of a house (that is mainly powered by solar energy) with a local storage unit, and analyse the impact of different battery usage strategies on its resilience for different production and consumption patterns. Our analysis shows that there is a direct relationship between resilience and flexibility, since increased resilience, i.e., reserving battery capacity for backup, decreases the flexibility of the storage unit.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在住宅和居民区使用可再生能源在很大程度上受到国家立法的管制，最近导致了能源市场的巨大变化，并对高峰生产时段电网的稳定性构成了严重威胁。实现更加平衡的电网的方法之一是，例如，德国政府通过补贴太阳能的本地存储。虽然能源运营商和政府的主要利益是平衡电网，从而确保其稳定性，但客户的主要利益是双重的:电力的总成本应该尽可能低，并且房子在停电时应该尽可能有弹性。使用本地电池存储有助于克服停电的影响。然而，考虑到电池的充电状态，由此产生的弹性高度依赖于控制器采用的电池使用策略。我们提出了一个带有本地存储单元的房子(主要由太阳能供电)的混合Petri网模型，并分析了不同的电池使用策略对不同生产和消费模式的弹性的影响。我们的分析表明，弹性和灵活性之间存在直接关系，因为增加的弹性，即保留备用电池容量，会降低存储单元的灵活性。",
                    "title_zh": "智能住宅的能量恢复模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.42",
                    "title": "Impact of Malfunction on the Energy Efficiency of Batch Processing Systems",
                    "authors": "Marcello Cinque, Domenico Cotroneo, Flavio Frattini, Stefano Russo",
                    "abstract": "Energy efficiency of large processing systems is usually assessed as the relation between a performance and a power consumption metric, neglecting malfunction. Execution failures have a tangible cost in terms of wasted energy, however. They are often managed through fault tolerance mechanisms, which in turn consume electricity. We introduce the consumability attribute for batch processing systems, encompassing performance, consumption, and dependability aspects altogether. We propose a metric for its quantification and a methodology for its analysis. Using a real 500-node batch system as a case study, we show that consumability is representative of both efficiency and effectiveness, and we show the usefulness of the proposed metric and the suitability of the proposed methodology.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大型处理系统的能效通常被评估为性能和功耗指标之间的关系，忽略了故障。然而，执行失败在浪费能源方面有有形的成本。它们通常通过容错机制来管理，而容错机制又会消耗电能。我们介绍批处理系统的可消费性属性，包括性能、消费和可靠性方面。我们提出了量化的标准和分析的方法。使用一个真实的500节点批处理系统作为案例研究，我们表明可消费性是效率和有效性的代表，我们表明了所提出的度量的有用性和所提出的方法的适用性。",
                    "title_zh": "故障对批处理系统能效的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.16",
                    "title": "phpSAFE: A Security Analysis Tool for OOP Web Application Plugins",
                    "authors": "Paulo Jorge Costa Nunes, José Fonseca, Marco Vieira",
                    "abstract": "There is nowadays an increasing pressure to develop complex Web applications at a fast pace. The vast majority is built using frameworks based on third-party server-side plugins that allow developers to easily add new features. However, as many plugin developers have limited programming skills, there is a spread of security vulnerabilities related to their use. Best practices advise the use of systematic code review for assure security, but free tools do not support OOP, which is how most Web applications are currently developed. To address this problem we propose phpSAFE, a static code analyzer that identifies vulnerabilities in PHP plugins developed using OOP. We evaluate phpSAFE against two well-known tools using 35 plugins for a widely used CMS. Results show that phpSAFE clearly outperforms other tools, and that plugins are being shipped with a considerable number of vulnerabilities, which tends to increase over time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，快速开发复杂的Web应用程序的压力越来越大。绝大多数是使用基于第三方服务器端插件的框架构建的，这些插件允许开发人员轻松添加新功能。然而，由于许多插件开发者的编程技能有限，因此存在与他们的使用相关的安全漏洞。最佳实践建议使用系统的代码审查来确保安全性，但是免费工具不支持面向对象程序设计，而这正是目前大多数Web应用程序的开发方式。为了解决这个问题，我们提出了phpSAFE，这是一个静态代码分析器，可以识别使用OOP开发的PHP插件中的漏洞。我们使用广泛使用的CMS的35个插件，针对两个著名的工具来评估phpSAFE。结果显示，phpSAFE明显优于其他工具，并且插件带有相当多的漏洞，这些漏洞往往会随着时间的推移而增加。",
                    "title_zh": "phpSAFE:面向对象Web应用插件的安全分析工具"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.43",
                    "title": "BAAT: Towards Dynamically Managing Battery Aging in Green Datacenters",
                    "authors": "Longjun Liu, Chao Li, Hongbin Sun, Yang Hu, Juncheng Gu, Tao Li",
                    "abstract": "Energy storage devices (batteries) have shown great promise in eliminating supply/demand power mismatch and reducing energy/power cost in green datacenters. These important components progressively age due to irregular usage patterns, which result in less effective capacity and even pose serious threat to server availability. Nevertheless, prior proposals largely ignore the aging issue of batteries or simply use ad-hoc discharge capping to extend their lifetime. To fill this critical void, we thoroughly investigate battery aging on a heavily instrumented prototype over an observation period of six months. We propose battery anti-aging treatment (BAAT), a novel framework for hiding, reducing, and planning the battery aging effects. We show that BAAT can extend battery lifetime by 69%. It enables datacenters to maximally utilize energy storage resources to enhance availability and boost performance. Moreover, it reduces 26% battery cost and allows datacenters to economically scale in the big data era.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "储能设备(电池)在消除绿色数据中心的供需电力不匹配和降低能源/电力成本方面显示出巨大的前景。由于不规则的使用模式，这些重要组件逐渐老化，导致有效容量降低，甚至对服务器可用性构成严重威胁。然而，先前的提议在很大程度上忽略了电池的老化问题，或者简单地使用特定的放电上限来延长它们的寿命。为了填补这一关键空白，我们在为期六个月的观察期内，对一个配备了大量仪器的原型进行了彻底的电池老化调查。我们提出了电池抗老化处理(BAAT)，一种隐藏、减少和规划电池老化效应的新框架。我们证明BAAT可以将电池寿命延长69%。它使数据中心能够最大限度地利用能源存储资源，以提高可用性和性能。此外，它降低了26%的电池成本，并允许数据中心在大数据时代经济地扩展。",
                    "title_zh": "BAAT:绿色数据中心的电池老化动态管理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.44",
                    "title": "Avoiding Pitfalls in Fault-Injection Based Comparison of Program Susceptibility to Soft Errors",
                    "authors": "Horst Schirmeier, Christoph Borchert, Olaf Spinczyk",
                    "abstract": "Since the first identification of physical causes for soft errors in memory circuits, fault injection (FI) has grown into a standard methodology to assess the fault resilience of computer systems. A variety of FI techniques trying to mimic these physical causes has been developed to measure and compare program susceptibility to soft errors. In this paper, we analyze the process of evaluating programs, which are hardened by software-based hardware fault-tolerance mechanisms, under a uniformly distributed soft-error model. We identify three pitfalls in FI result interpretation widespread in the literature, even published in renowned conference proceedings. Using a simple machine model and transient single-bit faults in memory, we find counterexamples that reveal the unfitness of common practices in the field, and substantiate our findings with real-world examples. In particular, we demonstrate that the fault coverage metric must be abolished for comparing programs. Instead, we propose to use extrapolated absolute failure counts as a valid comparison metric.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自从首次识别出存储器电路中软错误的物理原因以来，故障注入(FI)已经发展成为评估计算机系统故障恢复能力的标准方法。已经开发了各种试图模拟这些物理原因的FI技术来测量和比较程序对软错误的易感性。在本文中，我们分析了在均匀分布的软错误模型下评估程序的过程，这些程序是由基于软件的硬件容错机制加固的。我们发现文献中普遍存在的FI结果解释中的三个陷阱，甚至发表在著名的会议记录中。使用一个简单的机器模型和内存中的瞬时单位故障，我们找到了反例，揭示了该领域中常见实践的不适用性，并用真实世界的例子证实了我们的发现。特别是，我们证明了在比较程序时，必须废除故障覆盖率度量。相反，我们建议使用外推的绝对故障数作为有效的比较指标。",
                    "title_zh": "避免基于故障注入的程序对软错误敏感性比较中的陷阱"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.55",
                    "title": "Warped-RE: Low-Cost Error Detection and Correction in GPUs",
                    "authors": "Mohammad Abdel-Majeed, Waleed Dweik, Hyeran Jeon, Murali Annavaram",
                    "abstract": "Graphics processing units (GPUs) are now the dominant computing fabric within many supercomputers. As such many mission critical applications run on GPUs, which demand stringent reliability and computational correctness guarantees from GPUs. Prior approaches to GPU reliability have tackled solely either error detection, or error correction assuming error detection is already present. In this paper we present Warped Redundant Execution (Warped-RE), a unified framework that is capable of detecting and then correcting transient and nontransient errors in the GPU execution lanes. Our work exploits two critical properties of applications running on GPUs. First, we observe that neighboring execution lanes in GPUs may operate on the same values. Thus when neighboring lanes execute the same instruction using the same values then these lanes provide inherent DMR (dual modular redundancy) or even inherent TMR (triple modular redundancy) opportunities. The second property we exploit is that due to insufficient parallelism or due to branch divergence, applications do not fully utilize all the available execution lanes. In this case it is possible to force DMR or TMR on unused execution lanes, when inherent redundancy is insufficient. During error-free execution, Warped-RE uses a combination of inherent and forced DMR to guarantee that every thread computation within every warp instruction will be verified. When an error is detected in a warp instruction, the instruction is re-executed in TMR mode in order to correct the error and identify execution lanes with potential non-transient errors. Our evaluations show 8.4% and 29% average performance overhead during the DMR and TMR operation modes, respectively. Compared to traditional DMR and TMR, Warped-RE reduces the power overhead by 42% and 40%, respectively.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "图形处理单元(GPU)现在是许多超级计算机中的主导计算结构。如此多的关键任务应用程序运行在GPU上，这要求GPU提供严格的可靠性和计算正确性保证。现有的GPU可靠性方法只解决了错误检测或错误校正，假设错误检测已经存在。在本文中，我们提出了扭曲冗余执行(Warped-RE)，这是一个统一的框架，能够检测并纠正GPU执行通道中的瞬态和非瞬态错误。我们的工作利用了运行在GPU上的应用程序的两个关键属性。首先，我们观察到GPU中相邻的执行通道可能对相同的值进行操作。因此，当相邻通道使用相同的值执行相同的指令时，这些通道提供固有的DMR(双模冗余)或者甚至固有的TMR(三模冗余)机会。我们利用的第二个特性是，由于并行性不足或分支分歧，应用程序无法充分利用所有可用的执行通道。在这种情况下，当固有冗余不足时，可以在未使用的执行通道上强制DMR或TMR。在无错误执行期间，Warped-RE使用固有和强制DMR的组合来保证每个warp指令中的每个线程计算都将得到验证。当在warp指令中检测到错误时，该指令以TMR模式重新执行，以便纠正错误并识别具有潜在非瞬时错误的执行通道。我们的评估显示，在DMR和TMR操作模式下，平均性能开销分别为8.4%和29%。与传统的DMR和TMR相比，Warped-RE分别降低了42%和40%的功耗。",
                    "title_zh": "warped-RE:GPU中的低成本错误检测和纠正"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.15",
                    "title": "Decomposable Trust for Android Applications",
                    "authors": "Earlence Fernandes, Ajit Aluri, Alexander Crowell, Atul Prakash",
                    "abstract": "Current operating system designs require applications (apps) to implicitly place trust in a large amount of code. Taking Android as an example, apps must trust both the kernel as well as privileged userspace services that consist of hundreds of thousands of lines of code. Malware apps, on the other hand, aim to exploit any vulnerabilities in the above large trusted base to escalate their privileges. Once malware escalates its privileges, additional attacks become feasible, such as stealing credentials by scanning memory pages or intercepting user interactions of sensitive apps, e.g., those used for banking or health management. This paper introduces a novel mechanism, called Anception, that strategically deprivileges a significant portion of the kernel and system services, moving them to an untrusted container, thereby significantly reducing the attack surface for privilege escalation available to malware. Anception supports unmodified apps, running on a modified Android kernel. It achieves performance close to native Android on several popular macro benchmarks and provides security against many types of known Android root exploits.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当前的操作系统设计要求应用程序(app)隐含地信任大量代码。以Android为例，应用程序必须信任内核和特权用户空间服务，这些服务由成千上万行代码组成。另一方面，恶意软件应用程序旨在利用上述大型可信基础中的任何漏洞来提升其权限。一旦恶意软件提升其权限，其他攻击变得可行，例如通过扫描内存页面或拦截敏感应用程序(例如，用于银行或健康管理的应用程序)的用户交互来窃取凭证。本文介绍了一种新的机制，称为Anception，它从战略上剥夺了内核和系统服务的重要部分，将它们移动到不可信的容器中，从而大大减少了恶意软件对权限提升的攻击面。Anception支持未经修改的应用程序，运行在经过修改的Android内核上。它在几个流行的宏基准上实现了接近原生Android的性能，并提供了针对许多类型的已知Android root漏洞的安全性。",
                    "title_zh": "Android应用程序的可分解信任"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.33",
                    "title": "Reducing Refresh Power in Mobile Devices with Morphable ECC",
                    "authors": "Chia-Chen Chou, Prashant J. Nair, Moinuddin K. Qureshi",
                    "abstract": "Energy consumption is a primary consideration that determines the usability of emerging mobile computing devices such as smartphones. Refresh operations for main memory account for a significant fraction of the overall energy consumption, especially during idle periods, when processor can be switched off quickly, however, memory contents continue to get refreshed to avoid data loss. Given that mobile devices are idle most of the times, reducing refresh power in idle mode is critical to maximize the duration for which the device remains usable. The frequency of refresh operations in memory can be reduced significantly by using strong multi-bit error correction codes (ECC). Unfortunately, strong ECC codes incur high latency, which causes significant performance degradation (as high as 21%, and on average 10%). To obtain both low refresh power in idle periods and high performance in active periods, this paper proposes Morphable ECC (MECC). During idle periods, MECC keeps the memory protected with 6-bit ECC (ECC-6) and employs a refresh period of 1 second, instead of the typical refresh period of 64ms. During active operation, MECC reduces the refresh interval to 64ms, and converts memory from ECC-6 to weaker ECC (single-bit error correction) on a demand-basis, thus avoiding the high latency of ECC-6, except for the first access during the active mode. Our proposal reduces refresh operations during idle mode by 16x, memory power in idle mode by 2X, while retaining performance within 2% of a system that does not use any ECC.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "能耗是决定智能手机等新兴移动计算设备可用性的主要因素。主存储器的刷新操作占总能耗的很大一部分，尤其是在空闲期间，此时处理器可以快速关闭，但存储器内容会继续刷新以避免数据丢失。鉴于移动设备大部分时间都处于空闲状态，降低空闲模式下的刷新功率对于最大限度地延长设备的可用时间至关重要。通过使用强多位纠错码(ECC ),可以显著降低存储器中刷新操作的频率。不幸的是，强ECC代码会导致高延迟，从而导致显著的性能下降(高达21%，平均为10%)。为了同时获得空闲期的低刷新功耗和活跃期的高性能，提出了可变形ECC (MECC)。在空闲期间，MECC使用6位ECC (ECC-6)保护内存，并采用1秒的刷新周期，而不是64毫秒的典型刷新周期。在主动操作期间，MECC将刷新间隔缩短至64毫秒，并根据需求将内存从ECC-6转换为较弱的ECC(单比特纠错),从而避免了ECC-6的高延迟，但主动模式期间的第一次访问除外。我们的建议将空闲模式下的刷新操作减少了16倍，空闲模式下的内存功耗减少了2倍，同时保持了不使用任何ECC的系统的2%的性能。",
                    "title_zh": "使用可变形ECC降低移动设备的刷新功率"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.11",
                    "title": "TrustICE: Hardware-Assisted Isolated Computing Environments on Mobile Devices",
                    "authors": "He Sun, Kun Sun, Yuewu Wang, Jiwu Jing, Haining Wang",
                    "abstract": "Mobile devices have been widely used to process sensitive data and perform important transactions. It is a challenge to protect secure code from a malicious mobile OS. ARM TrustZone technology can protect secure code in a secure domain from an untrusted normal domain. However, since the attack surface of the secure domain will increase along with the size of secure code, it becomes arduous to negotiate with OEMs to get new secure code installed. We propose a novel TrustZone-based isolation framework named TrustICE to create isolated computing environments (ICEs) in the normal domain. TrustICE securely isolates the secure code in an ICE from an untrusted Rich OS in the normal domain. The trusted computing base (TCB) of TrustICE remains small and unchanged regardless of the amount of secure code being protected. Our prototype shows that the switching time between an ICE and the Rich OS is less than 12 ms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "移动设备已被广泛用于处理敏感数据和执行重要交易。保护安全代码免受恶意移动操作系统攻击是一项挑战。ARM TrustZone技术可以保护安全域中的安全代码免受不受信任的普通域的攻击。然而，由于安全域的攻击面将随着安全代码的大小而增加，因此与OEM协商以安装新的安全代码变得困难。我们提出了一种新的基于信任域的隔离框架TrustICE，用于在普通域中创建隔离计算环境。TrustICE将ICE中的安全代码与普通域中不受信任的富操作系统安全隔离。TrustICE的可信计算基础(TCB)保持较小且不变，无论受保护的安全代码数量有多少。我们的原型显示ICE和富操作系统之间的切换时间少于12毫秒。",
                    "title_zh": "TrustICE:移动设备上的硬件辅助隔离计算环境"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.47",
                    "title": "Delving into Internet DDoS Attacks by Botnets: Characterization and Analysis",
                    "authors": "An Wang, Aziz Mohaisen, Wentao Chang, Songqing Chen",
                    "abstract": "Internet Distributed Denial of Service (DDoS) at- tacks are prevalent but hard to defend against, partially due to the volatility of the attacking methods and patterns used by attackers. Understanding the latest DDoS attacks can provide new insights for effective defense. But most of existing understandings are based on indirect traffic measures (e.g., backscatters) or traffic seen locally. In this study, we present an in-depth analysis based on 50,704 different Internet DDoS attacks directly observed in a seven-month period. These attacks were launched by 674 botnets from 23 different botnet families with a total of 9,026 victim IPs belonging to 1,074 organizations in 186 countries. Our analysis reveals several interesting findings about today's Internet DDoS attacks. Some highlights include: (1) geolocation analysis shows that the geospatial distribution of the attacking sources follows certain patterns, which enables very accurate source prediction of future attacks for most active botnet families, (2) from the target perspective, multiple attacks to the same target also exhibit strong patterns of inter-attack time interval, allowing accurate start time prediction of the next anticipated attacks from certain botnet families, (3) there is a trend for different botnets to launch DDoS attacks targeting the same victim, simultaneously or in turn. These findings add to the existing literature on the understanding of today's Internet DDoS attacks, and offer new insights for designing new defense schemes at different levels.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "互联网分布式拒绝服务(DDoS)攻击很普遍，但很难防御，部分原因是攻击者使用的攻击方法和模式的易变性。了解最新的DDoS攻击可以为有效防御提供新的见解。但是，大多数现有的理解是基于间接交通测量(例如，反向散射)或局部可见的交通。在这项研究中，我们根据七个月内直接观察到的50，704次不同的互联网DDoS攻击进行了深入分析。这些攻击是由来自23个不同僵尸网络家族的674个僵尸网络发起的，共有9026个受害者IP，属于186个国家的1074个组织。我们的分析揭示了一些关于当今互联网DDoS攻击的有趣发现。一些亮点包括:(1)地理位置分析显示，攻击源的地理空间分布遵循某些模式，这使得能够对大多数活跃僵尸网络家族的未来攻击进行非常准确的源预测，(2)从目标角度来看，对同一目标的多次攻击也表现出强烈的攻击间时间间隔模式，允许对来自某些僵尸网络家族的下一次预期攻击进行准确的开始时间预测，(3)不同僵尸网络有同时或依次针对同一受害者发起DDoS攻击的趋势。这些发现增加了对当今互联网DDoS攻击理解的现有文献，并为在不同层面设计新的防御方案提供了新的见解。",
                    "title_zh": "僵尸网络对互联网DDoS攻击的研究:特征和分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.38",
                    "title": "Consensus Refined",
                    "authors": "Ognjen Maric, Christoph Sprenger, David A. Basin",
                    "abstract": "In this article, we analyse potential filters that moderate the transformation process between the realms of PCK defined in the refined consensus model of pedagogical content knowledge. We tested 58 preservice biology teachers in a 15-week one-group pretest/post-test design. To identify filters between collective PCK (cPCK) and personal PCK (pPCK), we set up moderation models with pretest pPCK as an independent variable, post-test pPCK as a dependent variable, and motivational orientations or professional values as moderator variables. To identify filters between pPCK and enacted PCK (ePCK), we set up moderation models with post-test pPCK as an independent variable, ePCK as a dependent variable, and noticing or knowledge-based reasoning as moderator variables. We did this specifically with a focus on language in biology education. We found that only the variable knowledge-based reasoning had a role as a filter. It moderates the transformation process between pPCK and ePCK (moderation analysis: F(3,19) = 10.40, p < 0.001, predicting 25.72% of the variance). In future studies, other filters should be identified.",
                    "files": {
                        "openAccessPdf": "https://www.mdpi.com/2227-7102/12/9/592/pdf?version=1661861662"
                    },
                    "abstract_zh": "在这篇文章中，我们分析了潜在的过滤器，调节在教学内容知识的精炼共识模型中定义的PCK领域之间的转换过程。我们对58名职前生物教师进行了为期15周的单组前测/后测设计。为了识别集体PCK (cPCK)和个人PCK (pPCK)之间的过滤器，我们建立了调节模型，将前测pPCK作为自变量，后测pPCK作为因变量，动机取向或职业价值观作为调节变量。为了识别pPCK和制定的PCK (ePCK)之间的过滤器，我们建立了调节模型，将后测pPCK作为自变量，ePCK作为因变量，通知或基于知识的推理作为调节变量。我们特别关注生物教育中的语言。我们发现只有可变的基于知识的推理有一个过滤器的作用。它调节pPCK和ePCK之间的转换过程(调节分析:F(3，19) = 10.40，p < 0.001，预测方差的25.72%)。在未来的研究中，应确定其他过滤器。",
                    "title_zh": "共识提炼"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.35",
                    "title": "Segugio: Efficient Behavior-Based Tracking of Malware-Control Domains in Large ISP Networks",
                    "authors": "Babak Rahbarinia, Roberto Perdisci, Manos Antonakakis",
                    "abstract": "In this paper, we propose Segugio, a novel defense system that allows for efficiently tracking the occurrence of new malware-control domain names in very large ISP networks. Segugio passively monitors the DNS traffic to build a machine-domain bipartite graph representing who is querying what. After labelling nodes in this query behavior graph that are known to be either benign or malware-related, we propose a novel approach to accurately detect previously unknown malware-control domains. We implemented a proof-of-concept version of Segugio and deployed it in large ISP networks that serve millions of users. Our experimental results show that Segugio can track the occurrence of new malware-control domains with up to 94% true positives (TPs) at less than 0.1% false positives (FPs). In addition, we provide the following results: (1) we show that Segugio can also detect control domains related to new, previously unseen malware families, with 85% TPs at 0.1% FPs, (2) Segugio's detection models learned on traffic from a given ISP network can be deployed into a different ISP network and still achieve very high detection accuracy, (3) new malware-control domains can be detected days or even weeks before they appear in a large commercial domain name blacklist, and (4) we show that Segugio clearly outperforms Notos, a previously proposed domain name reputation system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们提出了Segugio，一种新的防御系统，允许有效地跟踪超大型ISP网络中新的恶意软件控制域名的出现。Segugio被动地监控DNS流量，以构建一个机器域二分图，表示谁在查询什么。在标记该查询行为图中已知为良性或恶意软件相关的节点之后，我们提出了一种新的方法来准确地检测先前未知的恶意软件控制域。我们实现了Segugio的概念验证版本，并将其部署在为数百万用户提供服务的大型ISP网络中。我们的实验结果表明，Segugio可以以高达94%的真阳性率(TPs)和低于0.1%的假阳性率(FPs)跟踪新恶意软件控制域的出现。此外，我们提供了以下结果:(1)我们表明Segugio还可以检测与新的、以前未见过的恶意软件家族相关的控制域，85%的TPs，0.1%的FPs，(2) Segugio在来自给定ISP网络的流量上学习的检测模型可以部署到不同的ISP网络中，并且仍然可以实现非常高的检测准确性，(3)新的恶意软件控制域可以在它们出现在大型商业域名黑名单中之前几天甚至几周被检测到，以及(4)我们表明Segugio明显优于以前提出的Notos域名",
                    "title_zh": "Segugio:大型ISP网络中恶意软件控制域的高效基于行为的跟踪"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.57",
                    "title": "Revisiting Memory Errors in Large-Scale Production Data Centers: Analysis and Modeling of New Trends from the Field",
                    "authors": "Justin Meza, Qiang Wu, Sanjeev Kumar, Onur Mutlu",
                    "abstract": "Computing systems use dynamic random-access memory (DRAM) as main memory. As prior works have shown, failures in DRAM devices are an important source of errors in modern servers. To reduce the effects of memory errors, error correcting codes (ECC) have been developed to help detect and correct errors when they occur. In order to develop effective techniques, including new ECC mechanisms, to combat memory errors, it is important to understand the memory reliability trends in modern systems. In this paper, we analyze the memory errors in the entire fleet of servers at Facebook over the course of fourteen months, representing billions of device days. The systems we examine cover a wide range of devices commonly used in modern servers, with DIMMs manufactured by 4 vendors in capacities ranging from 2 GB to 24 GB that use the modern DDR3 communication protocol. We observe several new reliability trends for memory systems that have not been discussed before in literature. We show that (1) memory errors follow a power-law, specifically, a Pareto distribution with decreasing hazard rate, with average error rate exceeding median error rate by around 55×, (2) non-DRAM memory failures from the memory controller and memory channel cause the majority of errors, and the hardware and software overheads to handle such errors cause a kind of denial of service attack in some servers, (3) using our detailed analysis, we provide the first evidence that more recent DRAM cell fabrication technologies (as indicated by chip density) have substantially higher failure rates, increasing by 1.8× over the previous generation, (4) DIMM architecture decisions affect memory reliability: DIMMs with fewer chips and lower transfer widths have the lowest error rates, likely due to electrical noise reduction, (5) while CPU and memory utilization do not show clear trends with respect to failure rates, workload type can influence failure rate by up to 6:5×, suggesting certain memory access patterns may induce more errors, (6) we develop a model for memory reliability and show how system design choices such as using lower density DIMMs and fewer cores per chip can reduce failure rates of a baseline server by up to 57.7%, and (7) we perform the first implementation and real-system analysis of page offlining at scale, showing that it can reduce memory error rate by 67%, and identify several real-world impediments to the technique.",
                    "files": {
                        "openAccessPdf": "http://users.ece.cmu.edu/%7Eomutlu/pub/memory-errors-at-facebook_dsn15.pdf"
                    },
                    "abstract_zh": "计算系统使用动态随机存取存储器(DRAM)作为主存储器。如先前的工作所示，DRAM设备中的故障是现代服务器中错误的重要来源。为了减少存储器错误的影响，已经开发了纠错码(ECC)来帮助在错误发生时检测和纠正错误。为了开发有效的技术(包括新的ECC机制)来对抗存储器错误，理解现代系统中的存储器可靠性趋势是重要的。在本文中，我们分析了脸书整个服务器群在14个月内的内存错误，代表了数十亿个设备日。我们研究的系统涵盖了现代服务器中常用的各种设备，内存由4家供应商制造，容量从2 GB到24 GB不等，采用现代DDR3通信协议。我们观察到存储系统的几个新的可靠性趋势，这些趋势以前在文献中没有讨论过。我们证明了(1)内存错误遵循幂律，特别是风险率递减的帕累托分布，平均错误率超过中值错误率约55倍，(2)来自内存控制器和内存通道的非DRAM内存故障导致大多数错误，处理此类错误的硬件和软件开销在一些服务器中导致一种拒绝服务攻击，(3)使用我们的详细分析， 我们提供的第一个证据表明，最近的DRAM单元制造技术(如芯片密度所示)具有更高的故障率，比上一代增加了1.8倍，(4) DIMM架构决策影响内存可靠性:芯片数量更少、传输宽度更低的DIMM具有最低的错误率，这可能是由于电气噪声的降低，(5)虽然CPU和内存利用率没有显示出与故障率有关的明确趋势，但工作负载类型对故障率的影响高达6:5倍， 建议某些内存访问模式可能会导致更多错误，(6)我们开发了一个内存可靠性模型，并展示了系统设计选择(如使用更低密度的DIMMs和每芯片更少的内核)如何能够将基准服务器的故障率降低高达57.7%，(7)我们首次实施了大规模页面离线并对其进行了真实系统分析，结果表明它可以将内存错误率降低67%，并确定了该技术的几个现实障碍。",
                    "title_zh": "重新审视大规模生产数据中心的内存错误:来自现场的新趋势的分析和建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.58",
                    "title": "AVATAR: A Variable-Retention-Time (VRT) Aware Refresh for DRAM Systems",
                    "authors": "Moinuddin K. Qureshi, Dae-Hyun Kim, Samira Manabi Khan, Prashant J. Nair, Onur Mutlu",
                    "abstract": "Multirate refresh techniques exploit the non-uniformity in retention times of DRAM cells to reduce the DRAM refresh overheads. Such techniques rely on accurate profiling of retention times of cells, and perform faster refresh only for a few rows which have cells with low retention times. Unfortunately, retention times of some cells can change at runtime due to Variable Retention Time (VRT), which makes it impractical to reliably deploy multirate refresh. Based on experimental data from 24 DRAM chips, we develop architecture-level models for analyzing the impact of VRT. We show that simply relying on ECC DIMMs to correct VRT failures is unusable as it causes a data error once every few months. We propose AVATAR, a VRT-aware multirate refresh scheme that adaptively changes the refresh rate for different rows at runtime based on current VRT failures. AVATAR provides a time to failure in the regime of several tens of years while reducing refresh operations by 62%-72%.",
                    "files": {
                        "openAccessPdf": "https://figshare.com/articles/journal_contribution/AVATAR_A_Variable-Retention-Time_VRT_Aware_Refresh_for_DRAM_Systems/6468425/1/files/11896976.pdf"
                    },
                    "abstract_zh": "多速率刷新技术利用DRAM单元保持时间的不均匀性来减少DRAM刷新开销。这种技术依赖于单元保持时间的精确分布，并且仅对具有低保持时间单元的几行执行更快的刷新。不幸的是，由于可变的保持时间(VRT ),一些单元的保持时间可以在运行时改变，这使得可靠地部署多速率刷新不切实际。基于来自24个DRAM芯片的实验数据，我们开发了用于分析VRT影响的架构级模型。我们表明，简单地依靠ECC DIMMs来纠正VRT故障是不可行的，因为它每隔几个月就会导致一次数据错误。我们提出了AVATAR，一种VRT感知的多速率刷新方案，它在运行时根据当前VRT故障自适应地改变不同行的刷新率。AVATAR提供了几十年的故障时间，同时减少了62%-72%的刷新操作。",
                    "title_zh": "AVATAR:用于DRAM系统的可变保持时间(VRT)感知刷新"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.49",
                    "title": "Read Disturb Errors in MLC NAND Flash Memory: Characterization, Mitigation, and Recovery",
                    "authors": "Yu Cai, Yixin Luo, Saugata Ghose, Onur Mutlu",
                    "abstract": "NAND flash memory reliability continues to degrade as the memory is scaled down and more bits are programmed per cell. A key contributor to this reduced reliability is read disturb, where a read to one row of cells impacts the threshold voltages of unread flash cells in different rows of the same block. Such disturbances may shift the threshold voltages of these unread cells to different logical states than originally programmed, leading to read errors that hurt endurance. For the first time in open literature, this paper experimentally characterizes read disturb errors on state-of-the-art 2Y-nm (i.e., 20-24 nm) MLC NAND flash memory chips. Our findings (1) correlate the magnitude of threshold voltage shifts with read operation counts, (2) demonstrate how program/erase cycle count and retention age affect the read-disturb-induced error rate, and (3) identify that lowering pass-through voltage levels reduces the impact of read disturb and extend flash lifetime. Particularly, we find that the probability of read disturb errors increases with both higher wear-out and higher pass-through voltage levels. We leverage these findings to develop two new techniques. The first technique mitigates read disturb errors by dynamically tuning the pass-through voltage on a per-block basis. Using real workload traces, our evaluations show that this technique increases flash memory endurance by an average of 21%. The second technique recovers from previously-uncorrectable flash errors by identifying and probabilistically correcting cells susceptible to read disturb errors. Our evaluations show that this recovery technique reduces the raw bit error rate by 36%.",
                    "files": {
                        "openAccessPdf": "http://users.ece.cmu.edu/%7Eomutlu/pub/flash-read-disturb-errors_dsn15.pdf"
                    },
                    "abstract_zh": "随着存储器按比例缩小以及每单元编程更多的位，NAND闪存的可靠性继续下降。可靠性降低的主要原因是读取干扰，其中对一行单元的读取会影响同一块的不同行中的未读取闪存单元的阈值电压。这种干扰可能将这些未读单元的阈值电压转变为不同于原始编程的逻辑状态，导致损害耐久性的读取错误。在公开文献中，本文首次通过实验表征了最先进的2Y-nm(即20-24 nm) MLC NAND闪存芯片上的读取干扰错误。我们的发现(1)将阈值电压偏移的幅度与读取操作计数相关联，(2)证明编程/擦除循环计数和保留时间如何影响读取干扰引起的错误率，以及(3)确定降低通过电压电平减少读取干扰的影响并延长闪存寿命。特别地，我们发现读干扰错误的概率随着更高的损耗和更高的通过电压电平而增加。我们利用这些发现开发了两种新技术。第一种技术通过在每个块的基础上动态调整通过电压来减轻读取干扰误差。使用真实的工作负载跟踪，我们的评估表明，这种技术将闪存耐用性平均提高了21%。第二种技术通过识别和概率性地纠正易受读取干扰错误影响的单元，从先前不可纠正的闪存错误中恢复。我们的评估表明，这种恢复技术将原始误码率降低了36%。",
                    "title_zh": "MLC NAND闪存中的读取干扰错误:表征、缓解和恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.36",
                    "title": "Fine-Grained Characterization of Faults Causing Long Latency Crashes in Programs",
                    "authors": "Guanpeng Li, Qining Lu, Karthik Pattabiraman",
                    "abstract": "As the rate of transient hardware faults increases, researchers have investigated software techniques to tolerate these faults. An important class of faults are those that cause long- latency crashes (LLCs), or faults that can persist for a long time in the program before causing it to crash. In this paper, we develop a technique to automatically find program locations where LLC causing faults originate so that the locations can be protected to bound the program's crash latency. We first identify program code patterns that are responsible for the majority of LLC causing faults through an empirical study. We then build CRASHFINDER, a tool that finds LLC locations by statically searching the program for the patterns, and then refining the static analysis results with a dynamic analysis and selective fault injection-based approach. We find that CRASHFINDER can achieve an average of 9.29 orders of magnitude time reduction to identify more than 90% of LLC causing locations in the program, compared to exhaustive fault injection techniques, and has no false-positives.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着瞬时硬件故障率的增加，研究人员已经研究了容忍这些故障的软件技术。一类重要的错误是那些导致长延迟崩溃(LLC)的错误，或者在导致程序崩溃之前可以在程序中持续很长时间的错误。在这篇文章中，我们开发了一种技术来自动找到LLC导致故障的程序位置，以便可以保护这些位置来限制程序的崩溃延迟。我们首先通过一项经验研究来确定造成大多数LLC错误的程序代码模式。然后，我们构建CRASHFINDER，这是一个工具，它通过静态搜索程序中的模式来查找LLC位置，然后使用基于动态分析和选择性故障注入的方法来细化静态分析结果。我们发现，与穷举故障注入技术相比，CRASHFINDER可以实现平均9.29个数量级的时间减少，以识别程序中超过90%的LLC原因位置，并且没有假阳性。",
                    "title_zh": "导致程序长延迟崩溃的故障的细粒度特征"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.56",
                    "title": "User-Constraint and Self-Adaptive Fault Tolerance for Event Stream Processing Systems",
                    "authors": "André Martin, Tiaraju Smaneoto, Tobias Dietze, Andrey Brito, Christof Fetzer",
                    "abstract": "Event Stream Processing (ESP) Systems are currently enabling a renaissance in the data processing area as they provide results at low latency compared to the traditional MapReduce approach. Although the majority of ESP systems offer some form of fault tolerance to their users, the provided fault tolerance scheme is often not tailored to the application at hand. For example, active replication is well suited for critical applications where unresponsiveness due to a background recovery process is not acceptable. However, for other classes of applications without such tight constraints, the use of passive replication, based on checkpoints and logging, is a better choice as it can save a significant amount of resources compared to active replication. In this paper, we present StreamMine3G, a fault tolerant and elastic ESP system which employs several fault tolerance schemes, such as passive and active replication as well as intermediate alternatives such as active and passive standby. In order to free the user from the burden of choosing the correct scheme for the application at hand, StreamMine3G is equipped with a fault-tolerance controller that transitions between the employed schemes during runtime in response to the evolution of the given workload and the user's provided constraints (recovery time and semantics, i.e., gap or precise). Our evaluation shows that the overall resource footprint for fault tolerance can be considerably reduced using our adaptive approach without consequences to the recovery time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "事件流处理(ESP)系统目前正在推动数据处理领域的复兴，因为与传统的MapReduce方法相比，它们以低延迟提供结果。尽管大多数ESP系统为它们的用户提供了某种形式的容错，但是所提供的容错方案通常不适合手边的应用。例如，主动复制非常适合于关键应用程序，在这些应用程序中，由于后台恢复过程而导致的无响应是不可接受的。但是，对于没有如此严格限制的其他类别的应用程序，使用基于检查点和日志记录的被动复制是更好的选择，因为与主动复制相比，它可以节省大量资源。在本文中，我们介绍了StreamMine3G，这是一个容错和弹性ESP系统，它采用了多种容错方案，如被动和主动复制以及中间替代方案，如主动和被动备用。为了将用户从为手边的应用选择正确方案的负担中解放出来，StreamMine3G配备了容错控制器，该控制器在运行时根据给定工作负载的变化和用户提供的约束(恢复时间和语义，即gap或precise)在所采用的方案之间转换。我们的评估表明，使用我们的自适应方法可以显著减少容错的总体资源占用，而不会影响恢复时间。",
                    "title_zh": "事件流处理系统的用户约束和自适应容错"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.45",
                    "title": "Lightweight Memory Checkpointing",
                    "authors": "Dirk Vogt, Cristiano Giuffrida, Herbert Bos, Andrew S. Tanenbaum",
                    "abstract": "Memory check pointing is a pivotal technique in systems reliability, with applications ranging from crash recovery to replay debugging. Unfortunately, many traditional memory check pointing use-cases require high-frequency checkpoints, something for which existing application-level solutions are not well-suited. The problem is that they incur either substantial run-time performance overhead, or poor memory usage guarantees. As a result, their application in practice is hampered. This paper presents Lightweight Memory Check pointing (LMC), a new user-level memory check pointing technique that combines low performance overhead with strong memory usage guarantees for high check pointing frequencies. To this end, LMC relies on compiler-based instrumentation to shadow the entire memory address space of the running program and incrementally checkpoint modified memory bytes in a LMC-maintained shadow state. Our evaluation on popular server applications demonstrates the viability of our approach in practice, confirming that LMC imposes low performance overhead with strictly bounded memory usage at runtime.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内存检查点是系统可靠性的关键技术，应用范围从崩溃恢复到重放调试。不幸的是，许多传统的内存检查点用例需要高频率的检查点，而现有的应用程序级解决方案并不适合这种情况。问题是，它们要么导致大量的运行时性能开销，要么导致较差的内存使用保证。因此，它们在实践中的应用受到阻碍。本文介绍了轻量级内存检查点(LMC)，这是一种新的用户级内存检查点技术，结合了低性能开销和高检查点频率的强大内存使用保证。为此，LMC依靠基于编译器的工具来隐藏正在运行的程序的整个内存地址空间，并在LMC维护的隐藏状态中递增地检查点修改的内存字节。我们在流行的服务器应用程序上的评估证明了我们的方法在实践中的可行性，证实了LMC在运行时以严格受限的内存使用强加了低性能开销。",
                    "title_zh": "轻量级内存检查点"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.54",
                    "title": "HeapTherapy: An Efficient End-to-End Solution against Heap Buffer Overflows",
                    "authors": "Qiang Zeng, Mingyi Zhao, Peng Liu",
                    "abstract": "For decades buffer overflows have been one of the most prevalent and dangerous software vulnerabilities. Although many techniques have been proposed to address the problem, they mostly introduce a very high overhead while others assume the availability of a separate system to pinpoint attacks or provide detailed traces for defense generation, which is very slow in itself and requires considerable extra resources. We propose an efficient solution against heap buffer overflows that integrates exploit detection, defense generation, and overflow prevention in a single system, named Heap Therapy. During program execution it conducts on-the-fly lightweight trace collection and exploit detection, and initiates automated diagnosis upon detection to generate defenses in real-time. It can handle both over-write and over-read attacks, such as the recent Heartbleed attack. The system has no false positives, and keeps effective under polymorphic exploits.%as the generated defense captures semantic characteristics of exploits. It is compliant with mainstream hardware and operating systems, and does not rely on specific allocation algorithms. We evaluated Heap Therapy on a variety of services (database, web, and ftp) and benchmarks (SPEC CPU2006), it incurs a very low average overhead in terms of both speed (6.2%) and memory (7.7%).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "几十年来，缓冲区溢出一直是最普遍和最危险的软件漏洞之一。尽管已经提出了许多技术来解决该问题，但它们大多引入了非常高的开销，而其他技术则假设有单独的系统来查明攻击或提供防御生成的详细跟踪，这本身就非常慢，并且需要相当多的额外资源。我们提出了一种有效的解决堆缓冲区溢出的方法，它将利用检测、防御生成和溢出预防集成在一个系统中，称为堆疗法。在程序执行期间，它进行动态轻量级跟踪收集和漏洞检测，并在检测到漏洞时启动自动诊断，以实时生成防御措施。它可以处理重写和重写攻击，例如最近的Heartbleed攻击。该系统没有误报，在多态攻击下仍然有效。%因为生成的防御捕获了漏洞利用的语义特征。它兼容主流硬件和操作系统，不依赖于特定的分配算法。我们在各种服务(数据库、web和ftp)和基准(SPEC CPU2006)上评估了堆疗法，它在速度(6.2%)和内存(7.7%)方面产生了非常低的平均开销。",
                    "title_zh": "堆疗法:一种有效的防止堆缓冲区溢出的端到端解决方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.41",
                    "title": "Smart-TV Security Analysis: Practical Experiments",
                    "authors": "Yann Bachy, Frederic Basse, Vincent Nicomette, Eric Alata, Mohamed Kaâniche, Jean-Christophe Courrège, Pierre Lukjanenko",
                    "abstract": "Modern home networks are becoming more and more complex with the integration of various types of interconnected smart devices, using heterogeneous networking technologies. Many of these devices are also connected to the Internet, generally through an integrated access device. Those smart devices are potentially vulnerable to several types of attacks. In this practical experience report we investigate the specific case of smart TVs. The main objective is to experimentally explore possible attack vectors and identify practically exploitable vulnerabilities and attack scenarios. In particular, the study covers local and remote attacks using different entry points, including the Digital Video Broadcasting (DVB) transmission channel and the copper-pair local loop. Several methods, allowing to observe and simulate service provider networks, are used to support several experiments considering four types of commercially available smart TVs for a comparative analysis. We also discuss several methods allowing to extract and analyze the embedded firmware, and obtain relevant information concerning target devices.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01178553/file/dsn_smarttv_v12.pdf"
                    },
                    "abstract_zh": "随着使用异构网络技术的各种类型的互连智能设备的集成，现代家庭网络变得越来越复杂。这些设备中的许多也通常通过集成接入设备连接到互联网。这些智能设备可能容易受到几种类型的攻击。在这份实践经验报告中，我们调查了智能电视的具体案例。主要目的是通过实验探索可能的攻击媒介，并识别实际可利用的漏洞和攻击场景。特别是，该研究涵盖了使用不同入口点的本地和远程攻击，包括数字视频广播(DVB)传输通道和铜线对本地环路。允许观察和模拟服务提供商网络的几种方法用于支持几个实验，考虑四种类型的商用智能电视进行比较分析。我们还讨论了几种允许提取和分析嵌入式固件的方法，并获得关于目标设备的相关信息。",
                    "title_zh": "智能电视安全性分析:实践实验"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.30",
                    "title": "On the Metrics for Benchmarking Vulnerability Detection Tools",
                    "authors": "Nuno Antunes, Marco Vieira",
                    "abstract": "Research and practice show that the effectiveness of vulnerability detection tools depends on the concrete use scenario. Benchmarking can be used for selecting the most appropriate tool, helping assessing and comparing alternative solutions, but its effectiveness largely depends on the adequacy of the metrics. This paper studies the problem of selecting the metrics to be used in a benchmark for software vulnerability detection tools. First, a large set of metrics is gathered and analyzed according to the characteristics of a good metric for the vulnerability detection domain. Afterwards, the metrics are analyzed in the context of specific vulnerability detection scenarios to understand their effectiveness and to select the most adequate one for each scenario. Finally, an MCDA algorithm together with experts' judgment is applied to validate the conclusions. Results show that although some of the metrics traditionally used like precision and recall are adequate in some scenarios, others require alternative metrics that are seldom used in the benchmarking area.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "研究和实践表明，漏洞检测工具的有效性取决于具体的使用场景。基准测试可用于选择最合适的工具，帮助评估和比较备选解决方案，但其有效性在很大程度上取决于指标的充分性。本文研究了软件漏洞检测工具基准中度量标准的选择问题。首先，根据漏洞检测领域的良好指标的特征，收集并分析大量指标。然后，在特定漏洞检测场景的上下文中分析这些指标，以了解它们的有效性，并为每个场景选择最合适的指标。最后，应用MCDA算法和专家判断对结论进行验证。结果表明，虽然传统上使用的一些度量标准(如精确度和召回率)在某些场景中已经足够，但其他一些度量标准需要在基准测试领域中很少使用的替代度量标准。",
                    "title_zh": "漏洞检测工具的基准度量"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.28",
                    "title": "Formal Assurance Arguments: A Solution in Search of a Problem?",
                    "authors": "Patrick John Graydon",
                    "abstract": "An assurance case comprises evidence and argument showing how that evidence supports assurance claims (e.g., about safety or security). It is unsurprising that some computer scientists have proposed formalising assurance arguments: most associate formality with rigour. But while engineers can sometimes prove that source code refines a formal specification, it is not clear that formalisation will improve assurance arguments or that this benefit is worth its cost. For example, formalisation might reduce the benefits of argumentation by limiting the audience to people who can read formal logic. In this paper, we present (1) a systematic survey of the literature surrounding formal assurance arguments, (2) an analysis of errors that formalism can help to eliminate, (3) a discussion of existing evidence, and (4) suggestions for experimental work to definitively answer the question.",
                    "files": {
                        "openAccessPdf": "https://ntrs.nasa.gov/api/citations/20160006364/downloads/20160006364.pdf"
                    },
                    "abstract_zh": "保证案例包括证据和论证，表明该证据如何支持保证声明(例如，关于安全或保障)。不足为奇的是，一些计算机科学家提出了形式化的保证论点:大多数人将形式与严谨联系在一起。但是，虽然工程师有时可以证明源代码提炼了一个正式的规范，但还不清楚形式化是否会改善保证论点，或者这种好处是否值得其成本。例如，形式主义可能会通过将观众限制在能够理解形式逻辑的人身上来减少论证的好处。在这篇论文中，我们提出(1)围绕形式保证论证的文献的系统调查，(2)形式主义可以帮助消除的错误的分析，(3)现有证据的讨论，以及(4)明确回答这个问题的实验工作的建议。",
                    "title_zh": "形式保证论证:寻找问题的解决方案？"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.25",
                    "title": "A Quality Control Engine for Complex Physical Systems",
                    "authors": "Haifeng Chen, Takehiko Mizoguchi, Yan Tan, Kai Zhang, Geoff Jiang",
                    "abstract": "This paper proposes a novel framework to automatically pinpoint suspicious sensors that lead to the quality change in physical systems such as manufacture plants. Our framework treats sensor readings as time series, and contains three main stages: time series transformation to feature series, feature ranking, and ranking score fusion. In the first step, we transform time series into a number of different feature series to describe the underlying dynamics of each sensor data. After that, the importance scores of all feature series are computed by utilizing several feature selection and ranking techniques, each of which discovers specific aspects of feature importance and their dependencies in the feature space. Finally we combine importance scores from all the rankers and all the features to obtain the final ranking of each sensor with respect to the system quality change. Our experiments based on synthetic time series as well as sensor data from a real system demonstrate the effectiveness of proposed method. In addition, we have implemented our framework as a production engine, and successfully applied it to several real physical systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了一个新的框架来自动查明导致制造工厂等物理系统质量变化的可疑传感器。我们的框架将传感器读数视为时间序列，包含三个主要阶段:时间序列向特征序列的转换、特征排序和排序得分融合。在第一步中，我们将时间序列转换成一些不同的特征序列，以描述每个传感器数据的潜在动态。之后，通过利用几种特征选择和排序技术来计算所有特征序列的重要性分数，每种技术发现特征重要性的特定方面以及它们在特征空间中的依赖性。最后，我们结合来自所有排序器和所有特征的重要性分数，以获得每个传感器相对于系统质量变化的最终排序。基于合成时间序列和真实系统传感器数据的实验验证了该方法的有效性。此外，我们已经实现了我们的框架作为一个生产引擎，并成功地应用于几个实际的物理系统。",
                    "title_zh": "复杂物理系统的质量控制引擎"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.23",
                    "title": "Discovering and Visualizing Operations Processes with POD-Discovery and POD-Viz",
                    "authors": "Ingo Weber, Chao Li, Len Bass, Xiwei Xu, Liming Zhu",
                    "abstract": "Understanding the behavior of an operations process and capturing it as an abstract process model has been shown to improve dependability significantly [1]. In particular, process context can be used for error detection, diagnosis, and even automated recovery. Creating the process model is an essential step in determining process context and, consequently, improving dependability. This paper describes two systems. The first, POD-Discovery, simplifies the creation of such an abstract process model from operations logs. An activity that previously required many manual steps can now be done largely automatically and in minutes. Using the discovered model, the second system, POD-Viz, provides operators with the ability to visualize the current state of an operations process in near-real-time and to replay a set of events to understand how the process context changed over time. This allows operators to trace the progress of an operations process easily, and helps in analyzing encountered errors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "理解操作流程的行为并将其作为抽象流程模型捕获，已经被证明可以显著提高可靠性[1]。特别是，流程上下文可以用于错误检测、诊断，甚至自动恢复。创建过程模型是确定过程上下文，从而提高可靠性的重要步骤。本文描述了两个系统。第一个是POD-发现，它简化了从操作日志中创建这种抽象流程模型的过程。以前需要许多手动步骤的活动现在可以在几分钟内自动完成。使用发现的模型，第二个系统POD-Viz为操作员提供了近实时可视化操作过程的当前状态的能力，并重放一组事件以了解过程上下文如何随时间变化。这使得操作员可以轻松跟踪操作过程的进度，并有助于分析遇到的错误。",
                    "title_zh": "通过POD-探索和POD-发现和可视化操作流程"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.39",
                    "title": "Incinerator - Eliminating Stale References in Dynamic OSGi Applications",
                    "authors": "Koutheir Attouchi, Gaël Thomas, Gilles Muller, Julia Lawall, André Bottaro",
                    "abstract": "Java class loaders are commonly used in application servers to load, unload and update a set of classes as a unit. However, unloading or updating a class loader can introduce stale references to the objects of the outdated class loader. A stale reference leads to a memory leak and, for an update, to an inconsistency between the outdated classes and their replacements. To detect and eliminate stale references, we propose Incinerator, a Java virtual machine extension that introduces the notion of an outdated class loader. Incinerator detects stale references and sets them to null during a garbage collection cycle. We evaluate Incinerator in the context of the OSGi framework and show that Incinerator correctly detects and eliminates stale references, including a bug in Knopflerfish. We also evaluate the performance of Incinerator with the DaCapo benchmark on VMKit and show that Incinerator has an overhead of at most 3.3%.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-00952327/file/RR-8485.pdf"
                    },
                    "abstract_zh": "Java类装入器通常用在应用服务器中，作为一个单元装入、卸载和更新一组类。然而，卸载或更新类装入器可能会引入对过时的类装入器的对象的陈旧引用。过时的引用会导致内存泄漏，对于更新来说，还会导致过时的类和它们的替换类之间的不一致。为了检测和消除过时的引用，我们提出了焚化炉，一个Java虚拟机扩展，它引入了过时的类加载器的概念。焚烧炉在垃圾收集周期中检测过时的引用并将它们设置为空。我们在OSGi框架的上下文中评估了焚化炉，并展示了焚化炉能正确地检测和消除陈旧的引用，包括Knopflerfish中的一个bug。我们还使用VMKit上的DaCapo基准对焚烧炉的性能进行了评估，结果显示焚烧炉的开销最多为3.3%。",
                    "title_zh": "焚化炉-消除动态OSGi应用程序中的陈旧引用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.59",
                    "title": "Risk Assessment of Buffer \"Heartbleed\" Over-Read Vulnerabilities",
                    "authors": "Jun Wang, Mingyi Zhao, Qiang Zeng, Dinghao Wu, Peng Liu",
                    "abstract": "Buffer over-read vulnerabilities (e.g., Heartbleed) can lead to serious information leakage and monetary lost. Most of previous approaches focus on buffer overflow (i.e., over-write), which are either infeasible (e.g., canary) or impractical (e.g., bounds checking) in dealing with over-read vulnerabilities. As an emerging type of vulnerability, people need in-depth understanding of buffer over-read: the vulnerability, the security risk and the defense methods. This paper presents a systematic methodology to evaluate the potential risks of unknown buffer over-read vulnerabilities. Specifically, we model the buffer over-read vulnerabilities and focus on the quantification of how much information can be potentially leaked. We perform risk assessment using the RUBiS benchmark which is an auction site prototype modeled after eBay.com. We evaluate the effectiveness and performance of a few mitigation techniques and conduct a quantitative risk measurement study. We find that even simple techniques can achieve significant reduction on information leakage against over-read with reasonable performance penalty. We summarize our experience learned from the study, hoping to facilitate further studies on the over-read vulnerability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "缓冲区过度读取漏洞(例如Heartbleed)会导致严重的信息泄漏和金钱损失。大多数先前的方法集中于缓冲区溢出(即，重写)，这在处理过度读取漏洞时要么是不可行的(例如，canary)要么是不切实际的(例如，边界检查)。作为一种新兴的漏洞类型，人们需要深入了解缓冲区过度读取:漏洞、安全风险和防御方法。本文提出了一种评估未知缓冲区过度读取漏洞潜在风险的系统方法。具体来说，我们对缓冲区过度读取漏洞进行建模，并重点关注量化可能会泄露多少信息。我们使用RUBiS基准进行风险评估，这是一个模仿eBay.com的拍卖网站原型。我们评估一些缓解技术的有效性和性能，并进行定量风险测量研究。我们发现，即使是简单的技术也可以在合理的性能损失下显著减少过度读取的信息泄漏。我们总结了从研究中获得的经验，希望有助于对过度阅读漏洞的进一步研究。",
                    "title_zh": "缓冲区“Heartbleed”过度读取漏洞的风险评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.66",
                    "title": "Workshop on Dependability Issues on SDN and NFV (DISN)",
                    "authors": "Elias P. Duarte Jr., Matti A. Hiltunen",
                    "abstract": "Software-Defined Networks (SDN) and Network Function Virtualization (NFV) are two technologies that have already had a deep impact on computer and telecommunication networks. Software Defined Networks (SDN) decouple network control from forwarding functions, enabling network control to become directly programmable and the underlying infrastructure to be abstracted from applications and network services. Network Function Virtualization (NFV) is a network architecture concept where IT virtualization techniques are used to implement network node functions as building blocks that may be combined, or chained, together to create communication services. SDN and NFV make it simpler and faster to deploy and manage new services, avoiding the cost and the long time frame required to design and implement hardwarebased network services. SDN and NVF introduce numerous dependability challenges. In terms of reliability, the challenges range from the design of reliable new SDN and NFV technologies to the adaptation of classical network functions to these technologies. The effective, dependable deployment of the virtual network on the physical substrate is particularly important. In terms of security, the challenges are enormous, as SDN and NFV are meant to be the very fabric of both the Internet and private networks. Threats, privacy concerns, authentication issues, and isolation - defining a truly secure virtualized network requires work on multiple fronts. The program of DISN'2015 consists of 3 technical papers and 2 keynotes, which are briefly described.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(SDN)和网络功能虚拟化(NFV)是已经对计算机和电信网络产生深刻影响的两项技术。软件定义网络(SDN)将网络控制从转发功能中分离出来，使网络控制变得可直接编程，底层基础设施从应用和网络服务中抽象出来。网络功能虚拟化(NFV)是一种网络架构概念，其中IT虚拟化技术用于将网络节点功能实现为构建块，这些构建块可以组合或链接在一起以创建通信服务。SDN和NFV使部署和管理新服务变得更简单、更快速，避免了设计和实施基于硬件的网络服务所需的成本和长时间。SDN和NVF带来了众多可靠性挑战。在可靠性方面，挑战的范围从设计可靠的新SDN和NFV技术到使传统网络功能适应这些技术。在物理基础上有效、可靠地部署虚拟网络尤为重要。在安全性方面，挑战是巨大的，因为SDN和NFV是互联网和私有网络的基础。威胁、隐私问题、认证问题和隔离——定义真正安全的虚拟化网络需要多方面的努力。DISN 2015项目包括3篇技术论文和2篇主题演讲，简要介绍如下。",
                    "title_zh": "SDN和NFV可靠性问题研讨会(DISN)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.67",
                    "title": "Workshop on Model Based Design for Cyber-Physical Systems (MB4CP)",
                    "authors": "Alberto Avritzer, Daniel Sadoc Menasché, Kishor S. Trivedi, Lucia Happe, Sahra Sedigh Sarvestani",
                    "abstract": "This paper provides a summary of the First International Workshop on Model Based Design for Cyber- Physical Systems (MB4CP 2015) in conjunction with DSN 2015 conference in Rio de Janeiro, Brazil.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文总结了在巴西里约热内卢召开的首届基于模型的信息物理系统设计国际研讨会(MB4CP 2015)和DSN 2015会议。",
                    "title_zh": "基于模型的信息物理系统设计研讨会(MB4CP)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.68",
                    "title": "Workshop on Recent Advances in the DependabIlity AssessmeNt of Complex systEms (RADIANCE)",
                    "authors": "Ariadne M. B. R. Carvalho, Nuno Antunes, Andrea Ceccarelli, András Zentai",
                    "abstract": "The workshop on Recent Advances in the DependabIlity AssessmeNt of Complex systEms (RADIANCE), in its first edition, aims to discuss novel dependability assessment approaches for complex systems and to promote their adoption in real-world settings through industrial and academic research. The main objective is to promote and foster discussion on novel ideas, constituting a forum where researchers can share both real problems and innovative solutions for the assessment of complex systems. The workshop focuses on assessing complex evolving systems, where increasing complexity and changes are due to the introduction of new components and sensors, and to the extensive usage of software OTS components or black box components in general. In this macro area, the workshop welcomed a broad list of applications ranging from agile development in critical systems to model-driven assessment approaches as well as new needs for verification, validation and certification of dynamic and evolving systems, which also includes solutions for automating the verification and validation processes. Finally, the workshop was interested in",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/7265894/7266818/07266885.pdf"
                    },
                    "abstract_zh": "复杂系统可靠性评估最新进展研讨会(RADIANCE)的第一版旨在讨论复杂系统的新型可靠性评估方法，并通过工业和学术研究促进其在现实世界中的应用。主要目的是促进和鼓励对新思想的讨论，建立一个论坛，在这里研究人员可以分享真实的问题和复杂系统评估的创新解决方案。该研讨会重点评估复杂的进化系统，其中不断增加的复杂性和变化是由于新组件和传感器的引入，以及软件OTS组件或黑盒组件的广泛使用。在这一宏观领域，研讨会欢迎一系列广泛的应用，从关键系统的敏捷开发到模型驱动的评估方法，以及动态和不断发展的系统的验证、确认和认证的新需求，其中也包括验证和确认过程自动化的解决方案。最后，讲习班感兴趣的是",
                    "title_zh": "复杂系统可靠性评估最新进展研讨会"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2015.69",
                    "title": "Workshop on Safety and Security of Intelligent Vehicles (SSIV)",
                    "authors": "João Carlos Cunha, Kalinka Branco, António Casimiro, Urbano Nunes",
                    "abstract": "For intelligent vehicles to become a reality, further research and development must be performed, addressing the needs of multidisciplinary approaches like integrated control systems, communication and network, security algorithms, artificial intelligence, verification and validation, neural networks, safety assets and other technological concerns. The goal of this workshop is to explore the challenges and innovative solutions regarding intelligent vehicles, considering the implications of security and real-time issues on safety and certification, which emerge when introducing networked, autonomous and cooperative functionalities. It aims at joining together in an active debate, researchers and practitioners from several communities, namely dependability and security, realtime and embedded systems, intelligent transportation and mobile robot systems. This workshop is aimed at exploring the challenges and innovative solutions related to the security and safety of intelligent vehicles.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了让智能汽车成为现实，必须进行进一步的研究和开发，解决多学科方法的需求，如集成控制系统、通信和网络、安全算法、人工智能、验证和确认、神经网络、安全资产和其他技术问题。本次研讨会的目标是探讨智能车辆面临的挑战和创新解决方案，考虑引入联网、自主和协作功能时出现的安全和实时问题对安全和认证的影响。它旨在将来自几个社区的研究人员和从业人员聚集在一起进行积极的辩论，即可靠性和安全性、实时和嵌入式系统、智能交通和移动机器人系统。本次研讨会旨在探索与智能车辆的安保和安全相关的挑战和创新解决方案。",
                    "title_zh": "智能车辆安全与保障研讨会(SSIV)"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2015w.html",
            "conf_title": "DSN 2015: Rio de Janeiro, Brazil",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7269513/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.41",
                    "title": "MB4CP 2015 Keynote I: Dependability Modeling and Analysis Methods Integrated in Model-Driven Industrial Architectural Frameworks",
                    "authors": "Andrea Bondavalli",
                    "abstract": "Summary form only given. In the last ten years, model-driven engineering approaches have been extensively used for the analysis of extra-functional properties of complex systems, like safety, dependability, security, predictability, and quality of service. To this end, engineering languages such as UML and AADL have been extended with additional features to model the required non-functional attributes, and transformations have been used to automatically generate the analysis models to be solved by appropriate analysis tools. In this talk, we explore this research direction and describe our activities, presenting dependability modeling and analysis methods integrated in industrial-driven architectural frameworks for the specification, analysis, and verification of extra-functional properties of cyber-physical systems, developed within the past ARTEMIS-JU CHESS project and currently within the ARTEMIS-JU CONCERTO project. We discuss the lessons learned and experience gained from successful application of cyber-physical systems industry standards in software systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "仅提供总结表格。在过去的十年中，模型驱动的工程方法被广泛用于复杂系统的额外功能属性的分析，如安全性、可靠性、安全性、可预测性和服务质量。为此，诸如UML和AADL之类的工程语言已经被扩展了附加特征，以对所需的非功能属性进行建模，并且转换已经被用于自动生成将由适当的分析工具解决的分析模型。在本次演讲中，我们将探索这一研究方向并描述我们的活动，展示集成在工业驱动的架构框架中的可靠性建模和分析方法，用于信息物理系统额外功能属性的规范、分析和验证，这些方法是在过去的ARTEMIS-JU CHESS项目和当前的ARTEMIS-JU CONCERTO项目中开发的。我们讨论了在软件系统中成功应用信息物理系统行业标准的经验教训。",
                    "title_zh": "MB4CP 2015主题演讲I:集成在模型驱动的工业架构框架中的可信性建模和分析方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.42",
                    "title": "MB4CP 2015 Keynote II: Resilience of Cyber-Physical Energy Systems",
                    "authors": "Paulo Jorge Esteves Veríssimo",
                    "abstract": "Electrical utility infrastructures have become largely computerized, remotely/automatically controlled, and interconnected, amongst each other and with other types of critical infrastructures, and we are witnessing the explosion of new paradigms: distributed generation, smart grids. In this accelerated mutation of power grids to cyber-physical systems, may it be that some things are “lost in translation”? Are we using the right models to represent, design, build and analyze cyber physical energy systems? Especially when what used to be an electrical infrastructure became quite susceptible to computer-borne problems such as digital accidental faults and malicious cyber-attacks? This talk will challenge the audience with some reflections and points for discussion along these topics.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "电力设施基础设施已经基本上实现了计算机化、远程/自动控制，并且相互之间以及与其他类型的关键基础设施相互连接，我们正在见证新范例的爆炸:分布式发电、智能电网。在这种电网向网络物理系统的加速突变中，可能有些东西是“迷失在翻译中”的吗？我们是否使用了正确的模型来表示、设计、构建和分析网络物理能源系统？尤其是当曾经的电力基础设施变得非常容易受到计算机引发的问题(如数字意外故障和恶意网络攻击)的影响时？这个演讲将会向听众提出一些思考，以及围绕这些主题的讨论要点。",
                    "title_zh": "MB4CP 2015主题演讲II:信息物理能源系统的弹性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.25",
                    "title": "SeReNe: On Establishing Secure and Resilient Networking Services for an SDN-based Multi-tenant Datacenter Environment",
                    "authors": "Chun-Jen Chung, Tianyi Xing, Dijiang Huang, Deep Medhi, Kishor S. Trivedi",
                    "abstract": "In the current enterprise data enter networking environment, a major hurdle in the development of network security is the lack of an orchestrated and resilient defensive mechanism that uses well-established quantifiable metrics, models, and evaluation methods. In this position paper, we describe an emerging Secure and Resilient Networking (SeReNe) service model to establish a programmable and dynamic defensive mechanism that can adjust the system's networking resources such as topology, bandwidth allocation, and traffic/flow forwarding policies, according to the network security situations. We posit that this requires addressing two interdependent technical areas: (a) a Moving Target Defense (MTD) framework both at networking and software levels, and (b) an Adaptive Security-enabled Traffic Engineering (ASeTE) approach to select optimal countermeasures by considering the effectiveness of countermeasures and network bandwidth allocations while minimizing the intrusiveness to the applications and the cost of deploying the countermeasures. We believe that our position can greatly benefit the virtual networking system established in data Centerior enterprise virtual networking systems that have adopted latest Open Flow technologies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在当前的企业数据输入网络环境中，网络安全发展中的一个主要障碍是缺乏一个协调一致的弹性防御机制，该机制使用成熟的可量化指标、模型和评估方法。在本立场文件中，我们描述了一个新兴的安全和弹性网络(SeReNe)服务模型，以建立一个可编程的动态防御机制，该机制可以根据网络安全状况调整系统的网络资源，如拓扑结构、带宽分配和流量/流转发策略。我们认为，这需要解决两个相互依赖的技术领域:(a)网络和软件层面的移动目标防御(MTD)框架，以及(b)自适应安全启用流量工程(ASeTE)方法，通过考虑对策的有效性和网络带宽分配来选择最佳对策，同时最小化对应用程序的入侵和部署对策的成本。我们相信，我们的职位可以极大地有利于在数据中心建立的虚拟网络系统或采用最新开放流技术的企业虚拟网络系统。",
                    "title_zh": "SeReNe:为基于SDN的多租户数据中心环境建立安全、弹性的网络服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.11",
                    "title": "Video on Demand Hosted in Private Cloud: Availability Modeling and Sensitivity Analysis",
                    "authors": "Rosangela Melo, Maria Clara Bezerra, Jamilson Dantas, Rúbens de Souza Matos Júnior, Ivanildo José de Melo Filho, Paulo Romero Martins Maciel",
                    "abstract": "Cloud computing environments have recently emerged as a new computing paradigm for organizing a shared pool of servers in data centres into a cloud infrastructure that can provide on demand service utilities. Due to the business potential of the pay-per-use model, as well as the advantages of easy scalability, up-to-date Multimedia Services can rely on cloud infrastructures to offer a wide variety of services, like video streaming, where the user can access their videos from cloud environments. Hierarchical analytical models are effective tools to evaluate the availability of complex systems and services such as these. This paper proposes the application of availability models to a cloud environment designed for a video streaming service. The hierarchical models thus created comprise Reliability Block Diagrams (RBDs) and Markov chains. Sensitivity analysis's used to determine the parameters that cause the greatest impact on the availability. The results obtained from case studies clearly demonstrate that sensitivity analysis is a valuable tool for identifying which components require attention when attempting to achieve increased availability in a system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云计算环境最近作为一种新的计算模式出现，用于将数据中心的服务器共享池组织成能够提供按需服务实用程序的云基础设施。由于按使用付费模式的商业潜力以及易于扩展的优势，最新的多媒体服务可以依赖云基础设施来提供各种各样的服务，如视频流，用户可以从云环境中访问他们的视频。层次分析模型是评估此类复杂系统和服务可用性的有效工具。本文提出了可用性模型在为视频流服务设计的云环境中的应用。如此创建的分层模型包括可靠性框图(rbd)和马尔可夫链。敏感性分析用于确定对可用性影响最大的参数。从案例研究中获得的结果清楚地表明，敏感性分析是一种有价值的工具，用于确定在试图提高系统可用性时需要注意哪些组件。",
                    "title_zh": "私有云托管的视频点播:可用性建模和敏感性分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.30",
                    "title": "Implementation of Failure Detector Based on Network Function Virtualization",
                    "authors": "Rogério C. Turchetti, Elias Procópio Duarte Jr.",
                    "abstract": "Network Function Virtualization (NFV) is an emerging technology that uses software virtualization techniques to implement network functions that are usually deployed on specific hardware and software devices. With NFV it is possible to design, deploy, and manage network functions in a fraction of the time it often takes to do the same in non-virtualized settings. NFV improves the flexibility and reduces the time for the development, deployment and management of new functions. In this paper, we propose NFV-FD: a NFV to detect process and link failures. NFV-FD relies on an OpenFlow controller from which information about the network is obtained. With this information NFV-FD keeps track of the state of both processes and links. NFV-FD was implemented and experimental results are reported for the amount of resources required by the virtual function, as well as the quality of the failure detection and notification service.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络功能虚拟化(NFV)是一种新兴技术，它使用软件虚拟化技术来实现通常部署在特定硬件和软件设备上的网络功能。借助NFV，设计、部署和管理网络功能所需的时间只需在非虚拟化环境中完成同样工作所需时间的一小部分。NFV提高了灵活性，减少了开发、部署和管理新功能的时间。在本文中，我们提出了NFV-FD:一个NFV来检测进程和链路故障。NFV-FD依赖于OpenFlow控制器，从该控制器获得关于网络的信息。有了这些信息，NFV-FD可以跟踪进程和链路的状态。实现了NFV-FD，并且报告了虚拟功能所需的资源量以及故障检测和通知服务的质量的实验结果。",
                    "title_zh": "基于网络功能虚拟化的故障检测器的实现"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.36",
                    "title": "RADIANCE 2015 Keynote: Challenges in Engineering Dependable Self-Adaptive System",
                    "authors": "Bradley R. Schmerl",
                    "abstract": "To provide some levels of dependency in software systems, self-adaptive systems have been proposed as a principled approach to engineering software systems to adapt systems to meet requirements even in the face of changes and uncertainty in the environment. But how can we show that changing a system at run time will make systems more dependable? In this keynote, I will outline a set of challenges for providing assurances for self-adaptive systems, and describe work that our group has been doing that can provide evidence for assurances in a number of contexts, including collaborative self-adaptation with humans-in-the-loop. I will discuss how probabilistic model checking can be used to explore the state space of self-adaptive systems, and how they can provide more realistic models of the impacts that adapting a system may have on the system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了在软件系统中提供某种程度的依赖性，自适应系统已经被提出作为工程软件系统的原则方法，以使系统适应需求，即使面对环境中的变化和不确定性。但是我们如何证明在运行时改变系统会使系统更加可靠呢？在这个主题演讲中，我将概述为自适应系统提供保证的一系列挑战，并描述我们小组一直在做的工作，这些工作可以在许多情况下为保证提供证据，包括与人在回路中的协作自适应。我将讨论如何使用概率模型检验来探索自适应系统的状态空间，以及它们如何提供适应系统可能对系统产生的影响的更现实的模型。",
                    "title_zh": "RADIANCE 2015主题演讲:工程可靠自适应系统的挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.13",
                    "title": "Service Deterioration Analysis (SDA): An Early Development Phase Dependability Analysis Method",
                    "authors": "Georg Macher, Andrea Höller, Harald Sporer, Eric Armengaud, Christian Kreiner",
                    "abstract": "Dependability is a super ordinate concept regrouping different system attributes such as reliability, safety, security, or availability and a key selling point of modern embedded systems. Dependable systems rely on mature quality management and development methods such as requirements / systems engineering and system analyses. In the automotive domain analysis methods for safety and security attributes at early development phases are well known and partially mandatory by domain standards. Nevertheless, approaches for analysis of serviceability attributes (the combination of reliability and maintainability) at early development phases are not yet available. Aim of the paper is to present a novel analysis method to quantify the impact of individual system parts on the overall system serviceability at early development phases. This approach bases on the concepts of state-of-the-art methods for safety and security analysis and extends their scope of application to serviceability feature quantification, thus enables consistent identification of system dependability target attributes. This, in turn, is a pre-requisite for ensuring a certain level of system dependability from start of development. In the second part of the document the application of the novel approach is demonstrated on an automotive training example of a battery management system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可信性是一个超坐标概念，重新组合了不同的系统属性，如可靠性、安全性、安全性或可用性，也是现代嵌入式系统的一个关键卖点。可靠的系统依赖于成熟的质量管理和开发方法，如需求/系统工程和系统分析。在汽车领域，早期开发阶段的安全性和安全属性分析方法是众所周知的，并且部分是领域标准强制要求的。然而，在早期开发阶段，还没有分析可用性属性(可靠性和可维护性的组合)的方法。本文的目的是提出一种新的分析方法，在早期开发阶段量化单个系统部件对整个系统可用性的影响。该方法基于安全和保障分析的最新方法的概念，并将其应用范围扩展到可用性特征量化，从而实现系统可信性目标属性的一致识别。反过来，这是从开发开始就确保一定程度的系统可靠性的先决条件。在该文件的第二部分中，在电池管理系统的汽车训练实例上演示了新方法的应用。",
                    "title_zh": "服务退化分析(SDA):一种早期开发阶段的可靠性分析方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.22",
                    "title": "Quantifying the Impact of External Attacks on a Distributed Automatic Track Warning System",
                    "authors": "Leonardo Montecchi, Paolo Lollini, Andrea Bondavalli",
                    "abstract": "For several years, the vulnerability of Critical Infrastructures (CIs) to cyber-threats has been limited, since they were mostly isolated systems, using proprietary protocols. Nowadays, CIs are increasingly threatened by external attacks: the use of off-the-shelf components is common, they have become interconnected, and sometimes also connected to the Internet. This problem is exacerbated by the recent trend towards the adoption of wireless connectivity and mobile devices, which is gaining interest also in this domain. One of the main challenges is to quantify the impact that external attacks may have on the infrastructure, and ensure that its dependability and safety requirements can still be fulfilled. In this paper we focus on the ALARP system, which protects workers on the railway infrastructure using distributed mobile terminals, and evaluate the impact of two attacks to the communication infrastructure. In performing such analysis, we experiment with a new method, which combines a stochastic model of the system with a model of the attacker, and quantifies the impact of specific attacks on precise safety and availability metrics.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "几年来，关键基础设施(CIs)面对网络威胁的脆弱性一直有限，因为它们大多是使用专有协议的孤立系统。如今，配置项越来越受到外部攻击的威胁:现成组件的使用很普遍，它们变得相互连接，有时还连接到互联网。最近采用无线连接和移动设备的趋势加剧了这一问题，这种趋势在这一领域也越来越受关注。主要挑战之一是量化外部攻击对基础设施的影响，并确保其可靠性和安全性要求仍然能够得到满足。在本文中，我们将重点放在ALARP系统上，该系统使用分布式移动终端保护铁路基础设施上的工作人员，并评估两种攻击对通信基础设施的影响。在执行此类分析时，我们试验了一种新方法，该方法将系统的随机模型与攻击者的模型相结合，并量化特定攻击对精确的安全性和可用性指标的影响。",
                    "title_zh": "量化外部攻击对分布式自动跟踪报警系统的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.20",
                    "title": "An Approach to Clustering and Sequencing of Textual Requirements",
                    "authors": "Ricardo Barbosa, Daniele Januario, Ana Estela Silva, Regina Lúcia de Oliveira Moraes, Paulo Martins",
                    "abstract": "Natural language is often used to write software systems requirements. However, it may be prone to misunderstandings due to its ambiguities. Moreover, it is not easy to modularize these requirements and then find all related ones. In order to find out the impact of requirements in one another, it is necessary to look at every requirement rather than just a group of related requirements. When presented in large numbers, the understanding, organization and sequencing of requirements requires substantial time and effort. In this work, we introduce an approach based both on the clustering of textual requirements and on a data dictionary to organize them, as well as suggest a sequence for their implementation. A case study based on User Stories from Agile processes is introduced to illustrate the approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自然语言通常用于编写软件系统需求。然而，由于其模糊性，可能容易产生误解。而且，把这些需求模块化，然后找到所有相关的，并不容易。为了找出需求之间的相互影响，有必要查看每一个需求，而不仅仅是一组相关的需求。当出现大量需求时，需求的理解、组织和排序需要大量的时间和精力。在本文中，我们介绍了一种基于文本需求聚类和数据字典来组织它们的方法，并提出了它们的实现顺序。介绍了一个基于敏捷过程用户故事的案例研究来说明该方法。",
                    "title_zh": "文本需求的聚类和排序方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.17",
                    "title": "Semi-automatic Generation of Extended Finite State Machines from Natural Language Standard Documents",
                    "authors": "Juliana Galvani Greghi, Eliane Martins, Ariadne Maria Brito Rizzoni Carvalho",
                    "abstract": "Many requirement documents are written in natural language and, therefore, may contain problems such as inconsistencies and ambiguities. To minimize these problems, there is a trend in Software Engineering to use models to represent systems. These models are obtained from textual requirements. However, manual modelling is a complex task and, in order to do it semi-automatically, one has to deal with problems such as the kind of model to be generated, the automation degree to be achieved, and the quality of the document that must be processed. We propose a methodology to semi-automatically generate Extended Finite State Machines (EFSMs) from natural language standard documents. We used Natural Language Processing (NLP) techniques and tools to extract information from the document, and implemented a prototype which generates EFSMs. The generated EFSMs were validated with a model checking tool, and manually evaluated by comparing them with the manually generated models.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "许多需求文档是用自然语言编写的，因此，可能会包含诸如不一致和含糊不清之类的问题。为了最小化这些问题，软件工程中有一种趋势是使用模型来表示系统。这些模型是从文本需求中获得的。然而，手动建模是一项复杂的任务，并且为了半自动地完成它，必须处理诸如要生成的模型的种类、要实现的自动化程度以及必须处理的文档的质量等问题。我们提出了一种从自然语言标准文档半自动生成扩展有限状态机的方法。我们使用自然语言处理(NLP)技术和工具从文档中提取信息，并实现了一个生成EFSMs的原型。生成的EFSMs通过模型检查工具进行验证，并通过与手动生成的模型进行比较来进行手动评估。",
                    "title_zh": "从自然语言标准文档半自动生成扩展有限状态机"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.12",
                    "title": "An Asset-Based Development Approach for Availability and Safety Analysis on a Flood Alert System",
                    "authors": "Fumio Machida, Jianwen Xiang, Kumiko Tadano, Shigeru Hosono",
                    "abstract": "Dependability design of IT services including safety and availability analysis requires expertise and often takes long time to carry out. Efficient analysis of system dependability is thus a key to increase the productivity and quality of system development project in service provider. In this paper, we propose an approach to improve the process of system dependability analysis through asset-based development concept in which safety constraints, system designs, availability models, parameter values and empirical data are incorporated into project asset on the premise of reuse. A structure of asset for dependability analysis along with other software artifacts is presented. Through an example of availability and safety analysis of a flood alert system, we characterize the effectiveness of the asset-based approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "IT服务的可靠性设计(包括安全性和可用性分析)需要专业知识，通常需要很长时间才能完成。因此，对系统可信性的有效分析是提高服务提供商系统开发项目的生产率和质量的关键。在本文中，我们提出了一种通过基于资产的开发概念来改进系统可信性分析过程的方法，该方法在重用的前提下将安全约束、系统设计、可用性模型、参数值和经验数据纳入项目资产中。提出了用于可信性分析的资产结构以及其他软件工件。通过一个洪水警报系统的可用性和安全性分析的例子，我们描述了基于资产的方法的有效性。",
                    "title_zh": "基于资产的洪水预警系统可用性和安全性分析方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.15",
                    "title": "Cost Prediction for V&V and Certification Processes",
                    "authors": "Francesco Brancati, András Pataricza, Nuno Silva, Ábel Hegedüs, László Gönczy, Andrea Bondavalli, Rosaria Esposito",
                    "abstract": "Bus travel times are prone to high variability, especially in countries that lack lane discipline and have heterogeneous vehicle profiles. This leads to negative impacts such as bus bunching, increase in passenger waiting time and cost of operation. One way to minimize these issues is to accurately predict bus travel times. To address this, the present study used a model-based approach by incorporating mean and variance in the formulation of the model. However, the accuracy of prediction did not improve significantly and hence a machine learning-based approach was considered. Support vector machines were used and prediction was done using v-support vector regression with linear kernel function. The proposed scheme was implemented in Chennai using data collected from public transport buses fitted with global positioning system. The performance of the proposed method was analysed along the route, across subsections and at bus stops. Results show a clear improvement in performance under high variance conditions.",
                    "files": {
                        "openAccessPdf": "https://doi.org/10.18520/cs/v111/i4/700-711"
                    },
                    "abstract_zh": "公共汽车行驶时间很容易发生很大的变化，尤其是在缺乏车道纪律和车辆种类繁多的国家。这导致负面影响，如公交拥挤、乘客等待时间增加和运营成本增加。减少这些问题的一种方法是准确预测公交车的行驶时间。为了解决这个问题，本研究采用了一种基于模型的方法，在模型的公式中加入了均值和方差。然而，预测的准确性没有显著提高，因此考虑了基于机器学习的方法。使用支持向量机，并使用具有线性核函数的v-支持向量回归进行预测。提议的方案是在钦奈实施的，使用的数据是从装有全球定位系统的公共交通公交车上收集的。对所提出的方法的性能进行了沿线、跨分段和在公共汽车站的分析。结果表明，在高方差条件下，性能有明显的提高。",
                    "title_zh": "V&V和认证流程的成本预测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.19",
                    "title": "Assessment of Defect Type influence in Complex and Integrated Space Systems: Analysis Based on ODC and ISVV Issues",
                    "authors": "Nuno Silva, Marco Vieira, Dario Ricci, Domenico Cotroneo",
                    "abstract": "Safety or mission critical systems are those where failures should be avoided at all costs. Engineering processes, techniques and tools are, however, not perfect, and lead to software and systems with flaws. This paper presents an analysis of the impact of late found issues versus the fault types for critical aerospace systems. These issues are the independently detected faults that remain once the engineering processes that are required by European space standards have been applied and the engineering teams have performed their verification and validation activities. This study presents the analysis of the fault impact versus fault type distribution according to the detection phases and to the issues severity/type and presents recommendations to improve space systems engineering.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全或关键任务系统是那些应该不惜一切代价避免故障的系统。然而，工程过程、技术和工具并不完美，导致软件和系统存在缺陷。本文分析了最新发现的问题对关键航空航天系统故障类型的影响。这些问题是在应用了欧洲空间标准所要求的工程过程并且工程小组开展了验证和确认活动之后独立检测到的故障。这项研究根据探测阶段和问题严重性/类型分析了故障影响和故障类型分布，并提出了改进空间系统工程的建议。",
                    "title_zh": "复杂综合空间系统中缺陷类型影响的评估:基于ODC和ISVV问题的分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.16",
                    "title": "A Virtual Fault Injection Framework for Reliability-Aware Software Development",
                    "authors": "Andrea Höller, Georg Macher, Tobias Rauter, Johannes Iber, Christian Kreiner",
                    "abstract": "Ever more dependable embedded systems are built with commercial off-the-shelf hardware components that are not intended for highly reliable applications. Consequently, software-based fault tolerance techniques have to maintain a safe operation despite underlying hardware faults. In order to efficiently develop fault tolerant software, fault injection is needed in early development stages. However, common fault injection approaches require manufactured products or detailed hardware models. Thus, these techniques are typically not applicable if software and hardware providers are separate vendors. Additionally, the rise of third-party OTS software components limits the means to inject faults. In this paper, we present a virtual fault injection framework that simulates safety-standard aligned fault models and supports OTS software components as well as widely-used embedded processors such as ARM cores. Additionally, we show how to integrate the framework into various software development stages. Finally, we illustrate the practicability of the approach by exemplifying the integration of the framework in the development of an industrial safety-critical system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "越来越可靠的嵌入式系统是用商业上现成的硬件组件构建的，这些组件不是为高度可靠的应用程序设计的。因此，尽管潜在的硬件故障，基于软件的容错技术必须维持安全操作。为了有效地开发容错软件，在早期开发阶段需要进行故障注入。然而，常见故障注入方法需要制造的产品或详细的硬件模型。因此，如果软件和硬件提供商是不同的供应商，这些技术通常不适用。此外，第三方OTS软件组件的出现限制了注入故障的手段。在本文中，我们提出了一个虚拟故障注入框架，该框架模拟符合安全标准的对齐故障模型，并支持OTS软件组件以及广泛使用的嵌入式处理器，如ARM内核。此外，我们展示了如何将框架集成到不同的软件开发阶段。最后，我们以一个工业安全关键系统的开发为例，说明了该方法的实用性。",
                    "title_zh": "面向可靠性感知软件开发的虚拟故障注入框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.24",
                    "title": "Towards Assessing Representativeness of Fault Injection-Generated Failure Data for Online Failure Prediction",
                    "authors": "Ivano Irrera, Marco Vieira",
                    "abstract": "Online Failure Prediction allows improving system dependability by foreseeing incoming failures at runtime, enabling mitigation actions to be taken in advance, though prediction systems' learning and assessing is hard due to the scarcity of failure data. Realistic software fault injection has been identified as a valid solution for addressing the scarcity of failure data, as injecting software faults (the most occurring on computer systems) increases the probability of a system to fail, hence allowing the collection of failure-related data in short time. Moreover, realistic injection permits the emulation of software faults likely to exist in the target system after its deployment. However, besides the representativeness of the software faults injected is recognized as a necessary condition for generating valid failure data, studies on the representativeness of generated failure-related data has still not been addressed. In this work we present a preliminary study towards the assessment the representativeness of failure-related data by using G-SWFIT realistic software fault injection technique. We here address the definition of concepts and metrics for the representativeness estimation and assessment.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在线故障预测允许通过在运行时预见即将到来的故障来提高系统可靠性，从而能够提前采取缓解措施，尽管由于故障数据的缺乏，预测系统的学习和评估很困难。现实的软件故障注入已经被认为是解决故障数据缺乏的有效解决方案，因为注入软件故障(最常见于计算机系统)增加了系统故障的概率，因此允许在短时间内收集故障相关数据。此外，真实注入允许在目标系统部署后模拟可能存在于目标系统中的软件故障。然而，除了被注入的软件故障的代表性被认为是生成有效故障数据的必要条件之外，对所生成的故障相关数据的代表性的研究仍然没有得到解决。在这项工作中，我们提出了一个初步的研究评估代表性的故障相关数据使用G-SWFIT现实软件故障注入技术。我们在这里解决的代表性估计和评估的概念和指标的定义。",
                    "title_zh": "评估在线故障预测故障注入产生的故障数据的代表性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.18",
                    "title": "Studying the Propagation of Failures in SOAs",
                    "authors": "Cristiana Areias, João Carlos Cunha, Marco Vieira",
                    "abstract": "Although Service Oriented Architectures (SOAs) are being increasingly used in business-critical scenarios, the applicability of Verification and Validation (V&V) is still very limited. The problem is that V&V activities have to be implemented at runtime to fit the characteristics of SOA. Recent proposals of runtime V&V techniques specific to SOA domain are far from being complete and a key issue lies in understanding how the \"failures propagate\" in a dynamic system and how to continuously verify its evolving elements. This paper introduces an approach to deal with the propagation of failures in a SOA environment. The proposed technique is based on three key steps: estimating the failure rate of the individual services, using fault injection to find the exposure of each service to failures from the invoked services, and estimating the impact of each service in the overall architecture. The overall approach is presented with a brief demonstration of its application.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管面向服务的架构(SOA)越来越多地被用于业务关键的场景中，但是验证和确认(V&V)的适用性仍然非常有限。问题是V&V活动必须在运行时实现，以适应SOA的特征。特定于SOA领域的运行时V&V技术的最新提议远未完成，关键问题在于理解“故障”如何在动态系统中传播，以及如何持续验证其演进的元素。本文介绍了一种处理SOA环境中故障传播的方法。所提出的技术基于三个关键步骤:估计单个服务的故障率，使用故障注入来发现每个服务暴露于被调用服务的故障，以及估计每个服务在整个体系结构中的影响。介绍了总体方法，并简要演示了其应用。",
                    "title_zh": "研究SOA中故障的传播"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.44",
                    "title": "SSIV 2015 Keynote I: On the Security of Critical Cyber-Physical Systems",
                    "authors": "Roberto Gallo",
                    "abstract": "Intelligent vehicles are subject to a number of security and assurance challenges typical of the so-called cyber-physical systems - CPS. Counterfeiting, tampering, and hacking are examples of classes of attacks that can severely disrupt system functionality, security, and safety. In this talk we will describe main threats and countermeasures applicable to this critical system type.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "智能车辆面临许多安全和保证挑战，典型的是所谓的信息物理系统(CPS)。伪造、篡改和黑客攻击是可以严重破坏系统功能、安全性和安全性的攻击类别的例子。在本次讲座中，我们将描述适用于这种关键系统类型的主要威胁和对策。",
                    "title_zh": "SSIV 2015主题演讲I:关键网络物理系统的安全"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.31",
                    "title": "Using Data Integrity as an Improvement Characteristic to Assess the Safety of ADS-B-based Systems",
                    "authors": "Daniel Baraldi Sesso, Lucio Flavio Vismari, Antonio V. Silva Neto, Paulo Sérgio Cugnasca, João Batista Camargo Jr.",
                    "abstract": "The increasing demand for the densification of the national airspace in various social and economic applications have pressed aviation authorities to reduce aircraft separation, allowing more efficient operations in Air Traffic Management (ATM) in a given airspace. However, issues related to the safety of air traffic operations arise when considering the possibility of reducing aircraft separation. Surveillance plays a key role in monitoring and controlling air traffic in new scenarios in which a better flight performance is required. Accuracy of positional information provided by the Automatic Dependent Surveillance - Broadcast (ADS-B), originally designed to improve situational awareness for pilots and support controllers in air traffic management, is essential in order to avoid exposure to incidents and accidents such as events of loss of separation (AIRPROX) and collisions for new Global ATM paradigm. This paper presents a qualitative approach to assess safety when using ADS-B systems considering its data integrity as a relevant factor in aeronautical systems and operations for different scenarios. A testing platform -- the Integrated Platform for Testing Critical Embedded Systems (PIpE-SEC) -- is also presented as a possible solution for this safety evaluation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在各种社会和经济应用中对国家空域的密集化的日益增长的需求已经迫使航空当局减少飞机间隔，从而允许在给定空域中更有效地进行空中交通管理(ATM)操作。然而，在考虑减少飞机间隔的可能性时，出现了与空中交通安全有关的问题。在需要更好的飞行性能的新情况下，监视在监视和控制空中交通中起着关键作用。自动相关监视-广播(ADS-B)提供的位置信息的准确性，最初是为了在空中交通管理中提高飞行员和支持管制员的态势感知能力而设计的，对于避免暴露于新的全球空中交通管理范例中的偏离损失(AIRPROX)和碰撞等事件和事故是至关重要的。本文提出了一种定性的方法来评估使用ADS-B系统时的安全性，考虑到其数据完整性是航空系统和不同情况下操作的一个相关因素。一个测试平台——关键嵌入式系统测试集成平台(PIpE-SEC)——也作为一个可能的安全评估解决方案被提出。",
                    "title_zh": "使用数据完整性作为改进特征来评估基于ADS-B的系统的安全性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.29",
                    "title": "A Learning-Based Autonomous Control System Approach for Collision Avoidance within an Unmanned Aircraft",
                    "authors": "Thiago Toshio Matsumoto, Lucio Flavio Vismari, Ricardo Alexandre Veiga Gimenes, Jorge Rady de Almeida Jr., João Batista Camargo Jr.",
                    "abstract": "The growing public interest for Unmanned Aircraft Systems (UAS) applications has stimulated the debate over the integration of this kind of aircraft into the civil aviation system. However, the concept of not having a human pilot inside the aircraft presents uncertainties that may impede the creation of proper regulation. Having safety as the main concern for civil aviation, one important principle of aviation to be addressed in an UAS is collision avoidance, a traditionally pilot-dependent functionality. In this regard, as a possible substitute for the pilot in the aircraft, we propose a method for implementing a learning-based autonomous control system focused in guaranteeing collision avoidance. Regarding that safety aspect, we expect such system to be able to compensate for the lack of a human pilot in the aircraft. The proposed approach utilizes the concept of 'Learning from Demonstration' in order to define a behaviour for the autonomous aircraft based on manoeuvres commanded by a human. Therefore, the proposed approach would represent a possible implementation of an autonomous unmanned aircraft that presents the same collision avoidance capabilities observed in (human-based) civil aviation. Additionally, we identify metrics that can be used to select a suitable learning-based method and to compare its performance to those observed in manned aircraft.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "公众对无人驾驶飞机系统(UAS)应用的兴趣越来越大，这刺激了关于将这种类型的飞机纳入民用航空系统的讨论。然而，飞机内没有人类飞行员的概念存在不确定性，这可能会阻碍适当监管的建立。由于安全是民用航空的主要关注点，在UAS中要解决的一个重要的航空原则是防撞，这是一个传统上依赖于飞行员的功能。在这方面，作为飞机中飞行员的可能替代物，我们提出了一种用于实现基于学习的自主控制系统的方法，该系统集中于保证避免碰撞。关于安全方面，我们希望这种系统能够弥补飞机中缺少人类飞行员的不足。所提出的方法利用了“从演示中学习”的概念，以便根据人指挥的机动动作来定义自主飞行器的行为。因此，所提出的方法将代表一种自主无人驾驶飞机的可能实现，这种无人驾驶飞机具有在(以人为基础的)民用航空中观察到的相同的防撞能力。此外，我们确定了可用于选择合适的基于学习的方法并将其性能与在有人驾驶飞机上观察到的性能进行比较的指标。",
                    "title_zh": "基于学习的无人飞机避碰自主控制系统方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.28",
                    "title": "Using Simulation, Fault Injection and Property-Based Testing to Evaluate Collision Avoidance of a Quadcopter System",
                    "authors": "Benjamin Vedder, Jonny Vinter, Magnus Jonsson",
                    "abstract": "In this work we use our testing platform based on FaultCheck and QuickCheck that we apply on a quad copter simulator. We have used a hardware platform as the basis for the simulator and for deriving realistic fault models for our simulations. The quad copters have a collision-avoidance mechanism that shall take over control when the situation becomes hazardous, steer away from the potential danger and then give control back to the pilot, thereby preventing collisions regardless of what the pilot does. We use our testing platform to randomly generate thousands of simulations with different input stimuli (using QuickCheck) for hundreds of quad copters, while injecting faults simultaneously (using FaultCheck). This way, we can effectively adjust system parameters and enhance the collision-avoidance mechanism.",
                    "files": {
                        "openAccessPdf": "http://hh.diva-portal.org/smash/get/diva2:808255/FULLTEXT01"
                    },
                    "abstract_zh": "在这项工作中，我们使用了基于FaultCheck和QuickCheck的测试平台，并将其应用于四轴直升机模拟器。我们使用硬件平台作为模拟器的基础，并为我们的模拟推导出真实的故障模型。四轴直升机具有防撞机制，当情况变得危险时，该机制将接管控制权，避开潜在的危险，然后将控制权交还给飞行员，从而无论飞行员做什么都可以防止碰撞。我们使用我们的测试平台为数百架四轴直升机随机生成数千次不同输入激励的模拟(使用快速检查)，同时注入故障(使用故障检查)。这样，我们可以有效地调整系统参数并增强碰撞避免机制。",
                    "title_zh": "用模拟、故障注入和基于特性的试验评估四轴飞行器系统的防撞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.23",
                    "title": "Advantages in Crash Severity Prediction Using Vehicle to Vehicle Communication",
                    "authors": "Dennis Böhmländer, Sinan Hasirlioglu, Vitor Yano, Christian Lauerer, Thomas Brandmeier, Alessandro Zimmer",
                    "abstract": "The paper discusses a new approach in contactless crash detection combining measurements of vehicle dynamics, exteroceptive sensors and vehicle-to-vehicle (V2V) communication data. The proposed architecture aims to activate vehicle safety functions prior an imminent collision to minimize the risk of suffering a major injury. An activation needs a precise prediction of time to collision (TTC), the crash severity (Cs) and other relevant crash parameters. This paper studies the contribution of V2V communication data to predict potential collisions and to realize a reliable activation. An algorithm is presented, that merges fused measurements of a video camera, a laser range finder (LRF) and ego vehicle motion sensors with V2V communication data to predict collisions. The benefit using V2V communication is demonstrated by evaluating collision prediction errors. This analysis is carried out based on experimental data produced by two scale model vehicles.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文讨论了一种结合车辆动力学、外部传感器和车对车(V2V)通信数据的非接触式碰撞检测的新方法。提议的架构旨在在即将发生碰撞之前激活车辆安全功能，以最大限度地降低遭受重大伤害的风险。激活需要精确预测碰撞时间(TTC)、碰撞严重程度(Cs)和其他相关碰撞参数。本文研究V2V通信数据对预测潜在碰撞和实现可靠激活的贡献。提出了一种算法，该算法将摄像机、激光测距仪(LRF)和ego车辆运动传感器的融合测量与V2V通信数据合并，以预测碰撞。通过评估碰撞预测误差，展示了使用V2V通信的好处。这种分析是根据两个比例模型车辆产生的实验数据进行的。",
                    "title_zh": "使用车辆间通信预测碰撞严重程度的优势"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.27",
                    "title": "Heading Controller for a Fixed Wing UAV with Reduced Control Surfaces Based on ANFIS",
                    "authors": "Ian de Medeiros Esper, Paulo Fernando Ferreira Rosa",
                    "abstract": "In the last decade, there has been a rising interest in cyber physical systems (CPS), both in civil and military use. Together with the popularization and evolution of navigation sensors, as global position system (GPS) and inertial measurement unit (IMU), has triggered researches in control systems that are more suitable to non-linear systems of an airplane in flight. Classic control systems has been used from simplified mathematical model. As dynamic systems may present complex behaviour, new concepts and technologies of advanced control systems needs to be used. In this work is shown a control method that combine the reasoning of fuzzy logic with the learning of neural network. An adaptive neuro-fuzzy inference system is described to control the heading of an unmanned aerial vehicle (UAV) with a delta type fixed wing with reduced control surfaces called elevens. The UAV has an embedded autopilot board with a micro-controller (mcu) capable of real-time data processing and navigation sensors making this platform suitable for autonomous flight.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在过去的十年中，人们对网络物理系统(CPS)越来越感兴趣，无论是民用还是军用。随着全球定位系统(GPS)和惯性测量单元(IMU)等导航传感器的普及和发展，引发了对更适用于飞行中飞机非线性系统的控制系统的研究。经典的控制系统一直使用简化的数学模型。由于动态系统可能表现出复杂的行为，因此需要使用先进控制系统的新概念和新技术。本文提出了一种将模糊逻辑推理与神经网络学习相结合的控制方法。描述了一种自适应神经模糊推理系统来控制具有三角形固定翼的无人飞行器(UAV)的航向，该固定翼具有被称为elevens的减少的控制表面。该无人机具有嵌入式自动驾驶仪板，带有能够进行实时数据处理的微控制器(mcu)和导航传感器，使该平台适合自主飞行。",
                    "title_zh": "基于ANFIS的缩减操纵面固定翼无人机航向控制器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.43",
                    "title": "SSIV 2015 Keynote II: From Embedded Systems to Autonomous Cooperating Objects",
                    "authors": "Paulo Veríssimo",
                    "abstract": "The future of Internet lies with embedded systems’. This phrase of some years ago characterises a lot of what we now read about the Internet of Things (IoT), and if anything, the vision was surpassed by reality. In fact, even more specialised cyber-physical systems such as energy grids or telecom networks, or more detached realms, like train, plane or car automation systems, became dramatically convergent with the infrastructures relying on the Internet-Cloud complex. This progressive convergence creates a challenging scenario: such Internet-born cyber-physical systems, if not working properly, can do more damage than good, physical damage included. The key to these challenges lies in learning how to design safe, secure and dependable, autonomous and cooperating networked systems-of-embedded-systems, because this is how the future will look like. This talk reviews several years of research along these lines. Bio Paulo Esteves Veríssimo is a Professor of the University of Luxembourg Faculty of Science, Technology and Communication (FSTC), since fall 2014, and head of the CritiX group (Critical and Extreme Security and Dependability) at SnT, the Interdisciplinary Centre for Security, Reliability and Trust at the same University (http://wwwen.uni.lu/snt). He is adjunct Professor of the ECE Dept., Carnegie Mellon University. Previously, he has been a Professor of the Univ. of Lisbon, member of the Board of the same university and Director of LaSIGE (http://lasige.di.fc.ul.pt). Veríssimo is Fellow of the IEEE and Fellow of the ACM, and he is associate editor of the Elsevier Int’l Journal on Critical Infrastructure Protection. He is currently Chair of the IFIP WG 10.4 on Dependable Computing and Fault-Tolerance and vice-Chair of the Steering Committee of the IEEE/IFIP DSN conference. He is currently interested in secure and dependable distributed architectures, middleware and algorithms for: resilience of large-scale systems and critical infrastructures, privacy and integrity of highly sensitive data, and adaptability and safety of real-time networked embedded systems. He is author of over 170 peerrefereed publications and co-author of 5 books. 124 2015 IEEE International Conference on Dependable Systems and Networks Workshops Unrecognized Copyright Information DOI 10.1109/DSN-W.2015.43",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "“互联网的未来在于嵌入式系统”。几年前的这句话描述了我们现在读到的许多关于物联网(IoT)的内容，如果有什么不同的话，那就是愿景被现实超越了。事实上，甚至更专业的网络物理系统，如能源电网或电信网络，或更独立的领域，如火车、飞机或汽车自动化系统，都与依赖互联网-云复合体的基础设施显著融合。这种渐进的融合创造了一个具有挑战性的场景:这种互联网诞生的网络物理系统，如果不能正常工作，可能弊大于利，包括物理损害。应对这些挑战的关键在于学会如何设计安全、可靠、自主和协作的嵌入式网络化系统，因为这是未来的样子。这篇演讲回顾了几年来沿着这些路线的研究。比奥·保罗·埃斯特韦斯·韦里西莫(bio Paulo veríssimo)自2014年秋季起担任卢森堡大学科学、技术和通信学院(FSTC)教授，并担任卢森堡大学跨学科安全、可靠性和信任中心(SnT)CritiX小组(关键和极端安全和可靠性)负责人(http://wwwen.uni.lu/snt)。他是卡内基梅隆大学儿童早教系的兼职教授。此前，他一直是里斯本大学的教授、该大学董事会成员和LaSIGE(http://LaSIGE . di . fc . ul . pt)主任。Veríssimo是IEEE和ACM的会员，也是《Elsevier国际关键基础设施保护期刊》的副主编。他目前是IFIP工作组10.4关于可靠计算和容错的主席，也是IEEE/IFIP DSN会议指导委员会的副主席。他目前对以下领域的安全可靠的分布式架构、中间件和算法感兴趣:大规模系统和关键基础设施的弹性、高度敏感数据的隐私和完整性，以及实时网络嵌入式系统的适应性和安全性。他是170多种同行参考出版物的作者，也是5本书的合著者。124 2015 IEEE可信系统和网络国际会议研讨会未识别的版权信息DOI 10.1109/DSN-W.2015.43",
                    "title_zh": "SSIV 2015主题演讲II:从嵌入式系统到自主协作对象"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.21",
                    "title": "Model-Based Membership Verification in Vehicular Platoons",
                    "authors": "Mikael Asplund",
                    "abstract": "Cooperative vehicular systems have the potential to significantly increase traffic efficiency and safety. However, they also raise the question of to what extent information that is received from other vehicles can be trusted. In this paper we present a novel approach for increasing the trustworthiness of cooperative driving through a model-based approach for verifying membership views in vehicular platoons. We define a formal model for platoon membership, cooperative awareness claims, and membership verification mechanisms. With the help of a satisfiability solver, we are able to quantitatively analyse the impact of different system parameters on the verifiability of received information. Our results demonstrate the importance of cross validating received messages, as well as the surprising difficulty in establishing correct membership views despite powerful verification mechanisms.",
                    "files": {
                        "openAccessPdf": "http://liu.diva-portal.org/smash/get/diva2:891917/FULLTEXT02"
                    },
                    "abstract_zh": "协作式车辆系统具有显著提高交通效率和安全性的潜力。然而，它们也提出了一个问题，即从其他车辆接收的信息在多大程度上可以被信任。在本文中，我们提出了一种新的方法，通过基于模型的方法来验证车辆队列中的成员视图，以增加合作驾驶的可信度。我们定义了一个正式的排成员模型，合作意识声明，和成员验证机制。在可满足性求解器的帮助下，我们能够定量分析不同系统参数对所接收信息的可验证性的影响。我们的结果证明了交叉验证收到的消息的重要性，以及尽管有强大的验证机制，但在建立正确的成员视图时令人惊讶的困难。",
                    "title_zh": "车辆队列中基于模型的成员验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.26",
                    "title": "Software Faults Emulation at Model-Level: Towards Automated Software FMEA",
                    "authors": "Valentina Bonfiglio, Leonardo Montecchi, Ivano Irrera, Francesco Rossi, Paolo Lollini, Andrea Bondavalli",
                    "abstract": "Safety is a fundamental property for a wide class of systems, which can be assessed through safety analysis. Recent standards, as the ISO26262 for the automotive domain, recommend safety analysis processes to be performed at system, hardware, and software levels. While Failure Modes and Effects Analysis (FMEA) is a well-known technique for safety assessment at system level, its application at software level is still an open problem, especially concerning its integration into certification processes. Fault injection has been envisioned as a viable approach for performing Software-FMEA (SW-FMEA), but it typically requires an advanced development stage where code is available. The approach we propose in this paper, aims to perform software fault injection at model-level, namely on fUML-ALF models obtained from a component-based UML description through transformations proposed in a previous work. Model-level fault injection allows SW-FMEA to assess the effectiveness of safety mechanisms from the early stages of system design. The work in this paper focuses on how the software fault injection is implemented, and on the study of fault propagation through appropriate points of observation to highlight possible violations of requirements, with the identification critical paths.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全性是一大类系统的基本属性，可以通过安全性分析来评估。最近的标准，如汽车领域的ISO26262，建议在系统、硬件和软件级别执行安全分析过程。虽然故障模式和影响分析(FMEA)是一种众所周知的系统级安全评估技术，但其在软件级的应用仍然是一个公开的问题，尤其是关于其与认证过程的集成。故障注入被认为是执行软件FMEA (SW-FMEA)的一种可行方法，但是它通常需要一个高级开发阶段，在这个阶段代码是可用的。我们在本文中提出的方法旨在模型级执行软件故障注入，即在fUML-ALF模型上，通过先前工作中提出的转换，从基于组件的UML描述中获得。模型级故障注入允许SW-FMEA从系统设计的早期阶段评估安全机制的有效性。本文的工作集中在软件故障注入是如何实现的，以及通过适当的观察点来研究故障传播，以突出可能的需求违反，并识别关键路径。",
                    "title_zh": "模型级软件故障仿真:走向自动化软件FMEA"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.32",
                    "title": "The Use of a Graphic Processing Unit (GPU) in a Real Time Visual Odometry Application",
                    "authors": "Jaime Armando Delgado Vargas, Paulo Roberto Gardel Kurka",
                    "abstract": "This paper presents a practical application of visual odometry (VO). Visual odometry applications are computationally expensive due to the frequent and large number of required data processing. In the present work the application is implemented in a graphics processing unit card (GPU) using compute unified device architecture CUDA and OpenCV libraries, allowing real time processing with a speed of 30 frames per second. The algorithm begins with the capture and processing of stereoscopic images to find invariant interest points (keypoints) using the GPU-OpenCV speed-up robust features (SURF) library implementation. Stereoscopic image points are projected in the Euclidean space to yield 3-D estimates of the robot's translation and rotation movements. The real time VO algorithm is applied in a practical odometry estimation in a robot's outdoors navigation experiment.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了视觉里程计(VO)的实际应用。由于需要频繁和大量的数据处理，视觉里程计应用在计算上是昂贵的。在目前的工作中，该应用是在图形处理单元卡(GPU)中使用计算统一设备架构CUDA和OpenCV库实现的，允许以每秒30帧的速度进行实时处理。该算法从捕捉和处理立体图像开始，使用GPU-OpenCV加速鲁棒特征(SURF)库实现来寻找不变的兴趣点(关键点)。立体图像点被投影在欧几里德空间中，以产生机器人的平移和旋转运动的3d估计。在机器人户外导航实验中，实时VO算法被应用于实际的里程计估计。",
                    "title_zh": "图形处理单元(GPU)在实时视觉里程计应用中的使用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2015.14",
                    "title": "Improving Intelligent Vehicle Dependability by Means of Infrastructure-Induced Tests",
                    "authors": "Wilfried Steiner, Ayhan Mehmed, Sasikumar Punnekkat",
                    "abstract": "Advanced driver assistance systems (ADAS) take over more and more driving responsibilities from the human operator and, therefore, evolve into safety-critical systems. Thus, the dependability of such systems is of up-most importance. While upcoming automobiles themselves will implement fault-tolerance and robustness mechanisms, it can be beneficial to also take infrastructure measures into account when assessing the overall vehicle dependability. In this paper we discuss an example of an infrastructure measure that targets to improve the dependability of an on-board computer vision system. Based on this example we outline a cyber-physical systems (CPS) architecture for intelligent vehicles and address open research directions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高级驾驶辅助系统(ADAS)从操作人员手中接管了越来越多的驾驶职责，因此发展成为安全关键系统。因此，这种系统的可靠性是最重要的。虽然未来的汽车本身将实现容错和鲁棒性机制，但在评估整体车辆可靠性时，将基础设施措施也考虑在内可能是有益的。在本文中，我们讨论了一个基础设施措施的例子，旨在提高车载计算机视觉系统的可靠性。基于这个例子，我们概述了智能车辆的信息物理系统(CPS)架构，并提出了开放的研究方向。",
                    "title_zh": "通过基础设施诱导试验提高智能车辆的可靠性"
                }
            ]
        }
    ],
    "2018": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2018.html",
            "conf_title": "48th DSN 2018: Luxembourg City, Luxembourg",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8415926/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00014",
                    "title": "Wren: Nonblocking Reads in a Partitioned Transactional Causally Consistent Data Store",
                    "authors": "Kristina Spirovska, Diego Didona, Willy Zwaenepoel",
                    "abstract": "Transactional Causal Consistency (TCC) extends causal consistency, the strongest consistency model compatible with availability, with interactive read-write transactions, and is therefore particularly appealing for geo-replicated platforms. This paper presents Wren, the first TCC system that at the same time i) implements nonblocking read operations, thereby achieving low latency, and ii) allows an application to efficiently scale out within a replication site by sharding. Wren introduces new protocols for transaction execution, dependency tracking and stabilization. The transaction protocol supports nonblocking reads by providing a transaction with a snapshot that is the union of a fresh causal snapshot S installed by every partition in the local data center and a client-side cache for writes that are not yet included in S. The dependency tracking and stabilization protocols require only two scalar timestamps, resulting in efficient resource utilization and providing scalability in terms of replication sites. In return for these benefits, Wren slightly increases the visibility latency of updates. We evaluate Wren on an AWS deployment using up to 5 replication sites and 16 partitions per site. We show that Wren delivers up to 1.4x higher throughput and up to 3.6x lower latency when compared to the state-of-the-art design. The choice of an older snapshot increases local update visibility latency by a few milliseconds. The use of only two timestamps to track causality increases remote update visibility latency by less than 15%.",
                    "files": {
                        "openAccessPdf": "https://infoscience.epfl.ch/record/254970/files/sdw_wren_infoscience.pdf"
                    },
                    "abstract_zh": "事务因果一致性(TCC)扩展了因果一致性，这是与可用性兼容的最强的一致性模型，具有交互式读写事务，因此对地理复制平台特别有吸引力。本文介绍了Wren，它是第一个TCC系统，同时I)实现了无阻塞读取操作，从而实现了低延迟，ii)允许应用程序通过分片在复制站点内高效地横向扩展。Wren为事务执行、依赖性跟踪和稳定性引入了新的协议。事务协议通过为事务提供快照来支持非阻塞读取，该快照是由本地数据中心中的每个分区安装的新的因果快照和用于尚未包括在中的写入的客户端高速缓存的并集。依赖性跟踪和稳定协议仅需要两个标量时间戳，从而实现高效的资源利用并提供复制站点方面的可扩展性。作为这些好处的回报，Wren略微增加了更新的可见性延迟。我们使用多达5个复制站点和每个站点16个分区在AWS部署上评估Wren。我们发现，与最先进的设计相比，Wren的吞吐量提高了1.4倍，延迟降低了3.6倍。选择较旧的快照会将本地更新可见性延迟增加几毫秒。仅使用两个时间戳来跟踪因果关系会将远程更新可见性延迟增加不到15%。",
                    "title_zh": "Wren:分区事务性因果一致性数据存储中的非阻塞读取"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00015",
                    "title": "Code-Dependent and Architecture-Dependent Reliability Behaviors",
                    "authors": "Vinicius Fratin, Daniel Oliveira, Caio B. Lunardi, Fernando Santos, Gennaro Severino Rodrigues, Paolo Rech",
                    "abstract": "The increased need for computing capabilities and higher efficiency have stimulated industries to make available in the market novel architectures with increased complexity. The variety of codes that need to be executed combined with the complexity of novel architectures introduces challenges in the reliability evaluation of computing systems and applications. This paper compares the reliability behaviors of six different architectures (an Intel co-processor, three NVIDIA GPUs, an AMD APU, an embedded ARM) executing eight different codes. To support our evaluation, we present and discuss experimental beam data that covers a total of more than 352,000 years of natural exposure and fault-injection analysis based on a total of more than 120,000 injections. We first quantify both the Silent Data Corruptions and the Detected Unrecoverable Errors rates. Then, we qualify observed errors considering the difference between the corrupted and expected values as well as the portion of the output that has been corrupted. From these analyses, we identify the reliability characteristics which are related to the underlying hardware and the intrinsic behaviors of the executed code. Finally, we discuss the implications of the device- and code-dependent reliability behaviors for approximate computing. We analyze the benefits, in term of reduced error rate, of a relaxed output correctness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对计算能力和更高效率的日益增长的需求已经刺激了工业在市场上提供具有更高复杂性的新型体系结构。需要执行的各种代码与新颖架构的复杂性相结合，给计算系统和应用的可靠性评估带来了挑战。本文比较了执行八种不同代码的六种不同架构(一个英特尔协处理器、三个NVIDIA GPUs、一个AMD APU和一个嵌入式ARM)的可靠性行为。为了支持我们的评估，我们提出并讨论了涵盖总共超过352，000年的自然暴露和基于总共超过120，000次注入的故障注入分析的实验束数据。我们首先量化静默数据损坏和检测到的不可恢复错误率。然后，我们考虑被破坏的值和期望值之间的差异以及输出中被破坏的部分，来限定观察到的误差。通过这些分析，我们确定了与底层硬件和所执行代码的内在行为相关的可靠性特征。最后，我们讨论了近似计算中依赖于设备和代码的可靠性行为的含义。我们从降低错误率的角度分析了放松输出正确性的好处。",
                    "title_zh": "依赖代码和依赖架构的可靠性行为"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00016",
                    "title": "Modeling Soft-Error Propagation in Programs",
                    "authors": "Guanpeng Li, Karthik Pattabiraman, Siva Kumar Sastry Hari, Michael B. Sullivan, Timothy Tsai",
                    "abstract": "As technology scales to lower feature sizes, devices become more susceptible to soft errors. Soft errors can lead to silent data corruptions (SDCs), seriously compromising the reliability of a system. Traditional hardware-only techniques to avoid SDCs are energy hungry, and hence not suitable for commodity systems. Researchers have proposed selective software-based protection techniques to tolerate hardware faults at lower costs. However, these techniques either use expensive fault injection or inaccurate analytical models to determine which parts of a program must be protected for preventing SDCs. In this work, we construct a three-level model, TRIDENT, that captures error propagation at the static data dependency, control-flow and memory levels, based on empirical observations of error propagations in programs. TRIDENT is implemented as a compiler module, and it can predict both the overall SDC probability of a given program and the SDC probabilities of individual instructions, without fault injection. We find that TRIDENT is nearly as accurate as fault injection and it is much faster and more scalable. We also demonstrate the use of TRIDENT to guide selective instruction duplication to efficiently mitigate SDCs under a given performance overhead bound.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着技术向更小的特征尺寸发展，器件变得更容易出现软错误。软错误会导致静默数据损坏(SDCs)，严重影响系统的可靠性。避免SDC的传统纯硬件技术非常耗能，因此不适合商用系统。研究人员提出了选择性的基于软件的保护技术，以较低的成本容忍硬件故障。然而，这些技术要么使用昂贵的故障注入，要么使用不精确的分析模型来确定程序的哪些部分必须被保护以防止SDCs。在这项工作中，我们基于对程序中错误传播的经验观察，构建了一个三层模型TRIDENT，它在静态数据依赖、控制流和存储层捕获错误传播。TRIDENT被实现为一个编译器模块，它可以预测给定程序的整体SDC概率和单个指令的SDC概率，而无需故障注入。我们发现TRIDENT几乎与故障注入一样准确，而且速度更快，可扩展性更强。我们还演示了使用TRIDENT来指导选择性指令复制，以在给定的性能开销限制下有效地减轻SDC。",
                    "title_zh": "程序中软错误传播的建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00017",
                    "title": "Byzantine Fault-Tolerant Atomic Multicast",
                    "authors": "Paulo R. Coelho, Tarcisio Ceolin Junior, Alysson Bessani, Fernando Luís Dotti, Fernando Pedone",
                    "abstract": "Atomic multicast is an important building block in the architecture of scalable and highly available services. Atomic multicast reliably propagates and orders messages addressed to one or more groups of processes. Despite the large body of literature on atomic multicast, existing protocols target benign failures. This paper presents ByzCast, the first Byzantine Fault-Tolerant atomic multicast. Byzantine Fault Tolerance has become increasingly appealing as services can be deployed in inexpensive hardware (e.g., cloud environments) and new applications (e.g., blockchain) become more sensitive to malicious behavior. ByzCast has two important characteristics: it was designed to use existing BFT abstractions and it scales with the number of groups, for messages addressed to a single group. We discuss the design of ByzCast and how it can be optimized for particular workloads. Besides proposing a novel atomic multicast protocol, we extensively assess its performance experimentally.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "原子多播是可伸缩和高可用性服务架构中的重要组成部分。原子多播可靠地传播和排序寻址到一组或多组进程的消息。尽管有大量关于原子多播的文献，但现有的协议都是针对良性故障的。本文介绍了ByzCast，第一个拜占庭容错原子组播。随着服务可以部署在廉价的硬件(例如，云环境)中，以及新的应用(例如，区块链)变得对恶意行为更加敏感，拜占庭容错变得越来越有吸引力。ByzCast有两个重要的特征:它被设计成使用现有的BFT抽象，并且对于寻址到单个组的消息，它随着组的数量而扩展。我们讨论ByzCast的设计，以及如何针对特定的工作负载进行优化。除了提出一个新颖的原子多播协议，我们还通过实验广泛地评估了它的性能。",
                    "title_zh": "拜占庭容错原子多播"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00018",
                    "title": "A Byzantine Fault-Tolerant Ordering Service for the Hyperledger Fabric Blockchain Platform",
                    "authors": "João Sousa, Alysson Bessani, Marko Vukolic",
                    "abstract": "Hyperledger Fabric is a flexible operating system for permissioned blockchains designed for business applications beyond the basic digital coin addressed by Bitcoin and other existing networks. A key property of this system is its extensibility, and in particular the support for multiple ordering services for building the blockchain. However, version 1 was launched in 2017 without an implementation of a Byzantine fault-tolerant (BFT) ordering service. To overcome this limitation, we designed, implemented, and evaluated a BFT ordering service for this system on top of the BFT-SMART state machine replication/consensus library, with optimizations for wide-area deployment. Our results show that our ordering service can process up to ten thousand transactions per second and write a transaction irrevocably in the blockchain in half a second, even with peers spread across different continents.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/1163555/files/a6-sousa.pdf"
                    },
                    "abstract_zh": "Hyperledger Fabric是一个灵活的许可区块链操作系统，专为比特币和其他现有网络解决的基本数字货币之外的商业应用而设计。该系统的一个关键特性是其可扩展性，特别是支持构建区块链的多种订购服务。然而，版本1于2017年推出，没有实现拜占庭容错(BFT)订购服务。为了克服这一限制，我们在BFT智能状态机复制/一致性库的基础上设计、实现并评估了该系统的BFT订购服务，并针对广域部署进行了优化。我们的结果表明，我们的订购服务每秒可以处理多达10，000笔交易，并在半秒钟内在区块链中不可撤销地写下一笔交易，即使是与分布在不同大陆的同行。",
                    "title_zh": "Hyperledger Fabric区块链平台的拜占庭容错订购服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00019",
                    "title": "Troxy: Transparent Access to Byzantine Fault-Tolerant Systems",
                    "authors": "Bijun Li, Nico Weichbrodt, Johannes Behl, Pierre-Louis Aublin, Tobias Distler, Rüdiger Kapitza",
                    "abstract": "Various protocols and architectures have been proposed to make Byzantine fault tolerance (BFT) increasingly practical. However, the deployment of such systems requires dedicated client-side functionality. This is necessary as clients have to connect to multiple replicas and perform majority voting over the received replies to outvote faulty responses. Deploying custom client-side code is cumbersome, and often not an option, especially in open heterogeneous systems and for well-established protocols (e.g., HTTP and IMAP) where diverse client-side implementations co-exist. We propose Troxy, a system which relocates the BFT-specific client-side functionality to the server side, thereby making BFT transparent to legacy clients. To achieve this, Troxy relies on a trusted subsystem built upon hardware protection enabled by Intel SGX. Additionally, Troxy reduces the replication cost of BFT for read-heavy workloads by offering an actively maintained cache that supports trustworthy read operations while preserving the consistency guarantees offered by the underlying BFT protocol. A prototype of Troxy has been built and evaluated, and results indicate that using Troxy (1) leads to at most 43% performance loss with small ordered messages in a local network environment, while (2) improves throughput by 130% with read-heavy workloads in a simulated wide-area network.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "已经提出了各种协议和架构来使得拜占庭容错(BFT)越来越实用。然而，这种系统的部署需要专用的客户端功能。这是必要的，因为客户端必须连接到多个副本，并对收到的回复执行多数表决，以否决错误的响应。部署定制的客户端代码很麻烦，并且通常不是一个选项，特别是在开放的异构系统中，以及对于多种客户端实现共存的成熟协议(例如HTTP和IMAP)来说。我们提出了Troxy，一个将特定于BFT的客户端功能重新定位到服务器端的系统，从而使BFT对遗留客户端透明。为了实现这一目标，Troxy依赖于一个可信的子系统，该子系统建立在由SGX支持的硬件保护之上。此外，Troxy通过提供支持可信读取操作的主动维护高速缓存，同时保留底层BFT协议提供的一致性保证，降低了读取密集型工作负载的BFT复制成本。已经构建并评估了Troxy的原型，结果表明，在本地网络环境中，使用Troxy (1)会导致小有序消息最多43%的性能损失，而(2)在模拟的广域网中，在读取繁重的工作负载下，会将吞吐量提高130%。",
                    "title_zh": "Troxy:对拜占庭容错系统的透明访问"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00020",
                    "title": "RDMC: A Reliable RDMA Multicast for Large Objects",
                    "authors": "Jonathan Behrens, Sagar Jha, Ken Birman, Edward Tremel",
                    "abstract": "Multicast patterns are common in cloud computing and datacenter settings. Applications and infrastructure tools such as Spark frequently move large objects around, update files replicated to multiple nodes, or push new versions of programs to compute nodes. Some applications use replication directly, for example to increase fault-tolerance or achieve parallelism. Implementations of Paxos, block chains and other libraries often employ a hand-built reliable multicast as a primitive. Yet operating systems continue to be focused on point-to-point communication solutions such as TCP or RDMA, a hardware layer with TCP-like semantics that offers zero copy transfers, but lacks a reliable multi-destination transfer capability. Our system, RDMC (RDMA Multicast), offers reliable multicast functionality constructed from RDMA unicast. We discuss design choices, present a theoretical analysis of RDMC's robustness to delays and slow network links, and report on experiments that evaluate RDMC over Mellanox RDMA.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "多播模式在云计算和数据中心环境中很常见。Spark等应用和基础设施工具经常移动大型对象，更新复制到多个节点的文件，或将新版本的程序推送到计算节点。一些应用程序直接使用复制，例如增加容错能力或实现并行性。Paxos、区块链和其他库的实现通常采用手工构建的可靠多播作为原语。然而，操作系统继续专注于点对点通信解决方案，如TCP或RDMA，一种具有类似TCP语义的硬件层，提供零拷贝传输，但缺乏可靠的多目的地传输能力。我们的系统，RDMC (RDMA多播)，提供从RDMA单播构建的可靠多播功能。我们讨论了设计选择，提出了RDMC对延迟和慢速网络链接的鲁棒性的理论分析，并报告了评估梅兰诺克斯RDMA RDMC的实验。",
                    "title_zh": "RDMC:大型对象的可靠RDMA多播"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00021",
                    "title": "Shiraz: Exploiting System Reliability and Application Resilience Characteristics to Improve Large Scale System Throughput",
                    "authors": "Rohan Garg, Tirthak Patel, Gene Cooperman, Devesh Tiwari",
                    "abstract": "Large-scale applications rely on resilience mechanisms such as checkpoint-restart to make forward progress in the presence of failures. Unfortunately, this incurs huge I/O overhead and impedes productivity. To mitigate this challenge, this paper introduces a new technique, Shiraz, which demonstrates how to exploit differences in the checkpointing overhead among applications and knowledge of temporal characteristics of failures to improve both the overall system throughput and performance of individual applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大规模应用依赖于诸如检查点重启之类的弹性机制，以便在出现故障时向前推进。不幸的是，这导致了巨大的I/O开销并阻碍了生产率。为了缓解这一挑战，本文介绍了一种新技术Shiraz，它展示了如何利用应用程序之间检查点开销的差异和故障的时间特征知识来提高整个系统的吞吐量和单个应用程序的性能。",
                    "title_zh": "Shiraz:利用系统可靠性和应用弹性特性来提高大规模系统的吞吐量"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00022",
                    "title": "Machine Learning Models for GPU Error Prediction in a Large Scale HPC System",
                    "authors": "Bin Nie, Ji Xue, Saurabh Gupta, Tirthak Patel, Christian Engelmann, Evgenia Smirni, Devesh Tiwari",
                    "abstract": "GPUs are widely deployed on large-scale HPC systems to provide powerful computational capability for scientific applications from various domains. As those applications are normally long-running, investigating the characteristics of GPU errors becomes imperative for reliability. In this paper, we first study the system conditions that trigger GPU errors using six-month trace data collected from a large-scale, operational HPC system. Then, we use machine learning to predict the occurrence of GPU errors, by taking advantage of temporal and spatial dependencies of the trace data. The resulting machine learning prediction framework is robust and accurate under different workloads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "GPU被广泛部署在大规模HPC系统上，为各个领域的科学应用提供强大的计算能力。由于这些应用程序通常是长时间运行的，因此研究GPU错误的特征对于可靠性来说是必不可少的。在本文中，我们首先使用从大规模运行的HPC系统中收集的六个月跟踪数据来研究触发GPU错误的系统条件。然后，通过利用跟踪数据的时间和空间依赖性，我们使用机器学习来预测GPU错误的发生。由此产生的机器学习预测框架在不同的工作负载下都是鲁棒且准确的。",
                    "title_zh": "大规模高性能计算系统中GPU错误预测的机器学习模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00023",
                    "title": "Understanding and Analyzing Interconnect Errors and Network Congestion on a Large Scale HPC System",
                    "authors": "Mohit Kumar, Saurabh Gupta, Tirthak Patel, Michael Wilder, Weisong Shi, Song Fu, Christian Engelmann, Devesh Tiwari",
                    "abstract": "Today's High Performance Computing (HPC) systems are capable of delivering performance in the order of petaflops due to the fast computing devices, network interconnect, and back-end storage systems. In particular, interconnect resilience and congestion resolution methods have a major impact on the overall interconnect and application performance. This is especially true for scientific applications running multiple processes on different compute nodes as they rely on fast network messages to communicate and synchronize frequently. Unfortunately, the HPC community lacks state-of-practice experience reports that detail how different interconnect errors and congestion events occur on large-scale HPC systems. Therefore, in this paper, we process and analyze interconnect data of the Titan supercomputer to develop a thorough understanding of interconnects faults, errors and congestion events. We also study the interaction between interconnect, errors, network congestion and application characteristics.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于快速计算设备、网络互连和后端存储系统，今天的高性能计算(HPC)系统能够提供千万亿次浮点运算的性能。具体而言，互连弹性和拥塞解决方法对整体互连和应用性能具有重大影响。对于在不同计算节点上运行多个进程的科学应用程序来说尤其如此，因为它们依赖于快速网络消息来频繁通信和同步。不幸的是，HPC社区缺乏实践经验报告，这些报告详细描述了不同的互连错误和拥塞事件如何在大规模HPC系统上发生。因此，在本文中，我们处理和分析泰坦超级计算机的互连数据，以深入了解互连故障、错误和拥塞事件。我们还研究了互连、错误、网络拥塞和应用特性之间的相互作用。",
                    "title_zh": "了解和分析大规模HPC系统上的互连错误和网络拥塞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00024",
                    "title": "Fast Hypervisor Recovery Without Reboot",
                    "authors": "Diyu Zhou, Yuval Tamir",
                    "abstract": "System recovery latency is decreased by using microreboot to reboot only the failed component instead of the entire system. For large, complex components, such as hypervisors, even the latency of microreboot is unacceptably high in important deployment scenarios. We investigate an alternative component-level recovery mechanism, which we call microreset, that can achieve dramatically lower recovery latency for some such components. Instead of component reboot, microreset quickly resets the component to a quiescent state that is highly likely to be valid and where the component is ready to handle new or retried interactions with the rest of the system. We present a recovery mechanism for the Xen hypervisor, called NiLiHype, based on microreset. We show that, compared to microreboot-based hypervisor recovery, NiLiHype achieves nearly the same recovery success rate but with a recovery latency that is shorter by a factor of over 30.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过使用microreboot只重新启动故障组件而不是整个系统，减少了系统恢复延迟。对于大型复杂组件，如虚拟机管理程序，在重要的部署场景中，甚至微重启的延迟也高得令人无法接受。我们研究了一种替代的组件级恢复机制，我们称之为微重置，它可以显著降低某些组件的恢复延迟。微重置不是重新启动组件，而是将组件快速重置到静止状态，该状态极有可能是有效的，并且组件准备好处理与系统其余部分的新的或重试的交互。我们提出了一种基于微重置的Xen管理程序恢复机制，称为NiLiHype。我们发现，与基于微引导的虚拟机管理程序恢复相比，NiLiHype实现了几乎相同的恢复成功率，但恢复延迟缩短了30多倍。",
                    "title_zh": "无需重启即可快速恢复虚拟机管理程序"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00025",
                    "title": "ZOE: Content-Based Anomaly Detection for Industrial Control Systems",
                    "authors": "Christian Wressnegger, Ansgar Kellner, Konrad Rieck",
                    "abstract": "Due its complexity and a multitude of proprietary components, industrial control systems are an immanently difficult field of application for intrusion detection. Proprietary binary protocols and the lack of public specifications have forced the research community to move away from content-based detection to more abstract concepts. In this paper, we show that in contrast to prior belief the content of unknown binary protocols can very well be modeled. ZOE derives prototype models that are specific to individual types of messages in order to capture the characteristics of arbitrary binary protocols and enable detecting different forms of attacks as anomalies. In an evaluation based on 6 days of network traffic recorded at a large power plant (1,900 MW) with over 92,000 unique devices, we demonstrate that ZOE improves upon related approaches by up to an order of magnitude in detection performance, but also significantly decreases false positives.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于其复杂性和大量专有组件，工业控制系统是入侵检测的一个固有的困难应用领域。专有二进制协议和公共规范的缺乏迫使研究界从基于内容的检测转向更抽象的概念。在本文中，我们表明，与先前的信念相反，未知的二进制协议的内容可以很好地建模。ZOE派生出特定于各种类型消息的原型模型，以便捕捉任意二进制协议的特征，并能够将不同形式的攻击检测为异常。在基于在具有超过92，000个独特设备的大型发电厂(1，900 MW)记录的6天网络流量的评估中，我们证明了ZOE在检测性能方面比相关方法提高了多达一个数量级，而且显著降低了误报。",
                    "title_zh": "ZOE:基于内容的工业控制系统异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00026",
                    "title": "Cost-Benefit Analysis of Moving-Target Defense in Power Grids",
                    "authors": "Subhash Lakshminarayana, David K. Y. Yau",
                    "abstract": "We study moving-target defense (MTD) that actively perturbs transmission line reactances to thwart stealthy false data injection (FDI) attacks against state estimation in a power grid. Prior work on this topic has proposed MTD based on randomly selected reactance perturbations, but these perturbations cannot guarantee effective attack detection. To address the issue, we present formal design criteria to select MTD reactance perturbations that are truly effective. However, based on a key optimal power flow (OPF) formulation, we find that the effective MTD may incur a non-trivial operational cost that has not hitherto received attention. Accordingly, we characterize important tradeoffs between the MTD's detection capability and its associated required cost. Extensive simulations, using the MATPOWER simulator and benchmark IEEE bus systems, verify and illustrate the proposed design approach that for the first time addresses both key aspects of cost and effectiveness of the MTD.",
                    "files": {
                        "openAccessPdf": "http://wrap.warwick.ac.uk/113233/1/WRAP-cost-benefit-analysis-moving-target-defense-power-grids-Lakshminarayana-2018.pdf"
                    },
                    "abstract_zh": "我们研究了移动目标防御(MTD ),它主动干扰传输线电抗，以阻止针对电网状态估计的隐形虚假数据注入(FDI)攻击。关于该主题的先前工作已经提出了基于随机选择的电抗扰动的MTD，但是这些扰动不能保证有效的攻击检测。为了解决这个问题，我们提出了正式的设计标准来选择真正有效的MTD电抗扰动。然而，基于一个关键的最优潮流(OPF)公式，我们发现，有效的MTD可能会产生一个不小的运营成本，迄今尚未受到重视。因此，我们在MTD的检测能力及其相关的所需成本之间进行了重要的权衡。使用MATPOWER仿真器和基准IEEE总线系统进行的大量仿真验证并说明了所提出的设计方法，该方法首次解决了MTD的成本和有效性这两个关键方面。",
                    "title_zh": "电网中移动目标防御的成本效益分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00027",
                    "title": "Algorithmic Attack Synthesis Using Hybrid Dynamics of Power Grid Critical Infrastructures",
                    "authors": "Zhenqi Huang, Sriharsha Etigowni, Luis Garcia, Sayan Mitra, Saman A. Zonouz",
                    "abstract": "Automated vulnerability assessment and exploit generation for computing systems have been explored for decades. However, these approaches are incomplete in assessing industrial control systems, where networks of computing devices and physical processes interact for safety-critical missions. We present an attack synthesis algorithm against such cyber-physical electricity grids. The algorithm explores both discrete network configurations and continuous dynamics of the plant's embedded control system to search for attack strategies that evade detection with conventional monitors. The algorithm enabling this exploration is rooted in recent developments in the hybrid system verification research: it effectively approximates the behavior of the system for a set of possible attacks by computing sensitivity of the system's response to variations in the attack parameters. For parts of the attack space, the proposed algorithm can infer whether or not there exists a feasible attack that avoids triggering protection measures such as relays and steady-state monitors. The algorithm can take into account constraints on the attack space such as the power system topology and the set of controllers across the plant that can be compromised without detection. With a proof-of-concept prototype, we demonstrate the synthesis of transient attacks in several typical electricity grids and analyze the robustness of the synthesized attacks to perturbations in the network parameters.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "计算系统的自动化漏洞评估和漏洞利用生成已经探索了几十年。然而，这些方法在评估工业控制系统时是不完整的，在工业控制系统中，计算设备和物理过程的网络为了安全关键任务而相互作用。我们提出了一种针对这种信息物理电网的攻击合成算法。该算法探索工厂嵌入式控制系统的离散网络配置和连续动态，以搜索逃避传统监视器检测的攻击策略。实现这种探索的算法植根于混合系统验证研究的最新发展:它通过计算系统对攻击参数变化的响应灵敏度，有效地近似系统对一组可能攻击的行为。对于攻击空间的一部分，所提出的算法可以推断是否存在可行的攻击来避免触发保护措施，如继电器和稳态监控器。该算法可以考虑对攻击空间的约束，例如电力系统拓扑和整个工厂的控制器组，它们可能在没有检测到的情况下被破坏。通过一个概念验证原型，我们演示了几种典型电网中瞬态攻击的合成，并分析了合成攻击对网络参数扰动的鲁棒性。",
                    "title_zh": "基于电网关键基础设施混合动态的算法攻击综合"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00028",
                    "title": "On the Challenges of Building a BFT SCADA",
                    "authors": "André Nogueira, Miguel Garcia, Alysson Bessani, Nuno Neves",
                    "abstract": "In the last decade, Industrial Control Systems have been a frequent target of cyber attacks. As the current defenses sometimes fail to prevent more sophisticated threats, it is necessary to add advanced protection mechanisms to guarantee that correct operation is (always) maintained. In this work, we describe a Supervisory Control and Data Acquisition (SCADA) system enhanced with Byzantine fault-tolerant (BFT) techniques. We document the challenges of building such system from a \"\"traditional\"\" non-BFT solution. This effort resulted in a prototype that integrates the Eclipse NeoSCADA and the BFT-SMaRt open-source projects. We also present an evaluation comparing Eclipse NeoSCADA with our BFT solution. Although the results show a decrease in performance, our solution is still more than enough to accommodate realistic workloads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在过去的十年里，工业控制系统经常成为网络攻击的目标。由于当前的防御措施有时无法防止更复杂的威胁，因此有必要添加高级保护机制来保证(始终)保持正确的操作。在这项工作中，我们描述了一个监督控制和数据采集(SCADA)系统，增强了拜占庭容错(BFT)技术。我们记录了从“传统的”非BFT解决方案构建此类系统的挑战。这项工作产生了一个集成了Eclipse NeoSCADA和BFT智能开源项目的原型。我们还提供了一个比较Eclipse NeoSCADA和我们的BFT解决方案的评估。尽管结果显示性能有所下降，但我们的解决方案仍足以应对实际工作负载。",
                    "title_zh": "建设BFT SCADA系统面临的挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00029",
                    "title": "RECAST: Random Entanglement for Censorship-Resistant Archival STorage",
                    "authors": "Roberta Barbi, Dorian Burihabwa, Pascal Felber, Hugues Mercier, Valerio Schiavoni",
                    "abstract": "Users entrust an increasing amount of data to online cloud systems for archival purposes. Existing storage systems designed to preserve user data unaltered for decades do not, however, provide strong security guarantees - at least at a reasonable cost. This paper introduces RECAST, an anti-censorship data archival system based on random data entanglement. Documents are mixed together using an entanglement scheme that exploits erasure codes for secure and tamper-proof long-term archival. Data is intertwined in such a way that it becomes virtually impossible to delete a specific document that has been stored long enough in the system, without also erasing a substantial fraction of the whole archive, which requires a very powerful adversary and openly exposes the attack. We validate RECAST entanglement approach via simulations and we present and evaluate a full-fledged prototype deployed in a local cluster. In one of our settings, we show that RECAST, configured with the same storage overhead as triple replication, can withstand 10% of storage node failures without any data loss. Furthermore, we estimate that the effort required from a powerful censor to delete a specific target document is two orders of magnitude larger than for triple replication.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "用户出于存档目的将越来越多的数据委托给在线云系统。然而，现有的设计用来保存用户数据几十年不变的存储系统不能提供强有力的安全保证——至少不能以合理的成本提供。本文介绍了基于随机数据纠缠的反审查数据归档系统RECAST。使用纠缠方案将文档混合在一起，该方案利用擦除代码进行安全和防篡改的长期存档。数据以这样一种方式交织在一起，即几乎不可能删除在系统中存储足够长时间的特定文档，而不擦除整个档案的大部分，这需要非常强大的对手并公开暴露攻击。我们通过模拟验证了重铸纠缠方法，并提出和评估了部署在本地集群中的成熟原型。在我们的一个设置中，我们展示了使用与三重复制相同的存储开销配置的RECAST，它可以承受10%的存储节点故障，而不会丢失任何数据。此外，我们估计，一个强大的审查员删除一个特定的目标文件所需的努力比三重复制大两个数量级。",
                    "title_zh": "重铸:抗审查档案存储的随机纠缠"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00030",
                    "title": "Alpha Entanglement Codes: Practical Erasure Codes to Archive Data in Unreliable Environments",
                    "authors": "Vero Estrada-Galiñanes, Ethan L. Miller, Pascal Felber, Jehan-François Pâris",
                    "abstract": "Data centres that use consumer-grade disks drives and distributed peer-to-peer systems are unreliable environments to archive data without enough redundancy. Most redundancy schemes are not completely effective for providing high availability, durability and integrity in the long-term. We propose alpha entanglement codes, a mechanism that creates a virtual layer of highly interconnected storage devices to propagate redundant information across a large scale storage system. Our motivation is to design flexible and practical erasure codes with high fault-tolerance to improve data durability and availability even in catastrophic scenarios. By \"flexible and practical\", we mean code settings that can be adapted to future requirements and practical implementations with reasonable trade-offs between security, resource usage and performance. The codes have three parameters. Alpha increases storage overhead linearly but increases the possible paths to recover data exponentially. Two other parameters increase fault-tolerance even further without the need of additional storage. As a result, an entangled storage system can provide high availability, durability and offer additional integrity: it is more difficult to modify data undetectably. We evaluate how several redundancy schemes perform in unreliable environments and show that alpha entanglement codes are flexible and practical codes. Remarkably, they excel at code locality, hence, they reduce repair costs and become less dependent on storage locations with poor availability. Our solution outperforms Reed-Solomon codes in many disaster recovery scenarios.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1810.02974"
                    },
                    "abstract_zh": "使用消费级磁盘驱动器和分布式对等系统的数据中心是不可靠的环境，无法在没有足够冗余的情况下归档数据。从长期来看，大多数冗余方案在提供高可用性、耐用性和完整性方面并不完全有效。我们提出了阿尔法纠缠码，这是一种创建高度互连的存储设备的虚拟层的机制，用于在大规模存储系统中传播冗余信息。我们的目标是设计灵活实用的高容错纠删码，以提高数据的耐久性和可用性，即使在灾难性的情况下也是如此。所谓“灵活和实用”，我们指的是能够适应未来需求和实际实现的代码设置，在安全性、资源使用和性能之间进行合理的权衡。代码有三个参数。Alpha会线性增加存储开销，但会以指数方式增加恢复数据的可能路径。另外两个参数在不需要额外存储的情况下进一步提高了容错能力。因此，纠缠存储系统可以提供高可用性、耐用性和额外的完整性:更难以不被察觉地修改数据。我们评估了几种冗余方案在不可靠环境中的表现，并表明α纠缠码是灵活实用的编码。值得注意的是，它们在代码局部性方面表现出色，因此，它们降低了修复成本，并减少了对可用性差的存储位置的依赖。在许多灾难恢复场景中，我们的解决方案优于Reed-Solomon码。",
                    "title_zh": "阿尔法纠缠码:在不可靠环境中存档数据的实用擦除码"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00031",
                    "title": "Migrating SGX Enclaves with Persistent State",
                    "authors": "Fritz Alder, Arseny Kurnikov, Andrew Paverd, N. Asokan",
                    "abstract": "Hardware-supported security mechanisms like Intel Software Guard Extensions (SGX) provide strong security guarantees, which are particularly relevant in cloud settings. However, their reliance on physical hardware conflicts with cloud practices, like migration of VMs between physical platforms. For instance, the SGX trusted execution environment (enclave) is bound to a single physical CPU. Although prior work has proposed an effective mechanism to migrate an enclave's data memory, it overlooks the migration of persistent state, including sealed data and monotonic counters; the former risks data loss whilst the latter undermines the SGX security guarantees. We show how this can be exploited to mount attacks, and then propose an improved enclave migration approach guaranteeing the consistency of persistent state. Our software-only approach enables migratable sealed data and monotonic counters, maintains all SGX security guarantees, minimizes developer effort, and incurs negligible performance overhead.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1803.11021"
                    },
                    "abstract_zh": "英特尔软件防护扩展(SGX)等硬件支持的安全机制提供了强大的安全保障，这在云环境中尤为重要。然而，他们对物理硬件的依赖与云实践相冲突，例如在物理平台之间迁移虚拟机。例如，SGX可信执行环境(enclave)被绑定到单个物理CPU。尽管先前的工作已经提出了迁移enclave的数据存储器的有效机制，但是它忽略了持久状态的迁移，包括密封数据和单调计数器；前者有数据丢失的风险，而后者破坏了SGX的安全保证。我们展示了如何利用这一点来发起攻击，然后提出了一种改进的enclave迁移方法来保证持久状态的一致性。我们的纯软件方法支持可迁移的密封数据和单调计数器，维护所有SGX安全保证，最大限度地减少开发人员的工作量，并产生可忽略不计的性能开销。",
                    "title_zh": "具有持久状态的迁移SGX飞地"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00032",
                    "title": "IBBE-SGX: Cryptographic Group Access Control Using Trusted Execution Environments",
                    "authors": "Stefan Contiu, Rafael Pires, Sébastien Vaucher, Marcelo Pasin, Pascal Felber, Laurent Réveillère",
                    "abstract": "While many cloud storage systems allow users to protect their data by making use of encryption, only few support collaborative editing on that data. A major challenge for enabling such collaboration is the need to enforce cryptographic access control policies in a secure and efficient manner. In this paper, we introduce IBBE-SGX, a new cryptographic access control extension that is efficient both in terms of computation and storage even when processing large and dynamic workloads of membership operations, while at the same time offering zero knowledge guarantees. IBBE-SGX builds upon Identity-Based Broadcasting Encryption (IBBE). We address IBBE's impracticality for cloud deployments by exploiting Intel Software Guard Extensions (SGX) to derive cuts in the computational complexity. Moreover, we propose a group partitioning mechanism such that the computational cost of membership update is bound to a fixed constant partition size rather than the size of the whole group. We have implemented and evaluated our new access control extension. Results highlight that IBBE-SGX performs membership changes 1.2 orders of magnitude faster than the traditional approach of Hybrid Encryption (HE), producing group metadata that are 6 orders of magnitude smaller than HE, while at the same time offering zero knowledge guarantees.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1805.01563"
                    },
                    "abstract_zh": "虽然许多云存储系统允许用户通过使用加密来保护他们的数据，但只有少数支持对这些数据进行协作编辑。实现这种协作的一个主要挑战是需要以安全和有效的方式实施加密访问控制策略。在本文中，我们介绍了IBBE-SGX，一种新的密码访问控制扩展，即使在处理成员操作的大型和动态工作负载时，它在计算和存储方面都是有效的，同时提供零知识保证。IBBE-SGX法案建立在基于身份的广播加密(IBBE)之上。我们通过利用英特尔软件卫士扩展(SGX)来削减计算复杂性，解决了IBBE云部署的不可行性。此外，我们提出了一种组划分机制，使得成员更新的计算成本受限于一个固定不变的分区大小，而不是整个组的大小。我们已经实施并评估了新的访问控制扩展。结果显示，IBBE-SGX执行成员变更的速度比传统的混合加密方法快1.2个数量级，生成的组元数据比混合加密方法小6个数量级，同时提供零知识保证。",
                    "title_zh": "IBBE-SGX:使用可信执行环境的密码组访问控制"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00033",
                    "title": "OWL: Understanding and Detecting Concurrency Attacks",
                    "authors": "Shixiong Zhao, Rui Gu, Haoran Qiu, Tsz On Li, Yuexuan Wang, Heming Cui, Junfeng Yang",
                    "abstract": "Just like bugs in single-threaded programs can lead to vulnerabilities, bugs in multithreaded programs can also lead to concurrency attacks. We studied 31 real-world concurrency attacks, including privilege escalations, hijacking code executions, and bypassing security checks. We found that compared to concurrency bugs' traditional consequences (e.g., program crashes), concurrency attacks' consequences are often implicit, extremely hard to be observed and diagnosed by program developers. Moreover, in addition to bug-inducing inputs, extra subtle inputs are often needed to trigger the attacks. These subtle features make existing tools ineffective to detect concurrency attacks. To tackle this problem, we present OWL, the first practical tool that models general concurrency attacks' implicit consequences and automatically detects them. We implemented OWL in Linux and successfully detected five new concurrency attacks, including three confirmed and fixed by developers, and two exploited from previously known and well-studied concurrency bugs. OWL has also detected seven known concurrency attacks. Our evaluation shows that OWL eliminates 94.1% of the reports generated by existing concurrency bug detectors as false positive, greatly reducing developers' efforts on diagnosis. All OWL source code, concurrency attack exploit scripts, and results are available on github.com/hku-systems/owl.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "就像单线程程序中的bug会导致漏洞一样，多线程程序中的bug也会导致并发攻击。我们研究了31个真实世界的并发攻击，包括权限提升、劫持代码执行和绕过安全检查。我们发现，与并发错误的传统后果(如程序崩溃)相比，并发攻击的后果通常是隐性的，程序开发人员很难观察和诊断。此外，除了引发错误的输入，通常还需要额外的微妙输入来触发攻击。这些微妙的特征使得现有工具无法有效检测并发攻击。为了解决这个问题，我们提出了OWL，它是第一个模拟一般并发攻击的隐含后果并自动检测它们的实用工具。我们在Linux中实现了OWL，并成功检测到五种新的并发攻击，其中三种由开发人员确认和修复，两种利用了以前已知的和经过充分研究的并发错误。OWL还发现了七种已知的并发攻击。我们的评估表明，OWL消除了94.1%由现有并发错误检测器生成的误报报告，极大地减少了开发人员的诊断工作。所有OWL源代码、并发攻击利用脚本和结果都可以在github.com/hku-systems/owl.上找到",
                    "title_zh": "OWL:理解和检测并发攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00034",
                    "title": "FAROS: Illuminating In-memory Injection Attacks via Provenance-Based Whole-System Dynamic Information Flow Tracking",
                    "authors": "Meisam Navaki Arefi, Geoffrey Alexander, Hooman Rokham, Aokun Chen, Michalis Faloutsos, Xuetao Wei, Daniela Seabra Oliveira, Jedidiah R. Crandall",
                    "abstract": "In-memory injection attacks are extremely challenging to reverse engineer because they operate stealthily without leaving artifacts in the system or in any easily observable events from outside of a virtual machine. Because these attacks perform their actions in memory only, current malware analysis solutions cannot expose their behavior. This paper introduces FAROS^1 a reverse engineering tool for Windows malware analysis based on dynamic information flow tracking (DIFT), which can flag stealthy in-memory-only malware injection attacks by leveraging the synergy of: (i) whole-system taint analysis; (ii) per security policy-based handling of the challenge of indirect flows via the application of tags of different types, and (iii) the use of tags with fine-grained provenance information. We evaluated FAROS with six advanced in-memory-injecting malware and it flagged the attacks for all samples. We also analyzed FAROS' false positive rate with 90 non-injecting malware samples and 14 benign software from various categories. FAROS presented a very low false positive rate of 2%, which shows its potential towards practical solutions against advanced in-memory-only anti-reverse-engineering attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内存注入攻击对于逆向工程来说极具挑战性，因为它们是秘密进行的，不会在系统中或任何从虚拟机外部容易观察到的事件中留下痕迹。因为这些攻击只在内存中执行它们的动作，所以当前的恶意软件分析解决方案不能暴露它们的行为。本文介绍了一个基于动态信息流跟踪(DIFT)的Windows恶意软件分析的逆向工程工具FAROS^1，它可以通过利用以下协同作用来标记隐蔽的仅在内存中的恶意软件注入攻击:(I)全系统污点分析；(ii)通过应用不同类型的标签，基于每个安全策略处理间接流的挑战，以及(iii)使用具有细粒度出处信息的标签。我们用六种高级内存注入恶意软件评估了FAROS，它标记了所有样本的攻击。我们还分析了FAROS对来自不同类别的90个非注入式恶意软件样本和14个良性软件的误报率。FAROS呈现了2%的非常低的误报率，这显示了它在对抗高级内存中反逆向工程攻击的实际解决方案方面的潜力。",
                    "title_zh": "FAROS:通过基于出处的全系统动态信息流跟踪揭示内存注入攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00035",
                    "title": "To Detect Stack Buffer Overflow with Polymorphic Canaries",
                    "authors": "Zhilong Wang, Xuhua Ding, Chengbin Pang, Jian Guo, Jun Zhu, Bing Mao",
                    "abstract": "Stack Smashing Protection (SSP) is a simple and highly efficient technique widely used in practice as the front line defense against stack buffer overflow attacks. Unfortunately, SSP is known to be vulnerable to the so-called byte-by-byte attack. Although several remedy schemes are proposed in the recent literature, their security is achieved at the price of practicality, because their complex logics ruin SSP's simplicity and high-efficiency. In this paper, we present an elegant solution named as Polymorphic SSP (P-SSP) that attains the same security without sacrificing SSP's strengths. We also propose three extensions of the basic scheme for better compatibility, stronger security, and local variable protection, respectively. We have implemented both a compiler plugin and a binary instrumentation tool for deploying P-SSP. Their respective runtime overheads are only 0.24% and 1.01%. We have also experimented with our extensions and compared their pros and cons with the basic scheme.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "栈粉碎保护(SSP)是一种简单而高效的技术，在实践中被广泛用作抵御栈缓冲区溢出攻击的第一线防御。不幸的是，众所周知，SSP容易受到所谓的逐字节攻击。尽管最近的文献提出了几种补救方案，但它们的安全性是以牺牲实用性为代价的，因为它们复杂的逻辑破坏了SSP的简单性和高效性。在本文中，我们提出了一个优雅的解决方案，称为多态SSP (P-SSP ),它实现了相同的安全性，而没有牺牲SSP的优势。我们还提出了基本方案的三个扩展，分别用于更好的兼容性、更强的安全性和局部变量保护。我们已经为部署P-SSP实现了一个编译器插件和一个二进制插装工具。它们各自的运行时开销只有0.24%和1.01%。我们还试验了我们的扩展，并比较了它们与基本方案的优缺点。",
                    "title_zh": "用多态金丝雀检测堆栈缓冲区溢出"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00036",
                    "title": "Network-Attack-Resilient Intrusion-Tolerant SCADA for the Power Grid",
                    "authors": "Amy Babay, Thomas Tantillo, Trevor Aron, Marco Platania, Yair Amir",
                    "abstract": "As key components of the power grid infrastructure, Supervisory Control and Data Acquisition (SCADA) systems are likely to be targeted by nation-state-level attackers willing to invest considerable resources to disrupt the power grid. We present Spire, the first intrusion-tolerant SCADA system that is resilient to both system-level compromises and sophisticated network-level attacks and compromises. We develop a novel architecture that distributes the SCADA system management across three or more active sites to ensure continuous availability in the presence of simultaneous intrusions and network attacks. A wide-area deployment of Spire, using two control centers and two data centers spanning 250 miles, delivered nearly 99.999% of all SCADA updates initiated over a 30-hour period within 100ms. This demonstrates that Spire can meet the latency requirements of SCADA for the power grid.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为电网基础设施的关键组件，监控和数据采集(SCADA)系统很可能成为国家级攻击者的目标，这些攻击者愿意投入大量资源来破坏电网。我们提出Spire，第一个入侵容忍SCADA系统，它对系统级的危害和复杂的网络级攻击和危害都有弹性。我们开发了一种新颖的架构，将SCADA系统管理分布在三个或更多的活动站点上，以确保在同时存在入侵和网络攻击的情况下的连续可用性。Spire的广域部署使用两个控制中心和两个数据中心，跨越250英里，在100毫秒内交付了30小时内启动的所有SCADA更新的近99.999%。这表明Spire可以满足电网SCADA的延迟要求。",
                    "title_zh": "面向电网的抗网络攻击容侵SCADA系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00037",
                    "title": "Branching Bisimulation and Concurrent Object Verification",
                    "authors": "Xiaoxiao Yang, Joost-Pieter Katoen, Huimin Lin, Gaoang Liu, Hao Wu",
                    "abstract": "Linearizability and progress properties are key correctness notions for concurrent objects. This paper presents novel verification techniques for both property classes. The key of our techniques is based on the branching bisimulation equivalence. We first show that it suffices to check linearizability on the quotient object program under branching bisimulation. This is appealing, as it does not rely on linearization points. Further, by exploiting divergence-sensitive branching bisimilarity, our approach proves progress properties (e.g., lock-, wait-freedom) by comparing the concurrent to-be-verified object program against an abstract program consisting of atomic blocks. Our work thus enables the usage of well-known proof techniques for branching bisimulation to check the correctness of concurrent objects. The potential of our approach is illustrated by verifying linearizability and lock-freedom of 14 benchmark algorithms from the literature. Our experiments confirm one known bug and reveals one new bug.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "线性化和进度属性是并发对象的关键正确性概念。本文提出了两种属性类的新颖验证技术。我们技术的关键是基于分支互模拟等价。我们首先证明了在分支互模拟下检查商目标程序的线性化是足够的。这很有吸引力，因为它不依赖于线性化点。此外，通过利用对发散敏感的分支相似性，我们的方法通过将并发的待验证目标程序与由原子块组成的抽象程序进行比较来证明进度属性(例如，锁定、等待自由)。因此，我们的工作允许使用众所周知的分支互模拟证明技术来检查并发对象的正确性。通过验证文献中14个基准算法的线性化和无锁性，说明了我们方法的潜力。我们的实验证实了一个已知的错误，并揭示了一个新的错误。",
                    "title_zh": "分支互模拟和并发对象验证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00038",
                    "title": "Modeling Input-Dependent Error Propagation in Programs",
                    "authors": "Guanpeng Li, Karthik Pattabiraman",
                    "abstract": "Transient hardware faults are increasing in computer systems due to shrinking feature sizes. Traditional methods to mitigate such faults are through hardware duplication, which incurs huge overhead in performance and energy consumption. Therefore, researchers have explored software solutions such as selective instruction duplication, which require fine-grained analysis of instruction vulnerabilities to Silent Data Corruptions (SDCs). These are typically evaluated via Fault Injection (FI), which is often highly time-consuming. Hence, most studies confine their evaluations to a single input for each program. However, there is often significant variation in the SDC probabilities of both the overall program and individual instructions across inputs, which compromises the correctness of results with a single input. In this work, we study the variation of SDC probabilities across different inputs of a program, and identify the reasons for the variations. Based on the observations, we propose a model, VTRIDENT, which predicts the variations in programs' SDC probabilities without any FIs, for a given set of inputs. We find that VTRIDENT is nearly as accurate as FI in identifying the variations in SDC probabilities across inputs. We demonstrate the use of VTRIDENT to bound overall SDC probability of a program under multiple inputs, while performing FI on only a single input.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于特征尺寸的缩小，计算机系统中的瞬时硬件故障正在增加。减轻此类故障的传统方法是通过硬件复制，这会导致巨大的性能开销和能耗。因此，研究人员探索了选择性指令复制等软件解决方案，这些解决方案需要对静默数据损坏(SDC)的指令漏洞进行细粒度分析。这些通常通过故障注入(FI)进行评估，这通常非常耗时。因此，大多数研究将他们的评估局限于每个项目的单一输入。然而，整个程序和单个指令的SDC概率在输入之间经常有显著的变化，这损害了单个输入的结果的正确性。在这项工作中，我们研究了SDC概率在一个程序的不同输入中的变化，并找出了变化的原因。基于这些观察，我们提出了一个模型，VTRIDENT，它可以预测在没有任何FIs的情况下，对于给定的一组输入，程序的SDC概率的变化。我们发现，在识别输入的SDC概率变化方面，VTRIDENT几乎和FI一样准确。我们演示了在多个输入下使用VTRIDENT来限制程序的整体SDC概率，而只对单个输入执行FI。",
                    "title_zh": "程序中依赖输入的错误传播建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00039",
                    "title": "Efficient Transient Analysis of a Class of Compositional Fluid Stochastic Petri Nets",
                    "authors": "Peter Buchholz, Tugrul Dayar",
                    "abstract": "Fluid Stochastic Petri Nets (FSPNs) which have discrete and continuous places are an established model class to describe and analyze several dependability problems for computer systems, software architectures or critical infrastructures. Unfortunately, their analysis is faced with the curse of dimensionality resulting in very large systems of differential equations for a sufficiently accurate analysis. This contribution introduces a class of FSPNs with a compositional structure and shows how the underlying stochastic process can be described by a set of coupled partial differential equations. Using semi discretization, a set of linear ordinary differential equations is generated which can be described by a (hierarchical) sum of Kronecker products. Based on this compact representation of the transition matrix, a numerical solution approach is applied which also represents transient solution vectors in compact form using the recently developed concept of a Hierarchical Tucker Decomposition. The applicability of the approach is presented in a case study analyzing a degrading software system with rejuvenation, restart, and replication.",
                    "files": {
                        "openAccessPdf": "http://repository.bilkent.edu.tr/bitstream/11693/50175/1/Efficient_transient_analysis_of_a_class_of.pdf"
                    },
                    "abstract_zh": "具有离散和连续位置的流体随机Petri网(FSPNs)是一种已建立的模型类，用于描述和分析计算机系统、软件体系结构或关键基础设施的若干可信性问题。不幸的是，他们的分析面临着维数灾难，导致非常大的微分方程系统，无法进行足够精确的分析。本文介绍了一类具有复合结构的FSPNs，并展示了潜在的随机过程是如何被一组耦合的偏微分方程所描述的。使用半离散化，生成一组线性常微分方程，其可以由Kronecker积的(分层)和来描述。基于转换矩阵的这种紧凑表示，应用了一种数值求解方法，该方法还使用最近开发的分级Tucker分解概念以紧凑形式表示瞬态解向量。该方法的适用性在一个案例研究中提出，该案例研究分析了一个具有再生、重启和复制的退化软件系统。",
                    "title_zh": "一类组合流体随机Petri网的有效瞬态分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00040",
                    "title": "Importance Sampling of Interval Markov Chains",
                    "authors": "Cyrille Jégourel, Jingyi Wang, Jun Sun",
                    "abstract": "In real-world systems, rare events often characterize critical situations like the probability that a system fails within some time bound and they are used to model some potentially harmful scenarios in dependability of safety-critical systems. Probabilistic Model Checking has been used to verify dependability properties in various types of systems but is limited by the state space explosion problem. An alternative is the recourse to Statistical Model Checking (SMC) that relies on Monte Carlo simulations and provides estimates within predefined error and confidence bounds. However, rare properties require a large number of simulations before occurring at least once. To tackle the problem, Importance Sampling, a rare event simulation technique, has been proposed in SMC for different types of probabilistic systems. Importance Sampling requires the full knowledge of probabilistic measure of the system, e.g. Markov chains. In practice, however, we often have models with some uncertainty, e.g., Interval Markov Chains. In this work, we propose a method to apply importance sampling to Interval Markov Chains. We show promising results in applying our method to multiple case studies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在现实世界的系统中，罕见事件通常表征关键情况，如系统在某个时间范围内发生故障的概率，它们用于模拟安全关键系统可靠性中的一些潜在有害场景。概率模型检验已被用于验证各种类型系统的可靠性属性，但受到状态空间爆炸问题的限制。一种替代方法是求助于统计模型检验(SMC ),它依赖于蒙特卡罗模拟，并在预定义的误差和置信界限内提供估计值。然而，罕见的属性需要大量的模拟才能至少出现一次。为了解决这个问题，重要抽样，一种罕见的事件模拟技术，已经在SMC中被提出用于不同类型的概率系统。重要抽样需要系统的概率测量的全部知识，例如马尔可夫链。然而，在实践中，我们经常有一些不确定性的模型，例如，区间马尔可夫链。在这篇文章中，我们提出了一种将重要抽样应用于区间马氏链的方法。我们在将我们的方法应用于多个案例研究中显示了有希望的结果。",
                    "title_zh": "区间马氏链的重要抽样"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00041",
                    "title": "Low Overhead Tag Error Mitigation for GPU Architectures",
                    "authors": "Atieh Lotfi, Nirmal R. Saxena, Richard Bramley, Paul Racunas, Philip P. Shirvani",
                    "abstract": "Cache structures on modern GPUs or CPUs occupy a large area and are frequently accessed. This increases their vulnerability to transient errors. With some area and energy overhead, these structures are often protected by ECC or parity checking. However, in deference to the energy efficiency and scalability challenges in high-performance computing, it is crucial to minimize any unnecessary overhead while maintaining the desired reliability. This paper evaluates the reliability of unprotected tag SRAM structures in modern GPUs, and studies the use of a low-overhead tag error mitigation mechanism. The proposed mechanism exploits Galois-based hash functions for set-index calculation to mitigate some pathological address strides that cause false hit events. Extensive analysis on a modern GPU indicates that the hash-based mechanism yields 10x reduction in false hit probability (with 2% improvement in hit rate) for write-through data caches when compared to a baseline cache indexing scheme.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代GPU或CPU上的缓存结构占据了很大的面积，并且被频繁访问。这增加了它们对瞬时错误的脆弱性。由于一些面积和能量开销，这些结构通常由ECC或奇偶校验来保护。然而，考虑到高性能计算中的能效和可扩展性挑战，在保持所需可靠性的同时最大限度地减少任何不必要的开销至关重要。本文评估了现代GPU中无保护标签SRAM结构的可靠性，并研究了低开销标签错误缓解机制的使用。所提出的机制利用基于伽罗瓦的散列函数进行集合索引计算，以减轻导致错误命中事件的某些病态地址步长。对现代GPU的广泛分析表明，与基线缓存索引方案相比，基于哈希的机制使直写数据缓存的错误命中概率降低了10倍(命中率提高了2%)。",
                    "title_zh": "用于GPU架构的低开销标签错误缓解"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00042",
                    "title": "DAVOS: EDA Toolkit for Dependability Assessment, Verification, Optimisation and Selection of Hardware Models",
                    "authors": "Ilya Tuzov, David de Andrés, Juan Carlos Ruiz",
                    "abstract": "The high complexity of new designs and time-to-market pressure have caused design reuse to be at the heart of the common semi-custom hardware design flow. Accordingly, current Electronic Design Automation (EDA) toolchains are developed to support a wide range of hardware description languages, third-party EDA tools, intellectual property cores, and implementation technologies and goals. However, the seamless integration of dependability requirements into such toolchains remains today an open challenge. This paper presents DAVOS, an EDA toolkit supporting assessment, verification, optimisation (design space exploration), and selection (benchmarking) processes for dependability-aware hardware implementations. This toolkit fully automates these processes with efficiency and flexibility in mind, so underlying implementation and analysis phases can be customized to consider alternative off-the-self languages, tools, components and technologies from a dependability perspective. Three different embedded processor models exemplify the design scenarios supported by DAVOS.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "新设计的高度复杂性和上市时间的压力使得设计重用成为通用半定制硬件设计流程的核心。因此，当前的电子设计自动化(EDA)工具链被开发来支持广泛的硬件描述语言、第三方EDA工具、知识产权核心以及实现技术和目标。然而，将可靠性要求无缝集成到这样的工具链中在今天仍然是一个公开的挑战。本文介绍了DAVOS，一个支持评估、验证、优化(设计空间探索)和选择(基准测试)过程的EDA工具箱，用于可靠性感知硬件实现。该工具包考虑到效率和灵活性，完全自动化了这些过程，因此可以定制底层实现和分析阶段，以从可靠性角度考虑替代的非自我语言、工具、组件和技术。三种不同的嵌入式处理器模型展示了达沃斯支持的设计场景。",
                    "title_zh": "达沃斯:用于可靠性评估、验证、优化和硬件模型选择的EDA工具箱"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00043",
                    "title": "A Framework for Evaluating Software on Reduced Margins Hardware",
                    "authors": "Konstantinos Parasyris, Panos K. Koutsovasilis, Vassilis Vassiliadis, Christos D. Antonopoulos, Nikolaos Bellas, Spyros Lalis",
                    "abstract": "To improve power efficiency, researchers are experimenting with dynamically adjusting the voltage and frequency margins of systems to just above the minimum required for reliable operation. Traditionally, manufacturers did not allow reducing these margins. Consequently, existing studies use system simulators, or software fault-injection methodologies, which are slow, inaccurate and cannot be applied on realistic workloads. However recent CPUs allow the operation outside the nominal voltage/frequency envelope. We present eXtended Margins eXperiment Manager (XM^2) which enables the evaluation of software on systems operating outside their nominal margins. It supports both bare-metal and OS-controlled execution using an API to control the fault injection procedure and provides automatic management of experimental campaigns. XM^2 requires, on average, 5.6% extra lines of code and increases the application execution time by 2.5%. To demonstrate the flexibility of XM^2, we perform three case studies: two employing bare-metal execution on a raspberry PI, and one featuring a full-fledged software stack (including OS) on an Intel Skylake Xeon processor.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了提高能效，研究人员正在尝试动态调整系统的电压和频率裕度，使其刚好高于可靠运行所需的最低值。传统上，制造商不允许减少这些利润。因此，现有的研究使用系统模拟器，或软件故障注入方法，这是缓慢的，不准确的，不能应用于现实的工作负载。然而，最新的CPU允许在标称电压/频率范围之外工作。我们提出了扩展边际实验管理器(XM^2 ),它能够在超出其标称边际的系统上对软件进行评估。它支持裸机和操作系统控制的执行，使用API来控制故障注入过程，并提供实验活动的自动管理。XM^2平均需要5.6%的额外代码行，并将应用程序的执行时间增加了2.5%。为了展示XM^2的灵活性，我们进行了三个案例研究:两个在raspberry PI上采用裸机执行，一个在英特尔Skylake Xeon处理器上采用成熟的软件堆栈(包括操作系统)。",
                    "title_zh": "在低利润硬件上评估软件的框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00044",
                    "title": "Parallel Error Detection Using Heterogeneous Cores",
                    "authors": "Sam Ainsworth, Timothy M. Jones",
                    "abstract": "Microprocessor error detection is increasingly important, as the number of transistors in modern systems heightens their vulnerability. In addition, many modern workloads in domains such as the automotive and health industries are increasingly error intolerant, due to strict safety standards. However, current detection techniques require duplication of all hardware structures, causing a considerable increase in power consumption and chip area. Solutions in the literature involve running the code multiple times on the same hardware, which reduces performance significantly and cannot capture all errors. We have designed a novel hardware-only solution for error detection, that exploits parallelism in checking code which may not exist in the original execution. We pair a high-performance out-of-order core with a set of small low-power cores, each of which checks a portion of the out-of-order core's execution. Our system enables the detection of both hard and soft errors, with low area, power and performance overheads.",
                    "files": {
                        "openAccessPdf": "https://www.repository.cam.ac.uk/bitstream/1810/279226/1/dsn-final.pdf"
                    },
                    "abstract_zh": "微处理器错误检测越来越重要，因为现代系统中晶体管的数量增加了它们的脆弱性。此外，由于严格的安全标准，汽车和医疗行业等领域的许多现代工作负载越来越不能容忍错误。然而，当前的检测技术需要复制所有的硬件结构，导致功耗和芯片面积显著增加。文献中的解决方案涉及在同一硬件上多次运行代码，这显著降低了性能，并且不能捕获所有错误。我们为错误检测设计了一种新颖的纯硬件解决方案，它利用并行性来检查代码，而这在原始执行中可能不存在。我们将一个高性能乱序内核与一组小的低功耗内核配对，每个内核检查一部分乱序内核的执行。我们的系统能够以较低的面积、功耗和性能开销检测硬错误和软错误。",
                    "title_zh": "使用异构内核的并行错误检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00045",
                    "title": "Measuring IPv6 DNS Reconnaissance Attacks and Preventing Them Using DNS Guard",
                    "authors": "Qinwen Hu, Muhammad Rizwan Asghar, Nevil Brownlee",
                    "abstract": "Traditional address scanning attacks mainly rely on the naive 'brute forcing' approach, where the entire IPv4 address space is exhaustively searched by enumerating different possibilities. However, such an approach is inefficient for IPv6 due to its vast subnet size (i.e., 2^64). As a result, it is widely assumed that address scanning attacks are less feasible in IPv6 networks. In this paper, we evaluate new IPv6 reconnaissance techniques in real IPv6 networks and expose how to leverage the Domain Name System (DNS) for IPv6 network reconnaissance. We collected IPv6 addresses from 5 regions and 100,000 domains by exploiting DNS reverse zone and DNSSEC records. We propose a DNS Guard (DNSG) to efficiently detect DNS reconnaissance attacks in IPv6 networks. DNSG is a plug and play component that could be added to the existing infrastructure. We implement DNSG using Bro and Suricata. Our results demonstrate that DNSG could effectively block DNS reconnaissance attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传统的地址扫描攻击主要依靠简单的“暴力”方法，通过枚举不同的可能性来彻底搜索整个IPv4地址空间。然而，由于其巨大的子网大小(即2^64).)，这种方法对于IPv6是低效的因此，人们普遍认为地址扫描攻击在IPv6网络中不太可行。在本文中，我们评估了真实IPv6网络中的新IPv6侦测技术，并揭示了如何利用域名系统(DNS)进行IPv6网络侦测。我们通过利用DNS反向域和DNSSEC记录，从5个地区和100，000个域收集了IPv6地址。我们提出了一种DNSG来有效地检测IPv6网络中的DNS侦察攻击。DNSG是一个即插即用的组件，可以添加到现有的基础架构中。我们使用Bro和Suricata实现DNSG。我们的结果表明，DNSG可以有效地阻止DNS侦察攻击。",
                    "title_zh": "测量IPv6 DNS侦测攻击并使用DNS Guard防止它们"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00046",
                    "title": "Your Remnant Tells Secret: Residual Resolution in DDoS Protection Services",
                    "authors": "Lin Jin, Shuai Hao, Haining Wang, Chase Cotton",
                    "abstract": "The increasing prevalence of Distributed Denial of Service (DDoS) attacks on the Internet has led to the wide adoption of DDoS Protection Service (DPS), which is typically provided by Content Delivery Networks (CDNs) and is integrated with CDN's security extensions. The effectiveness of DPS mainly relies on hiding the IP address of an origin server and rerouting the traffic to the DPS provider's distributed infrastructure, where malicious traffic can be blocked. In this paper, we perform a measurement study on the usage dynamics of DPS customers and reveal a new vulnerability in DPS platforms, called residual resolution, by which a DPS provider may leak origin IP addresses when its customers terminate the service or switch to other platforms, resulting in the failure of protection from future DPS providers as adversaries are able to discover the origin IP addresses and launch the DDoS attack directly to the origin servers. We identify that two major DPS/CDN providers, Cloudflare and Incapsula, are vulnerable to such residual resolution exposure, and we then assess the magnitude of the problem in the wild. Finally, we discuss the root causes of residual resolution and the practical countermeasures to address this security vulnerability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "互联网上分布式拒绝服务(DDoS)攻击的日益流行导致了DDoS保护服务(DPS)的广泛采用，该服务通常由内容交付网络(CDN)提供，并与CDN的安全扩展相集成。DPS的有效性主要依赖于隐藏源服务器的IP地址，并将流量重新路由到DPS提供商的分布式基础设施，在那里可以阻止恶意流量。在本文中，我们对DPS客户的使用动态进行了测量研究，并揭示了DPS平台中一个新的漏洞，称为剩余解析，通过该漏洞，当DPS提供商的客户终止服务或切换到其他平台时，DPS提供商可能会泄漏原始IP地址，从而导致未来DPS提供商的保护失败，因为对手能够发现原始IP地址并直接对原始服务器发起DDoS攻击。我们发现两个主要的DPS/CDN提供商Cloudflare和Incapsula容易受到这种残余分辨率影响，然后我们评估了这一问题在野外的严重程度。最后，我们讨论了残留解析的根本原因和解决这个安全漏洞的实际对策。",
                    "title_zh": "你的残余告诉秘密:DDoS保护服务中的残余解决方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00047",
                    "title": "Effective Topology Tampering Attacks and Defenses in Software-Defined Networks",
                    "authors": "Richard Skowyra, Lei Xu, Guofei Gu, Veer Dedhia, Thomas Hobson, Hamed Okhravi, James Landry",
                    "abstract": "As Software-Defined Networking has gained increasing prominence, new attacks have been demonstrated which can corrupt the SDN controller's view of network topology. These topology poisoning attacks, most notably host-location hijacking and link fabrication attacks, enable adversaries to impersonate end-hosts or inter-switch links in order to monitor, corrupt, or drop network flows. In response, defenses have been developed to detect such attacks and raise an alert. In this paper, we analyze two such defenses, TopoGuard and Sphinx, and present two new attacks, Port Probing and Port Amnesia, that can successfully bypass them. We then develop and present extensions to TopoGuard to make it resilient to such attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着软件定义的网络越来越受重视，新的攻击已经出现，这些攻击会破坏SDN控制器的网络拓扑视图。这些拓扑中毒攻击，最明显的是主机位置劫持和链路伪造攻击，使对手能够冒充终端主机或交换机间链路，以监控、破坏或丢弃网络流。作为回应，已经开发了检测这种攻击并发出警报的防御措施。在本文中，我们分析了两种这样的防御，拓扑卫士和Sphinx，并提出了两种新的攻击，端口探测和端口遗忘，可以成功地绕过他们。然后，我们开发并提供了对TopoGuard的扩展，使其能够抵御此类攻击。",
                    "title_zh": "软件定义网络中有效的拓扑篡改攻击和防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00048",
                    "title": "EndBox: Scalable Middlebox Functions Using Client-Side Trusted Execution",
                    "authors": "David Goltzsche, Signe Rüsch, Manuel Nieke, Sébastien Vaucher, Nico Weichbrodt, Valerio Schiavoni, Pierre-Louis Aublin, Paolo Costa, Christof Fetzer, Pascal Felber, Peter R. Pietzuch, Rüdiger Kapitza",
                    "abstract": "Many organisations enhance the performance, security, and functionality of their managed networks by deploying middleboxes centrally as part of their core network. While this simplifies maintenance, it also increases cost because middlebox hardware must scale with the number of clients. A promising alternative is to outsource middlebox functions to the clients themselves, thus leveraging their CPU resources. Such an approach, however, raises security challenges for critical middlebox functions such as firewalls and intrusion detection systems. We describe EndBox, a system that securely executes middlebox functions on client machines at the network edge. Its design combines a virtual private network (VPN) with middlebox functions that are hardware-protected by a trusted execution environment (TEE), as offered by Intel's Software Guard Extensions (SGX). By maintaining VPN connection endpoints inside SGX enclaves, EndBox ensures that all client traffic, including encrypted communication, is processed by the middlebox. Despite its decentralised model, EndBox's middlebox functions remain maintainable: they are centrally controlled and can be updated efficiently. We demonstrate EndBox with two scenarios involving (i) a large company; and (ii) an Internet service provider that both need to protect their network and connected clients. We evaluate EndBox by comparing it to centralised deployments of common middlebox functions, such as load balancing, intrusion detection, firewalling, and DDoS prevention. We show that EndBox achieves up to 3.8x higher throughput and scales linearly with the number of clients.",
                    "files": {
                        "openAccessPdf": "https://leopard.tu-braunschweig.de/servlets/MCRFileNodeServlet/dbbs_derivate_00044609/Endbox.pdf"
                    },
                    "abstract_zh": "许多组织通过集中部署中间盒作为其核心网络的一部分来增强其受管网络的性能、安全性和功能。虽然这简化了维护，但也增加了成本，因为中间体硬件必须随着客户端的数量而扩展。一个有希望的替代方案是将中间体功能外包给客户机本身，从而利用它们的CPU资源。然而，这种方法对防火墙和入侵检测系统等关键的中间功能提出了安全挑战。我们描述了EndBox，一个在网络边缘的客户端机器上安全执行中间盒功能的系统。其设计结合了虚拟专用网络(VPN)和中间件功能，这些功能由可信执行环境(TEE)提供硬件保护，如英特尔的软件保护扩展(SGX)。通过维护SGX飞地内的VPN连接端点，EndBox确保所有客户端流量，包括加密通信，都由中间盒处理。尽管是分散的模型，但EndBox的中间盒功能仍然是可维护的:它们是集中控制的，可以有效地更新。我们用两个场景演示EndBox，涉及(I)一个大公司；以及(ii)互联网服务提供商，他们都需要保护他们的网络和连接的客户端。我们通过将EndBox与常见中间件功能的集中部署进行比较来评估EndBox，这些功能包括负载平衡、入侵检测、防火墙和DDoS防御。我们发现，EndBox的吞吐量提高了3.8倍，并且随着客户端数量的增加而线性扩展。",
                    "title_zh": "EndBox:使用客户端可信执行的可伸缩中间盒功能"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00049",
                    "title": "FragDroid: Automated User Interface Interaction with Activity and Fragment Analysis in Android Applications",
                    "authors": "Jia Chen, Ge Han, Shanqing Guo, Wenrui Diao",
                    "abstract": "Recent years have witnessed the enormous growth of Android phones in the consumer market. On the other hand, as the most popular mobile platform, Android also attracts lots of attackers' attention. As a result, more and more Android malicious apps appear in the wild, which poses a serious threat to user's security and privacy. To such massive volume of Android malware, automated UI testing techniques have become the mainstream solutions because of the detection efficiency and accuracy. However, all existing UI testing techniques treat the Activity as the basic unit of UI interactions and cannot carry out a fine-grained analysis for Fragments. Due to the lack of Fragment-level analysis, the path coverage is usually quite limited. To fill this gap, in this paper, we propose FragDroid, a novel automated UI testing framework supporting both Activity and Fragment analysis. To achieve the Fragment-level testing, we design the Activity & Fragment Transition Model (AFTM) to simulate the internal interactions of an app, and ATFM could be utilized to generate test cases automatically through UI interactions. With the assist of AFTM, FragDroid achieves accessing most Activities and Fragments contained in the app along with the capability of detecting arbitrary API calls. We implemented a prototype of FragDroid and evaluated it on 15 popular apps. The results show FragDroid successfully covered 66% Fragments and the corresponding API calls of testing apps. Also, the traditional approaches have to miss at least 9.6% of API calls invoked in Fragments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，Android手机在消费市场上取得了巨大的增长。另一方面，作为最流行的移动平台，Android也吸引了大量攻击者的注意。因此，越来越多的Android恶意应用出现在野外，对用户的安全和隐私造成了严重威胁。面对如此海量的Android恶意软件，自动化UI测试技术因其检测效率和准确性成为主流解决方案。然而，所有现有的UI测试技术都将活动视为UI交互的基本单元，无法对片段进行细粒度的分析。由于缺乏片段级分析，路径覆盖通常非常有限。为了填补这一空白，在本文中，我们提出了FragDroid，一个新颖的支持活动和片段分析的自动化UI测试框架。为了实现片段级测试，我们设计了活动和片段转换模型(AFTM)来模拟应用程序的内部交互，并利用ATFM通过UI交互自动生成测试用例。在AFTM的帮助下，FragDroid实现了访问应用程序中包含的大多数活动和片段，以及检测任意API调用的能力。我们实现了一个FragDroid的原型，并在15个流行的应用程序上对其进行了评估。实验结果表明，FragDroid成功覆盖了66%的测试应用的片段和相应的API调用。此外，传统方法必须错过至少9.6%的片段调用的API调用。",
                    "title_zh": "frag droid:Android应用程序中带有活动和片段分析的自动化用户界面交互"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00050",
                    "title": "How Reliable is My Wearable: A Fuzz Testing-Based Study",
                    "authors": "Edgardo Barsallo Yi, Amiya Maji, Saurabh Bagchi",
                    "abstract": "As wearable devices like smartwatches and fitness monitors gain in popularity and are being touted for clinical purposes, it becomes important to evaluate the reliability of Android Wear OS and apps on such devices. To date there has been no study done by systematic error injection into the OS or the apps. We address this gap in this work. We develop and open source a fuzz testing tool for Android Wear apps and services, called Qui-Gon Jinn (QGJ). We perform an extensive fault injection study by mutating inter-process communication messages and UI events and direct about 1.5M such mutated events at 46 apps. These apps are divided into two categories: health/fitness and other. The results of our study show some patterns distinct from prior studies of Android. Over the years, input validation has improved and fewer NullPointerExceptions are seen, however, Android Wear apps crash from unhandled IllegalStateExceptions at a higher rate. There are occasional troubling cases of the entire device rebooting due to unprivileged mutated messages. Reassuringly the apps are quite robust to mutations of UI events with only 0.05% of them causing an app crash.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着智能手表和健身监视器等可穿戴设备越来越受欢迎，并被吹捧为用于临床目的，评估Android Wear操作系统和应用在此类设备上的可靠性变得非常重要。迄今为止，还没有对操作系统或应用程序中的系统错误注入进行研究。我们在这项工作中填补了这一空白。我们为Android Wear应用和服务开发并开源了一个模糊测试工具，名为Qui-Gon Jinn (QGJ)。我们通过变异进程间通信消息和UI事件进行了广泛的故障注入研究，并在46个应用程序中引导了大约150万个这样的变异事件。这些app分为两类:健康/健身和其他。我们的研究结果显示了一些与之前Android研究截然不同的模式。这些年来，输入验证已经得到了改进，出现的NullPointerExceptions更少，但是，Android Wear应用程序更容易因未处理的IllegalStateExceptions而崩溃。偶尔会出现由于未授权的变异消息而导致整个设备重启的麻烦情况。令人放心的是，这些应用程序对UI事件的突变非常健壮，只有0.05%的突变会导致应用程序崩溃。",
                    "title_zh": "我的可穿戴设备有多可靠:一项基于模糊测试的研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00051",
                    "title": "Localizing Function Errors in Mobile Apps with User Reviews",
                    "authors": "Le Yu, Jiachi Chen, Hao Zhou, Xiapu Luo, Kang Liu",
                    "abstract": "Removing all function errors is critical for making successful mobile apps. Since app testing may miss some function errors given limited time and resource, the user reviews of mobile apps are very important to developers for learning the uncaught errors. Unfortunately, manually handling each review is time-consuming and even error-prone. Existing studies on mobile apps' reviews could not help developers effectively locate the problematic code according to the reviews, because the majority of such research does not take into account apps' code. Moreover, recent studies on mapping reviews to problematic source files just look for the matching between the words in reviews and that in source code, and thus result in many false positives and false negatives. In this paper, we propose a novel approach to localize function errors in mobile apps by exploiting the context information in user reviews and correlating the reviews and bytecode through their semantic meanings. We realize our new approach as a tool named ReviewSolver, and carefully evaluate it with reviews of real apps. The experimental result shows that ReviewSolver has much better performance than the state-of-the-art tool.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "消除所有功能错误对于开发成功的移动应用至关重要。由于有限的时间和资源，应用程序测试可能会遗漏一些功能错误，因此用户对移动应用程序的评论对于开发人员了解未被遗漏的错误非常重要。不幸的是，手动处理每一个审查非常耗时，甚至容易出错。现有的关于移动应用评论的研究不能帮助开发者根据评论有效地定位有问题的代码，因为大多数这样的研究没有考虑应用的代码。此外，最近关于将评论映射到有问题的源文件的研究只是寻找评论中的单词和源代码中的单词之间的匹配，因此导致了许多误报和漏报。在本文中，我们提出了一种新的方法来定位移动应用中的功能错误，该方法利用用户评论中的上下文信息，并通过它们的语义将评论和字节码相关联。我们认识到我们的新方法是一个名为ReviewSolver的工具，并通过真实应用的评论仔细评估它。实验结果表明，ReviewSolver比目前最先进的工具具有更好的性能。",
                    "title_zh": "利用用户评论定位移动应用中的功能错误"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00052",
                    "title": "DTaint: Detecting the Taint-Style Vulnerability in Embedded Device Firmware",
                    "authors": "Kai Cheng, Qiang Li, Lei Wang, Qian Chen, Yaowen Zheng, Limin Sun, Zhenkai Liang",
                    "abstract": "A rising number of embedded devices are reachable in the cyberspace, such as routers, cameras, printers, etc. Those devices usually run firmware whose code is proprietary with few public documents. Furthermore, most of the firmware images cannot be analyzed in dynamic analysis due to various hardware-specific peripherals. As a result, it hinders traditional static analysis and dynamic analysis techniques. In this paper, we propose a static binary analysis approach, DTaint, to detect taint-style vulnerabilities in the firmware. The taint-style vulnerability is a typical class of weakness, where the input data reaches a sensitive sink through an unsafe path. Specifically, we generate data dependency in a bottom-up manner through traversing callees before callers. To reduce the influence of the binary firmware, DTaint identifies pointer aliasing, interprocedural data flow, and similarity of the data structure layout. We have implemented a prototype of DTaint and conducted experiments to evaluate its performance. Our results show that DTaint discovers more vulnerabilities in less time, compared with the existing techniques. Furthermore, we illustrate the effectiveness of DTaint through applying it over six firmware images from four manufacturers. We have found 21 vulnerabilities, where 13 of them are previously-unknown and zero-day vulnerabilities.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "越来越多的嵌入式设备可以在网络空间中访问，如路由器、照相机、打印机等。这些设备通常运行固件，其代码是专有的，很少有公开文档。此外，由于各种硬件专用外设，大多数固件映像无法在动态分析中进行分析。因此，它阻碍了传统的静态分析和动态分析技术。在本文中，我们提出了一种静态二进制分析方法，DTaint，用于检测固件中的污点式漏洞。污点式漏洞是一种典型的弱点，输入数据通过不安全的路径到达敏感的接收器。具体来说，我们通过在调用方之前遍历被调用方，以自底向上的方式生成数据依赖。为了减少二进制固件的影响，DTaint识别指针混淆、过程间数据流和数据结构布局的相似性。我们已经实现了一个DTaint原型，并进行了实验来评估它的性能。我们的结果表明，与现有技术相比，DTaint可以在更短的时间内发现更多的漏洞。此外，我们通过在来自四个制造商的六个固件映像上应用DTaint来说明它的有效性。我们发现了21个漏洞，其中13个是以前未知的零日漏洞。",
                    "title_zh": "DTaint:检测嵌入式设备固件中的污点式漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00053",
                    "title": "Deceptive Secret Sharing",
                    "authors": "Lei Zhang, Douglas M. Blough",
                    "abstract": "Confidentiality is a fundamental goal in many security contexts. Deception is another goal in which the intention is to mislead adversaries, for example by planting false information in a system. In this paper, we consider an approach that combines confidentiality and deception using secret sharing, which has traditionally been used strictly for confidentiality purposes. The motivation for this is to protect confidentiality as far as possible while acknowledging that no confidentiality scheme provides perfect protection. If confidentiality is breached and information is accessed by unauthorized individuals, our techniques will reveal, with high probability, only false information. This provides deception on top of the confidentiality provided by ordinary secret sharing. We refer to our approach as \"deceptive secret sharing\" and we present techniques that work with both XOR secret sharing and Shamir's polynomial-based threshold secret sharing. We provide extensive evaluations of both overhead and security of our techniques and we also show how they provide tunable security that can trade off security and overhead by varying a single parameter of the schemes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "保密性是许多安全环境中的一个基本目标。欺骗是另一个目的，其意图是误导对手，例如通过在系统中植入虚假信息。在本文中，我们考虑了一种使用秘密共享将机密性和欺骗性结合起来的方法，秘密共享传统上被严格用于机密性目的。这样做的动机是尽可能地保护机密性，同时承认没有保密方案提供完美的保护。如果保密性被破坏，信息被未授权的个人访问，我们的技术将很有可能只揭示虚假信息。这在普通秘密共享所提供的保密性之上提供了欺骗。我们称我们的方法为“欺骗性秘密共享”,并且我们提出了与XOR秘密共享和Shamir的基于多项式的门限秘密共享一起工作的技术。我们对我们的技术的开销和安全性进行了广泛的评估，我们还展示了它们如何提供可调的安全性，可以通过改变方案的单个参数来权衡安全性和开销。",
                    "title_zh": "欺骗性秘密共享"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00054",
                    "title": "MobiCeal: Towards Secure and Practical Plausibly Deniable Encryption on Mobile Devices",
                    "authors": "Bing Chang, Fengwei Zhang, Bo Chen, Yingjiu Li, Wen Tao Zhu, Yangguang Tian, Zhan Wang, Albert Ching",
                    "abstract": "We introduce MobiCeal, the first practical Plausibly Deniable Encryption (PDE) system for mobile devices that can defend against strong coercive multi-snapshot adversaries, who may examine the storage medium of a user's mobile device at different points of time and force the user to decrypt data. MobiCeal relies on \"dummy write\" to obfuscate the differences between multiple snapshots of storage medium due to existence of hidden data. By incorporating PDE in block layer, MobiCeal supports a broad deployment of any block-based file systems on mobile devices. More importantly, MobiCeal is secure against side channel attacks which pose a serious threat to existing PDE schemes. A proof of concept implementation of MobiCeal is provided on an LG Nexus 4 Android phone using Android 4.2.2. It is shown that the performance of MobiCeal is significantly better than prior PDE systems against multi-snapshot adversaries.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们介绍了MobiCeal，这是第一个用于移动设备的实用可信可否认加密(PDE)系统，可以抵御强大的强制性多快照对手，他们可以在不同的时间点检查用户移动设备的存储介质，并强迫用户解密数据。由于隐藏数据的存在，MobiCeal依靠“虚拟写入”来混淆存储介质的多个快照之间的差异。通过在块层中加入PDE，MobiCeal支持在移动设备上广泛部署任何基于块的文件系统。更重要的是，MobiCeal可以抵御对现有PDE方案构成严重威胁的边信道攻击。在使用Android 4.2.2的LG Nexus 4 Android手机上提供了MobiCeal的概念验证实现。结果表明，在对抗多快照对手时，MobiCeal的性能明显优于现有的PDE系统。",
                    "title_zh": "移动加密:在移动设备上实现安全实用的可信可否认加密"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00055",
                    "title": "Collaborative Filtering Under a Sybil Attack: Similarity Metrics do Matter!",
                    "authors": "Antoine Boutet, Florestan De Moor, Davide Frey, Rachid Guerraoui, Anne-Marie Kermarrec, Antoine Rault",
                    "abstract": "Recommendation systems help users identify interesting content, but they also open new privacy threats. In this paper, we deeply analyze the effect of a Sybil attack that tries to infer information on users from a user-based collaborative-filtering recommendation systems. We discuss the impact of different similarity metrics used to identity users with similar tastes in the trade-off between recommendation quality and privacy. Finally, we propose and evaluate a novel similarity metric that combines the best of both worlds: a high recommendation quality with a low prediction accuracy for the attacker. Our results, on a state-of-the-art recommendation framework and on real datasets show that existing similarity metrics exhibit a wide range of behaviors in the presence of Sybil attacks, while our new similarity metric consistently achieves the best trade-off while outperforming state-of-the-art solutions.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01787060/file/main.pdf"
                    },
                    "abstract_zh": "推荐系统帮助用户识别感兴趣的内容，但也带来了新的隐私威胁。本文深入分析了Sybil攻击对基于用户的协同过滤推荐系统的影响。我们讨论了在推荐质量和隐私之间的权衡中，用于识别具有相似品味的用户的不同相似性度量的影响。最后，我们提出并评估了一种新的相似性度量，它结合了两个世界的优点:高推荐质量和对攻击者的低预测准确性。我们在最先进的推荐框架和真实数据集上的结果表明，现有的相似性度量在存在Sybil攻击的情况下表现出广泛的行为，而我们的新相似性度量在优于最先进的解决方案的同时，始终实现了最佳的折衷。",
                    "title_zh": "Sybil攻击下的协同过滤:相似性度量很重要！"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00056",
                    "title": "Specification-Based Protocol Obfuscation",
                    "authors": "Julien Duchêne, Eric Alata, Vincent Nicomette, Mohamed Kaâniche, Colas Le Guernic",
                    "abstract": "This paper proposes a new obfuscation technique of a communication protocol that is aimed at making the reverse engineering of the protocol more complex. The obfuscation is based on the transformation of protocol message format specification. The obfuscating transformations are applied to the Abstract Syntax Tree (AST) representation of the messages and mainly concern the ordering or aggregation of the AST nodes. The paper also presents the design of a framework that implements the proposed obfuscation technique by automatically generating, from the specification of the message format, a library performing the corresponding transformations. Finally, our framework is applied to two real application protocols (Modbus and HTTP) to illustrate the relevance and efficiency of the proposed approach. Various metrics recorded from the experiments show the significant increase of the complexity of the obfuscated protocol binary compared to the non-obfuscated code. It is also shown that the execution time and memory overheads remain acceptable for a practical deployment of the approach in operation.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1807.09464"
                    },
                    "abstract_zh": "提出了一种新的通信协议混淆技术，旨在使协议的逆向工程更加复杂。混淆是基于协议消息格式规范的转换。模糊转换应用于消息的抽象语法树(AST)表示，主要涉及AST节点的排序或聚合。本文还介绍了一个框架的设计，该框架通过根据消息格式的规范自动生成执行相应转换的库来实现所提出的混淆技术。最后，我们的框架被应用于两个实际的应用协议(Modbus和HTTP)来说明所提出的方法的相关性和有效性。从实验中记录的各种度量显示，与未混淆的代码相比，混淆的协议二进制代码的复杂性显著增加。它还表明，执行时间和内存开销仍然是可接受的实际部署的方法在运作中。",
                    "title_zh": "基于规范的协议混淆"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00057",
                    "title": "Obfuscated VBA Macro Detection Using Machine Learning",
                    "authors": "Sangwoo Kim, Seokmyung Hong, Jaesang Oh, Heejo Lee",
                    "abstract": "Malware using document files as an attack vector has continued to increase and now constitutes a large portion of phishing attacks. To avoid anti-virus detection, malware writers usually implement obfuscation techniques in their source code. Although obfuscation is related to malicious code detection, little research has been conducted on obfuscation with regards to Visual Basic for Applications (VBA) macros. In this paper, we summarize the obfuscation techniques and propose an obfuscated macro code detection method using five machine learning classifiers. To train these classifiers, our proposed method uses 15 discriminant static features, taking into account the characteristics of the VBA macros. We evaluated our approach using a real-world dataset of obfuscated and non-obfuscated VBA macros extracted from Microsoft Office document files. The experimental results demonstrate that our detection approach achieved a F2 score improvement of greater than 23% compared to those of related studies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "使用文档文件作为攻击媒介的恶意软件持续增加，现在构成了网络钓鱼攻击的很大一部分。为了避免反病毒检测，恶意软件作者通常在其源代码中实施混淆技术。尽管模糊处理与恶意代码检测相关，但很少有人研究与Visual Basic for Applications (VBA)宏相关的模糊处理。本文总结了混淆技术，提出了一种使用五个机器学习分类器的混淆宏代码检测方法。为了训练这些分类器，我们提出的方法使用了15个判别静态特征，同时考虑了VBA宏的特性。我们使用从Microsoft Office文档文件中提取的模糊和非模糊VBA宏的真实数据集来评估我们的方法。实验结果表明，与相关研究相比，我们的检测方法实现了大于23%的F2分数改善。",
                    "title_zh": "使用机器学习的模糊VBA宏检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00058",
                    "title": "Evaluating Self-Adaptive Authorisation Infrastructures Through Gamification",
                    "authors": "Christopher Michael Bailey, Rogério de Lemos",
                    "abstract": "Self-adaptive systems are able to modify their behaviour and/or structure in response to changes that occur to the system itself, its environment, or even its goals. In terms of authorisation infrastructures, self-adaptation has been shown to provide runtime capabilities for specifying and enforcing access control policies and subject access privileges, with a goal to mitigate insider threat. The evaluation of self-adaptive authorisation infrastructures, particularly, in the context of insider threats, is challenging because simulation of malicious behaviour can only demonstrate a fraction of the types of abuse that is representative of the real-world. In this paper, we present an innovative approach based on an ethical game of hacking, protected by an authorisation infrastructure. A key feature of the approach is the ability to observe user activity pre- and post-adaptation when evaluating runtime consequences of self-adaptation. Our live experiments captured a wide range of unpredictable changes, including malicious behaviour related to the exploitation of known vulnerabilities. As an outcome, we demonstrated the ability of our self-adaptive authorisation infrastructure to handle malicious behaviour given the existence of real and intelligent users, in addition to capturing how users responded to adaptation.",
                    "files": {
                        "openAccessPdf": "https://kar.kent.ac.uk/66570/1/dsn2018_main.pdf"
                    },
                    "abstract_zh": "自适应系统能够修改其行为和/或结构，以响应系统本身、其环境甚至其目标的变化。就授权基础设施而言，自适应已被证明为指定和执行访问控制策略和主体访问权限提供了运行时能力，目的是减轻内部威胁。自适应授权基础设施的评估，特别是在内部威胁的情况下，是具有挑战性的，因为恶意行为的模拟只能展示代表真实世界的滥用类型的一小部分。在本文中，我们提出了一种基于黑客道德游戏的创新方法，该方法受到授权基础设施的保护。该方法的一个关键特征是在评估自适应的运行时结果时，能够观察自适应前后的用户活动。我们的实时实验捕捉到了广泛的不可预测的变化，包括与利用已知漏洞相关的恶意行为。结果，我们展示了我们的自适应授权基础设施在真实和智能用户存在的情况下处理恶意行为的能力，以及捕捉用户对适应的反应。",
                    "title_zh": "通过游戏化评估自适应授权基础设施"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00059",
                    "title": "POWERALERT: Integrity Checking Using Power Measurement and a Game-Theoretic Strategy",
                    "authors": "Ahmed M. Fawaz, Mohammad A. Noureddine, William H. Sanders",
                    "abstract": "We propose POWERALERT, an efficient external integrity checker for untrusted hosts. Current attestation systems suffer from shortcomings, including requiring a complete checksum of the code segment, from being static, use of timing information sourced from the untrusted machine, or using imprecise timing information such as network round-trip time. We address those shortcomings by (1) using power measurements from the host to ensure that the checking code is executed and (2) checking a subset of the kernel space over an extended period. We compare the power measurement against a learned power model of the execution of the machine and validate that the execution was not tampered. Finally, POWERALERT randomizes the integrity checking program to prevent the attacker from adapting. We model the interaction between POWERALERT and an attacker as a time-continuous game. The Nash equilibrium strategy of the game shows that POWERALERT has two optimal strategy choices: (1) aggressive checking that forces the attacker into hiding, or (2) slow checking that minimizes cost. We implement a prototype of POWERALERT using Raspberry Pi and evaluate the performance of the integrity checking program generation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了POWERALERT，一种针对不可信主机的高效外部完整性检查器。当前的证明系统存在缺点，包括需要代码段的完整校验和、是静态的、使用来自不可信机器的定时信息、或者使用不精确的定时信息，例如网络往返时间。我们通过(1)使用来自主机的功率测量来确保检查代码被执行，以及(2)在延长的时间段内检查内核空间的子集来解决这些缺点。我们将功率测量与机器执行的学习功率模型进行比较，并验证该执行未被篡改。最后，POWERALERT将完整性检查程序随机化，以防止攻击者进行改编。我们将POWERALERT和攻击者之间的交互建模为一个时间连续的游戏。博弈的纳什均衡策略表明，POWERALERT有两个最优策略选择:(1)迫使攻击者躲藏起来的积极检查，或者(2)使成本最小化的缓慢检查。我们使用Raspberry Pi实现了一个POWERALERT原型，并评估了完整性检查程序生成的性能。",
                    "title_zh": "POWERALERT:使用功率测量和博弈论策略的完整性检查"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00060",
                    "title": "Generating Cloud Monitors from Models to Secure Clouds",
                    "authors": "Elena Troubitsyna, Irum Rauf",
                    "abstract": "Authorization is an important security concern in cloud computing environments. It aims at regulating an access of the users to system resources. A large number of resources associated with REST APIs typical in cloud makes an implementation of security requirements challenging and error-prone. To alleviate this problem, in this paper we propose an implementation of security cloud monitor. We rely on model-driven approach to represent the functional and security requirements. Models are then used to generate cloud monitors. The cloud monitors contain contracts used to automatically verify the implementation. We use Django web framework to implement cloud monitor and OpenStack to validate our implementation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "授权是云计算环境中一个重要的安全问题。它旨在管理用户对系统资源的访问。在云中，与REST APIs相关联的大量资源使得安全需求的实现变得具有挑战性并且容易出错。为了缓解这一问题，本文提出了一种安全云监控器的实现方案。我们依靠模型驱动的方法来表示功能和安全需求。模型然后被用来生成云监视器。云监视器包含用于自动验证实现的契约。我们使用Django web框架来实现云监控，使用OpenStack来验证我们的实现。",
                    "title_zh": "从模型到安全云生成云监视器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00061",
                    "title": "Falcon: A Practical Log-Based Analysis Tool for Distributed Systems",
                    "authors": "Francisco Neves, Nuno Machado, José Pereira",
                    "abstract": "Programmers and support engineers typically rely on log data to narrow down the root cause of unexpected behaviors in dependable distributed systems. Unfortunately, the inherently distributed nature and complexity of such distributed executions often leads to multiple independent logs, scattered across different physical machines, with thousands or millions entries poorly correlated in terms of event causality. This renders log-based debugging a tedious, time-consuming, and potentially inconclusive task. We present Falcon, a tool aimed at making log-based analysis of distributed systems practical and effective. Falcon's modular architecture, designed as an extensible pipeline, allows it to seamlessly combine several distinct logging sources and generate a coherent space-time diagram of distributed executions. To preserve event causality, even in the presence of logs collected from independent unsynchronized machines, Falcon introduces a novel happens-before symbolic formulation and relies on an off-the-shelf constraint solver to obtain a coherent event schedule. Our case study with the popular distributed coordination service Apache Zookeeper shows that Falcon eases the log-based analysis of complex distributed protocols and is helpful in bridging the gap between protocol design and implementation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "程序员和支持工程师通常依靠日志数据来缩小可靠分布式系统中意外行为的根本原因。不幸的是，这种分布式执行固有的分布式性质和复杂性经常导致多个独立的日志，分散在不同的物理机器上，成千上万的条目在事件因果关系方面相关性很差。这使得基于日志的调试成为一项乏味、耗时且可能不确定的任务。我们提出了Falcon，一个旨在使基于日志的分布式系统分析实用而有效的工具。Falcon的模块化架构设计为可扩展的管道，允许它无缝地组合几个不同的日志记录源，并生成分布式执行的连贯时空图。为了保持事件的因果关系，即使在存在从独立的非同步机器收集的日志的情况下，Falcon也引入了一种新的先发生后符号公式，并依靠现成的约束求解器来获得一致的事件时间表。我们对流行的分布式协调服务Apache Zookeeper的案例研究表明，Falcon简化了复杂分布式协议的基于日志的分析，并有助于弥合协议设计和实现之间的差距。",
                    "title_zh": "Falcon:分布式系统中基于日志的实用分析工具"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00062",
                    "title": "Pleiades: Distributed Structural Invariants at Scale",
                    "authors": "Simon Bouget, Yérom-David Bromberg, Adrien Luxey, François Taïani",
                    "abstract": "Modern large scale distributed systems increasingly espouse sophisticated distributed architectures characterized by complex distributed structural invariants. Unfortunately, maintaining these structural invariants at scale is time consuming and error prone, as developers must take into account asynchronous failures, loosely coordinated sub-systems and network delays. To address this problem, we propose PLEIADES, a new framework to construct and enforce large-scale distributed structural invariants under aggressive conditions. PLEIADES combines the resilience of self-organizing overlays, with the expressiveness of an assembly-based design strategy. The result is a highly survivable framework that is able to dynamically maintain arbitrary complex distributed structures under aggressive crash failures. Our evaluation shows in particular that PLEIADES is able to restore the overall structure of a 25,600 node system in less than 11 asynchronous rounds after half of the nodes have crashed.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01803881/file/camera-ready-PLEIADES.pdf"
                    },
                    "abstract_zh": "现代大规模分布式系统越来越支持复杂的分布式体系结构，其特征在于复杂的分布式结构不变量。不幸的是，大规模维护这些结构不变量既耗时又容易出错，因为开发人员必须考虑异步故障、松散协调的子系统和网络延迟。为了解决这个问题，我们提出了昴宿星，一个新的框架来构建和实施侵略条件下的大规模分布式结构不变量。昴宿星结合了自组织覆盖的弹性和基于组装的设计策略的表现力。其结果是一个高度可生存的框架，能够在严重崩溃故障下动态维护任意复杂的分布式结构。我们的评估特别显示，昴宿星能够在一半节点崩溃后，在不到11个异步回合内恢复25，600节点系统的整体结构。",
                    "title_zh": "昴宿星:尺度上的分布式结构不变量"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00063",
                    "title": "The Tortoise and the Hare: Characterizing Synchrony in Distributed Environments (Practical Experience Report)",
                    "authors": "Daniel Porto, João Leitão, Flavio Junqueira, Rodrigo Rodrigues",
                    "abstract": "The design of distributed protocols that run in data centers and enterprise clusters is heavily dependent on synchrony assumptions regarding the timing behavior of the participating nodes and the network. However, little is known about the actual synchrony of real distributed systems, and how it varies across deployments. To better understand this timing behavior and how it impacts the design and implementation of distributed protocols, we conduct an extensive measurement study of the latency for transmitting and processing messages between nodes in four different environments. Our study determines how protocol characteristics affect the latency behavior. We also determine how different environmental factors can affect the measured latency and whether high latency events manifest globally or locally. Our results suggest several directions for reducing latency, and for leveraging recent distributed computing models in a more judicious way.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "运行在数据中心和企业集群中的分布式协议的设计在很大程度上依赖于关于参与节点和网络的定时行为的同步假设。然而，对于真实的分布式系统的实际同步性，以及它如何在部署中变化，我们知之甚少。为了更好地理解这种计时行为以及它如何影响分布式协议的设计和实现，我们对四种不同环境中节点之间传输和处理消息的延迟进行了广泛的测量研究。我们的研究确定了协议特征如何影响延迟行为。我们还确定不同的环境因素如何影响测量的延迟，以及高延迟事件是在全球还是在本地出现。我们的结果提出了几个方向来减少延迟，并以更明智的方式利用最近的分布式计算模型。",
                    "title_zh": "龟兔赛跑:描述分布式环境中的同步性(实践经验报告)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00064",
                    "title": "Inferring, Characterizing, and Investigating Internet-Scale Malicious IoT Device Activities: A Network Telescope Perspective",
                    "authors": "Sadegh Torabi, Elias Bou-Harb, Chadi Assi, Mario Galluscio, Amine Boukhtouta, Mourad Debbabi",
                    "abstract": "Recent attacks have highlighted the insecurity of the Internet of Things (IoT) paradigm by demonstrating the impacts of leveraging Internet-scale compromised IoT devices. In this paper, we address the lack of IoT-specific empirical data by drawing upon more than 5TB of passive measurements. We devise data-driven methodologies to infer compromised IoT devices and those targeted by denial of service attacks. We perform large-scale characterization analysis of their traffic, as well as explore a public threat repository and an in-house malware database, to underlie their malicious activities. The results expose a significant 26 thousand compromised IoT devices \"in the wild,\" with 40% being active in critical infrastructure. More importantly, we uncover new, previously unreported malware variants that specifically target IoT devices. Our empirical results render a first attempt to highlight the large-scale insecurity of the IoT paradigm, while alarming about the rise of new generations of IoT-centric malware-orchestrated botnets.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近的攻击通过展示利用互联网规模的受损物联网设备的影响，凸显了物联网(IoT)范式的不安全性。在本文中，我们通过利用超过5TB的被动测量来解决物联网特定经验数据的缺乏问题。我们设计了数据驱动的方法来推断受损的物联网设备和那些被拒绝服务攻击作为目标的设备。我们对其流量进行大规模特征分析，并探索公共威胁存储库和内部恶意软件数据库，以此作为其恶意活动的基础。调查结果显示，有26，000台受威胁的物联网设备“处于未开发状态”，其中40%活跃在关键基础设施中。更重要的是，我们发现了专门针对物联网设备的新的、以前未报告的恶意软件变种。我们的实证结果首次试图强调物联网范式的大规模不安全性，同时对新一代以物联网为中心的恶意软件精心策划的僵尸网络的崛起发出警告。",
                    "title_zh": "推断、描述和调查互联网规模的恶意物联网设备活动:网络望远镜视角"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00065",
                    "title": "RoboADS: Anomaly Detection Against Sensor and Actuator Misbehaviors in Mobile Robots",
                    "authors": "Pinyao Guo, Hunmin Kim, Nurali Virani, Jun Xu, Minghui Zhu, Peng Liu",
                    "abstract": "Mobile robots such as unmanned vehicles integrate heterogeneous capabilities in sensing, computation, and control. They are representative cyber-physical systems where the cyberspace and the physical world are strongly coupled. However, the safety of mobile robots is significantly threatened by cyber/physical attacks and software/hardware failures. These threats can thwart normal robot operations and cause robot misbehaviors. In this paper, we propose a novel anomaly detection system, which leverages physical dynamics of mobile robots to detect misbehaviors in sensors and actuators. We explore issues raised in real-world implementations, e.g., distinctive robot dynamic models, sensor quantity and quality, decision parameters, etc., for practicality purposes. We implement the detection system on two types of mobile robots and evaluate the detection performance against various misbehavior scenarios, including signal interference, sensor spoofing, logic bomb and physical jamming. The experiments show detection effectiveness and small detection delays.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "无人驾驶车辆等移动机器人集成了传感、计算和控制方面的异构能力。它们是典型的网络物理系统，其中网络空间和物理世界紧密相连。然而，移动机器人的安全受到网络/物理攻击和软硬件故障的严重威胁。这些威胁会阻碍正常的机器人操作，并导致机器人行为不端。本文提出了一种新颖的异常检测系统，它利用移动机器人的物理动力学来检测传感器和执行器中的异常行为。我们探讨了现实世界实施中出现的问题，如独特的机器人动态模型、传感器数量和质量、决策参数等。，出于实用目的。我们在两种类型的移动机器人上实现了检测系统，并针对各种不当行为场景(包括信号干扰、传感器欺骗、逻辑炸弹和物理干扰)评估了检测性能。实验证明了检测的有效性和较小的检测延迟。",
                    "title_zh": "RoboADS:针对移动机器人中传感器和执行器不当行为的异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00066",
                    "title": "Hands Off the Wheel in Autonomous Vehicles?: A Systems Perspective on over a Million Miles of Field Data",
                    "authors": "Subho S. Banerjee, Saurabh Jha, James Cyriac, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer",
                    "abstract": "Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S. roads, offering the promise of improvements in traffic management, safety, and the comfort and efficiency of vehicular travel. The California Department of Motor Vehicles (DMV) reports that between 2014 and 2017, manufacturers tested 144 AVs, driving a cumulative 1,116,605 autonomous miles, and reported 5,328 disengagements and 42 accidents involving AVs on public roads. This paper investigates the causes, dynamics, and impacts of such AV failures by analyzing disengagement and accident reports obtained from public DMV databases. We draw several conclusions. For example, we find that autonomous vehicles are 15 - 4000Ã— worse than human drivers for accidents per cumulative mile driven; that drivers of AVs need to be as alert as drivers of non-AVs; and that the AVs' machine-learning-based systems for perception and decision-and-control are the primary cause of 64% of all disengagements.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动驾驶汽车(AV)技术正在美国道路上迅速成为现实，为改善交通管理、安全以及车辆行驶的舒适性和效率带来了希望。加州机动车辆管理局(DMV)报告称，在2014年至2017年期间，制造商测试了144辆自动驾驶汽车，累计行驶了1116605英里，并报告了5328起脱离事故和42起涉及自动驾驶汽车的公共道路事故。本文通过分析从DMV公共数据库中获得的脱离和事故报告，调查了这种AV故障的原因、动态和影响。我们得出几个结论。例如，我们发现自动驾驶汽车每行驶一英里发生的事故比人类司机多15 - 4000度；AVs的司机需要和非AVs的司机一样警觉；AVs基于机器学习的感知、决策和控制系统是64%脱离接触的主要原因。",
                    "title_zh": "自动驾驶汽车的手离开方向盘？:对超过一百万英里的现场数据的系统观点"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00067",
                    "title": "Impact of Software Approximations on the Resiliency of a Video Summarization System",
                    "authors": "Radha Venkatagiri, Karthik Swaminathan, Chung-Ching Lin, Liang Wang, Alper Buyuktosunoglu, Pradip Bose, Sarita V. Adve",
                    "abstract": "In this work, we examine the resiliency of a state-of-the-art end-to-end video summarization (VS) application that serves as a representative emerging workload in the domain of real time edge computing. The VS application constitutes key video and image analytic elements that are processed by embedded systems aboard unmanned aerial vehicles (UAVs). Real-time performance and energy constraints motivate the consideration of approximations to the VS algorithm. However, mission-critical UAV applications also demand stringent levels of resilience to soft errors that are exacerbated with higher altitude. In this work, we study the effects of three different types of software approximations on the application level resiliency (to soft errors) of the VS algorithm. We show that our approximations yield significant energy savings (up to 68%), with commensurate improvement in performance, without a degradation in the application resilience. Further, by proposing a novel quality metric (appropriate for the UAV vision analytics domain) for the summarized video output, we show that even though the rate of Silent Data Corruptions (SDCs) increases slightly (<2%), the impact of these SDCs on output quality is limited. Thus, we conclude that software approximation can be utilized to achieve significant gains in performance and energy without affecting application resiliency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在这项工作中，我们研究了最先进的端到端视频摘要(VS)应用的弹性，该应用是实时边缘计算领域中具有代表性的新兴工作负载。VS应用程序由无人机(UAV)上的嵌入式系统处理的关键视频和图像分析元素组成。实时性能和能量限制促使人们考虑VS算法的近似。然而，任务关键型无人机应用也要求对软错误具有严格的弹性，这种错误会随着海拔的升高而加剧。在这项工作中，我们研究了三种不同类型的软件近似对VS算法的应用级弹性(对软错误)的影响。我们表明，我们的近似方法可以显著节省能源(高达68%)，同时相应提高性能，而不会降低应用程序的弹性。此外，通过为汇总的视频输出提出一种新的质量度量(适用于UAV视觉分析领域)，我们表明即使无声数据损坏(SDC)的比率略有增加(< 2%)，这些SDC对输出质量的影响也是有限的。因此，我们得出结论，可以利用软件近似来实现性能和能源的显著提升，而不会影响应用弹性。",
                    "title_zh": "软件近似对视频摘要系统弹性的影响"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00068",
                    "title": "Detecting and Identifying Faulty IoT Devices in Smart Home with Context Extraction",
                    "authors": "Jiwon Choi, Hayoung Jeoung, Jihun Kim, Youngjoo Ko, Wonup Jung, Hanjun Kim, Jong Kim",
                    "abstract": "A fast and reliable method to detect faulty IoT devices is indispensable in IoT environments. In this paper, we present DICE, an automatic method to detect and identify faulty IoT devices with context extraction. Our system works in two phases. In a precomputation phase, the system precomputes sensor correlation and the transition probability between sensor states known as context. During a real-time phase, the system finds a violation of sensor correlation and transition to detect and identify the faults. In detection, we analyze the sensor data to find any missing or newly reacting IoT devices that are deviating from already grouped correlated sensors, and state transition to find the presence of an abnormal sequence. Then, the system identifies the faulty device by comparing the problematic context with the probable ones. We demonstrate that DICE identifies faulty devices accurately and promptly through the evaluation on various fault types and datasets.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在物联网环境中，快速可靠地检测故障物联网设备是必不可少的。在本文中，我们介绍了DICE，这是一种通过上下文提取来检测和识别故障物联网设备的自动方法。我们的系统分两个阶段工作。在预计算阶段，系统预计算传感器相关性和传感器状态之间的转移概率，称为上下文。在实时阶段，系统发现传感器相关性和转换的违反，以检测和识别故障。在检测中，我们分析传感器数据，以找到任何丢失的或新反应的物联网设备，这些设备偏离已经分组的相关传感器，并进行状态转换，以找到异常序列的存在。然后，系统通过将有问题的上下文与可能的上下文进行比较来识别故障设备。通过对各种故障类型和数据集的评估，我们证明了DICE能够准确而迅速地识别故障设备。",
                    "title_zh": "利用上下文提取检测和识别智能家居中的故障物联网设备"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00069",
                    "title": "Divide and Conquer for Fast SRLG Disjoint Routing",
                    "authors": "Kun Xie, Heng Tao, Xin Wang, Gaogang Xie, Jigang Wen, Jiannong Cao, Zheng Qin",
                    "abstract": "Ensuring transmission survivability is a crucial problem for high-speed networks. Path protection is a fast and capacity-efficient approach for increasing the availability of end to end connections. The emerging SDN infrastructure makes it feasible to provide diversity routing in a practical network. For more robust path protection, it is desirable to provide an alternative path that does not share any risk resource with the active path. We consider finding the SRLG-Disjoint paths, where a Shared Risk Link Group (SRLG) is a group of network links that share a common physical resource whose failure will cause the failure of all links of the group. Since the traffic is carried on the active path most of time, it is useful that the weight of the shorter path of the disjoint path pair is minimized, and we call it Min-Min SRLG-Disjoint routing problem. The key issue faced by SRLG-Disjoint routing is the trap problem, where the SRLG-disjoint backup path (BP) can not be found after an active path (AP) is decided. Based on the min-cut of the graph, we design an efficient algorithm that can take advantage of existing search results to quickly look for the SRLG-Disjoint path pair. Our performance studies demonstrate that our algorithm can outperform other approaches with a higher routing performance while also at a much faster speed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "确保传输生存性是高速网络的一个关键问题。路径保护是提高端到端连接可用性的一种快速且高效的方法。新兴的SDN基础设施使得在实际网络中提供分集路由成为可能。为了实现更强大的路径保护，需要提供一条不与活动路径共享任何风险资源的替代路径。我们考虑寻找SRLG不相交路径，其中共享风险链路组(SRLG)是共享公共物理资源的一组网络链路，该物理资源的故障将导致该组所有链路的故障。由于大部分时间流量是在活动路径上传送的，因此最小化不相交路径对中较短路径的权重是有用的，我们称之为最小-最小SRLG不相交路由问题。SRLG不相交路由面临的关键问题是陷阱问题，即在活动路径(ap)被确定后，SRLG不相交备份路径(BP)无法找到。基于图的最小割，我们设计了一个有效的算法，可以利用现有的搜索结果快速寻找SRLG不相交的路径对。我们的性能研究表明，我们的算法可以优于其他方法，具有更高的路由性能，同时也具有更快的速度。",
                    "title_zh": "快速SRLG不相交路由的分治法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00070",
                    "title": "Practical Experience: Methodologies for Measuring Route Origin Validation",
                    "authors": "Tomas Hlavacek, Amir Herzberg, Haya Shulman, Michael Waidner",
                    "abstract": "Performing Route Origin Validation (ROV) to filter BGP announcements, which contradict Route Origin Authorizations (ROAs) is critical for protection against BGP prefix hijacks. Recent works quantified ROV enforcing Autonomous Systems (ASes) using control-plane experiments. In this work we show that control-plane experiments do not provide accurate information about ROV-enforcing ASes. We devise data-plane approaches for evaluating ROV in the Internet and perform both control and data-plane experiments using different data acquisition sources. We analyze and correlate the results of our study to identify the number of ASes enforcing ROV, and hence protected with RPKI. We perform simulations with the ROV-enforcing ASes that we identified, and find that their impact on the Internet security against prefix hijacks is negligible. As a countermeasure we provide recommendations how to cope with the main factor hindering wide adoption of ROV.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "执行路由起点验证(ROV)来过滤与路由起点授权(ROAs)相矛盾的BGP公告，对于防止BGP前缀劫持至关重要。最近的工作使用控制平面实验量化了ROV执行自主系统(ASes)。在这项工作中，我们表明，控制平面实验并没有提供关于遥控潜水器执行自动化系统的准确信息。我们设计了数据平面方法，用于评估互联网中的ROV，并使用不同的数据采集源进行控制和数据平面实验。我们对研究结果进行分析和关联，以确定执行ROV的as数量，并因此受到RPKI的保护。我们使用我们识别的ROV-enforced as进行模拟，发现它们对互联网安全的影响可以忽略不计。作为对策，我们提供了如何应对阻碍ROV广泛采用的主要因素的建议。",
                    "title_zh": "实践经验:测量路线起点验证的方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00071",
                    "title": "In Production Performance Testing of SDN Control Plane for Telecom Operators",
                    "authors": "Catello Di Martino, Ugo Giordano, Nishok Mohanasamy, Stefano Russo, Marina Thottan",
                    "abstract": "One of the biggest emerging challenges for telco operators is to dynamically create new services while maintaining the network at its optimal performance/revenue break point. To this end, operators are moving to a much leaner cloud-based Software Defined Network (SDN) infrastructure to achieve a truly programmable network fabric. While cloud services can be provisioned in seconds and tested in-production, service provisioning in SDNs still lasts many weeks and requires substantial manual effort. A large part of this service creation time can be attributed to testing and tuning the control plane. In this paper we present SCP-CLUB (SDN Control Plane CLoUd-based Benchmarking), a platform for in-production performance testing of telco operator SDNs, offering a level of automation as available in deploying cloud services. Telco cloud SDN performance testing with SCP-CLUB focuses on the analysis of how design choices in the cloud and SDN control planes influence SLA metrics like throughput and latency. We describe the SCP-CLUB architecture and its performance testing support capabilities. Experiments are performed on an SDN telco cloud built to demonstrate SCP-CLUB under production load conditions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "电信运营商面临的最大挑战之一是动态创建新服务，同时保持网络处于最佳性能/收入平衡点。为此，运营商正在转向更加精简的基于云的软件定义网络(SDN)基础设施，以实现真正可编程的网络结构。虽然云服务可以在几秒钟内完成配置并在生产中进行测试，但sdn中的服务配置仍然需要持续数周，并且需要大量的手动工作。这种服务创建时间的很大一部分可以归因于控制平面的测试和调整。在本文中，我们介绍了SCP-CLUB (SDN控制平面基于云的基准测试)，这是一个用于电信运营商SDN生产性能测试的平台，提供了部署云服务时可用的自动化水平。SCP-CLUB的电信云SDN性能测试侧重于分析云和SDN控制平面中的设计选择如何影响吞吐量和延迟等SLA指标。我们描述了SCP-CLUB架构及其性能测试支持能力。实验在SDN telco云上进行，构建该云是为了在生产负载条件下演示SCP-CLUB。",
                    "title_zh": "面向电信运营商的SDN控制平面生产性能测试"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00072",
                    "title": "A Reexamination of Internationalized Domain Names: The Good, the Bad and the Ugly",
                    "authors": "Baojun Liu, Chaoyi Lu, Zhou Li, Ying Liu, Hai-Xin Duan, Shuang Hao, Zaifeng Zhang",
                    "abstract": "Internationalized Domain Names (IDNs) are domain names containing non-ASCII characters. Despite its installation in DNS for more than 15 years, little has been done to understand how this initiative was developed and its security implications. In this work, we aim to fill this gap by studying the IDN ecosystem and cyber-attacks abusing IDN. In particular, we performed by far the most comprehensive measurement study using IDNs discovered from 56 TLD zone files. Through correlating data from auxiliary sources like WHOIS, passive DNS and URL blacklists, we gained many insights. Our discoveries are multi-faceted. On one hand, 1.4 million IDNs were actively registered under over 700 registrars, and regions within east Asia have seen prominent development in IDN registration. On the other hand, most of the registrations were opportunistic: they are currently not associated with meaningful websites and they have severe configuration issues (e.g., shared SSL certificates). What is more concerning is the rising trend of IDN abuse. So far, more than 6K IDNs were determined as malicious by URL blacklists and we also identified 1,516 and 1,497 IDNs showing high visual and semantic similarity to reputable brand domains (e.g., apple.com). Meanwhile, brand owners have only registered a few of these domains. Our study suggests the development of IDN needs to be re-examined. New solutions and proposals are needed to address issues like its inadequate usage and new attack surfaces.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "国际化域名(IDN)是包含非ASCII字符的域名。尽管它在DNS中的安装已超过15年，但很少有人了解这一倡议是如何开发的及其安全影响。在这项工作中，我们旨在通过研究IDN生态系统和滥用IDN的网络攻击来填补这一空白。特别是，我们使用从56个TLD区域文件中发现的IDN进行了迄今为止最全面的测量研究。通过关联来自WHOIS、被动DNS和URL黑名单等辅助来源的数据，我们获得了许多见解。我们的发现是多方面的。一方面，700多家注册服务商积极注册了140万个IDN，东亚地区的IDN注册取得了显著发展。另一方面，大多数注册是机会性的:它们目前没有与有意义的网站相关联，并且它们有严重的配置问题(例如，共享SSL证书)。更令人担忧的是IDN滥用的上升趋势。到目前为止，超过6K个IDN被URL黑名单确定为恶意IDN，我们还发现了1，516个和1，497个IDN在视觉和语义上与知名品牌域名(如apple.com)高度相似。与此同时，品牌所有者只注册了其中的几个域名。我们的研究表明，IDN的发展需要重新审视。需要新的解决方案和提议来解决诸如其不充分使用和新的攻击面之类的问题。",
                    "title_zh": "重新审视国际化域名:好、坏、丑"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00073",
                    "title": "Manufacturing Resilient Bi-Opaque Predicates Against Symbolic Execution",
                    "authors": "Hui Xu, Yangfan Zhou, Yu Kang, Fengzhi Tu, Michael R. Lyu",
                    "abstract": "Control-flow obfuscation increases program complexity by semantic-preserving transformation. Opaque predicates are essential gadgets to achieve such transformation. However, we observe that real-world opaque predicates are generally very simple and engage little security consideration. Recently, such insecure opaque predicates have been severely attacked by symbolic execution-based adversaries and jeopardize the security of control-flow obfuscation. This paper, therefore, proposes symbolic opaque predicates which can be resilient to symbolic execution-based adversaries. We design a general framework to compose such opaque predicates, which requires introducing challenging symbolic analysis problems (e.g., symbolic memory) in each opaque predicate. In this way, we may mislead symbolic execution engines into reaching false conclusions. We observe a novel bi-opaque property about symbolic opaque predicates, which can incur not only false negative issues but also false positive issues to attackers. To evaluate the efficacy of our idea, we have implemented a prototype obfuscation tool based on Obfuscator-LLVM and conduct experiments with real-world programs. Our evaluation results show that symbolic opaque predicates demonstrate excellent resilience to prevalent symbolic execution engines, such as BAP, Triton, and Angr. Moreover, although the costs of symbolic opaque predicates may vary for different problem settings, some predicates can be very efficient. Therefore, our framework is both secure and usable. Users can follow the framework to introduce symbolic opaque predicates into their obfuscation tools and made them more powerful.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "控制流混淆通过保持语义的转换增加了程序的复杂性。不透明谓词是实现这种转换的基本工具。然而，我们观察到现实世界中的不透明谓词通常非常简单，很少涉及安全性考虑。最近，这种不安全的不透明谓词受到了基于符号执行的对手的严重攻击，并危及控制流混淆的安全性。因此，本文提出了符号不透明谓词，它可以抵抗基于符号执行的对手。我们设计了一个通用框架来组合这样的不透明谓词，这需要在每个不透明谓词中引入具有挑战性的符号分析问题(例如，符号记忆)。这样，我们可能会误导符号执行引擎得出错误的结论。我们观察到一个关于符号不透明谓词的新的双不透明性质，它不仅会导致攻击者的假阴性问题，还会导致攻击者的假阳性问题。为了评估我们的想法的有效性，我们实现了一个基于混淆器的原型混淆工具-LLVM，并用真实世界的程序进行了实验。我们的评估结果表明，符号不透明谓词对流行的符号执行引擎(如BAP、Triton和Angr)表现出优异的弹性。此外，尽管符号不透明谓词的成本可能因不同的问题设置而异，但有些谓词可能非常有效。因此，我们的框架既安全又可用。用户可以遵循该框架将符号不透明谓词引入到他们的混淆工具中，并使它们更加强大。",
                    "title_zh": "针对符号执行制造弹性双不透明谓词"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00074",
                    "title": "PreInfer: Automatic Inference of Preconditions via Symbolic Analysis",
                    "authors": "Angello Astorga, Siwakorn Srisakaokul, Xusheng Xiao, Tao Xie",
                    "abstract": "When tests fail (e.g., throwing uncaught exceptions), automatically inferred preconditions can bring various debugging benefits to developers. If illegal inputs cause tests to fail, developers can directly insert the preconditions in the method under test to improve its robustness. If legal inputs cause tests to fail, developers can use the preconditions to infer failure-inducing conditions. To automatically infer preconditions for better support of debugging, in this paper, we propose PREINFER, a novel approach that aims to infer accurate and concise preconditions based on symbolic analysis. Specifically, PREINFER includes two novel techniques that prune irrelevant predicates in path conditions collected from failing tests, and that generalize predicates involving collection elements (i.e., array elements) to infer desirable quantified preconditions. Our evaluation on two benchmark suites and two real-world open-source projects shows PREINFER's high effectiveness on precondition inference and its superiority over related approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当测试失败时(例如，抛出未捕获的异常)，自动推断的前提条件可以给开发人员带来各种调试好处。如果非法输入导致测试失败，开发人员可以直接在测试方法中插入前提条件，以提高其健壮性。如果合法的输入导致测试失败，开发人员可以使用前提条件来推断导致失败的条件。为了自动推断前提条件以更好地支持调试，在本文中，我们提出了PREINFER，一种新的方法，旨在基于符号分析推断准确和简洁的前提条件。具体来说，PREINFER包括两种新技术，这两种新技术剪除从失败的测试中收集的路径条件中的不相关谓词，并且概括涉及集合元素(即，数组元素)的谓词以推断期望的量化前提条件。我们在两个基准测试套件和两个真实开源项目上的评估表明了PREINFER在前提推理上的高效性和相对于相关方法的优越性。",
                    "title_zh": "PreInfer:通过符号分析自动推断前提条件"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2018.00075",
                    "title": "DexLego: Reassembleable Bytecode Extraction for Aiding Static Analysis",
                    "authors": "Zhenyu Ning, Fengwei Zhang",
                    "abstract": "The scale of Android applications in the market is growing rapidly. To efficiently detect the malicious behavior in these applications, an array of static analysis tools are proposed. However, static analysis tools suffer from code hiding techniques like packing, dynamic loading, self modifying, and reflection. In this paper, we thus present DexLego, a novel system that performs a reassembleable bytecode extraction for aiding static analysis tools to reveal the malicious behavior of Android applications. DexLego leverages just-in-time collection to extract data and bytecode from an application at runtime, and reassembles them to a new Dalvik Executable (DEX) file offline. The experiments on DroidBench and real-world applications show that DexLego precisely reconstructs the behavior of an application in the reassembled DEX file, and significantly improves analysis result of the existing static analysis systems.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1803.02471"
                    },
                    "abstract_zh": "市场上Android应用的规模正在快速增长。为了有效地检测这些应用程序中的恶意行为，提出了一组静态分析工具。然而，静态分析工具受制于代码隐藏技术，如打包、动态加载、自我修改和反射。因此，在本文中，我们提出了DexLego，这是一个新的系统，它执行可重组的字节码提取，以帮助静态分析工具揭示Android应用程序的恶意行为。DexLego利用即时收集在运行时从应用程序中提取数据和字节码，并离线将它们重新组装到一个新的Dalvik可执行(DEX)文件中。在DroidBench和真实应用程序上的实验表明，DexLego在重组后的DEX文件中精确地重构了应用程序的行为，显著改善了现有静态分析系统的分析结果。",
                    "title_zh": "DexLego:帮助静态分析的可重组字节码提取"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/hipeac/mils2018.html",
            "conf_title": "MILS@DSN 2018: Luxembourg",
            "conf_url": "http://mils-workshop-2018.mils.community/",
            "papers": [
                {
                    "url": "https://doi.org/10.5281/zenodo.1306081",
                    "title": "A Platform Approach for Fusing Safety and Security on a Solid Foundation",
                    "authors": "Reinhard Hametner, Stefan Resch",
                    "abstract": "This paper presents the concept example of how to integrate safety and security using a platform approach. The TAS Control Platform is a SIL4 vital computing platform for railway applications developed within Thales to support many different safety-critical applications. Using common standards, MILS concepts and building up on a generic safety concept, enables the integration of safety and security with TAS Control Platform, while still providing support for legacy applications. With this platform approach many applications can benefit from the consistent safe and secure basis.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文展示了如何使用平台方法集成安全性的概念示例。TAS控制平台是泰雷兹为铁路应用开发的SIL4重要计算平台，支持许多不同的安全关键应用。使用通用标准、MILS概念并建立在通用安全概念的基础上，实现了安全和安保与TAS控制平台的集成，同时仍为传统应用程序提供支持。通过这种平台方法，许多应用程序可以从一致的安全基础中受益。",
                    "title_zh": "在坚实的基础上融合安全和保障的平台方法"
                },
                {
                    "url": "https://doi.org/10.5281/zenodo.1307651",
                    "title": "Classic and Adaptive AUTOSAR in MILS terms",
                    "authors": "Holger Blasum, Sergey Tverdyshev",
                    "abstract": ": AUTOSAR (AUTomotive Open System ARchitecture) supports modular software development for automotive software. MILS (Multiple Independent Levels of Safety and Security) also is also inspired from modular systems such as integrated modular avionics. There are differences though: automotive electronic control units are under much more cost pressure than their avionics counterparts, and Classic AUTOSAR was targeting rather simple systems, with an initial focus on runnables that are compiled together, and we will highlight the difference as well as the evolution of AUTOSAR Adaptive that is much closer to the avionic model. On the other hand, AUTOSAR has a very good standardization momentum, resulting in hundreds of available documents, whereas the smaller MILS community has been less effusive. We map the AUTOSAR standards to MILS, to learn about (1) how well MILS systems can be used for AUTOSAR and vice-versa and (2) what other aspects the communities could mutually learn from.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": ":AUTOSAR(汽车开放系统架构)支持汽车软件的模块化软件开发。MILS(多级独立安全保障)也受到模块化系统的启发，如集成模块化航空电子设备。尽管存在差异:汽车电子控制单元比航空电子控制单元承受着更大的成本压力，经典AUTOSAR的目标是相当简单的系统，最初的重点是编译在一起的可运行系统，我们将强调这种差异以及更接近航空电子模型的AUTOSAR Adaptive的发展。另一方面，AUTOSAR有非常好的标准化势头，产生了数百个可用的文档，而较小的MILS社区就不那么热情了。我们将AUTOSAR标准映射到MILS，以了解(1)MILS系统如何适用于AUTOSAR，反之亦然，以及(2)社区可以相互学习的其他方面。",
                    "title_zh": "MILS术语中的经典和自适应AUTOSAR"
                },
                {
                    "url": "https://doi.org/10.5281/zenodo.1305175",
                    "title": "Enabling Civil/Military Cooperation in Crisis Management",
                    "authors": "Chera Bekker, Maurits de Graaf, Gerard Hoekstra, Thomas B. Quillinan",
                    "abstract": "Civil/Military cooperation is vital when addressing civil emergencies. In order to most efficiently enable such cooperations, it is important to ensure easy and secure information exchange. This paper describes an approach to enable such information exchange using a robust MILS kernel, using a content-based security approach to allow each organisation to remain in control of their own data. Furthermore, we demonstrate the approach by combining a military standard Command and Control (C2) system with a civilian system, where specific information can be securely and easily transmitted between the parties.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在处理民间紧急情况时，军民合作至关重要。为了最有效地实现这种合作，确保方便和安全的信息交换是很重要的。本文描述了一种使用健壮的MILS内核来实现这种信息交换的方法，使用基于内容的安全方法来允许每个组织保持对他们自己的数据的控制。此外，我们通过将军用标准指挥和控制(C2)系统与民用系统相结合来展示该方法，在民用系统中，特定信息可以在各方之间安全而方便地传输。",
                    "title_zh": "在危机管理中实现军民合作"
                },
                {
                    "url": "https://doi.org/10.5281/zenodo.1314095",
                    "title": "A Reference Architecture for Integrating Safety and Security Applications on Railway Command and Control Systems",
                    "authors": "Henk Birkholz, Christoph Krauß, Maria Zhdanova, Don Kuzhiyelil, Tolga Arul, Markus Heinrich, Stefan Katzenbeisser, Neeraj Suri, Tsvetoslava Vateva-Gurova, Christian Schlehuber",
                    "abstract": "In critical infrastructures such as railway systems, the continuous and resilient availability of safety critical functions residing on actuator and sensor components must be ensured. Since these components are also more and more connected using the Internet Protocol (IP), they additionally require security functions to provide protection against attackers. Moreover, the railway infrastructure is  highly distributed, with its critical components residing at the track side easily accessible to attackers. Thus, a continuous proofing that the safety-critical systems are not manipulated is required, too. The (safety) certification of such safety-critical systems covers both the hardware components and corresponding software components that compose a specific safety-critical application. Since  security functions are currently not in use, they are not part of the certification. However, the integration of security functions is imperative to provide the basis for preventing or detecting manipulations of the system. In essence, co-residing security functions are required to retain and assure the trusted interoperability of safety critical systems integrated in the rapidly growing number of newly deployed control networks based on the IP. Thus, it is required that a given safety certification (and the given guarantees) must not be violated by the integration of security functions. In this paper, we present the first results of the ongoing HASELNUSS  project1 by introducing the Haselnuss Reference Architecture (HRA) for Railway Command and Control Systems (CCS), that allows uncertified security functions to reside on the same hardware device as certified safety functions; without voiding the certification of these safety functions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在铁路系统等关键基础设施中，必须确保致动器和传感器组件上的安全关键功能的持续和弹性可用性。由于这些组件也越来越多地使用互联网协议(IP)连接，因此它们额外需要安全功能来提供针对攻击者的保护。此外，铁路基础设施高度分散，其关键组件位于轨道侧，攻击者很容易进入。因此，还需要持续证明安全关键系统未被操纵。这种安全关键系统的(安全)认证既包括硬件组件，也包括构成特定安全关键应用的相应软件组件。由于目前没有使用安全功能，所以它们不是认证的一部分。然而，安全功能的集成是必要的，以便为防止或检测对系统的操纵提供基础。本质上，需要共存的安全功能来保持和确保集成在快速增长的基于IP的新部署的控制网络中的安全关键系统的可信互操作性。因此，要求给定的安全认证(和给定的保证)不能被安全功能的集成违反。在本文中，我们介绍了正在进行的Haselnuss项目1的第一批成果，介绍了针对铁路指挥和控制系统(CCS)的HASELNUSS参考架构(HRA ),该架构允许未经认证的安全功能与经过认证的安全功能驻留在同一硬件设备上；而不会使这些安全功能的认证无效。",
                    "title_zh": "铁路指挥控制系统安全保障应用集成参考架构"
                },
                {
                    "url": "https://doi.org/10.5281/zenodo.1306101",
                    "title": "In Search for a Simple Secure Protocol for Safety-Critical High-Assurance Applications",
                    "authors": "Thorsten Schulz, Frank Golatowski, Dirk Timmermann",
                    "abstract": "Security and cryptography protocols are seen by many as black-magic, largely due to their complex mathematical algorithms and entangled state-machines. This complexity has also led to numerous vulnerabilities in past years. Recent developments have simplified conformance requirements, and also introduced formal proofs to mainstream security protocols. In this work-in-progress publication we discuss, how this evolution has greatly improved the situation for critical systems, and how the architecture of MILS systems can raise the confidence for high-assurance systems. Keywords—security, formal modeling, safety critical systems, CPS I. SECURITY IN CRITICAL SYSTEMS Critical systems are required to be reliable, available, maintainable and safe according to accepted and governing standards, e.g., EN 50126 in the railway domain. These attributes are a result of qualified processes and guided methods, requiring specially trained engineers, operators and maintainers to minimize application risks. The processes specifically require that access is limited to that qualified and authorized group to assure the integrity of the processes and the system (product). Physical access barriers, e.g., locked doors, typically have a constant ratio between cost of securing and effort to bypass, largely due to the required physical attendance of the intruder with the specific knowledge to that barrier. The introduction of electronic and networked access to critical systems as Cyber-Physical Systems (CPS), in principle, has not changed this paradigm, but removed the latter physical appearance of an intruder. This has introduced negative scaling effects making even well secured systems with only a small security vulnerability cheap for large scale attacks. The current mitigation trend in IT systems is to automate and improve testing methods, and to shorten time to update, i.e., patch vulnerabilities. In contrast, critical systems have stricter update policies and typically run on non-standardized hardware. As a consequence, testing requires more effort for a much smaller number of operative products. Modifying a critical system’s software requires re-certification – even if it is \"just\" a security update. Current research is developing methodologies to reduce the fore-said re-certification effort through dependable partitioning of a system, applying the Multiple Independent Levels of Security (MILS) architecture (Fig. 1). For example, the system design could split the application into a safe control component and an independent transmission component with security functions, such as remote authorization, authentication and encryption. The safety function within the control application would be independent of corruptions within the transmission component, if it can continue operation in degraded mode without transmission data. The data flow between the components is guarded by the MILS separation kernel, allowing only predefined data flows between the two domains. Depending on attack vectors, system and application design, the security relevant transmission component could then also be of lower confidence level and classified with a low Software Safety Integrity Level (SSIL), being less susceptible to re-certification requirements. A MILS system is composed of components. For the system to perform a critical safety function, it needs evaluation and certification to standards required by governmental authorities. As mentioned before, evaluation for security of a composed system of apriori certified components, requires special methodologies. Furgel et.al. [1] present the methodology for \"Non-Interfering Composed Evaluation\" within Common Criteria. The key requirement for non-interference is that the execution of one component does not undermine another component’s security policy. For the general case, this demands that all internal states of a component are well defined and well known at any time, as well as all implicit and explicit interfaces between components are clearly defined and accurately described. For a component to demonstrate the adequate evidence for evaluation, this either requires formal methods / proofs or exhaustive testing, including robustness testing.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全和加密协议被许多人视为黑魔法，主要是因为它们复杂的数学算法和纠缠的状态机。在过去几年中，这种复杂性也导致了许多漏洞。最近的发展已经简化了一致性要求，也为主流安全协议引入了形式证明。在这份进行中的出版物中，我们讨论了这种发展如何极大地改善了关键系统的状况，以及MILS系统的架构如何提高高保证系统的信心。关键词—安全性、形式化建模、安全关键系统、CPS I .关键系统中的安全性根据公认的管理标准，关键系统需要可靠、可用、可维护和安全，例如铁路领域的EN 50126。这些属性是合格流程和指导方法的结果，需要经过专门培训的工程师、操作员和维护人员将应用风险降至最低。这些流程特别要求访问仅限于合格和授权的小组，以确保流程和系统(产品)的完整性。物理进入屏障(例如，锁着的门)通常在保护成本和绕过努力之间具有恒定的比率，这主要是由于入侵者需要具有该屏障的特定知识的物理参与。原则上，对关键系统(如信息物理系统(CPS ))的电子和网络访问的引入并没有改变这种模式，但消除了入侵者的后一种物理外观。这带来了负面的规模效应，使得即使是只有很小安全漏洞的安全系统也很容易受到大规模攻击。IT系统中当前的缓解趋势是自动化和改进测试方法，并缩短更新时间，即修补漏洞。相比之下，关键系统具有更严格的更新策略，并且通常运行在非标准化的硬件上。因此，对于数量少得多的有效产品，测试需要更多的努力。修改关键系统的软件需要重新认证，即使“仅仅”是安全更新。目前的研究正在开发方法，通过可靠的系统分区，应用多级独立安全(MILS)架构(图1)，减少上述重新认证工作。例如，系统设计可以将应用程序分为安全控制组件和具有安全功能(如远程授权、认证和加密)的独立传输组件。如果在没有传输数据的情况下，控制应用内的安全功能可以在降级模式下继续操作，则它将独立于传输组件内的损坏。组件之间的数据流由MILS分离内核保护，只允许预定义的数据流在两个域之间流动。取决于攻击媒介、系统和应用设计，安全相关传输组件也可能具有较低的置信水平，并被分类为低软件安全完整性等级(SSIL)，对重新认证要求不太敏感。MILS系统由组件组成。对于执行关键安全功能的系统，它需要按照政府当局要求的标准进行评估和认证。如前所述，对先验认证组件组成的系统进行安全性评估需要特殊的方法。Furgel等人[1]提出了通用标准下的“无干扰组合评估”方法。无干扰的关键要求是一个组件的执行不会破坏另一个组件的安全策略。对于一般情况，这要求组件的所有内部状态在任何时候都被很好地定义和熟知，以及组件之间的所有隐式和显式接口都被清楚地定义和准确地描述。对于一个组件来说，要证明评估的充分证据，这要么需要正式的方法/证据，要么需要详尽的测试，包括健壮性测试。",
                    "title_zh": "在寻找用于安全关键的高保证应用的简单安全协议时"
                },
                {
                    "url": "https://doi.org/10.5281/zenodo.1306072",
                    "title": "Cybersecurity in the Railway Sector",
                    "authors": "Markus Engqvist, Staffan Persson",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "",
                    "title_zh": "铁路部门的网络安全"
                },
                {
                    "url": "https://doi.org/10.5281/zenodo.1306089",
                    "title": "A Model-based Approach to Certification of Adaptive MILS",
                    "authors": "Dorien Koelemeijer, Rasma Araby, Ayoub Nouri, Marius Bozga, Rance DeLong",
                    "abstract": "In this work, we tackle the problem of certifying Adaptive systems. These are able to automatically perform self-reconfiguration at runtime, which makes classical certification approaches inapplicable. The need for certification approaches for these systems is thus be-coming urgent, especially due to their prevalent use in safety- and mission critical settings. Due to the inherent complexity of adaptive systems and the absence of a principled methodology for their construction and assurance, there has been little movement by certification authorities to accept such systems. Among the challenges for certification are a way of generating an adequate assurance case for initial state of the adaptive system and for each step in its incremental adaptation, and generation and management of the evidence upon which the assurance case relies. We contribute in this research by proposing a novel modular approach to the certification of adaptive systems in the context of the Adaptive MILS architecture. The proposed approach is backed by an Evidential-Tool Bus implementation that allows a continuous on-demand generation of assurance cases.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在这项工作中，我们解决了自适应系统的认证问题。它们能够在运行时自动执行自我重新配置，这使得经典的认证方法不适用。因此，对这些系统的认证方法的需求变得越来越迫切，特别是由于它们在安全和任务关键环境中的普遍使用。由于自适应系统固有的复杂性和缺乏一种原则性的方法来构建和保证这些系统，认证机构几乎没有采取行动来接受这种系统。认证面临的挑战之一是如何为适应系统的初始状态及其增量适应中的每一步生成充分的保证案例，以及生成和管理保证案例所依赖的证据。我们在这项研究中提出了一种新的模块化方法，在自适应MILS体系结构的背景下对自适应系统进行认证。所提出的方法由证据工具总线实现支持，该实现允许连续按需生成保证案例。",
                    "title_zh": "一种基于模型的自适应MILS认证方法"
                },
                {
                    "url": "https://doi.org/10.5281/zenodo.1306063",
                    "title": "Towards adaptive MILS System: Model- Based Design, Verification and Run-Time Adaptation: Slides",
                    "authors": "Alessandro Cimatti, Rance DeLong, Ivan Stojic, Stefano Tonetta",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "",
                    "title_zh": "走向适应性MILS系统:基于模型的设计、验证和运行时适应性:幻灯片"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2018w.html",
            "conf_title": "48th DSN 2018: Luxembourg - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8415929/proceeding",
            "papers": [
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00011",
                    "title": "Foreword for the Industry Track",
                    "authors": "Sy-Yen Kuo, Hari Ramasamy, Bob Swarz, Alan Wood",
                    "abstract": "The DSN-2018 Industry track provides a forum for interaction between industry and academia, and presentation of the latest R&D and operational challenges, practical solutions, case studies, and field dependability data. Industrial practices often highlight new challenges, obstacles encountered when applying novel technology solutions and advanced current work in an industrial context, and real-world lessons about operation of dependable systems and networks. The objective of this track is to give the members of the industrial and academic communities the opportunity to unite to discuss hot topics regarding the present and future of dependable systems and networks, and to share experiences among different industrial domains and contexts. This year, we have accepted 11 short papers from among 28 submissions. The authors of the submitted papers have a wide geographic distribution covering China, Cyprus, France, Germany, Greece, India, Italy, Morocco, Taiwan, UK, and USA. Each paper was reviewed by at least two members of the Industry Track program committee, following which we had online and email discussions among the PC members. Contentious or borderline papers were thoroughly discussed and sometimes received additional reviews. The accepted papers have been organized for presentation at the conference into 3 sessions: Modeling and Measurement, Detection and Remediation, and Cloud Computing and the Internet of Things.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/8793211/8805752/08805778.pdf"
                    },
                    "abstract_zh": "DSN-2018行业跟踪为行业和学术界之间的互动提供了一个论坛，并展示了最新的R&D和运营挑战、实用解决方案、案例研究和现场可靠性数据。工业实践通常强调新的挑战、在工业环境中应用新的技术解决方案和先进的当前工作时遇到的障碍，以及关于可靠系统和网络操作的真实经验。本专题讲座的目的是为工业界和学术界的成员提供一个机会，让他们能够团结起来，共同讨论有关可靠系统和网络的现在和未来的热门话题，并在不同的工业领域和背景下分享经验。今年，我们从28份提交的文件中接受了11份短文。提交论文的作者分布广泛，包括中国、塞浦路斯、法国、德国、希腊、印度、意大利、摩洛哥、台湾、英国和美国。每篇论文都经过了至少两名行业跟踪计划委员会成员的审核，之后我们在PC成员之间进行了在线和电子邮件讨论。有争议或含糊不清的论文得到了彻底的讨论，有时还会收到额外的评论。被接受的论文已被组织为3场会议:建模和测量，检测和补救，云计算和物联网。",
                    "title_zh": "工业轨道的前言"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00012",
                    "title": "Autonomous Driving System : Model Based Safety Analysis",
                    "authors": "Mohamed Tlig, Mathilde Machin, Romain Kerneis, Emmanuel Arbaretier, Linda Zhao, Florent Meurville, Jean Van Frank",
                    "abstract": "The desire to introduce autonomous vehicles by 2020 on the roads represents a real technological challenge. It requires dismiss with traditional design, security and validation processes to achieve a safe system. As part of the SVA (Simulation of Autonomous Vehicle Safety) project, we present the process under development at the Institute for Technological Research SystemX, in order to optimally address the limitations of existing methods. The objective is to provide designers methods and tools to support safety considerations during the design and the validation phases of autonomous vehicles functions. In this paper, we apply a Model Based Safety Analysis methodology (MBSA) to an Advanced Driver-Assistance System (ADAS), using a modular numerical simulation platform. We describe the different activities carried out during each stage and define the associated objectives. Experimental simulation results are presented, showing the advantages of such approach.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01906465/file/ISX_DSN_2018%20%28MBSA%29.pdf"
                    },
                    "abstract_zh": "到2020年在道路上引入自动驾驶汽车的愿望代表了一个真正的技术挑战。它需要摒弃传统的设计、安全和验证流程来实现一个安全的系统。作为SVA(自动驾驶汽车安全模拟)项目的一部分，我们介绍了技术研究所SystemX正在开发的过程，以优化现有方法的局限性。目标是为设计者提供方法和工具，以支持自主车辆功能设计和验证阶段的安全考虑。在本文中，我们将基于模型的安全分析方法(MBSA)应用于先进的驾驶辅助系统(ADAS)，使用模块化的数值模拟平台。我们描述了每个阶段进行的不同活动，并定义了相关的目标。实验仿真结果表明了该方法的优越性。",
                    "title_zh": "自动驾驶系统:基于模型的安全性分析"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00013",
                    "title": "Measuring and Exploiting Guardbands of Server-Grade ARMv8 CPU Cores and DRAMs",
                    "authors": "Konstantinos Tovletoglou, Lev Mukhanov, Georgios Karakonstantis, Athanasios Chatzidimitriou, George Papadimitriou, Manolis Kaliorakis, Dimitris Gizopoulos, Zacharias Hadjilambrou, Yiannakis Sazeides, Alejandro Lampropulos, Shidhartha Das, Phong Vo",
                    "abstract": "In this paper, we present the results of our comprehensive measurement study of the timing and voltage guardbands in memories and cores of a commodity ARMv8 based micro-server. Using various synthetic micro-benchmarks, we reveal how the adopted voltage margins vary among the 8 cores of the CPU chip, and among 3 different sigma chips and we show how prone they are to worst-case voltage noise. In addition, we characterize the variation of 'weak' DRAM cells in terms of their retention time across 72 DRAM chips and evaluate the error mitigation efficacy of the available error-correcting codes in case of operation under aggressively relaxed refresh periods. Finally, we show the overall energy savings that could be achieved by shaving the adopted guardbands in the cores and memories using various applications. Our characterization results show the potential to obtain up-to 38.8% energy savings in cores and up-to 27.3% within DRAMs.",
                    "files": {
                        "openAccessPdf": "https://pureadmin.qub.ac.uk/ws/files/150355668/UniServer_DSN_2018_FINAL.pdf"
                    },
                    "abstract_zh": "在本文中，我们介绍了对基于ARMv8的商用微服务器的存储器和内核中的时序和电压保护带进行全面测量研究的结果。通过使用各种合成微基准测试，我们揭示了CPU芯片的8个内核以及3个不同的sigma芯片之间所采用的电压裕量是如何变化的，并展示了它们有多容易受到最差电压噪声的影响。此外，我们根据“弱”DRAM单元在72个DRAM芯片上的保持时间来表征“弱”DRAM单元的变化，并评估在过度宽松的刷新周期下操作的情况下可用纠错码的错误减轻功效。最后，我们展示了通过使用各种应用削减内核和存储器中采用的保护频带可以实现的整体节能。我们的表征结果显示，内核有可能实现高达38.8%的节能，DRAMs有可能实现高达27.3%的节能。",
                    "title_zh": "测量和开发服务器级ARMv8 CPU内核和DRAMs的防护带"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00014",
                    "title": "Hardening the Core: Understanding and Detection of XNU Kernel Vulnerabilities",
                    "authors": "Xianyu Liu, Min Zheng, Aimin Pan, Quan Lu",
                    "abstract": "The occurrence of security vulnerabilities in kernel, especially for macOS/iOS kernel XNU, has increased rapidly in recent years. Naturally, concerns were raised due to the high risks they would lead to, which in general are much more serious than common application vulnerabilities. However, discovering XNU kernel vulnerabilities is always very challenging, and the main approach in practice is still manual analysis, which obviously is not a scalable method. In this paper, we perform an in-depth empirical study on the 406 published XNU kernel vulnerabilities to identify distinguishing characteristics of them and then leverage the features to guide our vulnerability detection, i.e., locating suspicious functions. To further improve the efficiency of vulnerability detection, we present KInspector, a new and lightweight framework to detect XNU kernel vulnerabilities by leveraging feedback-based fuzzing techniques. We thoroughly evaluate our approach on XNU with various versions, and the results turn out to be quite promising: 21 N/0-day vulnerabilities have been discovered in our experiments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内核尤其是macOS/iOS内核XNU的安全漏洞的发生近年来迅速增加。很自然，由于它们会导致高风险，这种高风险通常比常见的应用程序漏洞更严重。然而，发现XNU内核漏洞总是非常具有挑战性，实践中的主要方法仍然是手动分析，这显然不是一种可扩展的方法。在本文中，我们对406个已发布的XNU内核漏洞进行了深入的实证研究，以识别它们的显著特征，然后利用这些特征来指导我们的漏洞检测，即定位可疑函数。为了进一步提高漏洞检测的效率，我们提出了一个新的轻量级框架KInspector，通过利用基于反馈的模糊化技术来检测XNU内核漏洞。我们在XNU上用各种版本彻底评估了我们的方法，结果证明是非常有希望的:在我们的实验中已经发现了21 N/0天的漏洞。",
                    "title_zh": "强化内核:XNU内核漏洞的理解和检测"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00015",
                    "title": "Hardware Remediation at Scale",
                    "authors": "Fan Fred Lin, Matt Beadon, Harish Dattatraya Dixit, Gautham Vunnam, Amol Desai, Sriram Sankar",
                    "abstract": "Large scale services have automated hardware remediation to maintain the infrastructure availability at a healthy level. In this paper, we share the current remediation flow at Facebook, and how it is being monitored. We discuss a class of hardware issues that are transient and typically have higher rates during heavy load. We describe how our remediation system was enhanced to be efficient in detecting this class of issues. As hardware and systems change in response to the advancement in technology and scale, we have also utilized machine learning frameworks for hardware remediation to handle the introduction of new hardware failure modes. We present an ML methodology that uses a set of predictive thresholds to monitor remediation efficiency over time. We also deploy a recommendation system based on natural language processing, which is used to recommend repair actions for efficient diagnosis and repair. We also describe current areas of research that will enable us to improve hardware availability further.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大规模服务具有自动化硬件修复功能，可将基础架构可用性保持在健康水平。在本文中，我们分享了脸书当前的修复流程，以及如何对其进行监控。我们讨论了一类硬件问题，它们是暂时的，并且通常在重负载期间发生率较高。我们描述了如何增强我们的补救系统，以有效检测此类问题。随着硬件和系统随着技术和规模的进步而变化，我们还利用机器学习框架进行硬件修复，以处理新硬件故障模式的引入。我们提出了一种ML方法，该方法使用一组预测阈值来监控补救效率随时间的变化。我们还部署了一个基于自然语言处理的推荐系统，用于推荐修复操作，以实现高效的诊断和修复。我们还描述了当前的研究领域，这将使我们能够进一步提高硬件的可用性。",
                    "title_zh": "大规模硬件修复"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00016",
                    "title": "Cross-Stack Threat Sensing for Cyber Security and Resilience",
                    "authors": "Frederico Araujo, Teryl Taylor, Jialong Zhang, Marc Ph. Stoecklin",
                    "abstract": "We propose a novel cross-stack sensor framework for realizing lightweight, context-aware, high-interaction network and endpoint deceptions for attacker disinformation, misdirection, monitoring, and analysis. In contrast to perimeter-based honeypots, the proposed method arms production workloads with deceptive attack-response capabilities via injection of booby-traps at the network, endpoint, operating system, and application layers. This provides defenders with new, potent tools for more effectively harvesting rich cyber-threat data from the myriad of attacks launched by adversaries whose identities and methodologies can be better discerned through direct engagement rather than purely passive observations of probe attempts. Our research provides new tactical deception capabilities for cyber operations, including new visibility into both enterprise and national interest networks, while equipping applications and endpoints with attack awareness and active mitigation capabilities.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了一种新的跨栈传感器框架，用于实现轻量级、上下文感知、高交互的网络和端点欺骗，用于攻击者的虚假信息、误导、监控和分析。与基于边界的蜜罐相比，所提出的方法通过在网络、端点、操作系统和应用层注入饵雷，使生产工作负载具备欺骗性的攻击响应能力。这为防御方提供了新的强大工具，可以更有效地从对手发起的无数攻击中收集丰富的网络威胁数据，通过直接参与而不是纯粹被动地观察探测尝试，可以更好地识别对手的身份和方法。我们的研究为网络运营提供了新的战术欺骗能力，包括对企业和国家利益网络的新可见性，同时为应用和终端配备攻击感知和主动缓解能力。",
                    "title_zh": "面向网络安全和弹性的跨堆栈威胁感知"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00017",
                    "title": "Lifeguard: Local Health Awareness for More Accurate Failure Detection",
                    "authors": "Armon Dadgar, James Phillips, Jon Currey",
                    "abstract": "SWIM is a peer-to-peer group membership protocol, with attractive scaling and robustness properties. However, our experience supporting an implementation of SWIM shows that a high rate of false positive failure detections (healthy members being marked as failed) is possible in certain real world scenarios, and that this is due to SWIM's sensitivity to slow message processing. To address this we propose a set of extensions to SWIM (together called Lifeguard), which employ heuristic measures of a failure detector's local health. In controlled tests, Lifeguard is able to reduce the false positive rate by more than 50x. Real world deployment of the extensions has significantly reduced support requests and observed instability. The need for this work points to the fail-stop failure model being overly simplistic for large datacenters, where the likelihood of some nodes experiencing transient CPU starvation, IO flakiness, random packet loss, or other non-crash problems becomes high. With increasing attention being given to these gray failures, we believe the local health abstraction may be applicable in a broad range of settings, including other kinds of distributed failure detectors.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1707.00788"
                    },
                    "abstract_zh": "SWIM是一个对等组成员协议，具有吸引人的伸缩性和健壮性。然而，我们支持SWIM实现的经验表明，在某些真实的场景中，可能会出现很高的误报失败检测率(健康成员被标记为失败)，这是因为SWIM对缓慢的消息处理非常敏感。为了解决这个问题，我们提出了一组SWIM的扩展(统称为救生员)，它采用了对故障检测器的本地健康状况的启发式测量。在受控测试中，救生员能够将误报率降低50倍以上。扩展的实际部署大大减少了支持请求和观察到的不稳定性。这项工作的需求表明，对于大型数据中心来说，故障停止故障模型过于简单，在这种情况下，一些节点出现瞬时CPU不足、IO剥落、随机数据包丢失或其他非崩溃问题的可能性变得很高。随着对这些灰色故障越来越多的关注，我们相信本地健康抽象可以适用于广泛的设置，包括其他种类的分布式故障检测器。",
                    "title_zh": "救生员:本地健康意识有助于更准确地检测故障"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00018",
                    "title": "Diagnosing Failures of Cloud Management Actions",
                    "authors": "Rohit Ranchal, Praveen Jayachandran",
                    "abstract": "Cloud management actions such as system patches and software updates are a regular activity in large-scale cloud deployments. Collected data shows that these actions have a high tendency of failures. System administrators currently spend hours on manual troubleshooting because limited solutions exist that can automatically diagnose such failures. This paper addresses the automatic analysis of cloud management action failures and determination of the root causes. The proposed failure diagnosis approach is able to identify the system attributes of cloud instances that are different in case of a failure. Furthermore, it doesn't require the knowledge of the source code. The design and implementation of the proposed solution are presented and it is evaluated using realistic management actions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "系统补丁和软件更新等云管理操作是大规模云部署中的常规活动。收集的数据显示，这些行动很容易失败。系统管理员目前花费数小时进行手动故障排除，因为能够自动诊断此类故障的解决方案有限。本文旨在自动分析云管理操作失败并确定根本原因。所提出的故障诊断方法能够识别在故障情况下不同的云实例的系统属性。此外，它不需要了解源代码。本文介绍了建议解决方案的设计和实施，并使用实际的管理措施对其进行了评估。",
                    "title_zh": "诊断云管理操作的故障"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00019",
                    "title": "ConfEx: Towards Automating Software Configuration Analytics in the Cloud",
                    "authors": "Ozan Tuncer, Nilton Bila, Sastry S. Duri, Canturk Isci, Ayse K. Coskun",
                    "abstract": "Modern cloud applications are designed in a highly configurable way to ensure increased reusability and portability. With the growing complexity of these applications, configuration errors (i.e., misconfigurations) have become major sources of service outages and disruptions. While some research has so far focused on detecting errors in configurations that are represented as well-structured key-value pairs, the configurations of cloud applications are typically stored in text files with application-specific syntax and in unlabeled file system locations, limiting the use of existing error detection tools. This paper introduces ConfEx, a framework that enables discovery and extraction of text-based configurations in multi-tenant cloud platforms and cloud image repositories for configuration analysis and validation. ConfEx uses a novel vocabulary-based technique to identify text-based configuration files in cloud system instances with unlabeled content, and leverages existing configuration parsers to extract the information in these files. We show that ConfEx achieves over 98% precision and recall in identifying configuration files on 3893 popular Docker Hub images and we also demonstrate a use case of ConfEx for detecting injected misconfigurations via outlier analysis.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代云应用程序以高度可配置的方式设计，以确保增加的可重用性和可移植性。随着这些应用程序越来越复杂，配置错误(即错误配置)已经成为服务中断和破坏的主要来源。虽然迄今为止一些研究集中于检测被表示为结构良好的键-值对的配置中的错误，但是云应用的配置通常存储在具有应用特定语法的文本文件中以及未标记的文件系统位置中，这限制了现有错误检测工具的使用。本文介绍了ConfEx，这是一个框架，能够在多租户云平台和云映像存储库中发现和提取基于文本的配置，用于配置分析和验证。ConfEx使用一种新颖的基于词汇的技术来识别云系统实例中带有未标记内容的基于文本的配置文件，并利用现有的配置解析器来提取这些文件中的信息。我们表明，在识别3893个流行的Docker Hub映像上的配置文件时，ConfEx实现了超过98%的精确度和召回率，我们还演示了ConfEx的一个用例，用于通过离群点分析检测注入的错误配置。",
                    "title_zh": "ConfEx:在云中实现软件配置分析的自动化"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00020",
                    "title": "A Large-Scale System for Real-Time Glucose Monitoring",
                    "authors": "Long H. Vu, Venkata N. Pavuluri, Yuan-Chi Chang, Deepak S. Turaga, Alex Zhong, Pratik Agrawal, Amit Singh, Boyi Jiang, Krishna Chirutha",
                    "abstract": "We present the design, implementation, and deployment of an industry-first solution for real-time remote diabetes monitoring at large-scale. Our system delivers live insights to patients, via their mobile phones, regarding the current and future influence of their food choices and daily activities on their glucose levels. The platform, built using a distributed stream processing system, ingests real-time continuous glucose readings from sensors, insulin and meal information entered by patients within a mobile phone app, and activity levels from sensors embedded on the phone, and couples these with real-time analysis to determine the impact that the patient behavior will have on their glucose levels. We describe our design that achieves scale and system high availability through data and pipelined parallelism, decoupled system components, caches, and stateless jobs. An initial pilot of the system was deployed for use by a few hundred real diabetic patients and showed improvements in patient health – in terms of reduced periods out of range and experienced lows and highs. [1]. A full-scale release will be deployed for several thousand patients by the end of in 2018.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们展示了行业首创的大规模实时远程糖尿病监测解决方案的设计、实施和部署。我们的系统通过患者的手机向他们提供关于他们的食物选择和日常活动对其血糖水平的当前和未来影响的实时见解。该平台使用分布式流处理系统构建，接收来自传感器的实时连续葡萄糖读数、患者在手机应用程序中输入的胰岛素和膳食信息，以及来自嵌入手机的传感器的活动水平，并将这些与实时分析相结合，以确定患者行为对其葡萄糖水平的影响。我们描述了通过数据和流水线并行、去耦系统组件、高速缓存和无状态作业实现规模和系统高可用性的设计。该系统的初步试点被部署用于数百名真正的糖尿病患者，并显示出患者健康状况的改善——在减少超出范围的周期和经历低点和高点方面。[1].到2018年底，将为数千名患者部署全面版本。",
                    "title_zh": "一种大规模实时血糖监测系统"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00021",
                    "title": "Challenges of DB2 Restore in a Distributed Systems Environment and Engineered Solutions",
                    "authors": "Pratik Mukherjee, Valentina Salapura",
                    "abstract": "Cloud computing and cloud storage enables modern day enterprises to store and access massive amounts of data quickly and efficiently every day. One of the major challenges of cloud storage and cloud computing is ensuring the reliability and availability of data due to network instability and virtual environment crashes. There are many approaches to data persistence, including periodic replication and data backup. However, the process of backing up a database and restoring it in a distributed multi-application environment often renders a data store unavailable, which may compromise the data and application availability. This paper explores some of the unique challenges encountered while restoring DB2 databases in a multi-application, virtual cloud environment for the Watson Health Cloud platform due to fast connecting applications, and discusses the engineered solutions to alleviate the failures.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云计算和云存储使现代企业能够每天快速高效地存储和访问大量数据。由于网络不稳定和虚拟环境崩溃，云存储和云计算的主要挑战之一是确保数据的可靠性和可用性。数据持久化有许多方法，包括定期复制和数据备份。但是，在分布式多应用程序环境中备份和恢复数据库的过程通常会导致数据存储不可用，这可能会影响数据和应用程序的可用性。本文探讨了在Watson Health云平台的多应用程序虚拟云环境中恢复DB2数据库时，由于快速连接应用程序而遇到的一些独特挑战，并讨论了减轻故障的工程解决方案。",
                    "title_zh": "分布式系统环境中DB2恢复的挑战和工程解决方案"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00022",
                    "title": "Dependability in a Multi-tenant Multi-framework Deep Learning as-a-Service Platform",
                    "authors": "Scott Boag, Parijat Dube, Kaoutar El Maghraoui, Benjamin Herta, Waldemar Hummer, K. R. Jayaram, Rania Khalaf, Vinod Muthusamy, Michael H. Kalantar, Archit Verma",
                    "abstract": "Deep learning (DL), a form of machine learning, is becoming increasingly popular in several application domains. As a result, cloud-based Deep Learning as a Service (DLaaS) platforms have become an essential infrastructure in many organizations. These systems accept, schedule, manage and execute DL training jobs at scale. This paper explores dependability in the context of a DLaaS platform used in IBM. We begin by explaining how DL training workloads are different, and what features ensure dependability in this context. We then describe the architecture, design and implementation of a cloud-based orchestration system for DL training. We show how this system has been architected with dependability in mind while also being horizontally scalable, elastic, flexible and efficient. We also present an initial empirical evaluation of the overheads introduced by our platform, and discuss tradeoffs between efficiency and dependability.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1805.06801"
                    },
                    "abstract_zh": "深度学习(DL)是机器学习的一种形式，在几个应用领域变得越来越流行。因此，基于云的深度学习即服务(DLaaS)平台已经成为许多组织的重要基础设施。这些系统大规模地接受、安排、管理和执行DL培训工作。本文以IBM使用的DLaaS平台为背景来探讨可靠性。我们首先解释DL培训的工作量是如何不同的，以及在这种情况下哪些特点可以确保可靠性。然后，我们描述了面向DL培训的基于云的编排系统的架构、设计和实现。我们展示了该系统是如何在考虑可靠性的基础上设计的，同时还具有水平可伸缩性、弹性、灵活性和高效性。我们还对我们的平台引入的开销进行了初步的经验评估，并讨论了效率和可靠性之间的权衡。",
                    "title_zh": "多租户多框架深度学习即服务平台中的可靠性"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00023",
                    "title": "EUBra-BIGSEA, A Cloud-Centric Big Data Scientific Research Platform",
                    "authors": "Ignacio Blanquer, Wagner Meira Jr.",
                    "abstract": "This paper describes the achievements of project EUBra-BIGSEA, which has delivered programming models and data analytics tools for the development of distributed Big Data applications. As framework components, multiple data models are supported (e.g. data streams, multidimensional data, etc.) and efficient mechanisms to ensure privacy and security, on top of a QoS-aware layer for the smart and rapid provisioning of resources in a cloud-based environment.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文描述了EUBra-BIGSEA项目的成就，该项目为分布式大数据应用的开发提供了编程模型和数据分析工具。作为框架组件，支持多种数据模型(例如数据流、多维数据等。)和高效的机制来确保隐私和安全性，在QoS感知层之上，在基于云的环境中智能、快速地配置资源。",
                    "title_zh": "EUBra-BIGSEA，一个以云为中心的大数据科学研究平台"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00024",
                    "title": "SWAMP: Smart Water Management Platform Overview and Security Challenges",
                    "authors": "Carlos Kamienski, João H. Kleinschmidt, Juha-Pekka Soininen, Kari Kolehmainen, Luca Roffia, Marcos Visoli, Rodrigo Filev Maia, Stenio Fernandes",
                    "abstract": "The intensive use of technology in precision irrigation for agriculture is getting momentum in order to optimize the use of water, reduce the energy consumption and improve the quality of crops. Internet of Things (IoT) and other technologies are the natural choices for smart water management applications, and the SWAMP project is expected to prove the appropriateness of IoT in real settings with the deployment of on-site pilots. At the same time, the more intense the use of technology is, agriculture turns new security risks, which may affect both crop development and the commodities market. A security breach may irreversibly compromise a crop and data eavesdropping may compromise price and contracts exposing sensitive data such crop quality, development or management. This paper discusses security challenges and technologies for the application of IoT in agriculture and indicates that one of the most relevant challenges to be handled in SWAMP project is dealing with the multitude of behaviors from IoT application and what would be considered as normal and what would be considered as a threat.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了优化水的利用、降低能源消耗和提高作物质量，农业精确灌溉技术的密集使用正在形成势头。物联网(IoT)和其他技术是智能水管理应用的自然选择，预计沼泽项目将通过部署现场试点来证明物联网在真实环境中的适用性。与此同时，技术的使用越密集，农业就会带来新的安全风险，这可能会影响作物生长和商品市场。安全漏洞可能会不可逆转地损害作物，数据窃听可能会损害价格和合同，暴露敏感数据，如作物质量、发展或管理。本文讨论了物联网在农业应用中的安全挑战和技术，并指出在SWAMP项目中需要处理的最相关的挑战之一是处理物联网应用中的大量行为，以及哪些行为被认为是正常的，哪些行为被认为是威胁。",
                    "title_zh": "沼泽:智能水管理平台概述和安全挑战"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00025",
                    "title": "ATMOSPHERE: Adaptive, Trustworthy, Manageable, Orchestrated, Secure, Privacy-Assuring, Hybrid Ecosystem for REsilient Cloud Computing",
                    "authors": "Francisco V. Brasileiro, Andrey Brito, Ignacio Blanquer",
                    "abstract": "This paper describes the goals of the ATMOSPHERE project, which is a multi-institutional research and development (R&D) effort aiming at designing and implementing a framework and platform to develop, build, deploy, measure and evolve trustworthy, cloud-enabled applications. The proposed system should address the federation of geographically distributed cloud computing providers that rely on lightweight virtualization, and provide access to heterogeneous sets of resources. We discuss some preliminary results, including the architecture that has been proposed to address these challenges.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文描述了ATMOSPHERE项目的目标，这是一个多机构研究和开发(R&D)项目，旨在设计和实现一个框架和平台来开发、构建、部署、测量和发展可信的云应用。提议的系统应该解决依赖轻量级虚拟化的地理上分布的云计算提供商的联合问题，并提供对异构资源集的访问。我们讨论了一些初步的结果，包括已经提出的解决这些挑战的架构。",
                    "title_zh": "氛围:适应、可信、可管理、协调、安全、隐私保证的混合生态系统，用于弹性云计算"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00026",
                    "title": "SecureCloud: Secure Big Data Processing in Untrusted Clouds",
                    "authors": "Andrey Brito, Christof Fetzer",
                    "abstract": "We present the SecureCloud EU Horizon 2020 project, whose goal is to enable new big data applications that use sensitive data in the cloud without compromising data security and privacy. For this, SecureCloud designs and develops a layered architecture that allows for (i) the secure creation and deployment of secure micro-services; (ii) the secure integration of individual micro-services to full-fledged big data applications; and (iii) the secure execution of these applications within untrusted cloud environments. To provide security guarantees, SecureCloud leverages novel security mechanisms present in recent commodity CPUs, in particular, Intel's Software Guard Extensions (SGX). SecureCloud applies this architecture to big data applications in the context of smart grids. We describe the SecureCloud approach, initial results, and considered use cases.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1805.01783"
                    },
                    "abstract_zh": "我们展示了SecureCloud EU Horizon 2020项目，其目标是支持在云中使用敏感数据的新大数据应用程序，而不会损害数据安全性和隐私。为此，SecureCloud设计并开发了一种分层架构，它允许(I)安全地创建和部署安全的微服务；㈡个别微观服务与成熟的大数据应用的安全整合；以及(iii)这些应用在不可信的云环境中的安全执行。为了提供安全保证，SecureCloud利用了最新商用CPU中的新型安全机制，特别是英特尔的软件保护扩展(SGX)。SecureCloud将这种架构应用于智能电网环境下的大数据应用。我们描述了SecureCloud方法、初步结果和考虑的使用案例。",
                    "title_zh": "SecureCloud:不可信云中的安全大数据处理"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00027",
                    "title": "AVFI: Fault Injection for Autonomous Vehicles",
                    "authors": "Saurabh Jha, Subho S. Banerjee, James Cyriac, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer",
                    "abstract": "Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S. roads, offering the promise of improvements in traffic management, safety, and the comfort and efficiency of vehicular travel. With this increasing popularity and ubiquitous deployment, resilience has become a critical requirement for public acceptance and adoption. Recent studies into the resilience of AVs have shown that though the AV systems are improving over time, they have not reached human levels of automation. Prior work in this area has studied the safety and resilience of individual components of the AV system (e.g., testing of neural networks powering the perception function). However, methods for holistic end-to-end resilience assessment of AV systems are still non-existent.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1907.01038"
                    },
                    "abstract_zh": "自动驾驶汽车(AV)技术正在美国道路上迅速成为现实，为改善交通管理、安全以及车辆行驶的舒适性和效率带来了希望。随着这种日益流行和无处不在的部署，弹性已经成为公众接受和采用的关键要求。最近对反病毒软件恢复能力的研究表明，尽管反病毒系统在不断改进，但它们还没有达到人类的自动化水平。该领域的前期工作已经研究了AV系统单个组件的安全性和弹性(例如，测试驱动感知功能的神经网络)。然而，全面的端到端抗毁性评估方法仍然不存在。",
                    "title_zh": "AVFI:自动驾驶汽车的故障注入"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00028",
                    "title": "Reconfiguration Strategies for Critical Adaptive Distributed Embedded Systems",
                    "authors": "Alberto Ballesteros, Julián Proenza, Manuel Barranco, Luís Almeida",
                    "abstract": "This paper describes the architecture and mechanisms proposed in the context of the DFT4FTT project for implementing Adaptive Distributed Embedded Systems (ADESs), that is, distributed systems with real-time, dependability and adaptivity requirements. The focus is on the reconfiguration strategies that allow, not only to change the system behaviour, but to improve its tolerance to permanent hardware faults.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文描述了在DFT4FTT项目背景下提出的用于实现自适应分布式嵌入式系统(ADESs)的体系结构和机制，即具有实时性、可靠性和自适应性要求的分布式系统。重点是重新配置策略，不仅允许改变系统行为，而且允许提高其对永久性硬件故障的容忍度。",
                    "title_zh": "关键自适应分布式嵌入式系统的重构策略"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00029",
                    "title": "Towards Lightweight Temporal and Fault Isolation in Mixed-Criticality Systems with Real-Time Containers",
                    "authors": "Marcello Cinque, Domenico Cotroneo",
                    "abstract": "This paper introduces real-time containers as a lightweight solution, if compared to virtual machines, to achieve temporal and fault isolation in mixed-criticality systems. The paper presents a reference architecture and an initial prototype implementation of the concept, using Docker containers on top of a patched real-time Linux kernel.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "与虚拟机相比，本文介绍了实时容器作为一种轻量级解决方案，用于在混合临界系统中实现时间和故障隔离。本文给出了一个参考架构和这个概念的初始原型实现，在一个打补丁的实时Linux内核上使用Docker容器。",
                    "title_zh": "具有实时容器的混合临界系统中的轻量级时间和故障隔离"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00030",
                    "title": "Finding Top-k Most Frequent Items in Distributed Streams in the Time-Sliding Window Model",
                    "authors": "Emmanuelle Anceaume, Yann Busnel, Vasile Cazacu",
                    "abstract": "We propose a new probabilistic algorithm to find the top-k most recent and frequent items in distributed streams. This algorithm significantly improves upon the reliability and accuracy of existing results, while significantly reducing the memory footprint needed by each of the distributed nodes to solve this problem.",
                    "files": {
                        "openAccessPdf": "https://hal-imt-atlantique.archives-ouvertes.fr/hal-01839930/file/finding-top-k.pdf"
                    },
                    "abstract_zh": "我们提出了一种新的概率算法来发现分布式流中前k个最近和最频繁的项目。该算法显著提高了现有结果的可靠性和准确性，同时显著减少了每个分布式节点解决该问题所需的内存占用。",
                    "title_zh": "在时间滑动窗口模型中查找分布式流中的前k个最频繁项目"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00031",
                    "title": "Mixing Time and Spatial Redundancy Over Time Sensitive Networking",
                    "authors": "Ines Alvarez, Julián Proenza, Manuel Barranco",
                    "abstract": "In this work we propose to mix time and spatial redundancy over a Time Sensitive Networking (TSN)-based network to increase its reliability while reducing resource consumption.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在这项工作中，我们提出在基于时间敏感网络(TSN)的网络上混合时间和空间冗余，以增加其可靠性，同时减少资源消耗。",
                    "title_zh": "通过时间敏感网络混合时间和空间冗余"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00032",
                    "title": "Stateless Security Risk Assessment for Dynamic Networks",
                    "authors": "Jin Bum Hong, Simon Yusuf Enoch, Dong Seong Kim, Khaled Md. Khan",
                    "abstract": "Emerging networking technologies, such as cloud and Software Defined Networking, provide flexibility, elasticity and functionalities to change the network configurations over time. However, changes also impose unpredictable security postures at different times, creating difficulties to the security assessment of the network. To address this issue, we propose a stateless security risk assessment, which combines the security posture of network states at different times to provide an overall security overview. This paper describes the methodologies of the stateless security risk assessment. Our approach is applicable to any emerging networking technologies with dynamic changes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "新兴的网络技术，如云和软件定义的网络，提供了灵活性、弹性和功能性，可以随着时间的推移改变网络配置。然而，变化也在不同的时间施加了不可预测的安全状态，给网络的安全评估带来了困难。为了解决这个问题，我们提出了一种无状态安全风险评估，它结合了网络状态在不同时间的安全状态，以提供一个整体的安全概览。本文描述了无状态安全风险评估的方法。我们的方法适用于任何动态变化的新兴网络技术。",
                    "title_zh": "动态网络的无状态安全风险评估"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00033",
                    "title": "Using Diverse Detectors for Detecting Malicious Web Scraping Activity",
                    "authors": "Pedro Marques, Zayani Dabbabi, Miruna-Mihaela Mironescu, Olivier Thonnard, Frances V. Buontempo, Ilir Gashi, Alysson Bessani",
                    "abstract": "We present ongoing work about how the use of diverse tools may help with detecting malicious web scraping behavior. We use a real dataset of Apache HTTP Access logs for an e-commerce application provided by Amadeus, a large multinational IT provider for the global travel and tourism industry. Two tools have been used to detect scraping activities based on the HTTP requests: a commercial tool from Distil Networks, and an in-house tool called Arcane. Preliminary results suggest there is considerable diversity in alerting behavior of these tools.",
                    "files": {
                        "openAccessPdf": "https://openaccess.city.ac.uk/id/eprint/19790/1/Using%20Diverse%20Detectors%20for%20Detecting%20Malicious%20Web%20Scraping%20Activity.pdf"
                    },
                    "abstract_zh": "我们提出了正在进行的工作，关于如何使用不同的工具可能有助于检测恶意网页抓取行为。我们为Amadeus提供的一个电子商务应用程序使用了一个真实的Apache HTTP访问日志数据集，Amadeus是一家为全球旅行和旅游业提供服务的大型跨国IT提供商。有两个工具被用来检测基于HTTP请求的抓取活动:一个是来自Distil Networks的商业工具，另一个是名为Arcane的内部工具。初步结果表明，这些工具的警报行为存在相当大的差异。",
                    "title_zh": "使用不同的检测器来检测恶意网页抓取活动"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00034",
                    "title": "On Verifying and Assuring the Cloud SLA by Evaluating the Performance of SaaS Web Services Across Multi-cloud Providers",
                    "authors": "Abdallah Ali Zainelabden Abdallah Ibrahim, Sébastien Varrette, Pascal Bouvry",
                    "abstract": "Software-as-a-service (SaaS) cloud web services are delivered by cloud providers to cloud customers on a pay-peruse model. Service level agreements (SLAs) are used to define the quality of the provided services. Unfortunately, there is no standard mechanism or an automatic way which exist to verify and assure that delivered services satisfy the signed SLA agreement and impede the possibility to measure accurately the Quality of Service (QoS). In this abstract, we offer a framework of steps to verify and assure the SLA compliance of Web Services offered across several Cloud providers. Our framework targets also the evaluation of the QoS of the SaaS Web Services (WSs). In this context, our framework aims at quantifying in a fair and by stealth way the performance and scalability of the delivered WS. The framework defines a set of Common performance metrics handled by a set of agents for measuring the behaviour of cloud applications on top of a given CSP. The premier results from this framework are summarized by the performance metrics monitoring, modelling and sensitivity analysis of the models' parameters. This framework opens novel perspectives for assessing the SLA compliance of Cloud providers and QoS evaluation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件即服务(SaaS)云web服务由云提供商以付费模式交付给云客户。服务水平协议(SLA)用于定义所提供服务的质量。不幸的是，不存在标准的机制或自动的方式来验证和确保所交付的服务满足所签署的SLA协议，并且妨碍了准确测量服务质量(QoS)的可能性。在本摘要中，我们提供了一个步骤框架，用于验证和确保跨多个云提供商提供的Web服务的SLA合规性。我们的框架还针对SaaS Web服务(WSs)的QoS评估。在这种情况下，我们的框架旨在以公平和隐秘的方式量化交付的WS的性能和可伸缩性。该框架定义了由一组代理处理的一组通用性能指标，用于测量给定CSP之上的云应用的行为。该框架的主要结果通过性能指标监控、建模和模型参数的敏感性分析进行总结。该框架为评估云提供商的SLA合规性和QoS评估开辟了新的视角。",
                    "title_zh": "通过评估跨多个云提供商的SaaS Web服务的性能来验证和保证云SLA"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00035",
                    "title": "Sources of Variation in Error Sensitivity Measurements, Significant or Not?",
                    "authors": "Fatemeh Ayatolahi, Johan Karlsson",
                    "abstract": "Measuring the error sensitivity by fault injection is an important method for assessing the dependability of computer systems. In this paper, we define error sensitivity as the conditional probability that a hardware-related error causes a silent data corruption. When measuring the error sensitivity it is important to consider how the experimental setup and the workload characteristics affect the estimated error sensitivity. We consider five such potential sources of variation (PSVs) in this paper. Three of these are related to the workload: i) input profile, ii) source code implementation, and, iii) use of compiler optimization. Two are related to the experimental setup: i) single vs. double bit-flips, and ii) inject-on-read vs. inject-on-write. The paper discusses the applicability of different statistical tests for assessing whether a PSV has a significant impact on error sensitivity.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过故障注入测量错误敏感度是评估计算机系统可靠性的重要方法。在本文中，我们将错误敏感度定义为硬件相关错误导致静默数据损坏的条件概率。当测量误差灵敏度时，重要的是考虑实验设置和工作负载特征如何影响估计的误差灵敏度。在本文中，我们考虑了五种潜在的变异源。其中三个与工作负载相关:I)输入配置文件，ii)源代码实现，以及iii)编译器优化的使用。两个与实验设置有关:I)单次与两次位翻转，以及ii)读取时注入与写入时注入。本文讨论了评估PSV是否对错误敏感性有显著影响的不同统计测试的适用性。",
                    "title_zh": "误差灵敏度测量中的变化来源，重要还是不重要？"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00036",
                    "title": "Towards Dynamic End-to-End Privacy Preserving Data Classification",
                    "authors": "Rania Talbi, Sara Bouchenak, Lydia Y. Chen",
                    "abstract": "In this paper we present DAPPLE, a standalone End-to-End privacy preserving data classification service. It allows incremental decision tree learning over encrypted training data continuously sent by multiple data owners, without having access to the actual content of this data. In the same time, the learnt classification model is used to respond to encrypted classification queries while preserving the privacy of the query, the output corresponding to it and the model itself.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们介绍了DAPPLE，一个独立的端到端隐私保护数据分类服务。它允许对多个数据所有者连续发送的加密训练数据进行增量决策树学习，而无需访问这些数据的实际内容。同时，学习的分类模型用于响应加密的分类查询，同时保持查询、对应于查询的输出和模型本身的私密性。",
                    "title_zh": "面向动态端到端隐私保护的数据分类"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00037",
                    "title": "HIT: Hybrid-Mode Information Flow Tracking with Taint Semantics Extraction and Replay",
                    "authors": "Yu-Hsin Hung, Hong-Wei Li, Yu-Sung Wu, Bing-Jhong Jheng, Yennun Huang",
                    "abstract": "Due to increasing complexity in security attacks, it is no longer sufficient to rely on generic network-level and system-level events for attack detection. We propose the hybrid-mode information flow tracking (HIT) system to reveal application-level events by integrating static information analysis (IFA) and dynamic information flow tracking (DIFT) into the applications. Preliminary results indicate the effectiveness of the approach in detecting sensitive data leakage with a modest performance overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于安全攻击越来越复杂，依靠一般的网络级和系统级事件进行攻击检测已经不够了。我们提出了混合模式信息流跟踪(HIT)系统，通过将静态信息分析(IFA)和动态信息流跟踪(DIFT)集成到应用程序中来揭示应用程序级事件。初步结果表明了该方法在检测敏感数据泄漏方面的有效性，并且具有适度的性能开销。",
                    "title_zh": "HIT:带有污点语义提取和重放的混合模式信息流跟踪"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00039",
                    "title": "An Analysis of Automated Software Diversity Using Unstructured Text Analytics",
                    "authors": "Andrew S. Gearhart, Peter A. Hamilton, Joel Coffman",
                    "abstract": "Automated software diversity promises to reduce an attacker's ability to reuse exploits across application instances. However, many questions remain regarding the efficacy of and application of software diversity. In particular, researchers have observed a lack of robust metrics to compare diversity strategies. Our work represents a step toward such metrics by using common methods from unstructured text analysis to differentiate strategies. Our investigation is agnostic to particular diversity strategies, and we analyze several methods of generating feature vectors from diversified binaries and comparing the resulting clusters in a high-dimensional space.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动化软件多样性有望降低攻击者跨应用程序实例重用漏洞的能力。然而，关于软件多样性的功效和应用仍然存在许多问题。特别是，研究人员观察到缺乏可靠的指标来比较多样性战略。我们的工作通过使用非结构化文本分析的通用方法来区分策略，向这样的度量标准迈进了一步。我们的研究与特定的多样性策略无关，我们分析了几种从多样化的二进制文件中生成特征向量并在高维空间中比较结果聚类的方法。",
                    "title_zh": "使用非结构化文本分析的自动化软件多样性分析"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00040",
                    "title": "Random Mining Group Selection to Prevent 51% Attacks on Bitcoin",
                    "authors": "Jaewon Bae, Hyuk Lim",
                    "abstract": "Bitcoin is a cryptocurrency based on blockchain technology that enables peer-to-peer transactions without a central authority. Bitcoin is known for resolving double-spending problems. When two or more miners generate a block that includes transaction information at nearly the same time, an accidental fork occurs. In this case, the longest chain of blocks is selected to avoid the double-spending problem. However, if there is an attacker node whose hash power is greater than half of the total hash power, that node can perform a double-spending attack, i.e., a 51% or majority attack. We propose a random mining group selection technique to reduce the probability of successful double-spending attacks. The analysis results demonstrate that if the number of groups is greater than or equal to two, the probability that the attacker will find the next block is less than 50%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "比特币是一种基于区块链技术的加密货币，可以在没有中央机构的情况下实现点对点交易。比特币以解决重复消费问题而闻名。当两个或更多挖掘器几乎同时生成包含事务信息的块时，会发生意外分叉。在这种情况下，选择最长的块链以避免双重花费问题。然而，如果有一个攻击者节点的散列功率大于总散列功率的一半，则该节点可以执行双重开销攻击，即51%或多数攻击。我们提出了一种随机挖掘组选择技术来降低成功的双花费攻击的概率。分析结果表明，如果组的数量大于或等于2，攻击者找到下一个块的概率小于50%。",
                    "title_zh": "随机挖掘组选择以防止51%对比特币的攻击"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00041",
                    "title": "PRESEnCE: A Framework for Monitoring, Modelling and Evaluating the Performance of Cloud SaaS Web Services",
                    "authors": "Abdallah Ali Zainelabden Abdallah Ibrahim",
                    "abstract": "Cloud Services Providers (CSPs) provide cloud services to the cloud customers in the pay-per-use model and use the Service Level Agreements (SLAs) to define the quality of the provided services. SLAs are just a contract which characterizing the performance and quality of the CSPs' services. Unfortunately, there is not an automatic and standard mechanism to verify and assure that delivered services satisfy the signed SLA agreement. In this context, this work aim at developing an automatic framework called PRESENCE, to evaluate the Quality of Service (QoS) for the deployment of the Software-as-a-Service (SaaS) Web Services (WSs) offered across several CSPs. This performance evaluation will be used to verify and check on the SLA contraventions. PRESENCE aims at quantifying in a fair and by stealth way the performance and scalability of the delivered WS. By stealthiness, we refer to the capacity of evaluating a given Cloud service through multiple workload patterns that makes them indistinguishable from a regular user traffic from the provider point of view. PRESENCE introduces a definition for the set of Common performance metrics for measuring the behaviour of cloud applications on top of a given CSP. This framework opens a novel perspectives for SLA contraventions assessment, monitoring, modelling the performance metrics for SaaS WSs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云服务提供商(CSP)以按使用付费的模式向云客户提供云服务，并使用服务水平协议(SLA)来定义所提供服务的质量。SLA只是一份合同，它描述了电信运营商服务的性能和质量。不幸的是，没有一个自动和标准的机制来验证和确保交付的服务满足签署的SLA协议。在这种背景下，该工作旨在开发一个名为PRESENCE的自动化框架，以评估跨多个CSP提供的软件即服务(SaaS) Web服务(WSs)的部署的服务质量(QoS)。该性能评估将用于验证和检查SLA违规情况。存在的目的是以公平和秘密的方式量化交付的WS的性能和可伸缩性。所谓隐蔽性，我们指的是通过多种工作负载模式来评估给定云服务的能力，从提供商的角度来看，这种能力使其无法与常规用户流量区分开来。PRESENCE引入了一组通用性能指标的定义，用于测量给定CSP之上的云应用程序的行为。该框架为SLA违规评估、监控、SaaS WSs性能指标建模提供了一个全新的视角。",
                    "title_zh": "存在:云SaaS网络服务性能的监控、建模和评估框架"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00042",
                    "title": "Mu-Transaction Sagas in Derecho",
                    "authors": "Sagar Jha",
                    "abstract": "Cloud computing infrastructures weaken consistency to improve responsiveness [1], but there are applications for which weak consistency is inadequate. This has stimulated interest in consistency models that scale and perform well. Our work extends the Derecho system [4] to support a constrained but powerful form of ACID transaction sagas. Unusually, the transactional infrastructure requires no locking or 2-phase commits, and yet guarantees serializability. All inter-node actions map to RDMA, allowing the saga infrastructure to achieve exceptional performance at very low overheads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云计算基础设施削弱了一致性以提高响应能力[1]，但是对于一些应用程序来说，弱一致性是不够的。这激发了人们对可扩展且性能良好的一致性模型的兴趣。我们的工作扩展了Derecho系统[4]以支持一种受约束但功能强大的ACID事务传奇。不同寻常的是，事务基础设施不需要锁定或两阶段提交，但却保证了可序列化性。所有节点间操作都映射到RDMA，使saga基础架构能够以极低的开销实现卓越的性能。",
                    "title_zh": "德雷乔的mu-交易传奇"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00043",
                    "title": "Enhanced Dependability Evaluation Through Krylov Methods and Matrix Functions: The Case of Load-Sharing Systems",
                    "authors": "Giulio Masetti",
                    "abstract": "Recently, the link between performance and dependability measures for Markovian models and the evaluation of bilinear forms induced by well-known matrix functions has been established. The connection can be exploited to obtain effective and efficient solution methods for allowing in particular the computation of reliability-related measures. In this paper, a reliability model for a load-sharing system is discussed and then solved through Krylov methods generated by the mentioned connection.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近，马尔可夫模型的性能和可靠性度量与由众所周知的矩阵函数导出的双线性形式的评估之间的联系已经建立。可以利用这种联系来获得有效和高效的求解方法，以便特别允许计算可靠性相关的度量。本文讨论了一个负荷分担系统的可靠性模型，并通过由上述连接产生的Krylov方法求解。",
                    "title_zh": "通过Krylov方法和矩阵函数增强可靠性评估:负载共享系统的情况"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00044",
                    "title": "Design, Development and Implementation of a Network Intrusion Detection Tool for Air Traffic Management Systems",
                    "authors": "Theobald de Riberolles",
                    "abstract": "An Air Traffic Management (ATM) relies on a set of critical systems composed of control centers, sensors, communication means and radio navigation systems. These critical systems may be subject to different attacks and thus compromise their security. Indeed as there is a desire to open this system more and more outward and there is a gap between this world and the interconnected world, threats are increasing. The ATM system have particular characteristics as the fact that it is a very distributed system with a lot of real-time applications using proprietary and/or legacy protocols. Thus, the need to have an efficient Intrusion Detection System (IDS) is primordial in terms of reliability (a false negative rate as low as possible) and relevance (a lowest possible false-positive rate). The development of an IDS combining misuse detection (i.e., defining attack scenarios and finding traces of these scenarios in the traffic.) and anomaly detection (i.e., the construction of a reference model of the behavior of the supervised entity to which we will be able to compare the observed behavior) based on wavelet theory is a promising approach as they are already shown for this type of systems. The detection capability for such complex system could be enhanced using the specific characteristics of its exchanges, use them to enrich its normal signature and reduce the probability of false positive and false negatives. This paper describes the context and the state of the art of the current research direction of the authors with the aim to present the challenges and the future works that the student aims to perform in the next years.",
                    "files": {
                        "openAccessPdf": "https://hal-enac.archives-ouvertes.fr/hal-01826053/file/Student%20Forum%20DSN%202018Theobald%20de%20Riberolles%20v2%203%20auteurs.pdf"
                    },
                    "abstract_zh": "空中交通管理(ATM)依赖于一套由控制中心、传感器、通信手段和无线电导航系统组成的关键系统。这些关键系统可能会受到不同的攻击，从而危及其安全性。事实上，随着这个系统越来越向外开放的愿望越来越强烈，这个世界和相互联系的世界之间存在着鸿沟，威胁正在增加。ATM系统具有特殊的特征，因为它是一个非常分布式的系统，具有许多使用专有和/或传统协议的实时应用。因此，就可靠性(尽可能低的假阴性率)和相关性(尽可能低的假阳性率)而言，对高效入侵检测系统(IDS)的需求是最基本的。结合误用检测(即定义攻击场景并在流量中找到这些场景的痕迹)的IDS的开发。)和基于小波理论的异常检测(即，被监督实体的行为的参考模型的构建，我们将能够将观察到的行为与该参考模型进行比较)是一种有前途的方法，因为它们已经被显示用于这种类型的系统。对于这种复杂系统的检测能力可以使用其交换的特定特征来增强，使用它们来丰富其正常签名并降低假阳性和假阴性的概率。本文描述了作者当前研究方向的背景和艺术状态，旨在提出挑战和学生在未来几年打算完成的未来工作。",
                    "title_zh": "空中交通管理系统网络入侵检测工具的设计、开发和实现"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00045",
                    "title": "Best of SELSE 2018 Introduction",
                    "authors": "Alan Wood",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/8415929/8416185/08416230.pdf"
                    },
                    "abstract_zh": "",
                    "title_zh": "SELSE 2018最佳游戏攻略"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00046",
                    "title": "Hamartia: A Fast and Accurate Error Injection Framework",
                    "authors": "Chun-Kai Chang, Sangkug Lym, Nicholas Kelly, Michael B. Sullivan, Mattan Erez",
                    "abstract": "Single bit-flip has been the most popular error model for resilience studies with fault injection. We use RTL gate-level fault injection to show that this model fails to cover many realistic hardware faults. Specifically, single-event transients from combinational logic and single-event upsets in pipeline latches can lead to complex multi-bit errors at the architecture level. However, although accurate, RTL simulation is too slow to evaluate application-level resilience. To strike a balance between model accuracy and injection speed, we refine the concept of hierarchical injection to prune faults with known outcomes, saving 62% of program runs at 2% margin of error on average across 9 benchmark programs. Our implementation of the hierarchical error injector is not only accurate but also fast because it is able to source realistic error patterns using on demand RTL gate-level fault injection. Our tool outperforms state-of-the-art assembly-level and compiler-based error injectors by up to 6X, while providing higher fidelity.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "单比特翻转是故障注入弹性研究中最流行的错误模型。我们使用RTL门级故障注入来说明该模型未能覆盖许多实际的硬件故障。具体而言，来自组合逻辑的单事件瞬态和流水线锁存器中的单事件翻转会导致架构级的复杂多位错误。然而，虽然准确，RTL模拟太慢，无法评估应用程序级别的弹性。为了在模型准确性和注入速度之间取得平衡，我们改进了分层注入的概念，以修剪已知结果的错误，在9个基准程序上以平均2%的误差范围节省了62%的程序运行。我们的分层错误注入器的实现不仅准确而且快速，因为它能够使用按需RTL门级错误注入来获得真实的错误模式。我们的工具比最先进的汇编级和基于编译器的错误注入器快6倍，同时提供更高的保真度。",
                    "title_zh": "Hamartia:一个快速准确的错误注入框架"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00047",
                    "title": "Low Cost Transient Fault Protection Using Loop Output Prediction",
                    "authors": "Sunghyun Park, Shikai Li, Scott A. Mahlke",
                    "abstract": "Performance-oriented optimizations have been successful by making transistor faster and smaller. However, the computer systems are becoming less reliable as optimizations increase their susceptibility to transient faults by reducing various design margins. The device cannot handle electromagnetic noise properly and naturally, the transient fault may lead to system failures or data corruptions. Given that transient fault occurs randomly in both time and space, the protection strategy should be constantly activated. Thus, the protection strategy should be cost-efficient and lightweight to be practical. In this paper, we propose RSkip which is a lightweight software-only protection technique. It focuses on minimizing the number of dynamic instructions for the fault protection. Rather than re-executing expensive identical computations, the output of re-computation is approximated and compared to validate execution. When the actual computation and estimation agree within predefined error bound, the computation is assumed fault-free and the expensive re-computation can be skipped. Prior instruction duplication work shows 2.89x normalized execution time compared to unreliable execution over five compute-intensive benchmarks. With negligible loss of protection rate, RSkip reduces the overhead to 1.20x by skipping 83.91% of re-computations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过使晶体管更快更小，面向性能的优化已经取得了成功。然而，计算机系统变得越来越不可靠，因为优化通过减少各种设计余量增加了它们对瞬时故障的敏感性。设备不能正确地处理电磁噪声，自然，瞬时故障可能导致系统故障或数据损坏。鉴于瞬时故障在时间和空间上随机发生，保护策略应不断激活。因此，保护策略应该是经济高效的和轻量级的，以便实用。本文提出了一种轻量级的纯软件保护技术RSkip。它关注于最小化故障保护的动态指令的数量。不是重新执行昂贵的相同计算，而是近似并比较重新计算的输出以验证执行。当实际计算和估计在预定误差范围内一致时，计算被认为是无故障的，并且可以跳过昂贵的重新计算。在五个计算密集型基准测试中，与不可靠执行相比，之前的指令复制工作显示出2.89倍的标准化执行时间。由于保护率损失可以忽略不计，RSkip通过跳过83.91%的重新计算，将开销降低到1.20倍。",
                    "title_zh": "使用环路输出预测的低成本瞬时故障保护"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00048",
                    "title": "Parity++: Lightweight Error Correction for Last Level Caches",
                    "authors": "Irina Alam, Clayton Schoeny, Lara Dolecek, Puneet Gupta",
                    "abstract": "As the size of on-chip SRAM caches is increasing rapidly and the physical dimension of the SRAM devices is decreasing, reliability of caches is becoming a growing concern. This is because with increased size of caches, the likelihood of radiation-induced soft faults also increases. As a result, information redundancy in the form of Error Correcting Codes (ECC) is becoming extremely important, especially to protect the larger sized last level caches (LLCs). In typical ECCs, extra redundancy bits are added to every row to detect and correct errors. There is additional encoding (while writing data) and decoding (while reading data) procedures required as well. In caches, these additional area, power and latency overheads need to be minimized as much as possible. To address this problem, we present in this paper Parity++: a novel unequal message protection scheme for last level caches that preferentially provides stronger error protection to certain \"special messages\". This protection scheme provides Single Error Detection (SED) for all messages and Single Error Correction (SEC) for a subset of messages. Thus, it is stronger than just a basic SED parity and has much lower parity storage overhead (4X lower for a 64-bit memory) and lower error detection energy than a traditional Single Error Correcting, Double Error Detecting (SECDED) code. We also evaluate Parity++ with a memory speculation procedure that can be used with any ECC scheme to hide the decoding latency while reading messages when there are no errors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着片上SRAM高速缓存的大小迅速增加，并且SRAM设备的物理尺寸减小，高速缓存的可靠性变得越来越受关注。这是因为随着高速缓存大小的增加，辐射引起的软故障的可能性也增加了。因此，纠错码(ECC)形式的信息冗余变得极其重要，尤其是为了保护较大尺寸的末级高速缓存(LLC)。在典型的ECC中，额外的冗余位被添加到每一行以检测和纠正错误。还需要额外的编码(写入数据时)和解码(读取数据时)过程。在高速缓存中，这些额外的面积、功率和延迟开销需要尽可能地最小化。为了解决这个问题，我们在这篇论文中提出了Parity++:一种新的用于末级高速缓存的不等消息保护方案，该方案优先为某些“特殊消息”提供更强的错误保护。这种保护方案为所有消息提供单一错误检测(SED ),为消息子集提供单一错误纠正(SEC)。因此，它比基本的SED奇偶校验更强，并且比传统的单纠错、双检错(SECDED)码具有更低的奇偶校验存储开销(对于64位存储器低4倍)和更低的检错能量。我们还使用内存推测程序评估了Parity++的性能，该程序可用于任何ECC方案，以隐藏在读取无错误消息时的解码延迟。",
                    "title_zh": "奇偶++:针对末级缓存的轻量级纠错"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00049",
                    "title": "BCRB 2018 introduction",
                    "authors": "Alysson Bessani, Hans P. Reiser, Marko Vukolic, Tobias Distler",
                    "abstract": "workshop abstract.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/8415929/8416185/08416234.pdf"
                    },
                    "abstract_zh": "研讨会摘要。",
                    "title_zh": "BCRB 2018介绍"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00050",
                    "title": "Protecting Early Stage Proof-of-Work Based Public Blockchain",
                    "authors": "Lin Chen, Lei Xu, Zhimin Gao, Yang Lu, Weidong Shi",
                    "abstract": "Proof-of-work was originally proposed by Dwork and Naor in 1992 and has proved its powerfulness in Bitcoin as a decentralized mechanism for blockchain construction. Proof-of-work is the basis of most popular cryptocurrencies and smart contract systems, where participating miners are required to solve difficult mathematical problems to validate transactions. One of the major challenges that proof-of-work faces is the 51% attack, i.e., if an adversary controls more than half of the computation power, he/she can control the blockchain construction and determine which blocks will be included. This is not a major concern when the number of miners is large. However, for an early stage blockchain system with a limited number of users, it is relatively easy for an attacker to launch the 51% attack. To mitigate such risk, we propose a new hybrid blockchain construction scheme that uses the combination of proof-of-work and the stake, which is the number of coins produced by a miner, to determine whether this miner is allowed to construct a block. We prove that stakes play an important role in the hybrid scheme at the beginning, so that an attacker is not able to launch the 51% attack even if he/she controls the majority of the computational power. Meanwhile, the hybrid scheme will converge to pure proof-of-work after sufficiently many blocks are generated, and thus captures the desired properties of proof-of-work. Most importantly, such a convergence is \"smooth\" in the sense that neither changes in the rules nor parameters are introduced, and thus no hard/soft-forks will be triggered. We also demonstrate the effectiveness of the new scheme using simulations with different configurations, which can help a designer to select adequate parameters for a specific blockchain application.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "工作证明最初是由Dwork和Naor在1992年提出的，并且已经证明了它作为区块链构造的去中心化机制在比特币中的强大功能。工作证明是最受欢迎的加密货币和智能合约系统的基础，参与的矿工需要解决困难的数学问题来验证交易。工作证明面临的一个主要挑战是51%攻击，即如果对手控制了一半以上的计算能力，他/她就可以控制区块链的构建并决定将包括哪些块。当矿工人数众多时，这不是一个主要问题。然而，对于用户数量有限的早期区块链系统，攻击者发起51%攻击相对容易。为了降低这种风险，我们提出了一种新的混合区块链建造方案，该方案结合使用工作证明和赌注，即矿工生产的硬币数量，来确定该矿工是否被允许建造一个区块。我们从一开始就证明了赌注在混合方案中起着重要的作用，使得攻击者即使控制了大部分的计算能力也无法发起51%的攻击。同时，在生成足够多的块之后，混合方案将收敛到纯工作证明，并因此捕获工作证明的期望属性。最重要的是，这种收敛是“平滑的”,因为既没有引入规则的变化，也没有引入参数的变化，因此不会触发硬/软分叉。我们还使用不同配置的仿真来证明新方案的有效性，这可以帮助设计者为特定的区块链应用选择适当的参数。",
                    "title_zh": "保护基于早期工作证明的公共区块链"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00051",
                    "title": "Challenges and Pitfalls of Partitioning Blockchains",
                    "authors": "Enrique Fynn, Fernando Pedone",
                    "abstract": "Blockchain has received much attention in recent years. This immense popularity has raised a number of concerns, scalability of blockchain systems being a common one. In this paper, we seek to understand how Ethereum, a well-established blockchain system, would respond to sharding. Sharding is a prevalent technique to increase the scalability of distributed systems. To understand how sharding would affect Ethereum, we model Ethereum blockchain as a graph and evaluate five methods to partition the graph. We assess methods using three metrics: the balance among shards, the number of transactions that would involve multiple shards, and the amount of data that would be relocated across shards upon repartitioning of the graph.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1804.07356"
                    },
                    "abstract_zh": "区块链近年来备受关注。这种巨大的受欢迎程度已经引起了许多关注，区块链系统的可伸缩性是一个常见的问题。在本文中，我们试图了解以太坊，一个成熟的区块链系统，将如何响应分片。分片是提高分布式系统可伸缩性的一种流行技术。为了理解分片将如何影响以太坊，我们将以太坊区块链建模为一个图，并评估了五种划分该图的方法。我们使用三个指标来评估方法:碎片之间的平衡，涉及多个碎片的事务数量，以及在图的重新分区时跨碎片重新定位的数据量。",
                    "title_zh": "分割区块链的挑战和陷阱"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00052",
                    "title": "Towards Model-Driven Engineering of Smart Contracts for Cyber-Physical Systems",
                    "authors": "Péter Garamvölgyi, Imre Kocsis, Benjamin Gehl, Attila Klenik",
                    "abstract": "Applications of Distributed Ledger Technologies (DLTs) in IoT and Cyber-Physical Systems (CPS) are rapidly emerging. However, developing correct and resilient smart contracts for these use cases is even less understood than it is for cryptocurrency-based contracts. This paper presents an initial approach for generating smart contracts for coordinating the usage of cyber-physical system elements from UML statecharts. While the current target platform is Ethereum, our approach can easily be extended to other blockchain platforms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分布式账本技术(DLTs)在物联网和信息物理系统(CPS)中的应用正在迅速涌现。然而，为这些用例开发正确且有弹性的智能合约甚至比基于加密货币的合约更难理解。本文提出了一种从UML状态图中生成智能契约以协调信息物理系统元素使用的初步方法。虽然当前的目标平台是以太坊，我们的方法可以很容易地扩展到其他区块链平台。",
                    "title_zh": "面向信息物理系统智能合同的模型驱动工程"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00053",
                    "title": "Latency-Aware Leader Selection for Geo-Replicated Byzantine Fault-Tolerant Systems",
                    "authors": "Michael Eischer, Tobias Distler",
                    "abstract": "In a geo-replicated setting, the response time of a leader-based Byzantine fault-tolerant (BFT) protocol often differs significantly depending on which of the replicas in the system is currently acting as leader. Identifying a single optimal leader position in general is impossible due to workload characteristics usually varying over the course of the day. As a consequence, the approach used in many existing BFT replication protocols, which assign the leader role in a static manner and only change the leader in case of suspected or detect faulty behavior, results in unnecessarily high latency in wide-area environments. In this paper we address this problem with Archer, a latency-aware mechanism to select the leader of a geo-replicated BFT system based on end-to-end response times measured by clients. To prevent faulty replicas from gaining an unfair advantage by sending protocol messages early, Archer relies on a hash-chain-based approach that enables clients to detect if a protocol phase has been skipped. In addition, Archer offers means to tolerate incorrect latency values reported by faulty clients and can also be extended to solve other selection problems such as the placement of active and passive replicas in resource-efficient BFT systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在地理复制设置中，基于领导者的拜占庭容错(BFT)协议的响应时间通常会有很大差异，具体取决于系统中哪个副本当前充当领导者。一般来说，确定一个最佳领导职位是不可能的，因为工作负载的特征通常会在一天中不断变化。因此，许多现有BFT复制协议中使用的方法以静态方式分配领导者角色，并且仅在怀疑或检测到错误行为的情况下改变领导者，这导致了广域环境中不必要的高延迟。在本文中，我们通过Archer解决了这一问题，Archer是一种延迟感知机制，可根据客户端测量的端到端响应时间来选择地理复制BFT系统的领导者。为了防止有缺陷的副本通过提前发送协议消息获得不公平的优势，Archer依赖于一种基于哈希链的方法，该方法使客户端能够检测协议阶段是否被跳过。此外，Archer提供了容忍故障客户端报告的错误延迟值的方法，并且还可以扩展以解决其他选择问题，例如在资源高效型BFT系统中放置主动和被动副本。",
                    "title_zh": "地理复制拜占庭容错系统的延迟感知领导者选择"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00054",
                    "title": "Towards Low-Latency Byzantine Agreement Protocols Using RDMA",
                    "authors": "Signe Rüsch, Ines Messadi, Rüdiger Kapitza",
                    "abstract": "Byzantine fault tolerance (BFT) protocols can mitigate attacks and errors and are increasingly investigated as consensus protocols in blockchains. However, they are traditionally considered costly in terms of message complexity and latency due to the required multiple rounds of message exchanges. With the availability of Remote Direct Memory Access (RDMA) in data centers, message exchange latency can be reduced compared to TCP, as RDMA enables kernel bypassing and thereby avoids intermediate data copying. Retaining the performance benefits for RDMA during its integration, however, is non-trivial and error-prone. While the use of RDMA has previously been explored for key/value stores, databases and distributed file systems, agreement protocols especially for BFT have so far been neglected. We investigate the usage of RDMA in the Reptor BFT protocol for low-latency agreement and show first steps towards an RDMA-enabled consensus protocol. For this, we present Rubin, a framework offering similar functionality to the Java NIO selector, which can handle multiple network connections efficiently with a single thread and is employed in several BFT protocol implementations such as BFT-SMaRt and UpRight.",
                    "files": {
                        "openAccessPdf": "https://leopard.tu-braunschweig.de/servlets/MCRFileNodeServlet/dbbs_derivate_00046813/ruesch-bcrb18.pdf"
                    },
                    "abstract_zh": "拜占庭容错(BFT)协议可以减少攻击和错误，并且在区块链作为共识协议被越来越多地研究。然而，由于需要多轮消息交换，传统上认为它们在消息复杂性和延迟方面成本很高。随着数据中心远程直接内存访问(RDMA)的出现，与TCP相比，消息交换延迟可以降低，因为RDMA支持内核旁路，从而避免了中间数据复制。然而，在集成过程中保持RDMA的性能优势并不简单，而且容易出错。虽然RDMA的使用先前已经被探索用于键/值存储、数据库和分布式文件系统，但是特别是用于BFT的协议协议迄今为止一直被忽视。我们研究了RDMA在Reptor BFT协议中的低延迟协议的使用，并展示了实现RDMA支持的共识协议的第一步。为此，我们提出了Rubin，一个提供与Java NIO选择器类似功能的框架，它可以用单线程有效地处理多个网络连接，并在几个BFT协议实现中使用，如BFT智能和直立。",
                    "title_zh": "使用RDMA的低延迟拜占庭协议"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00055",
                    "title": "Visualizing BFT SMR Distributed Systems - Example of BFT-SMaRt",
                    "authors": "Noëlle Rakotondravony, Hans P. Reiser",
                    "abstract": "Byzantine Fault Tolerant (BFT) State Machine Replication (SMR) distributed systems are very complex systems whose optimization traditionally relies on the analysis of log files or the output of debugging processes. In this work in progress, we use visualization techniques to support human users in the task of analyzing, understand, and optimizing a BFT SMR distributed system in both online and offline modes. The visualization of the execution of BFT SMR distributed systems features with the possibility to correlate information from different levels of abstraction. Our design methodologies also allow us to address the different challenges accompanying the visualization of distributed systems in general. We illustrate our study with an example usage scenario in which the execution of a BFT-SMaRt-based distributed system is visualized.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "拜占庭容错(BFT)状态机复制(SMR)分布式系统是非常复杂的系统，其优化传统上依赖于日志文件的分析或调试过程的输出。在这项正在进行的工作中，我们使用可视化技术来支持人类用户在线和离线模式下分析、理解和优化BFT SMR分布式系统的任务。BFT·SMR分布式系统执行的可视化具有关联来自不同抽象层次的信息的可能性。我们的设计方法也允许我们解决伴随分布式系统可视化的不同挑战。我们用一个使用场景的例子来说明我们的研究，在这个场景中，一个基于BFT智能的分布式系统的执行被可视化。",
                    "title_zh": "可视化BFT SMR分布式系统-BFT智能的例子"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00056",
                    "title": "Dynamic State Partitioning in Parallelized Byzantine Fault Tolerance",
                    "authors": "Bijun Li, Wenbo Xu, Rüdiger Kapitza",
                    "abstract": "Recent research works have shown that applying parallelization to request processing in Byzantine Fault Tolerance (BFT) can bring significant performance improvement. Based on partitioned service state, parallelism is introduced to both agreement and execution to address performance and scalability limitations caused by the global total order of all requests. However, in case of inefficient state partitioning, expensive synchronization among partitions is expected, which leads to a considerable performance loss. To improve the efficiency of parallel processing, we present Dynamic State Partitioning (DYPART), a framework that maps service state into multiple partitions and periodically reconfigures the partitions for different usage patterns. DYPART relies on the knowledge about relations between the state objects for partitioning, which is obtained by collecting request dependencies. It utilizes a high-performance graph partitioning algorithm to ensure that the resulting state partitions can achieve both workload balance and low synchronization among partitions. Our evaluation of a key-value store shows that compared to a random partitioning, DYPART can improve the performance by at least 40%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近的研究工作表明，在拜占庭容错(BFT)中将并行化应用于请求处理可以带来显著的性能提升。基于分区的服务状态，并行性被引入到协议和执行中，以解决由所有请求的全局总顺序引起的性能和可伸缩性限制。然而，在低效的状态分区的情况下，分区之间的昂贵的同步是预期的，这导致相当大的性能损失。为了提高并行处理的效率，我们提出了动态状态分区(DYPART)，这是一个将服务状态映射到多个分区并针对不同的使用模式定期重新配置分区的框架。DYPART依赖于关于状态对象之间关系的知识进行划分，这是通过收集请求依赖关系获得的。它利用一种高性能的图划分算法来确保所产生的状态分区能够实现分区之间的工作负载平衡和低同步。我们对键值存储的评估表明，与随机分区相比，DYPART至少可以提高40%的性能。",
                    "title_zh": "并行拜占庭容错中的动态划分"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00057",
                    "title": "CERTS 2018 Introduction",
                    "authors": "Mikael Asplund, Sibin Mohan",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/8415929/8416185/08416242.pdf"
                    },
                    "abstract_zh": "",
                    "title_zh": "CERTS 2018简介"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00058",
                    "title": "A Systematic Way to Incorporate Security in Safety Analysis",
                    "authors": "Elena Lisova, Aida Causevic, Kaj Hänninen, Henrik Thane, Hans Hansson",
                    "abstract": "Today's systems are being built to connect to public or semi-public networks, are able to communicate with other systems, e.g., in the context of Internet-of-Things (IoT), involve multiple stakeholders, have dynamic system reconfigurations, and operate in increasingly unpredictable environments. In such complex systems, assuring safety and security in a continuous and joint effort is a major challenge, not the least due to the increasing number of attack surfaces arising from the increased connectivity. In this paper we present an approach that aims to bridge the gap between safety and security engineering. The potential of the approach is illustrated on the example of E-gas system, discussing the cases when unintentional faults as well as malicious attacks are taken into consideration when assuring safety of the described system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "今天的系统被构建为连接到公共或半公共网络，能够与其他系统通信，例如在物联网(IoT)的环境中，涉及多个利益相关方，具有动态的系统重新配置，并且在越来越不可预测的环境中运行。在这种复杂的系统中，通过持续的联合努力来确保安全是一项重大挑战，尤其是因为连接性的增加导致攻击面的增加。在本文中，我们提出了一种方法，旨在弥合安全和安全工程之间的差距。以E-gas系统为例说明了该方法的潜力，讨论了在确保所述系统的安全性时考虑无意故障以及恶意攻击的情况。",
                    "title_zh": "将安全性纳入安全分析的系统方法"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00059",
                    "title": "Design for Dependability Through Error Propagation Space Exploration",
                    "authors": "Imre Kocsis",
                    "abstract": "With dependability-, and specifically safety-critical systems becoming more and more open, the importance of the ability to reason about error propagation in an exploratory style is becoming increasingly important. This paper proposes an initial theoretical framework for Error Propagation Space Exploration (EPSE) and outlines the activities it is able to support. The key difference from classic Error Propagation Analysis (EPA) is that all error propagation hypotheses are handled together as a hypothesis set relation. Key aspects of operationalizing the framework are also discussed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着可靠性，特别是安全关键系统变得越来越开放，以探索的方式对错误传播进行推理的能力变得越来越重要。本文提出了误差传播空间探索(EPSE)的初步理论框架，并概述了它能够支持的活动。与经典误差传播分析(EPA)的关键区别在于，所有误差传播假设都作为一个假设集关系一起处理。还讨论了实施该框架的关键方面。",
                    "title_zh": "通过误差传播空间探索的可靠性设计"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00060",
                    "title": "Validating and Securing DLMS/COSEM Implementations with the ValiDLMS Framework",
                    "authors": "Henrique Mendes, Iberia Medeiros, Nuno Neves",
                    "abstract": "The electrical grid is a critical infrastructure for modern society. It has been evolving into a smart(er) grid, allowing infrastructure aware decisions based on data collected in real-time from smart meters and other devices. Smart meters and their uplinks have, however, limited physical security due to their location within customer premises. DLMS/COSEM is a standard protocol for remote interactions with smart meters, often being deployed above power-line communication links. The paper presents the ValiDLMS framework, the first open source solution for validation and security auditing of DLMS/COSEM implementations using this communication profile. The framework was developed as an extension to Wireshark and was used to analyse an industry partner's DLMS/COSEM implementation. The results show that ValiDLMS can effectively support the discovery of bugs and/or other non-conformance problems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "电网是现代社会的重要基础设施。它已经发展成为智能(er)电网，允许根据从智能电表和其他设备实时收集的数据做出基础设施感知决策。然而，智能电表及其上行链路的物理安全性有限，这是因为它们位于客户驻地内。DLMS/COSEM是与智能电表远程交互的标准协议，通常部署在电力线通信链路之上。本文介绍了ValiDLMS框架，这是第一个使用这种通信配置文件对DLMS/COSEM实现进行验证和安全审计的开源解决方案。该框架是作为Wireshark的扩展开发的，用于分析行业合作伙伴的DLMS/COSEM实施。结果表明，ValiDLMS能够有效地支持发现错误和/或其他不符合问题。",
                    "title_zh": "使用ValiDLMS框架验证和保护DLMS/COSEM实现"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00061",
                    "title": "Real-Time Security Through a TEE",
                    "authors": "Roberto Duenez, Albert Mo Kim Cheng",
                    "abstract": "The incrementing complexity in embedded and cyber-physical systems has demanded a new dimension of security. Trusted Execution Environments (TEE) provide process isolation and dedicated hardware to prevent breach of sensitive information. This paper will focus on the use of TEE on TrustZone architectures for embedded systems security and an implementation with real-time constraints.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "嵌入式和信息物理系统日益增加的复杂性要求新的安全维度。可信执行环境(TEE)提供进程隔离和专用硬件来防止敏感信息泄露。本文将重点介绍如何在TrustZone架构上使用TEE来实现嵌入式系统的安全性和实时约束。",
                    "title_zh": "通过发球台的实时安全"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00062",
                    "title": "DSML 2018 Introduction",
                    "authors": "Homa Alemzadeh, Karthik Pattabiraman, David E. Evans",
                    "abstract": "workshop abstract.",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/8415929/8416185/08416247.pdf"
                    },
                    "abstract_zh": "研讨会摘要。",
                    "title_zh": "DSML 2018介绍"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00063",
                    "title": "Fairness and Transparency of Machine Learning for Trustworthy Cloud Services",
                    "authors": "Nuno Antunes, Leandro Balby, Flavio V. D. de Figueiredo, Nuno Lourenço, Wagner Meira Jr., Walter Santos",
                    "abstract": "Machine learning is nowadays ubiquitous, providing mechanisms for supporting decision making that leverages big data analytics. However, this recent rise in importance of machine learning also raises societal concerns about the dependability and trustworthiness of systems which depend on such automated predictions. Within this context, the new general data protection regulation (GDPR) demands that organizations take the appropriate measures to protect individuals' data, and use it in a privacy-preserving, fair and transparent fashion. In this paper we present how fairness and transparency are supported in the ATMOSPHERE ecosystem for trustworthy clouds. For this, we present the scope of fairness and transparency concerns in the project and then discuss the techniques that are being developed to address each of these concerns. Furthermore, we discuss how fairness and transparency are used with other quality attributes to characterize the trustworthiness of cloud systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，机器学习无处不在，为支持利用大数据分析的决策提供了机制。然而，最近机器学习重要性的上升也引起了社会对依赖于这种自动预测的系统的可靠性和可信度的关注。在这种情况下，新的一般数据保护条例(GDPR)要求组织采取适当的措施来保护个人数据，并以保护隐私、公平和透明的方式使用数据。在本文中，我们展示了可信云的大气生态系统是如何支持公平性和透明性的。为此，我们提出了项目中公平性和透明性问题的范围，然后讨论了正在开发的解决这些问题的技术。此外，我们还讨论了如何将公平性和透明性与其他质量属性结合使用，以描述云系统的可信度。",
                    "title_zh": "可信云服务机器学习的公平性和透明性"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00064",
                    "title": "Model, Data and Reward Repair: Trusted Machine Learning for Markov Decision Processes",
                    "authors": "Shalini Ghosh, Susmit Jha, Ashish Tiwari, Patrick Lincoln, Xiaojin Zhu",
                    "abstract": "When machine learning (ML) models are used in safety-critical or mission-critical applications (e.g., self driving cars, cyber security, surgical robotics), it is important to ensure that they provide some high-level guarantees (e.g., safety, liveness). We introduce a paradigm called Trusted Machine Learning (TML) for making ML models more trustworthy. We use Markov Decision Processes (MDPs) as the underlying dynamical model and outline three TML approaches: (1) Model Repair, wherein we modify the learned model directly; (2) Data Repair, wherein we modify the data so that re-learning from the modified data results in a trusted model; and (3) Reward Repair, wherein we modify the reward function of the MDP to satisfy the specified logical constraint. We show how these repairs can be done efficiently for probabilistic models (e.g., MDP) when the desired properties are expressed in some appropriate fragment of logic such as temporal logic (for example PCTL, i.e., Probabilistic Computation Tree Logic), first order logic or propositional logic. We illustrate our approaches on case studies from multiple domains, e.g., car controller for obstacle avoidance, and a query routing controller in a wireless sensor network.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当机器学习(ML)模型用于安全关键或任务关键应用(例如，自动驾驶汽车、网络安全、手术机器人)时，确保它们提供一些高级别的保证(例如，安全性、活性)是很重要的。我们引入了一种称为可信机器学习(TML)的范式，使ML模型更加可信。我们使用马尔可夫决策过程(MDPs)作为基本的动态模型，并概述了三种TML方法:(1)模型修复，其中我们直接修改学习的模型；(2)数据修复，其中我们修改数据，以便从修改的数据中重新学习产生可信的模型；以及(3)奖励修复，其中我们修改MDP的奖励函数以满足指定的逻辑约束。我们展示了当期望的属性在诸如时序逻辑(例如PCTL，即概率计算树逻辑)、一阶逻辑或命题逻辑的一些适当的逻辑片段中被表达时，这些修复可以如何有效地对概率模型(例如MDP)进行。我们在多个领域的案例研究中阐述了我们的方法，例如，用于避障的汽车控制器和无线传感器网络中的查询路由控制器。",
                    "title_zh": "模型、数据和回报修复:马尔可夫决策过程的可信机器学习"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00065",
                    "title": "On the Limitation of MagNet Defense Against L1-Based Adversarial Examples",
                    "authors": "Pei-Hsuan Lu, Pin-Yu Chen, Kang-Cheng Chen, Chia-Mu Yu",
                    "abstract": "In recent years, defending adversarial perturbations to natural examples in order to build robust machine learning models trained by deep neural networks (DNNs) has become an emerging research field in the conjunction of deep learning and security. In particular, MagNet consisting of an adversary detector and a data reformer is by far one of the strongest defenses in the black-box oblivious attack setting, where the attacker aims to craft transferable adversarial examples from an undefended DNN model to bypass an unknown defense module deployed on the same DNN model. Under this setting, MagNet can successfully defend a variety of attacks in DNNs, including the high-confidence adversarial examples generated by the Carlini and Wagner's attack based on the L2 distortion metric. However, in this paper, under the same attack setting we show that adversarial examples crafted based on the L1 distortion metric can easily bypass MagNet and mislead the target DNN image classifiers on MNIST and CIFAR-10. We also provide explanations on why the considered approach can yield adversarial examples with superior attack performance and conduct extensive experiments on variants of MagNet to verify its lack of robustness to L1 distortion based attacks. Notably, our results substantially weaken the assumption of effective threat models on MagNet that require knowing the deployed defense technique when attacking DNNs (i.e., the gray-box attack setting).",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1805.00310"
                    },
                    "abstract_zh": "近年来，防御自然样本的对抗性扰动以建立由深度神经网络(DNNs)训练的鲁棒机器学习模型已经成为深度学习和安全结合的新兴研究领域。特别是，由对手检测器和数据重组器组成的MagNet是迄今为止黑盒遗忘攻击设置中最强的防御之一，在黑盒遗忘攻击设置中，攻击者旨在从不设防的DNN模型中创建可转移的敌对示例，以绕过部署在同一DNN模型上的未知防御模块。在这种设置下，MagNet可以成功防御DNNs中的各种攻击，包括基于L2失真度量的Carlini和Wagner攻击产生的高置信度对抗性例子。然而，在本文中，在相同的攻击设置下，我们表明基于L1失真度量制作的敌对示例可以很容易地绕过MagNet并误导MNIST和CIFAR-10上的目标DNN图像分类器。我们还解释了为什么所考虑的方法可以产生具有优越攻击性能的对抗示例，并对MagNet的变体进行了广泛的实验，以验证其对基于L1失真的攻击缺乏鲁棒性。值得注意的是，我们的结果大大削弱了MagNet上有效威胁模型的假设，该假设要求在攻击DNNs时了解部署的防御技术(即灰箱攻击设置)。",
                    "title_zh": "基于L1的对抗性事例磁防御的局限性"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00066",
                    "title": "DCN: Detector-Corrector Network Against Evasion Attacks on Deep Neural Networks",
                    "authors": "Jing Wen, Lucas C. K. Hui, Siu-Ming Yiu, Ruoqing Zhang",
                    "abstract": "Deep neural networks are extensively used in image recognition. However, its integrity is compromised by evasion attacks. Attackers can easily craft adversarial examples that make DNNs unknowingly output the labels they want rather than the right labels. In a recent study, it was shown that existing detection methods are not effective in identifying these adversarial examples, i.e., it is a realistic threat to existing systems. Unlike the previous detection methods, we observe that the classification probability distributions of adversarial examples and those of untampered examples exhibit a big difference, which can be easily identified based on the output of a DNN without getting into the complicated DNN internal structure. Based on this new insight, we propose a new light-weight detection method by transforming the detection of adversarial examples into a binary classification problem. The detector we train achieves almost 100% accuracy on adversarial examples. Moreover, we propose a detector-corrector network that effectively reduces successful rate of existing state-of-the-art evasion attacks under three commonly used distance metrics. In particular, for the common L2 attack, DCN mitigates 99% adversarial examples on MNIST and 95% on CIFAR-10. Our evaluation demonstrates that DCN is significantly more effective and efficient against various evasion attacks than existing methods.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "深度神经网络广泛应用于图像识别。然而，它的完整性受到规避攻击的损害。攻击者可以很容易地制造对抗性的例子，使DNS不知不觉地输出他们想要的标签，而不是正确的标签。在最近的一项研究中，显示了现有的检测方法在识别这些敌对的例子中是不有效的，即，它是对现有系统的现实威胁。与之前的检测方法不同，我们观察到对立样本和非对立样本的分类概率分布表现出很大的差异，这可以基于DNN的输出而容易地识别，而无需进入复杂的DNN内部结构。基于这一新的观点，我们提出了一种新的轻量级检测方法，将对立样本的检测转化为一个二元分类问题。我们训练的检测器在对立的例子上达到了几乎100%的准确率。此外，我们提出了一个检测器-校正器网络，在三种常用的距离度量下，该网络有效地降低了现有最先进的规避攻击的成功率。特别地，对于常见的L2攻击，DCN在MNIST上减轻了99%的对抗实例，在CIFAR-10上减轻了95%。我们的评估表明，与现有方法相比，DCN在抵御各种逃避攻击方面明显更加有效和高效。",
                    "title_zh": "DCN:检测-校正网络对抗深度神经网络的逃避攻击"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00067",
                    "title": "SSIV 2018 Introduction",
                    "authors": "João Carlos Cunha, Kalinka Branco, Michaël Lauer",
                    "abstract": "workshop introduction",
                    "files": {
                        "openAccessPdf": "https://ieeexplore.ieee.org/ielx7/8415929/8416185/08416252.pdf"
                    },
                    "abstract_zh": "研讨会介绍",
                    "title_zh": "SSIV 2018介绍"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00068",
                    "title": "Risk Assessment and Security Countermeasures for Vehicular Instrument Clusters",
                    "authors": "Eugen Horatiu Gurban, Bogdan Groza, Pal-Stefan Murvay",
                    "abstract": "The vehicular instrument cluster has the vital task of informing the driver on vehicle status or potential malfunctions. While this role is merely informative, the implications are far reaching as the driver needs to take decisions based on the reports provided by the instrument cluster. Past attacks on instrument clusters were rather concerned with mundane tasks, e.g., mileage modification, but giving false information to the driver on vehicle speed or triggering/hiding relevant alarms may have serious consequences as it can lead to severe traffic accidents. In this work we discuss risks associated to attacker actions on instrument clusters and envision a potential model based intrusion detection system to detect potential attacks. Rather than advocating a holistic approach, in which security is designed for the entire vehicle network, e.g. CAN or FlexRay, we follow a component-based approach in which particularities of the instrument cluster and redundancy of information are used to detect potential attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "车辆仪表组的重要任务是通知驾驶员车辆状态或潜在故障。虽然这种作用只是提供信息，但其影响是深远的，因为驾驶员需要根据组合仪表提供的报告做出决定。过去对组合仪表的攻击更多地涉及日常任务，如里程修改，但向驾驶员提供错误的车速信息或触发/隐藏相关警报可能会导致严重的后果，因为这可能会导致严重的交通事故。在本文中，我们讨论了与攻击者在仪表组上的行为相关的风险，并设想了一种基于潜在模型的入侵检测系统来检测潜在的攻击。我们并不提倡为整个车辆网络(如CAN或FlexRay)设计安全性的整体方法，而是采用基于组件的方法，利用组合仪表的特性和信息冗余来检测潜在的攻击。",
                    "title_zh": "车载组合仪表的风险评估及安全对策"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00069",
                    "title": "Detection of Automotive CAN Cyber-Attacks by Identifying Packet Timing Anomalies in Time Windows",
                    "authors": "Andrew Tomlinson, Jeremy W. Bryans, Siraj Ahmed Shaikh, Harsha Kumara Kalutarage",
                    "abstract": "Cyber-attacks on the automotive controller area network (CAN) have recently been shown to be achievable and potentially disruptive or deadly. Detecting an attack quickly will require the development of intrusion detection systems that can cope with the rapid broadcast of CAN data, the comparatively limited computational power of automotive components, and the proprietary nature of CAN data specifications. This paper presents an analysis of CAN broadcasts and consequent testing of statistical methods to detect timing changes in the CAN traffic indicative of some predicted attacks. The detection is implemented in time-defined windows. The generation of simulated attack data, and the determination of positive detections, are also considered.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对汽车控制器局域网(CAN)的网络攻击最近被证明是可以实现的，并且具有潜在的破坏性或致命性。快速检测攻击需要开发入侵检测系统，以应对can数据的快速传播、汽车部件相对有限的计算能力以及CAN数据规范的专有性质。本文介绍了对CAN广播的分析以及随后对统计方法的测试，以检测CAN流量中指示某些预测攻击的时序变化。检测在时间定义的窗口中实现。还考虑了模拟攻击数据的生成和肯定检测的确定。",
                    "title_zh": "通过识别时间窗口中的数据包时序异常来检测汽车CAN网络攻击"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00070",
                    "title": "Fuzz Testing for Automotive Cyber-Security",
                    "authors": "Daniel S. Fowler, Jeremy W. Bryans, Siraj Ahmed Shaikh, Paul Wooderson",
                    "abstract": "There is increasing computational complexity within the connected car, and with the advent of autonomous vehicles, how do manufacturers test for cyber-security assurance? The fuzz test is a successful black box testing method that hackers have used to find security weaknesses in various domains. Therefore, should the fuzz test, mentioned (without any details) in SAE J3061, be applied more widely into the vehicle systems development process to help reduce vulnerabilities? To investigate this question a custom fuzzer was developed to allow for experimentation against a target vehicle's CAN bus (used as the data interconnect for the vehicle's ECUs). The results demonstrate that the fuzz test has a part to play as one of the many security tests that a vehicle's systems need to undergo before being made ready for series production. However, previous problems raised when cyber testing a vehicle were confirmed. Thus, in adding the fuzz test to the automotive engineering tool box some issues are raised that need addressing in future research.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "联网汽车的计算复杂度越来越高，随着自动驾驶汽车的出现，制造商如何测试网络安全保障？模糊测试是一种成功的黑盒测试方法，黑客们用它来寻找各种领域中的安全弱点。因此，SAE J3061中提到的模糊测试(没有任何细节)是否应该更广泛地应用于车辆系统开发过程，以帮助减少漏洞？为了研究这个问题，开发了一种定制引信，允许对目标车辆的CAN总线(用作车辆ECU的数据互连)进行实验。结果表明，模糊测试是车辆系统在准备批量生产之前需要进行的众多安全测试之一。然而，之前对车辆进行网络测试时出现的问题得到了证实。因此，在将模糊测试添加到汽车工程工具箱中时，提出了一些需要在未来研究中解决的问题。",
                    "title_zh": "汽车网络安全的模糊测试"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00071",
                    "title": "Evaluating Optical Flow Vectors Under Varying Computer-Generated Snow Intensities and Pixel Density for Autonomous Vehicles",
                    "authors": "Vikas Agrawal, Marcel Frueh, Oliver Bringmann, Wolfgang Rosenstiel",
                    "abstract": "The success of Advanced Driver Assistance Systems (ADAS) in self-driving vehicles depends on the accuracy of underlying algorithms used for vision and range-based sensors. In this paper, we present an evaluation model, that measures the performance of optical flow algorithms in noisy conditions and different data processing methods used to determine a mean flow vector of objects. To validate the evaluation model, we run the dense polynomial expansion Farneback [1] algorithm and then perform the evaluation (i) under light, mild and heavy snow intensities, (ii) pixel densities of 0.5, 0.16 and 0.1 pixels/pixel and (iii) data processing methods: Moving Average, Voted Mean and Weighted Mean on Edges. We provide experimental evidence about the quality of robustness of algorithms through Jaccard Index and deviation of displacement vectors from their expected value under different practical criteria that are relevant for the automotive domain.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动驾驶车辆中高级驾驶辅助系统(ADAS)的成功取决于视觉和距离传感器所用的底层算法的准确性。在本文中，我们提出了一个评估模型，该模型测量光流算法在噪声条件下的性能以及用于确定物体的平均流矢量的不同数据处理方法。为了验证评估模型，我们运行了密集多项式展开Farneback [1]算法，然后执行评估(I)在轻度、中度和重度雪强度下，(ii)0.5、0.16和0.1像素/像素的像素密度，以及(iii)数据处理方法:移动平均、投票平均和边缘加权平均。我们通过Jaccard指数和在与汽车领域相关的不同实际标准下位移向量与其期望值的偏差，提供了关于算法鲁棒性质量的实验证据。",
                    "title_zh": "自动车辆在不同的计算机生成的雪强度和像素密度下评估光流矢量"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00072",
                    "title": "Prototyping Automotive Smart Ecosystems",
                    "authors": "Emilia Cioroaica, Thomas Kuhn, Thomas Bauer",
                    "abstract": "The breakthrough of smart ecosystems formed by open adaptive systems requires new testing methods. The need for safety and security on the roads is pushed ahead by new developments in the area of autonomous driving. Frameworks that support testing of control functions are therefore needed. We present a prototype platform for automotive smart ecosystem that enables testing of smart ecosystems with a special focus on visualization and integration with real world. An abstract and a detailed description of the platform components, together with argumentation of the chosen components and interface description is presented as well. The platform provides a meaningful visualization of scenarios that verify and validate behavior interaction between component of the real and virtual world.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "开放自适应系统形成的智能生态系统的突破，需要新的测试方法。自动驾驶领域的新发展推动了对道路安全的需求。因此，需要支持控制功能测试的框架。我们展示了一个汽车智能生态系统的原型平台，该平台能够测试智能生态系统，特别关注可视化和与现实世界的集成。还提供了平台组件的摘要和详细描述，以及所选组件的论证和接口描述。该平台提供了场景的有意义的可视化，其验证和确认真实和虚拟世界的组件之间的行为交互。",
                    "title_zh": "原型汽车智能生态系统"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00073",
                    "title": "Model-Based Dependability Analysis of Unmanned Aerial Vehicles - A Case Study",
                    "authors": "Matheus Lopes Franco, Kalinka R. J. L. Branco, Rosana T. V. Braga, André Luíz de Oliveira, Catherine Dezan, Jean-Philippe Diguet",
                    "abstract": "Unmanned aerial vehicles (UAVs) are a type of safety-critical system, which demand the verification of dependability properties in different levels of abstraction in order to achieve certification and to be released for operation. Existing model-based techniques have been successfully used in the industry, and recommended by safety standards in automotive and aerospace domains to support system design and dependability analysis. However, there is a lack of a context-aware and systematic approach to support the usage of model-based techniques to support dependability analysis in the UAV domain. This paper presents a systematic and context-aware model-based approach to support dependability analysis and automated generation of artefacts required for safety-certification of UAVs. The approach was applied in SLUGs UAV with the support of HiP-HOPS dependability analysis technique/tool. As a result, the application of the proposed approach enabled the automated generation of dependability artefacts, reducing the effort/costs, and number of errors in performing dependability analysis.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "无人机是一种安全关键系统，需要在不同抽象层次上验证可信性属性，以获得认证并投入使用。现有的基于模型的技术已经在工业中成功使用，并被汽车和航空领域的安全标准推荐，以支持系统设计和可靠性分析。然而，在UAV领域，缺乏一种环境感知和系统化的方法来支持使用基于模型的技术来支持可靠性分析。本文提出了一种系统的、基于上下文感知模型的方法来支持无人机安全认证所需的可信性分析和人工制品的自动生成。在HiP-HOPS可信性分析技术/工具的支持下，该方法应用于SLUGs无人机。结果，所提出的方法的应用使得可靠性工件的自动生成成为可能，减少了在执行可靠性分析中的工作量/成本和错误数量。",
                    "title_zh": "基于模型的无人机可信性分析——案例研究"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00074",
                    "title": "On the Safety of Automotive Systems Incorporating Machine Learning Based Components: A Position Paper",
                    "authors": "Mohamad Gharib, Paolo Lollini, Marco Botta, Elvio Gilberto Amparore, Susanna Donatelli, Andrea Bondavalli",
                    "abstract": "Machine learning (ML) components are increasingly adopted in many automated systems. Their ability to learn and work with novel input/incomplete knowledge and their generalization capabilities make them highly desirable solutions for complex problems. This has motivated the inclusion of ML techniques/components in products for many industrial domains including automotive systems. Such systems are safety-critical systems since their failure may cause death or injury to humans. Therefore, their safety must be ensured before they are used in their operational environment. However, existing safety standards and Verification and Validation (V&V) techniques do not properly address the special characteristics of ML-based components such as non-determinism, non-transparency, instability. This position paper presents the authors' view on the safety of automotive systems incorporating ML-based components, and it is intended to motivate and sketch a research agenda for extending a safety standard, namely ISO 26262, to address challenges posed by incorporating ML-based components in automotive systems.",
                    "files": {
                        "openAccessPdf": "https://iris.unito.it/bitstream/2318/1764226/1/On%20the%20Safety%20of%20Automotive%20Systems%20Incorporating%20Machine%20Learning%20Based%20Components%20-%20A%20Position%20Paper.pdf"
                    },
                    "abstract_zh": "机器学习(ML)组件越来越多地被许多自动化系统采用。他们学习和处理新输入/不完整知识的能力以及他们的泛化能力使他们成为解决复杂问题的理想解决方案。这促使在包括汽车系统在内的许多工业领域的产品中包含ML技术/组件。这种系统是安全关键系统，因为它们的故障可能导致人员死亡或受伤。因此，在将它们用于操作环境之前，必须确保它们的安全。然而，现有的安全标准和验证和确认(V&V)技术没有适当地解决基于ML的组件的特殊特性，例如非确定性、非透明性和不稳定性。本立场文件介绍了作者对采用基于ML的组件的汽车系统的安全性的看法，旨在激励和概述扩展安全标准(即ISO 26262)的研究议程，以应对在汽车系统中采用基于ML的组件所带来的挑战。",
                    "title_zh": "关于包含基于机器学习的组件的汽车系统的安全性:立场文件"
                },
                {
                    "url": "https://doi.ieeecomputersociety.org/10.1109/DSN-W.2018.00075",
                    "title": "FMEDA-Based Fault Injection and Data Analysis in Compliance with ISO-26262",
                    "authors": "Kuen-Long Lu, Yung-Yuan Chen, Li-Ren Huang",
                    "abstract": "With the growing demand on automotive electronics for the advanced driver assistance systems and autonomous driving, the functional safety becomes one of the most important issues in the hardware development. Thus, the safety standard for automotive E/E system, ISO-26262, becomes state-of-the-art guideline to ensure that the required safety level can be achieved. In this study, we base on ISO-26262 to develop a FMEDA-based fault injection and data analysis framework. The main contribution of this study is to effectively reduce the effort for generating FMEDA report which is used to evaluate hardware's safety level based on ISO-26262 standard.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着汽车电子对高级驾驶辅助系统和自动驾驶的需求不断增长，功能安全性成为硬件开发中最重要的问题之一。因此，汽车电子电气系统的安全标准ISO-26262成为最先进的指南，以确保能够达到所需的安全水平。在本研究中，我们基于ISO-26262开发了一个基于FMEDA的故障注入和数据分析框架。本研究的主要贡献在于有效地减少了基于ISO-26262标准评估硬件安全水平的FMEDA报告的生成工作量。",
                    "title_zh": "符合ISO-26262标准的基于FMEDA的故障注入和数据分析"
                }
            ]
        }
    ],
    "2016": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2016.html",
            "conf_title": "46th DSN 2016: Toulouse, France",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7579391/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN.2016.10",
                    "title": "A Quantitative Methodology for Security Monitor Deployment",
                    "authors": "Uttam Thakore, Gabriel A. Weaver, William H. Sanders",
                    "abstract": "Intrusion detection and forensic analysis techniques depend upon monitors to collect information about possible attacks. Since monitoring can be expensive, however, monitors must be selectively deployed to maximize their overall utility. This paper introduces a methodology both to evaluate monitor deployments quantitatively in terms of security goals and to deploy monitors optimally based on cost constraints. First, we define a model that describes the system assets, deployable monitors, and the relationship between generated data and intrusions. Then, we define a set of metrics that quantify the utility and richness of monitor data with respect to intrusion detection and the cost associated with deployment. Finally, we formulate a method using our model and metrics to determine the cost-optimal, maximum-utility placement of monitors. We present an enterprise Web service use case and illustrate how our metrics can be used to determine optimal monitor deployments for a set of common attacks on Web servers. Our approach is scalable, being able to compute within minutes optimal monitor deployments for systems with hundreds of monitors and attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "入侵检测和取证分析技术依靠监视器来收集有关可能攻击的信息。然而，由于监视可能很昂贵，所以必须有选择地部署监视器以最大化它们的整体效用。本文介绍了一种方法，既可以根据安全目标定量评估监视器部署，又可以根据成本约束优化部署监视器。首先，我们定义一个模型来描述系统资产、可部署的监视器以及生成的数据和入侵之间的关系。然后，我们定义一组指标，量化监控数据在入侵检测和部署相关成本方面的效用和丰富程度。最后，我们制定了一个方法，使用我们的模型和指标，以确定成本最优，最大效用的显示器的位置。我们给出了一个企业Web服务用例，并说明了如何使用我们的度量来确定针对Web服务器上一组常见攻击的最佳监视器部署。我们的方法是可扩展的，能够在几分钟内为具有数百个监视器和攻击的系统计算出最佳监视器部署。",
                    "title_zh": "一种安全监视器部署的量化方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.11",
                    "title": "Dynamic Scalable State Machine Replication",
                    "authors": "Long Hoang Le, Carlos Eduardo Benevides Bezerra, Fernando Pedone",
                    "abstract": "State machine replication (SMR) is a well-known technique that guarantees strong consistency (i.e., linearizability) to online services. In SMR, client commands are executed in the same order on all server replicas: after executing each command, every replica reaches the same state. However, SMR lacks scalability: every replica executes all commands, so adding servers does not increase the maximum throughput. Scalable SMR (S-SMR) addresses this problem by partitioning the service state, allowing commands to execute only in some replicas, providing scalability while still ensuring linearizability. One problem is that ssmr quickly saturates when executing multi-partition commands, as partitions must communicate. Dynamic S-SMR (DS-SMR) solves this issue by repartitioning the state dynamically, based on the workload. Variables that are usually accessed together are moved to the same partition, which significantly improves scalability. We evaluate the performance of DS-SMR with a scalable social network application.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "状态机复制(SMR)是一种众所周知的技术，它保证在线服务的强一致性(即线性化)。在SMR中，客户端命令在所有服务器副本上以相同的顺序执行:在执行每个命令后，每个副本都达到相同的状态。然而，SMR缺乏可伸缩性:每个副本执行所有命令，因此添加服务器不会增加最大吞吐量。可伸缩SMR (S-SMR)通过划分服务状态解决了这个问题，允许命令只在一些副本中执行，在提供可伸缩性的同时仍然确保线性化。一个问题是ssmr在执行多分区命令时会很快饱和，因为分区必须通信。动态SMR (DS-SMR)通过根据工作负载对状态进行动态重新分区来解决这一问题。通常一起访问的变量被移动到同一个分区，这显著提高了可伸缩性。我们用一个可扩展的社交网络应用程序来评估DS-SMR的性能。",
                    "title_zh": "动态可扩展状态机复制"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.12",
                    "title": "OSIRIS: Efficient and Consistent Recovery of Compartmentalized Operating Systems",
                    "authors": "Koustubha Bhat, Dirk Vogt, Erik van der Kouwe, Ben Gras, Lionel Sambuc, Andrew S. Tanenbaum, Herbert Bos, Cristiano Giuffrida",
                    "abstract": "Much research has gone into making operating systems more amenable to recovery and more resilient to crashes. Traditional solutions rely on partitioning the operating system (OS) to contain the effects of crashes within compartments and facilitate modular recovery. However, state dependencies among the compartments hinder recovery that is globally consistent. Such recovery typically requires expensive runtime dependency tracking which results in high performance overhead, highcomplexity and a large Reliable Computing Base (RCB). We propose a lightweight strategy that limits recovery to cases where we can statically and conservatively prove that compartment recovery leads to a globally consistent state - trading recoverable surface for a simpler and smaller RCB with lower performance overhead and maintenance cost. We present OSIRIS, a research OS design prototype that demonstrates efficient and consistent crash recovery. Our evaluation shows that OSIRIS effectively recovers from important classes of real-world software bugs with a modest RCB and low overheads.",
                    "files": {
                        "openAccessPdf": "http://www.cs.vu.nl/~giuffrida/papers/dsn-2016-2.pdf"
                    },
                    "abstract_zh": "许多研究都致力于使操作系统更易于恢复，更能抵御崩溃。传统的解决方案依赖于对操作系统(OS)进行分区，以将崩溃的影响限制在区间内，并促进模块化恢复。然而，隔离专区之间的状态依赖性阻碍了全局一致的恢复。这种恢复通常需要昂贵的运行时依赖性跟踪，这导致高性能开销、高复杂性和大的可靠计算基础(RCB)。我们提出了一种轻量级策略，将恢复限制在这样的情况下，即我们可以静态地、保守地证明区间恢复导致全局一致的状态——用更简单、更小的RCB换取更低的性能开销和维护成本。我们展示了OSIRIS，一个研究操作系统设计原型，它展示了高效和一致的崩溃恢复。我们的评估表明，OSIRIS以适度的RCB和较低的开销有效地从现实世界的重要软件错误中恢复。",
                    "title_zh": "OSIRIS:有效和一致地恢复分割的操作系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.13",
                    "title": "Towards a Scalable and Write-Free Multi-version Checkpointing Scheme in Solid State Drives",
                    "authors": "Hoda Aghaei Khouzani, Chengmo Yang",
                    "abstract": "Flash memory based solid state drives (SSDs) are widely adopted in mobile devices, PCs and data centers, making their reliability critical. Although periodically creating checkpoints is a well-developed technique for traditional hard disk drives, very few work has exploited the unique properties of SSDs to accelerate checkpoint creation and reduce storage cost. More specifically, the remap-on-write property of SSD creates a trail of multiple versions of data, which can be exploited to create multiple checkpoints without engendering extra writes. However, efficiently managing the metadata to support multiple checkpoints is challenging. In this paper, we propose a low storage cost and high performance scheme to support multiple checkpoints in SSDs. Instead of storing a log-based snapshot of the entire Flash Translation Layer (FTL) per checkpoint, we efficiently keep track of the changes to the FTL across multiple checkpoints, thus accelerating the creation, deletion, and activation of checkpoints within minimum storage overhead and minimum impact on regular SSD operations. Experiments on Microsoft real-world benchmarks confirm the advantage of the proposed scheme over a fully snapshot scheme in terms of storage and performance overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于闪存的固态硬盘(SSD)广泛应用于移动设备、电脑和数据中心，因此其可靠性至关重要。虽然定期创建检查点是传统硬盘驱动器的一项成熟技术，但很少有人利用SSD的独特属性来加速检查点创建并降低存储成本。更具体地说，SSD的写入时重新映射属性创建了多个数据版本的踪迹，可以利用它来创建多个检查点，而不会产生额外的写入。然而，有效管理元数据以支持多个检查点是一项挑战。在本文中，我们提出了一个低存储成本和高性能的方案来支持固态硬盘中的多个检查点。我们不再为每个检查点存储整个闪存转换层(FTL)的基于日志的快照，而是跨多个检查点高效地跟踪FTL的变化，从而以最小的存储开销和对常规SSD操作的最小影响来加速检查点的创建、删除和激活。在微软真实世界基准上的实验证实了所提出的方案在存储和性能开销方面优于完全快照方案。",
                    "title_zh": "固态硬盘中可扩展的免写多版本检查点方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.14",
                    "title": "Elastic Parity Logging for SSD RAID Arrays",
                    "authors": "Yongkun Li, Helen H. W. Chan, Patrick P. C. Lee, Yinlong Xu",
                    "abstract": "Parity-based RAID poses a design trade-off issue for large-scale SSD storage systems: it improves reliability against SSD failures through redundancy, yet its parity updates incur extra I/Os and garbage collection operations, thereby degrading the endurance and performance of SSDs. We propose EPLOG, a storage layer that reduces parity traffic to SSDs, so as to provide endurance, reliability, and performance guarantees for SSD RAID arrays. EPLOG mitigates parity update overhead via elastic parity logging, which redirects parity traffic to separate log devices (to improve endurance and reliability) and eliminates the need of pre-reading data in parity computations (to improve performance). We design EPLOG as a user-level implementation that is fully compatible with commodity hardware and general erasure coding schemes. We evaluate EPLOG through reliability analysis and trace-driven testbed experiments. Compared to the Linux software RAID implementation, our experimental results show that our EPLOG prototype reduces the total write traffic to SSDs, reduces the number of garbage collection operations, and increases the I/O throughput. In addition, EPLOG significantly improves the I/O performance over the original parity logging design, and incurs low metadata overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于奇偶校验的RAID为大规模SSD存储系统提出了一个设计权衡问题:它通过冗余提高了SSD故障的可靠性，但其奇偶校验更新会导致额外的I/o和垃圾收集操作，从而降低了SSD的耐用性和性能。我们提出了EPLOG，这是一个减少固态硬盘奇偶校验流量的存储层，可以为固态硬盘RAID阵列提供耐用性、可靠性和性能保证。EPLOG通过弹性奇偶校验日志记录减少了奇偶校验更新开销，该日志记录将奇偶校验流量重定向到单独的日志设备(以提高耐用性和可靠性)，并消除了奇偶校验计算中预读数据的需要(以提高性能)。我们将EPLOG设计为用户级实现，与商用硬件和通用擦除编码方案完全兼容。我们通过可靠性分析和跟踪驱动的测试床实验来评估EPLOG。与Linux软件RAID实现相比，我们的实验结果表明，我们的EPLOG原型减少了SSD的总写入流量，减少了垃圾收集操作的数量，并增加了I/O吞吐量。此外，与原始奇偶校验日志记录设计相比，EPLOG显著提高了I/O性能，并降低了元数据开销。",
                    "title_zh": "固态硬盘RAID阵列的弹性奇偶校验日志记录"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.15",
                    "title": "OI-RAID: A Two-Layer RAID Architecture towards Fast Recovery and High Reliability",
                    "authors": "Neng Wang, Yinlong Xu, Yongkun Li, Si Wu",
                    "abstract": "A lot of inexpensive disks in modern storage systems induce frequent disk failures. It takes a long time to recover a failed disk due to its large capacity and limited I/O. This paper proposes a hierarchical architecture of erasure code, OI-RAID. OI-RAID consists of two layers of codes, outer layer code and inner layer code. The outer layer code is based on disk grouping and Balanced Incomplete Block Design (BIBD) with skewed data layout to provide efficient parallel I/O of all disks for failure recovery. Inner layer code is deployed within a group of disks. As an example, we deploy RAID5 in both layers and present detailed performance analysis. With RAID5 in both layers, OI-RAID tolerates at least three disk failures meeting practical data availability, and achieves much higher speed up of disk failure recovery than existing approaches, while keeping optimal data update complexity and practically low storage overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代存储系统中的大量廉价磁盘导致了频繁的磁盘故障。由于磁盘容量大，I/O有限，恢复故障磁盘需要很长时间。OI-RAID由两层代码组成，外层代码和内层代码。外层代码基于磁盘分组和具有偏斜数据布局的平衡不完全块设计(BIBD ),为故障恢复提供所有磁盘的高效并行I/O。内层代码部署在一组磁盘中。例如，我们在两层中都部署了RAID5，并提供了详细的性能分析。OI-RAID在两个层中都有RAID5，可以容忍至少三个磁盘故障，满足实际数据可用性，并实现比现有方法更高的磁盘故障恢复速度，同时保持最佳的数据更新复杂性和实际的低存储开销。",
                    "title_zh": "OI-RAID:一种面向快速恢复和高可靠性的双层RAID体系结构"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.16",
                    "title": "StorM: Enabling Tenant-Defined Cloud Storage Middle-Box Services",
                    "authors": "Hui Lu, Abhinav Srivastava, Brendan Saltaformaggio, Dongyan Xu",
                    "abstract": "In an Infrastructure-as-a-Service cloud, tenants rely on the cloud provider to provide \"value-added\" services such as data security and reliability. However, this provider-controlled service model is less flexible and cannot be customized to meet individual tenants' needs. In this paper, we present StorM, a novel middle-box service platform that allows each tenant to deploy tenant-specific security and reliability services -- in virtualized middle-boxes -- for their cloud data. With such middle-boxes, StorM divides the responsibilities of service creation between tenants and the provider by allowing tenants to customize their own cloud data polices and the provider to offer corresponding infrastructural support. In developing StorM, we address key challenges including network splicing, platform efficiency, and semantic gap. We implement a StorM prototype on top of OpenStack and demonstrate three tenant-defined security/reliability middle-box services, with low performance overhead (<; 10%).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在基础设施即服务云中，租户依赖云提供商提供“增值”服务，如数据安全性和可靠性。然而，这种由提供商控制的服务模式灵活性较差，并且无法定制以满足各个租户的需求。在本文中，我们介绍了StorM，这是一个新颖的中间设备服务平台，允许每个租户在虚拟化的中间设备中为其云数据部署特定于租户的安全和可靠性服务。通过这种中间盒，StorM在租户和提供商之间划分了服务创建的责任，允许租户定制自己的云数据策略，提供商提供相应的基础设施支持。在开发StorM的过程中，我们解决了包括网络拼接、平台效率和语义鸿沟在内的关键挑战。我们在OpenStack上实现了一个StorM原型，并演示了三个租户定义的安全性/可靠性中间盒服务，具有低性能开销(<；10%).",
                    "title_zh": "StorM:支持租户定义的云存储中间服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.17",
                    "title": "Process-Oriented Non-intrusive Recovery for Sporadic Operations on Cloud",
                    "authors": "Min Fu, Liming Zhu, Ingo Weber, Len Bass, Anna Liu, Xiwei Xu",
                    "abstract": "Cloud-based systems get changed more frequently than traditional systems. These frequent changes involve sporadic operations such as installation and upgrade. Sporadic operations may fail due to the uncertainty of cloud platforms. Each sporadic operation manipulates a number of cloud resources. The accessibility of resources manipulated makes it possible to build an accurate process model of the correct behavior for an operation and its desired effects. This paper proposes a non-intrusive recovery approach for sporadic operations on cloud, called POD-Recovery. POD-Recovery utilizes the above-mentioned process model of the operation. When needed, it triggers recovery actions based on the model through non-intrusive means, i.e., without modifying the code which implements the sporadic operation. POD-Recovery employs an efficient artificial intelligence (AI) planning technique for generating recovery plans. We implement POD-Recovery and evaluate it by recovering from faults injected into 920 runs of five representative sporadic operations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于云的系统比传统系统变化更频繁。这些频繁的更改涉及安装和升级等零星操作。由于云平台的不确定性，零星操作可能会失败。每个零星的操作都会操作大量的云资源。被操纵的资源的可访问性使得为操作的正确行为及其期望的效果建立精确的过程模型成为可能。本文提出了一种针对云上零星操作的非侵入式恢复方法，称为POD-恢复。POD-回收利用上述操作过程模型。当需要时，它基于该模型通过非侵入方式触发恢复动作，即，不修改实现零星操作的代码。POD-恢复采用高效的人工智能(AI)规划技术来生成恢复计划。我们实现了POD-恢复，并通过从注入到五个有代表性的零星操作的920次运行中的故障中恢复来评估它。",
                    "title_zh": "云上零星操作的面向过程的非侵入式恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.18",
                    "title": "Network Recovery After Massive Failures",
                    "authors": "Novella Bartolini, Stefano Ciavarella, Thomas F. La Porta, Simone Silvestri",
                    "abstract": "This paper addresses the problem of efficiently restoring sufficient resources in a communications network to support the demand of mission critical services after a large scale disruption. We give a formulation of the problem as an MILP and show that it is NP-hard. We propose a polynomial time heuristic, called Iterative Split and Prune (ISP) that decomposes the original problem recursively into smaller problems, until it determines the set of network components to be restored. We performed extensive simulations by varying the topologies, the demand intensity, the number of critical services, and the disruption model. Compared to several greedy approaches ISP performs better in terms of number of repaired components, and does not result in any demand loss. It performs very close to the optimal when the demand is low with respect to the supply network capacities, thanks to the ability of the algorithm to maximize sharing of repaired resources.",
                    "files": {
                        "openAccessPdf": "https://iris.uniroma1.it/bitstream/11573/961948/1/Bartolini_network_2016.pdf"
                    },
                    "abstract_zh": "本文解决了在大规模中断后，如何在通信网络中有效地恢复足够的资源以支持关键任务服务需求的问题。我们给出了该问题的一个MILP公式，并证明它是NP难的。我们提出了一种多项式时间启发式算法，称为迭代分裂和修剪(ISP)，它将原始问题递归地分解为更小的问题，直到它确定要恢复的网络组件集。我们通过改变拓扑、需求强度、关键服务数量和中断模型进行了广泛的模拟。与几种贪婪方法相比，ISP在修复组件的数量方面表现更好，并且不会导致任何需求损失。当需求相对于供应网络容量较低时，由于算法最大化共享修复资源的能力，它的性能非常接近最优。",
                    "title_zh": "大规模故障后的网络恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.19",
                    "title": "JURY: Validating Controller Actions in Software-Defined Networks",
                    "authors": "Kshiteej Mahajan, Rishabh Poddar, Mohan Dhawan, Vijay Mann",
                    "abstract": "Software-defined networks (SDNs) only logically centralize the control plane. In reality, SDN controllers are distributed entities, which may exhibit different behavior on event triggers. We identify several classes of faults that afflict an SDN controller cluster and demonstrate them on two enterprise SDN controllers, ONOS and OpenDaylight. We present JURY, a system to validate controller activities in a clustered SDN deployment, involving topological and forwarding state, without imposing any restrictions on the controller behavior. Our evaluation shows that JURY requires minimal changes to the SDN controllers for deployment, and is capable of validating controller actions in near real time with low performance overheads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(sdn)仅在逻辑上集中控制平面。实际上，SDN控制器是分布式实体，在事件触发时可能表现出不同的行为。我们确定了影响SDN控制器集群的几类故障，并在两个企业级SDN控制器ONOS和OpenDaylight上演示了它们。我们介绍了JURY，这是一个在集群SDN部署中验证控制器活动的系统，涉及拓扑和转发状态，而不对控制器行为施加任何限制。我们的评估表明，JURY只需对SDN控制器进行最少的更改即可进行部署，并且能够以较低的性能开销近乎实时地验证控制器操作。",
                    "title_zh": "陪审团:验证软件定义网络中的控制器动作"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.20",
                    "title": "SDNShield: Reconciliating Configurable Application Permissions for SDN App Markets",
                    "authors": "Xitao Wen, Bo Yang, Yan Chen, Chengchen Hu, Yi Wang, Bin Liu, Xiaolin Chen",
                    "abstract": "The OpenFlow paradigm embraces third-party development efforts, and therefore suffers from potential attacks that usurp the excessive privileges of control plane applications (apps). Such privilege abuse could lead to various attacks impacting the entire administrative domain. In this paper, we present SDNShield, a permission control system that helps network administrators to express and enforce only the minimum required privileges to individual controller apps. SDNShield achieves this goal through (i) fine-grained SDN permission abstractions that allow accurate representation of app behavior boundary, (ii) automatic security policy reconciliation that incorporates security policies specified by administrators into the requested app permissions, and (iii) a lightweight thread-based controller architecture for controller/app isolation and reliable permission enforcement. Through prototype implementation, we verify its effectiveness against proof-of-concept attacks. Performance evaluation shows that SDNShield introduces negligible runtime overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "OpenFlow范例包含第三方开发工作，因此遭受篡夺控制平面应用程序(app)的过度特权的潜在攻击。这种权限滥用可能导致影响整个管理域的各种攻击。在本文中，我们介绍了SDNShield，这是一个权限控制系统，可帮助网络管理员仅向单个控制器应用程序表达和强制执行最低要求的权限。SDNShield通过以下方式实现这一目标:( I)细粒度的SDN权限抽象，可准确表示应用行为边界;( ii)自动安全策略协调，可将管理员指定的安全策略整合到请求的应用权限中;( iii)基于线程的轻量级控制器架构，可实现控制器/应用隔离和可靠的权限实施。通过原型实现，我们验证了其对抗概念证明攻击的有效性。性能评估表明，SDNShield引入的运行时开销可以忽略不计。",
                    "title_zh": "SDNShield:协调SDN应用市场的可配置应用权限"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.21",
                    "title": "Can't Touch This: Consistent Network Updates for Multiple Policies",
                    "authors": "Szymon Dudycz, Arne Ludwig, Stefan Schmid",
                    "abstract": "Computer networks such as the Internet or datacenter networks have become a a crucial infrastructure for many criticial services. Accordingly, it is important that such networks preserve correctness criteria, even during transitions from one correct configuration to a new correct configuration. This paper initiates the study of how to simultaneously update multiple routes in a Software-Defined Network (SDN) in a transiently consistent and efficient manner. In particular, we study the problem of minimizing the number of switch interactions, in this paper also called \"touches\". Our main result is a negative one: we rigorously prove that jointly optimizing multiple route updates in a consistent and efficient manner is NP-hard, alreadyfor two routing policies. However, we also present an efficient, polynomial-time algorithm that, given correct update schedules for individual policies, computes an optimal global schedule with minimal touches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "诸如互联网或数据中心网络之类的计算机网络已经成为许多关键服务的关键基础设施。因此，即使在从一个正确的配置转换到新的正确配置期间，这种网络保持正确性标准也是很重要的。本文开始研究如何在软件定义网络(SDN)中以瞬时一致和有效的方式同时更新多条路由。特别地，我们研究了最小化开关交互次数的问题，在本文中也称为“触摸”。我们的主要结果是否定的:我们严格地证明了以一致和有效的方式联合优化多个路由更新是NP难的，已经有两个路由策略。然而，我们也提出了一个有效的多项式时间算法，在给定个体策略的正确更新时间表的情况下，计算出一个最小接触的最优全局时间表。",
                    "title_zh": "不能碰这个:多个策略的一致网络更新"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.22",
                    "title": "HSFI: Accurate Fault Injection Scalable to Large Code Bases",
                    "authors": "Erik van der Kouwe, Andrew S. Tanenbaum",
                    "abstract": "When software fault injection is used, faults are typically inserted at the binary or source level. The former is fast but provides poor fault accuracy while the latter cannot scale to large code bases because the program must be rebuilt for each experiment. Alternatives that avoid rebuilding incur large run-time overheads by applying fault injection decisions at run-time. HSFI, our new design, injects faults with all context information from the source level and applies fault injection decisions efficiently on the binary. It places markers in the original code that can be recognized after code generation. We implemented a tool according to the new design and evaluated the time taken per fault injection experiment when using operating systems as targets. We can perform experiments more quickly than other source-based approaches, achieving performance that come close to that of binary-level fault injection while retaining the benefits of source-level fault injection.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当使用软件故障注入时，通常在二进制或源代码级别插入故障。前者速度快，但提供的错误准确性差，而后者不能扩展到大型代码库，因为必须为每个实验重新构建程序。通过在运行时应用故障注入决策，避免重新构建的替代方案会导致巨大的运行时开销。我们的新设计——HSFI，使用来自源代码级别的所有上下文信息注入故障，并在二进制文件上有效地应用故障注入决策。它在原始代码中放置标记，这些标记可以在代码生成后被识别。我们根据新的设计实现了一个工具，并评估了使用操作系统作为目标时每个故障注入实验所花费的时间。我们可以比其他基于源的方法更快地执行实验，实现接近二进制级故障注入的性能，同时保留源级故障注入的优势。",
                    "title_zh": "HSFI:精确的故障注入可扩展到大型代码库"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.23",
                    "title": "Making Fast Consensus Generally Faster",
                    "authors": "Sebastiano Peluso, Alexandru Turcu, Roberto Palmieri, Giuliano Losa, Binoy Ravindran",
                    "abstract": "New multi-leader consensus protocols leverage the Generalized Consensus specification to enable low latency, even load balancing, and high parallelism. However, these protocols introduce inherent costs with significant performance impact: they need quorums bigger than the minimum required to solve consensus and need to track dependency relations among proposals. In this paper we present M2PAXOS, an implementation of Generalized Consensus that provides fast decisions (i.e., delivery of a command in two communication delays) by leveraging quorums composed of a majority of nodes and by exploiting workload locality. M2PAXOS does not establish command dependencies based on conflicts, instead mapping nodes to accessed objects and enforcing that commands accessing the same objects be ordered by the same node. Our experimental evaluation confirms the effectiveness of M2PAXOS, gaining up to 7X over state-of-the-art Consensus and Generalized Consensus algorithms under partitioned data accesses and up to 5.5× using the TPC-C workload.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "新的多领导者共识协议利用通用共识规范来实现低延迟、均匀负载平衡和高并行性。然而，这些协议引入了具有显著性能影响的固有成本:它们需要比解决共识所需的最小法定人数更大的法定人数，并且需要跟踪提议之间的依赖关系。在本文中，我们介绍了M2PAXOS，这是一种通用共识的实现，它通过利用由大多数节点组成的定额和利用工作负载局部性来提供快速决策(即，在两次通信延迟中传递命令)。M2PAXOS不基于冲突建立命令依赖关系，而是将节点映射到被访问的对象，并强制访问相同对象的命令由相同的节点排序。我们的实验评估证实了M2PAXOS的有效性，在分区数据访问下，它比最先进的一致性和广义一致性算法提高了7倍，在使用TPC-C工作负载的情况下提高了5.5倍。",
                    "title_zh": "使得快速达成共识通常更快"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.24",
                    "title": "ePVF: An Enhanced Program Vulnerability Factor Methodology for Cross-Layer Resilience Analysis",
                    "authors": "Bo Fang, Qining Lu, Karthik Pattabiraman, Matei Ripeanu, Sudhanva Gurumurthi",
                    "abstract": "The Program Vulnerability Factor (PVF) has been proposed as a metric to understand the impact of hardware faults on software. The PVF is calculated by identifying the program bits required for architecturally correct execution (ACE bits). PVF, however, is conservative as it assumes that all erroneous executions are a major concern, not just those that result in silent data corruptions, and it also does not account for errorsthat are detected at runtime, i.e., lead to program crashes. A more discriminating metric can inform the choice of the appropriate resilience techniques with acceptable performance and energy overheads. This paper proposes ePVF, an enhancement of the original PVF methodology, which filters out the crash-causing bits from the ACE bits identified by the traditional PVF analysis. The ePVF methodology consists of an error propagation model that reasons about error propagation in the program, and a crash model that encapsulates the platform-specific characteristics for handling hardware exceptions. ePVF reduces the vulnerable bits estimated by the original PVF analysis by between 45% and 67% depending on the benchmark, and has high accuracy (89% recall, 92% precision) in identifying the crash-causing bits. We demonstrate the utility of ePVF by using it to inform selective protection of the most SDC-prone instructions in a program.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "程序脆弱性因子(PVF)已经被提议作为理解硬件故障对软件的影响的度量。PVF是通过识别体系结构正确执行所需的程序位(ACE位)来计算的。然而，PVF是保守的，因为它假设所有的错误执行都是主要关注的问题，而不仅仅是那些导致静默数据损坏的错误，并且它也没有考虑在运行时检测到的错误，即导致程序崩溃的错误。一个更具鉴别性的度量可以为选择具有可接受的性能和能量开销的适当弹性技术提供信息。本文提出了ePVF，它是原始PVF方法的一个改进，它从传统PVF分析识别的ACE位中过滤出导致崩溃的位。ePVF方法由一个错误传播模型和一个崩溃模型组成，错误传播模型推理程序中的错误传播，崩溃模型封装了用于处理硬件异常的特定于平台的特征。根据基准测试，ePVF将原始PVF分析估计的易受攻击位减少了45%到67%,并且在识别导致崩溃的位方面具有高准确性(89%的召回率，92%的精确度)。我们通过使用ePVF通知程序中最易发生SDC的指令的选择性保护来展示它的效用。",
                    "title_zh": "ePVF:一种用于跨层弹性分析的增强型程序漏洞因子方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.25",
                    "title": "Methuselah Flash: Rewriting Codes for Extra Long Storage Lifetime",
                    "authors": "Georgios Mappouras, Alireza Vahid, A. Robert Calderbank, Daniel J. Sorin",
                    "abstract": "Motivated by embedded systems and datacenters that require long-life components, we extend the lifetime of Flash memory using rewriting codes that allow for multiple writes to a page before it needs to be erased. Although researchers have previously explored rewriting codes for this purpose, we make two significant contributions beyond prior work. First, we remove the assumption of idealized -- and unrealistically optimistic -- Flash cells used in prior work on endurance codes. Unfortunately, current Flash technology has a non-ideal interface, due to its underlying physical design, and does not, for example, allow all seemingly possible increases in a cell's level. We show how to provide the ideal multi-level cell interface, by developing a virtual Flash cell, and we evaluate its impact on existing endurance codes. Our second contribution is our development of novel endurance codes, called Methuselah Flash Codes (MFC), that provide better cost/lifetime trade-offs than previously studied codes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "受需要长寿命组件的嵌入式系统和数据中心的推动，我们使用重写代码来延长闪存的寿命，这些代码允许在需要擦除页面之前对页面进行多次写入。尽管研究人员先前已经探索过为此目的重写代码，我们在先前的工作之外做出了两个重要的贡献。首先，我们去除了在耐久性代码的先前工作中使用的理想化的-和不切实际的乐观的-闪光单元的假设。不幸的是，当前的闪存技术由于其基础物理设计而具有非理想的接口，并且例如不允许单元水平上所有看似可能的增加。我们展示了如何通过开发虚拟闪存单元来提供理想的多级单元接口，并评估了其对现有耐久性代码的影响。我们的第二个贡献是我们开发了新的耐久性代码，称为Methuselah Flash Codes (MFC ),与以前研究的代码相比，它提供了更好的成本/寿命权衡。",
                    "title_zh": "Methuselah闪存:重写代码以获得超长存储寿命"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.26",
                    "title": "Enabling Deep Voltage Scaling in Delay Sensitive L1 Caches",
                    "authors": "Chao Yan, Russ Joseph",
                    "abstract": "Voltage scaling is one of the most effective techniques for providing power savings on a chip-wide basis. However, reducing supply voltage in the presence of process variation introduces significant reliability challenges for large SRAM arrays. In this work, we demonstrate that the emergence of SRAM failures in delay sensitive L1 caches presents significant impediments to voltage scaling. We show that increases in the L1 cache latency would have a detrimental impact on a processor's performance and power consumption at aggressively scaled voltages. We propose techniques for L1 instruction/data caches to enable deep voltage scaling without compromising the L1 cache latency. For the data cache, we employ fault-free windows to adaptively hold the likely accessed data using the fault-free words within each cache line. For the instruction cache, we avoid the addresses that map to defective words by relocating basic blocks. During high voltage operation, both L1 caches have full capability to support high-performance. During low voltage operation, our schemes reduce Vccmin below 400mV. Compared to a conventional cache with a Vccmin of 760mV, we reduce the energy per instruction by 64%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "电压缩放是在芯片范围内提供功率节省的最有效技术之一。然而，在存在工艺变化的情况下降低电源电压给大型SRAM阵列带来了重大的可靠性挑战。在这项工作中，我们证明了在延迟敏感L1缓存中SRAM故障的出现对电压缩放造成了显著的障碍。我们发现，L1缓存延迟的增加会对处理器的性能和功耗产生不利影响。我们提出了用于L1指令/数据高速缓存的技术，以在不损害L1高速缓存延迟的情况下实现深度电压缩放。对于数据高速缓存，我们采用无故障窗口，在每个高速缓存行内使用无故障字来自适应地保存可能被访问的数据。对于指令高速缓存，我们通过重新定位基本块来避免映射到有缺陷字的地址。在高电压运行期间，两个L1缓存都完全有能力支持高性能。在低电压操作期间，我们的方案将Vccmin降低到400mV以下。与Vccmin为760mV的传统高速缓存相比，我们将每条指令的能耗降低了64%。",
                    "title_zh": "在延迟敏感L1缓存中实现深度电压缩放"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.27",
                    "title": "ReadDuo: Constructing Reliable MLC Phase Change Memory through Fast and Robust Readout",
                    "authors": "Rujia Wang, Youtao Zhang, Jun Yang",
                    "abstract": "Phase change memory (PCM) has emerged as a promising non-volatile memory technology. Multi-level cell (MLC) PCM, while effectively reducing per bit fabrication cost, suffers from resistance drift based soft errors. It is challenging to construct reliable MLC chips that achieve high performance, high storage density, and low energy consumption simultaneously. In this paper, we propose ReadDuo, a fast and robust readout solution to address resistance drift in MLC PCM. We first integrate fast current sensing and resistance drift resilient voltage sensing, which exposes performance optimization opportunities without sacrificing reliability. We then devise last writes tracking and selective different write schemes to minimize performance and energy consumption overhead in scrubbing. Our experimental results show that ReadDuo achieves 37% improvement on average over existing solutions when considering performance, dynamic energy consumption, and storage density all together.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "相变存储器(PCM)已经成为一种有前途的非易失性存储器技术。多级单元(MLC) PCM虽然有效地降低了每比特的制造成本，但是遭受基于电阻漂移的软错误。构建同时实现高性能、高存储密度和低能耗的可靠MLC芯片具有挑战性。在本文中，我们提出了ReadDuo，这是一种快速、鲁棒的读出解决方案，可解决MLC PCM中的电阻漂移问题。我们首先集成快速电流检测和电阻漂移弹性电压检测，在不牺牲可靠性的情况下提供性能优化机会。然后，我们设计最后一次写入跟踪和选择性的不同写入方案，以最大限度地降低清理过程中的性能和能耗开销。我们的实验结果表明，当综合考虑性能、动态能耗和存储密度时，ReadDuo比现有解决方案平均提高了37%。",
                    "title_zh": "ReadDuo:通过快速和鲁棒的读出构建可靠的MLC相变存储器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.28",
                    "title": "Leveraging ECC to Mitigate Read Disturbance, False Reads and Write Faults in STT-RAM",
                    "authors": "Seyed Mohammad Seyedzadeh, Rakan Maddah, Alex K. Jones, Rami G. Melhem",
                    "abstract": "Designing reliable systems using scaled Spin-Transfer Torque Random Access Memory (STT-RAM) has become a significant challenge as the memory technology feature size is scaled down. The introduction of a more prominent read disturbance is a key contributor in this reliability challenge. However, techniques to address read disturbance are often considered in a vacuum that assumes other concerns like transient read errors (false reads) and write faults do not occur. This paper studies several techniques that leverage ECC to mitigate persistent errors resulting from read disturbance and write faults of STT-RAM while still considering the impact of transient errors of false reads. In particular, we study three policies to enable better-than-conservative read disturbance mitigation. The first policy, write after error (WAE), uses ECC to detect errors and write back data to clear persistent errors. The second policy, write after persistent error (WAP), filters out false reads by reading a second time when an error is detected leading to trade-off between write and read energy. The third policy, write after error threshold (WAT), leaves cells with incorrect data behind (up to a threshold) when the number of errors is less than the ECC capability. To evaluate the effectiveness of the different schemes and compare with the simple previously proposed scheme of writing after every read (WAR), we model these policies using Markov processes. This approach allows the determination of appropriate bit error rates in the context of both persistent and transient errors to accurately estimate the system reliability and the energy consumption of different error correction approaches. Our evaluations show that each of these policies provides benefits for different error scenarios. Moreover some approaches can save energy by an average of 99.5%, while incurring the same reliability as other approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着存储器技术特征尺寸按比例缩小，使用按比例缩小的自旋转移矩随机存取存储器(STT-RAM)来设计可靠的系统已经成为重大挑战。更显著的读取干扰的引入是这种可靠性挑战的关键因素。然而，解决读取干扰的技术通常被认为是在真空中进行的，该技术假定不会发生瞬时读取错误(错误读取)和写入故障等其他问题。本文研究了几种利用ECC来减轻由STT-RAM的读干扰和写故障导致的持久性错误的技术，同时还考虑了假读的瞬时错误的影响。特别地，我们研究了三种策略来实现优于保守的读干扰减轻。第一种策略是出错后写入(WAE ),它使用ECC来检测错误并回写数据以清除持续错误。第二种策略是持久错误后写入(WAP ),通过在检测到错误时进行第二次读取来过滤错误读取，从而在写入和读取能量之间进行权衡。第三种策略是错误阈值后写入(WAT ),当错误数量小于ECC能力时，留下具有不正确数据的单元(达到阈值)。为了评估不同方案的有效性，并与之前提出的简单的每次读取后写入(WAR)方案进行比较，我们使用马尔可夫过程对这些策略进行建模。这种方法允许在持久和瞬时错误的情况下确定适当的误码率，以准确估计不同纠错方法的系统可靠性和能量消耗。我们的评估表明，这些策略中的每一个都为不同的错误场景提供了好处。此外，一些方法可以节省平均99.5%的能量，同时产生与其他方法相同的可靠性。",
                    "title_zh": "利用ECC减轻STT-RAM的读取干扰、错误读取和写入故障"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.29",
                    "title": "SuperGlue: IDL-Based, System-Level Fault Tolerance for Embedded Systems",
                    "authors": "Jiguo Song, Gedare Bloom, Gabriel Parmer",
                    "abstract": "As the processor feature sizes shrink, mitigating faults in low level system services has become a critical aspect of dependable system design. In this paper we introduce SuperGlue, an interface description language (IDL) and compiler for recovery from transient faults in a component-based operating system. SuperGlue generates code for interface-driven recovery that uses commodity hardware isolation, micro-rebooting, and interface-directed fault recovery to provide predictable and efficient recovery from faults that impact low-level system services. SuperGlue decreases the amount of recovery code system designers need to implement by an order of magnitude, and replaces it with declarative specifications. We evaluate SuperGlue with a fault injection campaign in low-level system components (e.g., memory mapping manager and scheduler). Additionally, we evaluate the performance of SuperGlue in a web-server application. Results show that SuperGlue improves system reliability with only a small performance degradation of 11.84%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着处理器特征尺寸的缩小，减少低级系统服务中的故障已经成为可靠系统设计的关键方面。本文介绍了SuperGlue，一种接口描述语言(IDL)和编译器，用于在基于组件的操作系统中从瞬时故障中恢复。SuperGlue生成用于接口驱动的恢复的代码，该代码使用商用硬件隔离、微重启和接口导向的故障恢复，以从影响低级系统服务的故障中提供可预测且高效的恢复。SuperGlue将系统设计者需要实现的恢复代码量减少了一个数量级，并用声明性规范来代替它。我们在低级系统组件(例如，内存映射管理器和调度器)中使用故障注入活动来评估SuperGlue。此外，我们评估了超级胶水在web服务器应用程序中的性能。结果表明，强力胶提高了系统的可靠性，性能仅下降了11.84%。",
                    "title_zh": "SuperGlue:基于IDL的嵌入式系统系统级容错"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.30",
                    "title": "PARBOR: An Efficient System-Level Technique to Detect Data-Dependent Failures in DRAM",
                    "authors": "Samira Manabi Khan, Donghyuk Lee, Onur Mutlu",
                    "abstract": "System-level detection and mitigation of DRAM failures offer a variety of system enhancements, such as better reliability, scalability, energy, and performance. Unfortunately, system-level detection is challenging for DRAM failures that depend on the data content of neighboring cells (data-dependent failures). DRAM vendors internally scramble/remap the system-level address space. Therefore, testing data-dependent failures using neighboring system-level addresses does not actually test the cells that are physically adjacent. In this work, we argue that one promising way to uncover data-dependent failures in the system is to determine the location of physically neighboring cells in the system address space. Unfortunately, if done naively, such a test takes 49 days to detect neighboring addresses even in a single memory row, making it infeasible in real systems. We develop PARBOR, an efficient system-level technique that determines the locations of the physically neighboring DRAM cells in the system address space and uses this information to detect data-dependent failures. To our knowledge, this is the first work that solves the challenge of detecting data-dependent failures in DRAM in the presence of DRAM-internal scrambling of system-level addresses. We experimentally demonstrate the effectiveness of PARBOR using 144 real DRAM chips from three major vendors. Our experimental evaluation shows that PARBOR 1) detects neighboring cell locations with only 66-90 tests, a 745,654X reduction compared to the naive test, and 2) uncovers 21.9% more failures compared to a random-pattern test that is unaware of the neighbor cell locations. We introduce a new mechanism that utilizes PARBOR to reduce refresh rate based on the data content of memory locations, thereby improving system performance and efficiency. We hope that our fast and efficient system-level detection technique enables other new ideas and mechanisms that improve the reliability, performance, and energy efficiency of DRAM-based memory systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "DRAM故障的系统级检测和缓解提供了各种系统增强，例如更好的可靠性、可扩展性、能源和性能。不幸的是，对于依赖于相邻单元的数据内容的DRAM故障(数据相关故障)，系统级检测具有挑战性。DRAM供应商在内部扰乱/重新映射系统级地址空间。因此，使用相邻系统级地址测试数据相关故障实际上并不测试物理上相邻的单元。在这项工作中，我们认为揭示系统中数据相关故障的一种有希望的方法是确定系统地址空间中物理相邻单元的位置。不幸的是，如果天真地做，这样的测试需要49天来检测相邻地址，即使是在单个内存行中，这使得它在实际系统中不可行。我们开发了PARBOR，这是一种高效的系统级技术，可以确定系统地址空间中物理相邻DRAM单元的位置，并使用此信息来检测数据相关的故障。据我们所知，这是第一项工作，解决了在存在系统级地址DRAM内部加扰的情况下检测DRAM中数据相关故障的挑战。我们使用来自三个主要供应商的144个真实DRAM芯片实验性地展示了PARBOR的有效性。我们的实验评估表明，PARBOR 1)仅用66-90次测试就检测到相邻小区位置，与原始测试相比减少了745，654倍，2)与不知道相邻小区位置的随机模式测试相比，发现的故障多21.9%。我们引入了一种新的机制，利用PARBOR根据存储单元的数据内容来降低刷新率，从而提高系统性能和效率。我们希望我们快速高效的系统级检测技术能够实现其他新的理念和机制，从而提高基于DRAM的存储系统的可靠性、性能和能效。",
                    "title_zh": "PARBOR:一种有效的检测DRAM中数据相关故障的系统级技术"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.31",
                    "title": "Efficient Algorithm-Based Fault Tolerance for Sparse Matrix Operations",
                    "authors": "Alexander Schöll, Claus Braun, Michael A. Kochte, Hans-Joachim Wunderlich",
                    "abstract": "We propose a fault tolerance approach for sparse matrix operations that detects and implicitly locates errors in the results for efficient local correction. This approach reduces the runtime overhead for fault tolerance and provides high error coverage. Existing algorithm-based fault tolerance approaches for sparse matrix operations detect and correct errors, but they often rely on expensive error localization steps. General checkpointing schemes can induce large recovery cost for high error rates. For sparse matrix-vector multiplications, experimental results show an average reduction in runtime overhead of 43.8%, while the error coverage is on average improved by 52.2% compared to related work. The practical applicability is demonstrated in a case study using the iterative Preconditioned Conjugate Gradient solver. When scaling the error rate by four orders of magnitude, the average runtime overhead increases only by 31.3% compared to low error rates.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了一种用于稀疏矩阵运算的容错方法，该方法检测并隐式定位结果中的错误，以进行有效的局部校正。这种方法减少了容错的运行时开销，并提供了高错误覆盖率。用于稀疏矩阵操作的现有基于算法的容错方法检测和纠正错误，但是它们通常依赖于昂贵的错误定位步骤。对于高错误率，一般的检查点方案会导致大的恢复成本。对于稀疏矩阵向量乘法，实验结果表明，与相关工作相比，运行时开销平均降低了43.8%，而错误覆盖率平均提高了52.2%。通过一个使用迭代预处理共轭梯度求解器的实例研究，验证了该方法的实用性。当将错误率缩放四个数量级时，与低错误率相比，平均运行时开销仅增加了31.3%。",
                    "title_zh": "基于高效算法的稀疏矩阵操作容错"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.32",
                    "title": "Formal Analysis for Dependable Supervisory Control and Data Acquisition in Smart Grids",
                    "authors": "Mohammad Ashiqur Rahman, A. H. M. Jakaria, Ehab Al-Shaer",
                    "abstract": "Smart grids provide innovative and efficient energy management services that offer operational reliability. The Supervisory Control and Data Acquisition (SCADA) system is a core component of a smart grid. Unlike the traditional cyber networks, these components consist of heterogeneous devices, such as intelligent electronic devices, programmable logic controllers, remote terminal units, control servers, routing and security devices, etc. SCADA devices communicate with one another under various communication protocols, physical media, and security properties. Failures or attacks on such networks have the potential of data unavailability and false data injection causing incorrect system estimations and control decisions leading to critical damages including power outages and destruction of equipment. In this work, we develop an automated security and resiliency analysis framework for SCADA in smart grids. This framework takes smart grid configurations and organizational security and resiliency requirements as inputs, formally models configurations and various security constraints, and verifies the dependability of the system under potential contingencies. We demonstrate the execution of this framework on an example problem. We also evaluate the scalability of the framework on synthetic SCADA systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "智能电网提供创新和高效的能源管理服务，提供可靠的运行。监控和数据采集(SCADA)系统是智能电网的核心组成部分。与传统的网络不同，这些组件由异构设备组成，如智能电子设备、可编程逻辑控制器、远程终端设备、控制服务器、路由和安全设备等。SCADA设备在各种通信协议、物理介质和安全属性下相互通信。此类网络上的故障或攻击有可能导致数据不可用和错误的数据注入，从而导致不正确的系统估计和控制决策，从而导致严重的损害，包括停电和设备损坏。在这项工作中，我们为智能电网中的SCADA开发了一个自动化的安全性和弹性分析框架。该框架以智能电网配置和组织安全及弹性需求为输入，对配置和各种安全约束进行形式化建模，并验证系统在潜在突发事件下的可靠性。我们在一个示例问题上演示了这个框架的执行。我们还评估了框架在合成SCADA系统上的可扩展性。",
                    "title_zh": "智能电网中可靠监控和数据采集的形式化分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.33",
                    "title": "A Model-Based Approach to Support Safety-Related Decisions in the Petroleum Domain",
                    "authors": "Leonardo Montecchi, Atle Refsdal, Paolo Lollini, Andrea Bondavalli",
                    "abstract": "Accidents on petroleum installations can have huge consequences, to mitigate the risk, a number of safety barriers are devised. Faults and unexpected events may cause barriers to temporarily deviate from their nominal state. For safety reasons, a work permit process is in place: decision makers accept or reject work permits based on the current state of barriers. However, this is difficult to estimate, as it depends on a multitude of physical, technical and human factors. Information obtained from different sources needs to be aggregated by humans, typically within a limited amount of time. In this paper we propose an approach to provide an automated decision support to the work permit system, which consists in the evaluation of quantitative measures of the risk associated with the execution of work. The approach relies on state-based stochastic models, which can be automatically composed based on the work permit to be examined.",
                    "files": {
                        "openAccessPdf": "https://sintef.brage.unit.no/sintef-xmlui/bitstream/11250/2462604/2/DSN2016.pdf"
                    },
                    "abstract_zh": "石油设施上的事故会产生巨大的后果，为了降低风险，设计了许多安全屏障。故障和意外事件可能导致护栏暂时偏离其标称状态。出于安全原因，工作许可程序已经到位:决策者根据当前的障碍状态接受或拒绝工作许可。然而，这很难估计，因为它取决于许多物理、技术和人为因素。从不同来源获得的信息需要由人来汇总，通常是在有限的时间内。在本文中，我们提出了一种为工作许可系统提供自动化决策支持的方法，该方法包括评估与工作执行相关的风险的定量措施。该方法依赖于基于状态的随机模型，这些模型可以根据要检查的工作许可证自动组成。",
                    "title_zh": "支持石油领域安全相关决策的基于模型的方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.34",
                    "title": "Mean Field Approximation of Uncertain Stochastic Models",
                    "authors": "Luca Bortolussi, Nicolas Gast",
                    "abstract": "We consider stochastic models in presence of uncertainty, originating from lack of knowledge of parameters or by unpredictable effects of the environment. We focus on population processes, encompassing a large class of systems, from queueing networks to epidemic spreading. We set up a formal framework for imprecise stochastic processes, where some parameters are allowed to vary in time within a given domain, but with no further constraint. We then consider the limit behaviour of these systems as the population size goes to infinity. We prove that this limit is given by a differential inclusion that can be constructed from the (imprecise) drift. We provide results both for the transient and the steady state behaviour. Finally, we discuss different approaches to compute bounds of the so-obtained differential inclusions, proposing an effective control-theoretic method based on Pontryagin principle for transient bounds. This provides an efficient approach for the analysis and design of large-scale uncertain and imprecise stochastic models. The theoretical results are accompanied by an in-depth analysis of an epidemic model and a queueing network. These examples demonstrate the applicability of the numerical methods and the tightness of the approximation.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01302416/file/meanFieldApproximation_uncertainStochasticModels.pdf"
                    },
                    "abstract_zh": "我们考虑存在不确定性的随机模型，这种不确定性源于参数知识的缺乏或环境不可预测的影响。我们关注人口过程，包括一大类系统，从排队网络到流行病传播。我们为不精确的随机过程建立了一个正式的框架，其中允许一些参数在给定的域内随时间变化，但没有进一步的约束。然后，我们考虑这些系统的极限行为，因为人口规模趋于无穷大。我们证明了这个极限是由一个可以从(不精确的)漂移中构造出来的微分包含给出的。我们提供了瞬态和稳态行为的结果。最后，我们讨论了计算微分包含界的不同方法，提出了一种基于庞特里亚金原理的有效的控制理论方法。这为大规模不确定和不精确随机模型的分析和设计提供了一种有效的方法。理论结果伴随着一个流行病模型和排队网络的深入分析。这些例子证明了数值方法的适用性和近似的严密性。",
                    "title_zh": "不确定随机模型的平均场近似"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.35",
                    "title": "Uncovering Dynamic Fault Trees",
                    "authors": "Sebastian Junges, Dennis Guck, Joost-Pieter Katoen, Mariëlle Stoelinga",
                    "abstract": "Fault tree analysis is a widespread industry standard for assessing system reliability. Standard (static) fault trees model the failure behaviour of systems in dependence of their component failures. To overcome their limited expressive power, common dependability patterns, such as spare management, functional dependencies, and sequencing are considered. A plethora of such dynamic fault trees (DFTs) have been defined in the literature. They differ in e.g., the types of gates (elements), their meaning, expressive power, the way in which failures propagate, how elements are claimed and activated, and how spare races are resolved. This paper systematically uncovers these differences and categorises existing DFT variants. As these differences may have huge impact on the reliability assessment, awareness of these impacts is important when using DFT modelling and analysis.",
                    "files": {
                        "openAccessPdf": "https://ris.utwente.nl/ws/files/60345462/main.pdf"
                    },
                    "abstract_zh": "故障树分析是评估系统可靠性的普遍工业标准。标准(静态)故障树根据组件故障模拟系统的故障行为。为了克服它们有限的表达能力，考虑了常见的可靠性模式，如备用管理、功能依赖和排序。文献中已经定义了过多的这种动态故障树。它们在例如门(元素)的类型、它们的含义、表达能力、故障传播的方式、元素如何被要求和激活以及备用竞争如何被解决方面不同。本文系统地揭示了这些差异，并对现有的DFT变体进行了分类。由于这些差异可能会对可靠性评估产生巨大影响，因此在使用DFT建模和分析时，了解这些影响非常重要。",
                    "title_zh": "揭示动态故障树"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.36",
                    "title": "Power-Capping Aware Checkpointing: On the Interplay Among Power-Capping, Temperature, Reliability, Performance, and Energy",
                    "authors": "Kun Tang, Devesh Tiwari, Saurabh Gupta, Ping Huang, Qiqi Lu, Christian Engelmann, Xubin He",
                    "abstract": "Checkpoint and restart mechanisms have been widely used in large scientific simulation applications to make forward progress in case of failures. However, none of the prior works have considered the interaction of power-constraint with temperature, reliability, performance, and checkpointing interval. It is not clear how power-capping may affect optimal checkpointing interval. What are the involved reliability, performance, and energy trade-offs? In this paper, we develop a deep understanding about the interaction between power-capping and scientific applications using checkpoint/restart as resilience mechanism, and propose a new model for the optimal checkpointing interval (OCI) under power-capping. Our study reveals several interesting, and previously unknown, insights about how power-capping affects the reliability, energy consumption, performance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "检查点和重启机制已经广泛用于大型科学模拟应用中，以在失败的情况下向前推进。然而，先前的工作都没有考虑功率约束与温度、可靠性、性能和检查点间隔的相互作用。不清楚功率封顶如何影响最佳检查点间隔。在可靠性、性能和能源方面有哪些权衡？本文以检查点/重启作为弹性机制，深入理解了功率封顶与科学应用之间的相互作用，并提出了一种新的功率封顶下的最优检查点间隔(OCI)模型。我们的研究揭示了一些有趣的、以前未知的关于功率封顶如何影响可靠性、能耗和性能的见解。",
                    "title_zh": "功率封顶感知检查点:功率封顶、温度、可靠性、性能和能量之间的相互作用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.37",
                    "title": "Reconsidering Single Failure Recovery in Clustered File Systems",
                    "authors": "Zhirong Shen, Jiwu Shu, Patrick P. C. Lee",
                    "abstract": "How to improve the performance of single failure recovery has been an active research topic because of its prevalence in large-scale storage systems. We argue that when erasure coding is deployed in a cluster file system (CFS), existing single failure recovery designs are limited in different aspects: neglecting the bandwidth diversity property in a CFS architecture, targeting specific erasure code constructions, and no special treatment on load balancing during recovery. In this paper, we reconsider the single failure recovery problem in a CFS setting, and propose CAR, a cross-rack-aware recovery algorithm. For each stripe, CAR finds a recovery solution that retrieves data from the minimum number of racks. It also reduces the amount of cross-rack repair traffic by performing intra-rack data aggregation prior to cross-rack transmission. Furthermore, by considering multi-stripe recovery, CAR balances the amount of cross-rack repair traffic across multiple racks. Evaluation results show that CAR can effectively reduce the amount of cross-rack repair traffic and the resulting recovery time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于单故障恢复在大规模存储系统中的普遍存在，如何提高单故障恢复的性能一直是一个活跃的研究课题。我们认为，当在集群文件系统(CFS)中部署擦除编码时，现有的单故障恢复设计在不同方面受到限制:忽略CFS架构中的带宽多样性属性，针对特定的擦除编码构造，以及在恢复期间没有对负载平衡进行特殊处理。在本文中，我们重新考虑了CFS环境下的单故障恢复问题，并提出了CAR，一种跨机架感知的恢复算法。对于每个条带，CAR都会找到一个恢复解决方案，从最少数量的机架中检索数据。它还通过在跨机架传输之前执行机架内数据聚合来减少跨机架维修流量。此外，通过考虑多条带恢复，CAR平衡了跨多个机架的跨机架维修流量。评估结果表明，CAR能有效减少跨机架修复的通信量和由此产生的恢复时间。",
                    "title_zh": "重新考虑集群文件系统中的单一故障恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.38",
                    "title": "Managing Data Center Tickets: Prediction and Active Sizing",
                    "authors": "Ji Xue, Robert Birke, Lydia Y. Chen, Evgenia Smirni",
                    "abstract": "Performance ticket handling is an expensive operation in highly virtualized cloud data centers where physical boxes host multiple virtual machines (VMs). A large body of tickets arise from the resource usage warnings, e.g., CPU and RAM usages that exceed predefined thresholds. The transient nature of CPU and RAM usage as well as their strong correlation across time among co-located VMs drastically increase the complexity in ticket management. Based on a large resource usage data collected from production data centers, amount to 6K physical machines and more than 80K VMs, we first discover patterns of spatial dependency among co-located virtual resources. Leveraging our key findings, we develop an Active Ticket Managing(ATM) system that consists of (i) a novel time series prediction methodology and (ii) a proactive VM resizing policy for CPU and RAM resources for co-located VMs on a physical box that aims to drastically reduce usage tickets. ATM exploits the spatial dependency across multiple resources of co-located VMs for usage prediction and proactive VM resizing. Evaluation results on traces of 6K physical boxes and a prototype of a MediaWiki system show that ATM is able to achieve excellent prediction accuracy of a large number of VM time series and significant usage ticket reduction, i.e., up to 60%, at low computational overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在高度虚拟化的云数据中心中，性能票证处理是一项成本高昂的操作，在这些数据中心中，物理机箱托管着多个虚拟机。大量票证来自资源使用警告，例如，超过预定义阈值的CPU和RAM使用。CPU和RAM使用的瞬时性以及它们随时间推移在位于同一位置的虚拟机之间的强烈相关性极大地增加了票证管理的复杂性。基于从生产数据中心收集的大量资源使用数据，总计6K个物理机和超过80K个虚拟机，我们首先发现了位于同一位置的虚拟资源之间的空间依赖模式。利用我们的主要发现，我们开发了一个主动票证管理(ATM)系统，该系统包括(I)一种新颖的时间序列预测方法和(ii)一种针对物理机箱上共存虚拟机的CPU和RAM资源的主动虚拟机大小调整策略，旨在大幅减少使用票证。ATM利用位于同一位置的虚拟机的多种资源之间的空间依赖性来预测使用情况和主动调整虚拟机大小。在6K物理盒和MediaWiki系统原型上的评估结果表明，ATM能够以较低的计算开销实现大量VM时间序列的优异预测精度和显著的使用票据减少，即高达60%。",
                    "title_zh": "管理数据中心票证:预测和主动调整"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.39",
                    "title": "A Privacy Analysis of Google and Yandex Safe Browsing",
                    "authors": "Thomas Gerbet, Amrit Kumar, Cédric Lauradoux",
                    "abstract": "Google and Yandex Safe Browsing are popular services included in many web browsers to prevent users from visiting phishing or malware websites. If these services protect their users from losing private information, they also require that their servers receive browsing information on the very same users. In this paper, we analyze Google and Yandex Safe Browsing services from a privacy perspective. We quantify the privacy provided by these services by analyzing the possibility of re-identifying URLs visited by a client. We thereby challenge Google's privacy policy which claims thatGoogle cannot recover URLs visited by its users. Our analysis and experimental results show that Google and Yandex Safe Browsing canpotentially be used as a tool to track specific classes of individuals. Additionally, our investigations on the data currently included in Google and Yandex Safe Browsing provides a concrete set of URLs/domains that can be re-identified without much effort.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01120186v4/file/RR8686.pdf"
                    },
                    "abstract_zh": "谷歌和Yandex安全浏览是许多网络浏览器中包含的流行服务，用于防止用户访问网络钓鱼或恶意软件网站。如果这些服务保护他们的用户不丢失私人信息，他们也要求他们的服务器接收相同用户的浏览信息。本文从隐私角度分析了Google和Yandex的安全浏览服务。我们通过分析重新识别客户访问的URL的可能性来量化这些服务提供的隐私。因此，我们质疑谷歌的隐私政策，该政策声称谷歌不能恢复其用户访问的网址。我们的分析和实验结果表明，Google和Yandex安全浏览有可能被用作跟踪特定类别个人的工具。此外，我们对目前包含在Google和Yandex安全浏览中的数据的调查提供了一组具体的URLs域，无需太多努力即可重新识别。",
                    "title_zh": "Google和Yandex安全浏览的隐私分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.40",
                    "title": "PUPPIES: Transformation-Supported Personalized Privacy Preserving Partial Image Sharing",
                    "authors": "Jianping He, Bin Liu, Deguang Kong, Xuan Bao, Na Wang, Hongxia Jin, George Kesidis",
                    "abstract": "Sharing photos through Online Social Networks is an increasingly popular fashion. However, it poses a seriousthreat to end users as private information in the photos maybe inappropriately shared with others without their consent. This paper proposes a design and implementation of a system using a dynamic privacy preserving partial image sharing technique (namely PUPPIES), which allows data owners to stipulate specific private regions (e.g., face, SSN number) in an image and correspondingly set different privacy policies for each user. As a generic technique and system, PUPPIES targets at threats about over-privileged and unauthorized sharing of photos at photo service provider (e.g., Flicker, Facebook, etc) side. To this end, PUPPIES leverages the image perturbation technique to \"encrypt\" the sensitive areas in the original images, and therefore it can naturally support popular image transformations (such as cropping, rotation) and is well compatible with most image processing libraries. The extensive experiments on 19,000 images demonstrate that PUPPIES is very effective for privacy protection and incurs only a small computational overhead. In addition, PUPPIES offers high flexibility for different privacy settings, and is very robust to different types of privacy attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过在线社交网络分享照片越来越流行。然而，它对最终用户构成了严重的威胁，因为照片中的私人信息可能会在未经他们同意的情况下不恰当地与其他人共享。本文提出了一种使用动态隐私保护部分图像共享技术(即小狗)的系统的设计和实现，该技术允许数据所有者在图像中指定特定的隐私区域(例如，面部、SSN号码),并相应地为每个用户设置不同的隐私策略。作为一个通用的技术和系统，小狗的目标是在照片服务提供商(如闪烁，脸书等)方面的过度特权和未经授权的照片共享的威胁。为此，PUPPIES利用图像扰动技术来“加密”原始图像中的敏感区域，因此它可以自然地支持流行的图像变换(如裁剪、旋转)，并与大多数图像处理库兼容。在19，000张图像上的大量实验表明，小狗对于隐私保护非常有效，并且只产生很小的计算开销。此外，小狗为不同的隐私设置提供了高度的灵活性，并且对不同类型的隐私攻击非常鲁棒。",
                    "title_zh": "小狗:支持变换的个性化隐私保护部分图像共享"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.41",
                    "title": "Modeling Privacy and Tradeoffs in Multichannel Secret Sharing Protocols",
                    "authors": "Devin J. Pohly, Patrick D. McDaniel",
                    "abstract": "Privacy is an important aspect of network communications, but privacy protocols require an investment of network resources. For any such protocol to be of use, we need to understand quantitatively how much privacy to expect, as well as the tradeoff between privacy and other network properties, for any given configuration of networks and parameters. We develop a practical privacy measure and protocol model for multichannel secret sharing protocols which integrates privacy and measurable network properties, deriving optimality results for the overall privacy and performance of these protocols. After proving these results, we evaluate the effectiveness of our model by providing a reference implementation and comparing its behavior to the optimality results derived from the model. In our benchmarks, the behavior of this proof-of-concept protocol matched that which is predicted by our model, furthermore, our results demonstrate the feasibility of implementing secret sharing protocols which transmit at a rate within 3-4% of optimal. This model and its results allow us to understand quantitatively the tradeoffs between privacy and network performance in secret-sharing based protocols.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "隐私是网络通信的一个重要方面，但是隐私协议需要网络资源的投资。对于任何要使用的这种协议，我们需要定量地理解对于任何给定的网络和参数配置，期望多少隐私，以及隐私和其他网络属性之间的权衡。我们为多信道秘密共享协议开发了一个实用的隐私度量和协议模型，该模型集成了隐私和可测量的网络属性，导出了这些协议的整体隐私和性能的优化结果。在证明了这些结果之后，我们通过提供一个参考实现并将其行为与从模型导出的最优性结果进行比较来评估我们的模型的有效性。在我们的基准测试中，该概念验证协议的行为与我们的模型预测的行为相匹配，此外，我们的结果证明了实现以最佳3-4%的速率传输的秘密共享协议的可行性。该模型及其结果允许我们定量地理解基于秘密共享的协议中隐私和网络性能之间的权衡。",
                    "title_zh": "多信道秘密共享协议中隐私和折衷的建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.42",
                    "title": "On False Data Injection Attacks Against Railway Traction Power Systems",
                    "authors": "Subhash Lakshminarayana, Zhan-Teng Teo, Rui Tan, David K. Y. Yau, Pablo Arboleya",
                    "abstract": "Modern urban railways extensively use computerized-sensing and control technologies to achieve safe, reliable, and well-timed operations. However, the use of these technologies may provide a convenient leverage to cyber-attackers who have bypassed the air gaps and aim at causing safety incidents and service disruptions. In this paper, we study false data injection (FDI) attacks against railways' traction power systems (TPSes). Specifically, we analyze two types of FDI attacks on the train-borne voltage, current, and position sensor measurements -- which we call efficiency attack and safety attack -- that (i) maximize the system's total power consumption and (ii) mislead trains' local voltages to exceed given safety-critical thresholds, respectively. To counteract, we develop a global attack detection system that serializes a bad data detector anda novel secondary attack detector designed based on unique TPS characteristics. With intact position data of trains, our detection system can effectively detect the FDI attacks ontrains' voltage and current measurements even if the attacker has full and accurate knowledge of the TPS, attack detection, and real-time system state. Extensive simulations driven by realistic running profiles of trains verify that a TPS setup isvulnerable to the FDI attacks, but these attacks can be detected effectively by the proposed global monitoring.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代城市铁路广泛使用计算机化的传感和控制技术来实现安全、可靠和适时的运营。然而，这些技术的使用可能为绕过空气间隙并旨在造成安全事故和服务中断的网络攻击者提供便利的手段。本文研究针对铁路牵引供电系统的虚假数据注入攻击。具体来说，我们分析了对车载电压、电流和位置传感器测量的两种类型的FDI攻击——我们称之为效率攻击和安全攻击——它们分别(I)最大化系统的总功耗和(ii)误导列车的局部电压超过给定的安全临界阈值。为了应对这种情况，我们开发了一个全局攻击检测系统，它序列化了一个坏数据检测器和一个基于独特TPS特征设计的新的二次攻击检测器。利用完整的列车位置数据，我们的检测系统可以有效地检测对列车电压和电流测量的FDI攻击，即使攻击者对TPS、攻击检测和实时系统状态有完整和准确的了解。由真实的列车运行概况驱动的广泛模拟验证了TPS设置对于FDI攻击是脆弱的，但是这些攻击可以通过所提出的全局监控来有效地检测。",
                    "title_zh": "铁路牵引供电系统虚假数据注入攻击研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.43",
                    "title": "Targeted Attacks on Teleoperated Surgical Robots: Dynamic Model-Based Detection and Mitigation",
                    "authors": "Homa Alemzadeh, Daniel Chen, Xiao Li, Thenkurussi Kesavadas, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer",
                    "abstract": "This paper demonstrates targeted cyber-physical attacks on teleoperated surgical robots. These attacks exploit vulnerabilities in the robot's control system to infer a critical time during surgery to drive injection of malicious control commands to the robot. We show that these attacks can evade the safety checks of the robot, lead to catastrophic consequences in the physical system (e.g., sudden jumps of robotic arms or system's transition to an unwanted halt state), and cause patient injury, robot damage, or system unavailability in the middle of a surgery. We present a model-based analysis framework that can estimate the consequences of control commands through real-time computation of robot's dynamics. Our experiments on the RAVEN II robot demonstrate that this framework can detect and mitigate the malicious commands before they manifest in the physical system with an average accuracy of 90%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文展示了对遥控手术机器人的有针对性的网络物理攻击。这些攻击利用机器人控制系统中的漏洞来推断手术期间的关键时间，以驱动向机器人注入恶意控制命令。我们发现，这些攻击可以逃避机器人的安全检查，导致物理系统中的灾难性后果(例如，机械臂的突然跳跃或系统转换到不希望的停止状态)，并导致患者受伤、机器人损坏或手术过程中系统不可用。我们提出了一个基于模型的分析框架，可以通过机器人动力学的实时计算来估计控制命令的结果。我们在RAVEN II机器人上的实验表明，该框架可以在恶意命令出现在物理系统之前检测并减轻它们，平均准确率为90%。",
                    "title_zh": "遥控手术机器人的目标攻击:基于动态模型的检测和缓解"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.44",
                    "title": "F-DETA: A Framework for Detecting Electricity Theft Attacks in Smart Grids",
                    "authors": "Varun Badrinath Krishna, Kiryung Lee, Gabriel A. Weaver, Ravishankar K. Iyer, William H. Sanders",
                    "abstract": "Electricity theft is a major concern for utilities all over the world, and leads to billions of dollars in losses every year. Although improving the communication capabilities between consumer smart meters and utilities can enable many smart grid features, these communications can be compromised in ways that allow an attacker to steal electricity. Such attacks have recently begun to occur, so there is a real and urgent need for a framework to defend against them. In this paper, we make three major contributions. First, we develop what is, to our knowledge, the most comprehensive classification of electricity theft attacks in the literature. These attacks are classified based on whether they can circumvent security measures currently used in industry, and whether they are possible under different electricity pricing schemes. Second, we propose a theft detector based on Kullback-Leibler (KL) divergence to detect cleverly-crafted electricity theft attacks that circumvent detectors proposed in related work. Finally, we evaluate our detector using false data injections based on real smart meter data. For the different attack classes, we show that our detector dramatically mitigates electricity theft in comparison to detectors in prior work.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "窃电是全世界公用事业的一个主要问题，每年导致数十亿美元的损失。虽然提高消费智能电表和公用事业之间的通信能力可以实现许多智能电网功能，但这些通信可能会受到损害，从而使攻击者能够窃电。此类攻击最近开始出现，因此迫切需要一个框架来防御它们。在本文中，我们做出了三个主要贡献。首先，据我们所知，我们开发了文献中最全面的窃电攻击分类。这些攻击是基于它们是否能够绕过当前工业中使用的安全措施，以及它们在不同的电力定价方案下是否是可能的来分类的。第二，我们提出了一种基于Kullback-Leibler (KL)散度的窃电检测器，用于检测巧妙制作的窃电攻击，这些攻击绕过了相关工作中提出的检测器。最后，我们使用基于真实智能电表数据的虚假数据注入来评估我们的检测器。对于不同的攻击类别，我们表明，与先前工作中的检测器相比，我们的检测器显著地减少了窃电。",
                    "title_zh": "F-DETA:智能电网中检测窃电攻击的框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.45",
                    "title": "Secure Identification of Actively Executed Code on a Generic Trusted Component",
                    "authors": "Bruno Vavala, Nuno Ferreira Neves, Peter Steenkiste",
                    "abstract": "Code identity is a fundamental concept for authenticated operations in Trusted Computing. In today's approach, the overhead of assigning an identity to a protected service increases linearly with the service code size. In addition, service code size continues to grow to accommodate richer services. This trend negatively impacts either the security or the efficiency of current protocols for trusted executions. We present an execution protocol that breaks the dependency between the code size of the service and the identification overhead, without affecting security, and that works on different trusted components. This is achieved by computing an identity for each of the code modules that are actually executed, and then building a robust chain of trust that links them together for efficient verification. We implemented and applied our protocol to a widely-deployed database engine, improving query-processing time up to 2× compared to the monolithic execution of the engine.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "代码身份是可信计算中认证操作的一个基本概念。在当今的方法中，为受保护的服务分配身份的开销随着服务代码的大小而线性增加。此外，服务代码的大小继续增长，以适应更丰富的服务。这种趋势对当前可信执行协议的安全性或效率产生了负面影响。我们提出了一个执行协议，它打破了服务的代码大小和标识开销之间的依赖性，而不影响安全性，并且在不同的可信组件上工作。这是通过为实际执行的每个代码模块计算一个身份，然后构建一个健壮的信任链来实现的，该信任链将它们链接在一起以进行有效的验证。我们在一个广泛部署的数据库引擎上实现并应用了我们的协议，与引擎的整体执行相比，查询处理时间提高了2倍。",
                    "title_zh": "通用可信组件上主动执行的代码的安全识别"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.46",
                    "title": "Secure and Efficient Multi-Variant Execution Using Hardware-Assisted Process Virtualization",
                    "authors": "Koen Koning, Herbert Bos, Cristiano Giuffrida",
                    "abstract": "Memory error exploits rank among the most serious security threats. Of the plethora of memory error containment solutions proposed over the years, most have proven to be too weak in practice. Multi-Variant eXecution (MVX) solutions can potentially detect arbitrary memory error exploits via divergent behavior observed in diversified program variants running in parallel. However, none have found practical applicability in security due to their non-trivial performance limitations. In this paper, we present MvArmor, an MVX system that uses hardware-assisted process virtualization to monitor variants for divergent behavior in an efficient yet secure way. To provide comprehensive protection against memory error exploits, MvArmor relies on a new MVX-aware variant generation strategy. The system supports user-configurable security policies to tune the performance-security trade-off. Our analysis shows that MvArmor can counter many classes of modern attacks at the cost of modest performance overhead, even with conservative detection policies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内存错误利用是最严重的安全威胁之一。在过去几年提出的众多内存错误控制解决方案中，大多数在实践中被证明是太弱了。多变体执行(MVX)解决方案可以通过并行运行的各种程序变体中观察到的不同行为来检测任意内存错误漏洞。然而，由于它们的非平凡的性能限制，它们都没有在安全性方面找到实际的应用。在本文中，我们介绍了MvArmor，这是一个MVX系统，它使用硬件辅助的进程虚拟化来以高效而安全的方式监控不同行为的变体。为了提供针对内存错误利用的全面保护，MvArmor依赖于一种新的MVX感知变体生成策略。该系统支持用户可配置的安全策略，以调整性能与安全之间的平衡。我们的分析表明，即使采用保守的检测策略，MvArmor也能以适度的性能开销为代价对抗多种类型的现代攻击。",
                    "title_zh": "使用硬件辅助进程虚拟化的安全高效的多变体执行"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.47",
                    "title": "Overhaul: Input-Driven Access Control for Better Privacy on Traditional Operating Systems",
                    "authors": "Kaan Onarlioglu, William Robertson, Engin Kirda",
                    "abstract": "The prevailing security model for OSes focuses on isolating users from each other, however, the changing computing landscape has led to the extension of traditional access control models for single-user devices. Modern OSes for mobile devices such as iOS and Android have taken the opportunity provided by these new platforms to introduce permission systems in which users can manage access to sensitive resources during application installation or runtime. One drawback of similar efforts on desktop environments is that applications must be rewritten with this security model in mind, which hinders traditional OSes from enjoying the benefits of user-driven access control. We present a novel architecture for retrofitting a dynamic, input-driven access control model into traditional OSes. In this model, access to privacy-sensitive resources is mediated based on the temporal proximity of user interactions to access requests, and requests are communicated back to the user via visual alerts. We present a prototype implementation and demonstrate how input-driven access control can be realized for resources such as the microphone, camera, clipboard, and screen contents. Our approach is transparent to applications and users, and incurs no discernible performance overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "目前流行的操作系统安全模型侧重于将用户相互隔离，然而，不断变化的计算环境导致了传统的单用户设备访问控制模型的扩展。iOS和Android等现代移动设备操作系统利用这些新平台提供的机会引入了权限系统，用户可以在应用程序安装或运行时管理对敏感资源的访问。在桌面环境上进行类似努力的一个缺点是，应用程序必须根据这种安全模型进行重写，这阻碍了传统操作系统享受用户驱动的访问控制的好处。我们提出了一种新的架构，用于将动态的、输入驱动的访问控制模型改造到传统的操作系统中。在这种模型中，对隐私敏感资源的访问是基于用户交互与访问请求的时间接近度来调节的，并且请求通过视觉警报传达回用户。我们展示了一个原型实现，并演示了如何对麦克风、摄像头、剪贴板和屏幕内容等资源实现输入驱动的访问控制。我们的方法对应用程序和用户是透明的，不会导致明显的性能开销。",
                    "title_zh": "革新:输入驱动的访问控制，在传统操作系统上实现更好的隐私保护"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.48",
                    "title": "Kizzle: A Signature Compiler for Detecting Exploit Kits",
                    "authors": "Ben Stock, Benjamin Livshits, Benjamin G. Zorn",
                    "abstract": "In recent years, the drive-by malware space has undergone significant consolidation. Today, the most common source of drive-by downloads are so-called exploit kits (EKs). This paper presents Kizzle, the first prevention technique specifically designed for finding exploit kits. Our analysis shows that while the JavaScript delivered by kits varies greatly, the unpacked code varies much less, due to the kits authors' code reuse between versions. Ironically, this well-regarded software engineering practice allows us to build a scalable and precise detector that is able to quickly respond to superficial but frequent changes in EKs. Kizzle is able to generate anti-virus signatures for detecting EKs, which compare favorably to manually created ones. Kizzle is highly responsive and can generate new signatures within hours. Our experiments show that Kizzle produces high-accuracy signatures. When evaluated over a four-week period, false-positive rates for Kizzle are under 0.03%, while the false-negative rates are under 5%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，恶意软件领域经历了重大整合。今天，最常见的驱动下载来源是所谓的漏洞工具包(EKs)。本文介绍了Kizzle，这是第一种专门为寻找漏洞工具包而设计的防范技术。我们的分析表明，虽然工具包交付的JavaScript差异很大，但未打包的代码差异很小，这是因为工具包作者在不同版本之间重用了代码。具有讽刺意味的是，这种备受推崇的软件工程实践允许我们构建一种可扩展的精确检测器，能够快速响应心电图表面但频繁的变化。Kizzle能够生成用于检测EKs的反病毒签名，与手动创建的签名相比，它更具优势。Kizzle响应速度非常快，可以在几个小时内生成新的签名。我们的实验表明，Kizzle产生了高精度的签名。经过四周的评估，Kizzle的假阳性率低于0.03%，而假阴性率低于5%。",
                    "title_zh": "Kizzle:一个用于检测漏洞工具包的签名编译器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.49",
                    "title": "A Sharper Sense of Self: Probabilistic Reasoning of Program Behaviors for Anomaly Detection with Context Sensitivity",
                    "authors": "Kui Xu, Ke Tian, Danfeng Yao, Barbara G. Ryder",
                    "abstract": "Program anomaly detection models legitimate behaviors of complex software and detects deviations during execution. Behavior deviations may be caused by malicious exploits, design flaws, or operational errors. Probabilistic detection computes the likelihood of occurrences of observed call sequences. However, maintaining context sensitivity in detection incurs high modeling complexity and runtime overhead. We present a new anomaly-based detection technique that is both probabilistic and 1-level calling-context sensitive. We describe a matrix representation and clustering-based solution for model reduction, specifically reducing the number of hidden states in a special hidden Markov model whose parameters are initialized with program analysis. Our extensive experimental evaluation confirms the significantly improved detection accuracy and shows that attacker's ability to conduct code-reuse exploits is substantially limited.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "程序异常检测模拟复杂软件的合法行为，并检测执行过程中的偏差。行为偏差可能由恶意利用、设计缺陷或操作错误引起。概率检测计算观察到的调用序列出现的可能性。然而，在检测中保持上下文敏感性会导致很高的建模复杂度和运行时开销。我们提出了一种新的基于异常的检测技术，它既是概率性的，又是一级调用上下文敏感的。我们描述了一种用于模型缩减的矩阵表示和基于聚类的解决方案，特别是在一个特殊的隐藏马尔可夫模型中减少隐藏状态的数量，该模型的参数通过程序分析来初始化。我们广泛的实验评估证实了检测准确性的显著提高，并表明攻击者进行代码重用利用的能力受到了极大的限制。",
                    "title_zh": "更敏锐的自我意识:基于上下文敏感性的异常检测程序行为的概率推理"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.50",
                    "title": "BAYWATCH: Robust Beaconing Detection to Identify Infected Hosts in Large-Scale Enterprise Networks",
                    "authors": "Xin Hu, Jiyong Jang, Marc Ph. Stoecklin, Ting Wang, Douglas Lee Schales, Dhilung Kirat, Josyula R. Rao",
                    "abstract": "Sophisticated cyber security threats, such as advanced persistent threats, rely on infecting end points within a targeted security domain and embedding malware. Typically, such malware periodically reaches out to the command and control infrastructures controlled by adversaries. Such callback behavior, called beaconing, is challenging to detect as (a) detection requires long-term temporal analysis of communication patterns at several levels of granularity, (b) malware authors employ various strategies to hide beaconing behavior, and (c) it is also employed by legitimate applications (such as updates checks). In this paper, we develop a comprehensive methodology to identify stealthy beaconing behavior from network traffic observations. We use an 8-step filtering approach to iteratively refine and eliminate legitimate beaconing traffic and pinpoint malicious beaconing cases for in-depth investigation and takedown. We provide a systematic evaluation of our core beaconing detection algorithm and conduct a large-scale evaluation of web proxy data (more than 30 billion events) collected over a 5-month period at a corporate network comprising over 130,000 end-user devices. Our findings indicate that our approach reliably exposes malicious beaconing behavior, which may be overlooked by traditional security mechanisms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "复杂的网络安全威胁，如高级持续威胁，依赖于感染目标安全域内的端点和嵌入恶意软件。通常，这种恶意软件会定期攻击由对手控制的命令和控制基础设施。这种称为信标的回调行为很难检测，因为(a)检测需要在几个粒度级别对通信模式进行长期的时间分析，(b)恶意软件作者采用各种策略来隐藏信标行为，以及(c)它也被合法应用程序采用(如更新检查)。在本文中，我们开发了一个综合的方法来识别网络流量观测的隐形信标行为。我们使用八步过滤方法来反复提炼和消除合法信标流量，并查明恶意信标案例，以便进行深入调查和清除。我们对我们的核心信标检测算法进行了系统评估，并对一个包含130，000多台最终用户设备的企业网络在5个月内收集的web代理数据(超过300亿个事件)进行了大规模评估。我们的发现表明，我们的方法可靠地揭露了恶意信标行为，这可能被传统的安全机制所忽略。",
                    "title_zh": "海滩救护队:在大规模企业网络中识别受感染主机的健壮信标检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.51",
                    "title": "DomainProfiler: Discovering Domain Names Abused in Future",
                    "authors": "Daiki Chiba, Takeshi Yagi, Mitsuaki Akiyama, Toshiki Shibahara, Takeshi Yada, Tatsuya Mori, Shigeki Goto",
                    "abstract": "Cyber attackers abuse the domain name system (DNS) to mystify their attack ecosystems, they systematically generate a huge volume of distinct domain names to make it infeasible for blacklisting approaches to keep up with newly generated malicious domain names. As a solution to this problem, we propose a system for discovering malicious domain names that will likely be abused in future. The key idea with our system is to exploit temporal variation patterns (TVPs) of domain names. The TVPs of domain names include information about how and when a domain name has been listed in legitimate/popular and/or malicious domain name lists. On the basis of this idea, our system actively collects DNS logs, analyzes their TVPs, and predicts whether a given domain name will be used for malicious purposes. Our evaluation revealed that our system can predict malicious domain names 220 days beforehand with a true positive rate of 0.985.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络攻击者滥用域名系统(DNS)来迷惑他们的攻击生态系统，他们系统地生成大量不同的域名，使黑名单方法无法跟上新生成的恶意域名。作为这个问题的解决方案，我们提出了一个系统，用于发现将来可能被滥用的恶意域名。我们系统的关键思想是利用域名的时间变化模式(tvp)。域名的tvp包括关于域名如何以及何时被列入合法/流行和/或恶意域名列表的信息。基于这一思想，我们的系统主动收集DNS日志，分析它们的tvp，预测给定的域名是否会被用于恶意目的。我们的评估显示，我们的系统可以提前220天预测恶意域名，正确率为0.985。",
                    "title_zh": "DomainProfiler:发现未来被滥用的域名"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.52",
                    "title": "FTP: The Forgotten Cloud",
                    "authors": "Drew Springall, Zakir Durumeric, J. Alex Halderman",
                    "abstract": "Once pervasive, the File Transfer Protocol (FTP) has been largely supplanted by HTTP, SCP, and BitTorrent for transferring data between hosts. Yet, in a comprehensive analysis of the FTP ecosystem as of 2015, we find that there are still more than 13~million FTP servers in the IPv4 address space, 1.1~million of which allow \"anonymous\" (public) access. These anonymous FTP servers leak sensitive information, such as tax documents and cryptographic secrets. More than 20,000 FTP servers allow public write access, which has facilitated malicious actors' use of free storage as well as malware deployment and click-fraud attacks. We further investigate real-world attacks by deploying eight FTP honeypots, shedding light on how attackers are abusing and exploiting vulnerable servers. We conclude with lessons and recommendations for securing FTP.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "文件传输协议(FTP)曾经非常普及，现在已经被HTTP、SCP和BitTorrent所取代，用于在主机之间传输数据。然而，在对截至2015年的FTP生态系统的全面分析中，我们发现IPv4地址空间中仍有超过1300万台FTP服务器，其中110万台允许“匿名”(公共)访问。这些匿名FTP服务器会泄露敏感信息，如税务文档和加密秘密。超过20，000个FTP服务器允许公共写入访问，这为恶意行为者使用免费存储以及恶意软件部署和点击欺诈攻击提供了便利。我们通过部署八个FTP蜜罐进一步调查真实世界的攻击，揭示攻击者如何滥用和利用易受攻击的服务器。最后，我们总结了保护FTP的经验和建议。",
                    "title_zh": "FTP:被遗忘的云"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.53",
                    "title": "Practical, Formal Synthesis and Automatic Enforcement of Security Policies for Android",
                    "authors": "Hamid Bagheri, Alireza Sadeghi, Reyhaneh Jabbarvand Behrouz, Sam Malek",
                    "abstract": "As the dominant mobile computing platform, Android has become a prime target for cyber-security attacks. Many of these attacks are manifested at the application level, and through the exploitation of vulnerabilities in apps downloaded from the popular app stores. Increasingly, sophisticated attacks exploit the vulnerabilities in multiple installed apps, making it extremely difficult to foresee such attacks, as neither the app developers nor the store operators know a priori which apps will be installed together. This paper presents an approach that allows the end-users to safeguard a given bundle of apps installed on their device from such attacks. The approach, realized in a tool, called SEPAR, combines static analysis with lightweight formal methods to automatically infer security-relevant properties from a bundle of apps. It then uses a constraint solver to synthesize possible security exploits, from which fine-grained security policies are derived and automatically enforced to protect a given device. In our experiments with over 4,000 Android apps, SEPAR has proven to be highly effective at detecting previously unknown vulnerabilities as well as preventing their exploitation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为占主导地位的移动计算平台，Android已经成为网络安全攻击的主要目标。这些攻击中的许多都表现在应用程序级别，并通过利用从流行的应用程序商店下载的应用程序中的漏洞。复杂的攻击越来越多地利用多个已安装应用程序中的漏洞，这使得预测此类攻击变得极其困难，因为应用程序开发人员和商店运营商都不知道哪些应用程序将被一起安装。本文介绍了一种方法，允许最终用户保护安装在他们设备上的给定应用包免受此类攻击。这种方法是在一个名为SEPAR的工具中实现的，它将静态分析与轻量级形式方法结合起来，从一堆应用程序中自动推断出安全相关的属性。然后，它使用约束求解器来综合可能的安全利用，从中导出细粒度的安全策略并自动执行以保护给定的设备。在我们对超过4，000个Android应用程序的实验中，SEPAR已被证明在检测以前未知的漏洞以及防止其被利用方面非常有效。",
                    "title_zh": "Android安全策略的实用、正式综合和自动实施"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.54",
                    "title": "Don't Just BYOD, Bring-Your-Own-App Too! Protection via Virtual Micro Security Perimeters",
                    "authors": "Gabriel Salles-Loustau, Luis Garcia, Kaustubh R. Joshi, Saman A. Zonouz",
                    "abstract": "Mobile devices are increasingly becoming a melting pot of different types of data ranging from sensitive corporate documents to commercial media to personal content produced and shared via online social networks. While it is desirable for such diverse content to be accessible from the same device via a unified user experience and through a rich plethora of mobile apps, ensuring that this data remains protected has become challenging. Even though different data types have very different security and privacy needs and accidental instances of data leakage are common, today's mobile operating systems include few, if any, facilities for fine-grained data protection and isolation. In this paper, we present SWIRLS, an Android-based mobile OS that provides a rich policy-based information-flow data protection abstraction for mobile apps to support BYOD (bring-your-own-device) use cases. SWIRLS allows security and privacy policies to be attached to individual pieces of data contained in signed and encrypted capsules, and enforces these policies as the data flows through the device. Unlike current BYOD solutions like VMs and containers that create duplication and cognitive overload, SWIRLS provides a single environment that allows users to access content belonging to different security contexts using the same applications without fear of inadverdant or malicious data leakage. SWIRLS also unburdens app developers from having to worry about security policies, and provides APIs through which they can create seamless multi-security-context user interfaces. To implement it's abstractions, SWIRLS develops a cryptographically protected capsule distribution and installation scheme, enhances Taintdroid-based taint-tracking mechanisms to support efficient kernel and user-space security policy enforcement, implements techniques for persisting security context along with data, and provides transparent security-context switching mechanisms. Using our Android-based prototype (>25K LOC), we show a number of data protection use-cases such as isolation of personal and work data, limiting document sharing and preventing leakage based on document classification, and security policies based on geo-and time-fencing. Our experiments show that SWIRLS imposes a very minimal overhead in both battery consumption and performance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "移动设备正日益成为不同类型数据的大熔炉，从敏感的公司文件到商业媒体，再到通过在线社交网络制作和分享的个人内容。虽然人们希望通过统一的用户体验和丰富的移动应用程序从同一台设备上访问如此多样的内容，但确保这些数据受到保护却变得颇具挑战性。尽管不同的数据类型具有非常不同的安全性和隐私需求，并且数据泄漏的意外情况很常见，但当今的移动操作系统几乎没有(如果有的话)用于细粒度数据保护和隔离的设施。在本文中，我们介绍了基于Android的移动操作系统SWIRLS，它为移动应用程序提供了丰富的基于策略的信息流数据保护抽象，以支持BYOD(自带设备)用例。SWIRLS允许将安全和隐私政策附加到包含在签名和加密胶囊中的单个数据片段上，并在数据流经设备时强制执行这些政策。与当前的BYOD解决方案(如虚拟机和容器)不同，这些解决方案会造成重复和认知超载，而SWIRLS提供了一个单一的环境，允许用户使用相同的应用程序访问属于不同安全环境的内容，而不必担心无意或恶意的数据泄漏。SWIRLS还让应用程序开发人员不必担心安全策略，并提供了API，他们可以通过这些API创建无缝的多安全上下文用户界面。为了实现其抽象，SWIRLS开发了一个加密保护的胶囊分发和安装方案，增强了基于Taintdroid的污点跟踪机制以支持高效的内核和用户空间安全策略实施，实现了将安全上下文与数据一起持久化的技术，并提供了透明的安全上下文切换机制。使用我们基于Android的原型(> 25K LOC)，我们展示了许多数据保护用例，如隔离个人和工作数据、基于文档分类限制文档共享和防止泄露，以及基于地理和时间防护的安全策略。我们的实验表明，漩涡在电池消耗和性能方面的开销非常小。",
                    "title_zh": "不要自带设备，也要自带应用！通过虚拟微安全边界提供保护"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.55",
                    "title": "Can We Trust the Privacy Policies of Android Apps?",
                    "authors": "Le Yu, Xiapu Luo, Xule Liu, Tao Zhang",
                    "abstract": "Recent years have witnessed the sharp increase of malicious apps that steal users' personal information. To address users' concerns about privacy risks, more and more apps are accompanied with privacy policies written in natural language because it is difficult for users to infer an app's behaviors according to the required permissions. However, little is known whether these privacy policies are trustworthy or not. It is worth noting that a questionable privacy policy may result from careless preparation by an app developer or intentional deception by an attacker. In this paper, we conduct the first systematic study on privacy policy by proposing a novel approach to automatically identify three kinds of problems in privacy policy. After tackling several challenging issues, we realize our approach in a system, named PPChecker, and evaluate it with real apps and privacy policies. The experimental results show that PPChecker can effectively identify questionable privacy policies with high precision. Moreover, applying PPChecker to 1,197 popular apps, we found that 282 apps (i.e., 23.6%) have at least one kind of problems. This study sheds light on the research of improving and regulating apps' privacy policies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，窃取用户个人信息的恶意应用急剧增加。为了解决用户对隐私风险的担忧，越来越多的应用程序附带了用自然语言编写的隐私政策，因为用户很难根据所需的权限推断应用程序的行为。然而，很少有人知道这些隐私政策是否值得信赖。值得注意的是，有问题的隐私政策可能是由应用程序开发人员的粗心准备或攻击者的故意欺骗造成的。本文首次对隐私策略进行了系统的研究，提出了一种新的方法来自动识别隐私策略中的三类问题。在解决了几个具有挑战性的问题后，我们在一个名为PPChecker的系统中实现了我们的方法，并用实际应用和隐私策略对其进行了评估。实验结果表明，PPChecker能有效识别可疑隐私策略，准确率较高。此外，将PPChecker应用于1197个流行应用程序，我们发现282个应用程序(即23.6%)至少存在一种问题。该研究为改进和规范应用程序隐私政策的研究提供了启示。",
                    "title_zh": "我们能相信安卓应用的隐私政策吗？"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.56",
                    "title": "Repackage-Proofing Android Apps",
                    "authors": "Lannan Luo, Yu Fu, Dinghao Wu, Sencun Zhu, Peng Liu",
                    "abstract": "App repackaging has become a severe threat to theAndroid ecosystem. While various protection techniques, such as watermarking and repackaging detection, have been proposed, a defense that stops repackaged apps from working on user devices, i.e., repackage-proofing, is missing. We propose a technique that builds a reliable and stealthy repackage-proofing capability into Android apps. A large number of detection nodes are inserted into the original app without incurring much overhead, each is woven into the surrounding code to blur itself. Once repackaging is detected, a response node injects a failure in the form of delayed malfunctions, making it difficult to trace back. The response nodes and detection nodes form high-degree connections and communicate through stealthy communication channels, such that upon detection several of the many response nodes are selected stochastically to take actions, which further obfuscates and enhances the protection. We have built a prototype. The evaluation shows that the technique is effective and efficient.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "应用程序重新打包已经对机器人生态系统构成了严重威胁。虽然已经提出了各种保护技术，例如水印和重新打包检测，但是缺少阻止重新打包的应用在用户设备上工作的防御措施，即重新打包防护。我们提出了一种技术，在Android应用程序中建立一种可靠的、秘密的防重新包装功能。大量检测节点被插入到原始应用程序中，而不会产生太多开销，每个节点都被编织到周围的代码中，以模糊自身。一旦重新打包被检测到，响应节点就会以延迟故障的形式注入一个失败，从而很难追溯。响应节点和检测节点形成高度连接，并通过秘密通信信道进行通信，使得在检测时随机选择多个响应节点中的几个来采取行动，这进一步混淆和增强了保护。我们已经建造了一个原型。评价表明该技术是有效的。",
                    "title_zh": "重新包装验证Android应用程序"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.57",
                    "title": "Measuring the Role of Greylisting and Nolisting in Fighting Spam",
                    "authors": "Fabio Pagani, Matteo De Astis, Mariano Graziano, Andrea Lanzi, Davide Balzarotti",
                    "abstract": "Spam has been largely studied in the past years from different perspectives but, unfortunately, it is still an open problem and a lucrative and active business for criminals and bot herders. While several countermeasures have been proposed and deployed in the past decade, their impact and effectiveness is not always clear. In particular, on top of the most common content-and sender-based anti-spam techniques, two minor approaches are popular among system administrators to cope with this annoying problem: greylisting and nolisting. These techniques exploit known features of the Simple Mail Transfer Protocol (SMTP) protocol that are not often respected by spambots. This assumption makes these two countermeasures really simple to adopt and, at least in theory, quite effective. In this paper we present the first comprehensive study of nolisting and greylisting, in which we analyze these spam countermeasures from different perspectives. First, we measure their world-wide deployment and provide insights from their distribution. Second, we measure their effectiveness against areal dataset of malware samples responsible to generate over 70% of the global spam traffic. Finally, we measure the impact of these two defensive mechanisms on the delivery of normal emails. Our study provides a unique and valuable perspective on two of the most innovative and atypical anti-spam systems. Our findings may guide system administrators and security experts to better assess their anti-spam infrastructure and shed some light on myths about greylisting and nolisting.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在过去的几年里，人们从不同的角度对垃圾邮件进行了大量的研究，但不幸的是，对于罪犯和机器人牧民来说，垃圾邮件仍然是一个公开的问题和一个有利可图的活跃业务。虽然在过去十年中已经提出并部署了一些对策，但它们的影响和有效性并不总是很清楚。特别是，除了最常见的基于内容和发件人的反垃圾邮件技术之外，系统管理员还流行两种较小的方法来处理这个恼人的问题:灰名单和无名单。这些技术利用简单邮件传输协议(SMTP)协议的已知功能，而垃圾邮件通常不考虑这些功能。这种假设使得这两种对策非常容易采用，并且至少在理论上非常有效。在本文中，我们首次对黑名单和灰名单进行了全面的研究，从不同的角度分析了这些垃圾邮件对策。首先，我们衡量他们在世界范围内的部署，并从他们的分布提供见解。其次，我们根据恶意软件样本的区域数据集来衡量它们的有效性，这些恶意软件样本产生了超过70%的全球垃圾邮件流量。最后，我们测量这两种防御机制对正常电子邮件传递的影响。我们的研究为两个最具创新性和非典型的反垃圾邮件系统提供了独特而有价值的视角。我们的发现可能会指导系统管理员和安全专家更好地评估他们的反垃圾邮件基础设施，并揭示一些关于灰名单和无名单的神话。",
                    "title_zh": "衡量灰名单和不名单在打击垃圾邮件中的作用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.58",
                    "title": "Malware Slums: Measurement and Analysis of Malware on Traffic Exchanges",
                    "authors": "Salman Yousaf, Umar Iqbal, Shehroze Farooqi, Raza Ahmad, Muhammad Zubair Shafiq, Fareed Zaffar",
                    "abstract": "Auto-surf and manual-surf traffic exchanges are an increasingly popular way of artificially generating website traffic. Previous research in this area has focused on the makeup, usage, and monetization of underground traffic exchanges. In this paper, we analyze the role of traffic exchanges as a vector for malware propagation. We conduct a measurement study of nine auto-surf and manual-surf traffic exchanges over several months. We present a first of its kind analysis of the different types of malware that are propagated through these traffic exchanges. We find that more than 26% of the URLs surfed on traffic exchanges contain malicious content. We further analyze different categories of malware encountered on traffic exchanges, including blacklisted domains, malicious JavaScript, malicious Flash, and malicious shortened URLs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动冲浪和手动冲浪流量交换是一种日益流行的人工生成网站流量的方式。这一领域以前的研究集中在地下交通交易所的构成、使用和货币化上。在本文中，我们分析了流量交换作为恶意软件传播媒介的作用。我们对九个自动冲浪和手动冲浪的流量交换进行了几个月的测量研究。我们首次对通过这些流量交换传播的不同类型的恶意软件进行了分析。我们发现超过26%的流量交换网址包含恶意内容。我们进一步分析了流量交换中遇到的不同类别的恶意软件，包括黑名单域、恶意JavaScript、恶意Flash和恶意缩短的URL。",
                    "title_zh": "恶意软件贫民窟:流量交换中恶意软件的测量和分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.59",
                    "title": "Secure Point-of-Care Medical Diagnostics via Trusted Sensing and Cyto-Coded Passwords",
                    "authors": "Tuan Le, Gabriel Salles-Loustau, Laleh Najafizadeh, Mehdi Javanmard, Saman A. Zonouz",
                    "abstract": "Trustworthy and usable healthcare requires not only effective disease diagnostic procedures to ensure delivery of rapid and accurate outcomes, but also lightweight user privacy-preserving capabilities for resource-limited medical sensing devices. In this paper, we present MedSen, a portable, inexpensive and secure smartphone-based biomarker1 detection sensor to provide users with easy-to-use real-time disease diagnostic capabilities without the need for in-person clinical visits. To minimize the deployment cost and size without sacrificing the diagnostic accuracy, security and time requirement, MedSen operates as a dongle to the user's smartphone and leverages the smartphone's computational capabilities for its real-time data processing. From the security viewpoint, MedSen introduces a new hardware-level trusted sensing framework, built in the sensor, to encrypt measured analog signals related to cell counting in the patient's blood sample, at the data acquisition point. To protect the user privacy, MedSen's in-sensor encryption scheme conceals the user's private information before sending them out for cloud-based medical diagnostics analysis. The analysis outcomes are sent back to Med-Sen for decryption and user notifications. Additionally, MedSen introduces cyto-coded passwords to authenticate the user to the cloud server without the need for explicit screen password entry. Each user's password constitutes a predetermined number of synthetic beads with different dielectric characteristics. MedSen mixes the password beads with the user's blood before submitting the data for diagnostics analysis. The cloud server authenticates the user based on the statistics and characteristics of the beads with the blood sample, and links the user's identity to the encrypted analysis outcomes. We have implemented a real-world working prototype of MedSen through bio-sensor fabrication and smartphone app (Android) implementations. Our results show that MedSen can reliably classify different users based on their cyto-coded passwords with high accuracy. MedSen's built-in analog signal encryption guarantees the user's privacy by considering the smartphone and cloud server possibly untrusted (curious but honest). MedSen's end-to-end time requirement for disease diagnostics is approximately 0.2 seconds on average.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可信和可用的医疗保健不仅需要有效的疾病诊断程序来确保提供快速和准确的结果，还需要资源有限的医疗传感设备具有轻量级的用户隐私保护能力。在本文中，我们介绍了一种便携式、廉价且安全的基于智能手机的生物标记1检测传感器MedSen，它可以为用户提供易于使用的实时疾病诊断功能，而无需亲临临床。为了在不牺牲诊断准确性、安全性和时间要求的情况下最大限度地降低部署成本和尺寸，MedSen充当用户智能手机的加密狗，并利用智能手机的计算能力进行实时数据处理。从安全角度来看，MedSen引入了一种新的硬件级可信传感框架，内置于传感器中，在数据采集点对与患者血样中细胞计数相关的测量模拟信号进行加密。为了保护用户隐私，MedSen的传感器内加密方案在将用户的私人信息发送出去进行基于云的医疗诊断分析之前，会隐藏这些信息。分析结果被发送回Med-Sen进行解密和用户通知。此外，MedSen引入了细胞编码密码，无需显式输入屏幕密码即可向云服务器验证用户身份。每个用户的密码由预定数量的具有不同介电特性的合成珠子组成。在提交数据进行诊断分析之前，MedSen会将密码珠与用户的血液混合。云服务器基于带有血液样本的珠子的统计数据和特征来认证用户，并将用户的身份链接到加密的分析结果。我们已经通过生物传感器制造和智能手机应用程序(Android)实施实现了MedSen的真实工作原型。我们的结果表明，MedSen可以基于不同用户的细胞编码密码高精度地对其进行可靠分类。MedSen内置的模拟信号加密通过考虑智能手机和云服务器可能不可信(好奇但诚实)来保证用户的隐私。MedSen对疾病诊断的端到端时间要求平均约为0.2秒。",
                    "title_zh": "通过可信的传感和细胞编码密码实现安全的现场医疗诊断"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.60",
                    "title": "fuzzyPSM: A New Password Strength Meter Using Fuzzy Probabilistic Context-Free Grammars",
                    "authors": "Ding Wang, Debiao He, Haibo Cheng, Ping Wang",
                    "abstract": "To provide timely feedbacks to users, nearly every respectable Internet service now imposes a password strength meter (PSM) upon user registration or password change. It is a rare bit of good news in password research that well-designed PSMs do help improve the strength of user-chosen passwords. However, leading PSMs in the industrial world (e.g., Zxcvbn, KeePSM and NIST PSM) are mainly composed of simple heuristic rules and found to be highly inaccurate, while state-of-the-art PSMs from academia (e.g., probabilistic context-free grammar based ones and Markov-based ones) are still far from satisfactory, especially incompetent at gauging weak passwords. As preventing weak passwords is the primary goal of any PSM, this means that existing PSMs largely fail to serve their purpose. To fill this gap, in this paper we propose a novel PSM that is grounded on real user behavior. Our user survey reveals that when choosing passwords for a new web service, most users (77.38%) simply retrieve one of their existing passwords from memory and then reuse (or slightly modify) it. This is in vast contrast to the seemingly intuitive yet unrealistic assumption (often implicitly) made in most of the existing PSMs that, when user registers, a whole new password is constructed by mixing segments of letter, digit and/or symbol or by combining n-grams. To model users' realistic behaviors, we use passwords leaked from a less sensitiveservice as our base dictionary and another list of relatively strong passwords leaked from a sensitive service as our training dictionary, and determine how mangling rules are employed by users to construct passwords for new services. This process automatically creates a fuzzy probabilistic context-free grammar (PCFG) and gives rise to our fuzzy-PCFG-based meter, fuzzyPSM. It can react dynamically to changes in how users choose passwords and is evaluated by comparisons with five representative PSMs. Extensive experiments on 11 real-world password lists show that fuzzyPSM, in general, outperforms all its counterparts, especially accurate in telling apart weak passwords and suitable for services where online guessing attacks prevail.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了向用户提供及时的反馈，几乎每一个值得尊敬的互联网服务现在都在用户注册或密码更改时强制使用密码强度计(PSM)。在密码研究中，设计良好的PSM确实有助于提高用户选择的密码的强度，这是一个难得的好消息。然而，工业世界中领先的PSM(例如，Zxcvbn、KeePSM和NIST PSM)主要由简单的启发式规则组成，并且被发现是非常不准确的，而来自学术界的最先进的PSM(例如，基于概率上下文无关语法的PSM和基于马尔可夫的PSM)仍然远不能令人满意，尤其是在测量弱密码方面不胜任。由于防止弱密码是任何PSM的主要目标，这意味着现有的PSM在很大程度上无法达到其目的。为了填补这一空白，本文提出了一种基于真实用户行为的新型PSM。我们的用户调查显示，当选择新web服务的密码时，大多数用户(77.38%)只是从内存中检索他们现有的密码之一，然后重用(或稍微修改)它。这与大多数现有的PSM中做出的看似直观但不现实的假设(通常是隐含的)形成了巨大的对比，即当用户注册时，通过混合字母、数字和/或符号的片段或者通过组合n-gram来构建全新的密码。为了模拟用户的实际行为，我们使用从不太敏感的服务泄露的密码作为我们的基本字典，使用从敏感服务泄露的另一个相对强的密码列表作为我们的训练字典，并确定用户如何使用mangling规则来构造新服务的密码。这个过程自动创建了一个模糊概率上下文无关文法(PCFG ),并产生了我们的基于模糊PCFG的度量工具fuzzyPSM。它可以对用户选择密码的方式的变化做出动态反应，并通过与五个有代表性的PSM进行比较来进行评估。在11个真实世界密码列表上进行的大量实验表明，fuzzyPSM总体上优于所有同类产品，尤其是在区分弱密码方面更为准确，并且适用于在线猜测攻击盛行的服务。",
                    "title_zh": "fuzzyPSM:一种新的使用模糊概率上下文无关文法的密码强度计"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.61",
                    "title": "Balancing Security and Performance for Agility in Dynamic Threat Environments",
                    "authors": "Michael L. Winterrose, Kevin M. Carter, Neal Wagner, William W. Streilein",
                    "abstract": "In cyber security, achieving the desired balance between system security and system performance in dynamic threat environments is a long-standing open challenge for cyber defenders. Typically an increase in system security comes at the price of decreased system performance, and vice versa, easily resulting in systems that are misaligned to operator specified requirements for system security and performance as the threat environment evolves. We develop an online, reinforcement learning based methodology to automatically discover and maintain desired operating postures in security-performance space even as the threat environment changes. We demonstrate the utility of our approach and discover parameters enabling an agile response to a dynamic adversary in a simulated security game involving prototype cyber moving target defenses.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在网络安全中，在动态威胁环境中实现系统安全和系统性能之间的理想平衡是网络防御者长期面临的公开挑战。通常，系统安全性的提高是以降低系统性能为代价的，反之亦然，随着威胁环境的发展，很容易导致系统不符合运营商对系统安全性和性能的特定要求。我们开发了一种基于强化学习的在线方法，即使在威胁环境发生变化的情况下，也能自动发现和维护安全性能空间中所需的操作状态。我们展示了我们的方法的效用，并发现了在涉及原型网络移动目标防御的模拟安全游戏中能够对动态对手做出敏捷响应的参数。",
                    "title_zh": "在动态威胁环境中平衡安全性和性能以实现敏捷性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.62",
                    "title": "Rekeying for Encrypted Deduplication Storage",
                    "authors": "Jingwei Li, Chuan Qin, Patrick P. C. Lee, Jin Li",
                    "abstract": "Rekeying refers to an operation of replacing an existing key with a new key for encryption. It renews security protection, so as to protect against key compromise and enable dynamic access control in cryptographic storage. However, it is non-trivial to realize efficient rekeying in encrypted deduplication storage systems, which use deterministic content-derived encryption keys to allow deduplication on ciphertexts. We design and implement REED, a rekeying-aware encrypted deduplication storage system. REED builds on a deterministic version of all-or-nothing transform (AONT), such that it enables secure and lightweight rekeying, while preserving the deduplication capability. We propose two REED encryption schemes that trade between performance and security, and extend REED for dynamic access control. We implement a REED prototype with various performance optimization techniques. Our trace-driven testbed evaluation shows that our REED prototype maintains high performance and storage efficiency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "密钥更新是指用新密钥替换现有密钥进行加密的操作。它更新了安全保护，以防止密钥泄露，并实现加密存储中的动态访问控制。然而，在加密的去重复存储系统中实现有效的密钥更新是非常重要的，该系统使用确定性的内容导出的加密密钥来允许对密文进行去重复。我们设计并实现了REED，这是一个支持密钥更新的加密重复数据删除存储系统。REED建立在全有或全无变换(AONT)的确定性版本上，因此它支持安全、轻量级的密钥更新，同时保留重复数据删除功能。我们提出了两个REED加密方案，在性能和安全性之间进行权衡，并扩展REED用于动态访问控制。我们用各种性能优化技术实现了一个REED原型。我们的跟踪驱动测试床评估表明，我们的REED原型保持了高性能和存储效率。",
                    "title_zh": "加密重复数据删除存储的密钥更新"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.63",
                    "title": "Equipping WAP with WEAPONS to Detect Vulnerabilities: Practical Experience Report",
                    "authors": "Iberia Medeiros, Nuno Ferreira Neves, Miguel Correia",
                    "abstract": "Although security starts to be taken into account during software development, the tendency for source code to contain vulnerabilities persists. Open source static analysis tools provide a sensible approach to mitigate this problem. However, these tools are programmed to detect a specific set of vulnerabilities and they are often difficult to extend to detect new ones. WAP is a recent popular open source tool that detects vulnerabilities in the source code of web applications written in PHP. The paper addresses the difficulty of extending these tools by proposing a modular and extensible version of the WAP tool, equipping it with \"weapons\" to detect (and correct) new vulnerability classes. The new version of the tool was evaluated with seven new vulnerability classes using web applications and plugins of the widely-adopted WordPress content management system. The experimental results show that this extensibility allows WAP to find many new (zero-day) vulnerabilities.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管在软件开发过程中开始考虑安全性，但是源代码包含漏洞的趋势仍然存在。开源静态分析工具提供了一种明智的方法来缓解这个问题。然而，这些工具被编程为检测一组特定的漏洞，并且它们通常难以扩展到检测新的漏洞。WAP是最近流行的开源工具，它可以检测用PHP编写的web应用程序源代码中的漏洞。本文通过提出WAP工具的模块化和可扩展版本，为其配备检测(和纠正)新漏洞类别的“武器”,解决了扩展这些工具的困难。该工具的新版本使用广泛采用的WordPress内容管理系统的web应用程序和插件，通过七个新的漏洞类别进行了评估。实验结果表明，这种可扩展性允许WAP发现许多新的(零日)漏洞。",
                    "title_zh": "用武器装备WAP来检测漏洞:实践经验报告"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.64",
                    "title": "Characterizing the Consistency of Online Services (Practical Experience Report)",
                    "authors": "Filipe Freitas, João Leitão, Nuno M. Preguiça, Rodrigo Rodrigues",
                    "abstract": "While several proposals for the specification and implementation of various consistency models exist, little is known about what is the consistency currently offered by online services with millions of users. Such knowledge is important, not only because it allows for setting the right expectations and justifying the behavior observed by users, but also because it can be used for improving the process of developing applications that use APIs offered by such services. To fill this gap, this paper presents a measurement study of the consistency of the APIs exported by four widely used Internet services, the Facebook Feed, Facebook Groups, Blogger, and Google+. To conduct this study, our work (1) proposes definitions for a set of relevant consistency properties, (2) develops a simple, yet generic methodology comprising a small number of tests, which probe these services from a user perspective, and try to uncover consistency anomalies that are key to our definitions, and (3) reports on the analysis of the data obtained from running these tests for a period of several weeks. Our measurement study shows that some of these services do exhibit consistency anomalies, including some behaviors that may appear counter-intuitive for users, such as the lack of session guarantees for write monotonicity.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然存在关于各种一致性模型的规范和实现的几个提议，但是对于具有数百万用户的在线服务当前所提供的一致性却知之甚少。这种知识非常重要，不仅因为它允许设置正确的期望值并证明用户观察到的行为是正确的，还因为它可以用于改进开发使用此类服务提供的API的应用程序的过程。为了填补这一空白，本文提出了一个由四个广泛使用的互联网服务，脸书饲料，脸书集团，博客和谷歌+输出的API的一致性的测量研究。为了进行这项研究，我们的工作(1)提出了一组相关一致性属性的定义，(2)开发了一种简单而通用的方法，包括少量的测试，从用户的角度探索这些服务，并试图发现对我们的定义至关重要的一致性异常，以及(3)报告对运行这些测试几周所获得的数据的分析。我们的测量研究表明，其中一些服务确实表现出一致性异常，包括一些对用户来说可能看起来与直觉相反的行为，例如缺乏对写单调性的会话保证。",
                    "title_zh": "表征在线服务的一致性(实践经验报告)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.65",
                    "title": "ELZAR: Triple Modular Redundancy Using Intel AVX (Practical Experience Report)",
                    "authors": "Dmitrii Kuvaiskii, Oleksii Oleksenko, Pramod Bhatotia, Pascal Felber, Christof Fetzer",
                    "abstract": "Instruction-Level Redundancy (ILR) is a well-known approach to tolerate transient CPU faults. It replicates instructions in a program and inserts periodic checks to detect and correct CPU faults using majority voting, which essentially requires three copies of each instruction and leads to high performance overheads. As SIMD technology can operate simultaneously on several copies of the data, it appears to be a good candidate for decreasing these overheads. To verify this hypothesis, we propose ELZAR, a compiler framework that transforms unmodified multithreaded applications to support triple modular redundancy using Intel AVX extensions for vectorization. Our experience with several benchmark suites and real-world case-studies yields mixed results: while SIMD may be beneficial for some workloads, e.g., CPU-intensive ones with many floating-point operations, it exposes higher overhead than ILR in many applications we tested.",
                    "files": {
                        "openAccessPdf": "https://www.pure.ed.ac.uk/ws/files/29266222/1604.00500.pdf"
                    },
                    "abstract_zh": "指令级冗余(ILR)是一种众所周知的容忍瞬时CPU故障的方法。它复制程序中的指令，并插入定期检查，以使用多数表决来检测和纠正CPU故障，这实质上需要每个指令的三个副本，并导致高性能开销。由于SIMD技术可以同时操作多个数据副本，因此它似乎是降低这些开销的一个很好的选择。为了验证这一假设，我们提出了ELZAR，这是一个编译器框架，它使用面向矢量化的AVX扩展来转换未修改的多线程应用，以支持三重模块化冗余。我们在几个基准测试套件和真实案例研究中的经验产生了不同的结果:虽然SIMD可能有利于某些工作负载，例如，具有许多浮点操作的CPU密集型工作负载，但在我们测试的许多应用中，它暴露了比ILR更高的开销。",
                    "title_zh": "ELZAR:采用英特尔AVX的三重模块化冗余(实践经验报告)"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.66",
                    "title": "An Evaluation Study on Log Parsing and Its Use in Log Mining",
                    "authors": "Pinjia He, Jieming Zhu, Shilin He, Jian Li, Michael R. Lyu",
                    "abstract": "Logs, which record runtime information of modern systems, are widely utilized by developers (and operators) in system development and maintenance. Due to the ever-increasing size of logs, data mining models are often adopted to help developers extract system behavior information. However, before feeding logs into data mining models, logs need to be parsed by a log parser because of their unstructured format. Although log parsing has been widely studied in recent years, users are still unaware of the advantages of different log parsers nor the impact of them on subsequent log mining tasks. Thus they often re-implement or even re-design a new log parser, which would be time-consuming yet redundant. To address this issue, in this paper, we study four log parsers and package them into a toolkit to allow their reuse. In addition, we obtain six insightful findings by evaluating the performance of the log parsers on five datasets with over ten million raw log messages, while their effectiveness on a real-world log mining task has been thoroughly examined.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "记录现代系统运行时信息的日志被开发者(和操作者)广泛用于系统开发和维护。由于日志的大小不断增加，通常采用数据挖掘模型来帮助开发人员提取系统行为信息。但是，在将日志提供给数据挖掘模型之前，由于日志的非结构化格式，需要由日志解析器对其进行解析。尽管近年来日志解析得到了广泛的研究，但是用户仍然不知道不同日志解析器的优势以及它们对后续日志挖掘任务的影响。因此，他们经常重新实现甚至重新设计一个新的日志解析器，这既费时又多余。为了解决这个问题，在本文中，我们研究了四个日志解析器，并将它们打包成一个工具包，以允许它们的重用。此外，我们通过在五个数据集上评估日志解析器的性能获得了六个有见地的发现，这五个数据集包含超过一千万条原始日志消息，同时它们在现实世界日志挖掘任务中的有效性也得到了彻底的检验。",
                    "title_zh": "日志解析及其在日志挖掘中的应用评价研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2016.67",
                    "title": "Reliability-Centered Maintenance of the Electrically Insulated Railway Joint via Fault Tree Analysis: A Practical Experience Report",
                    "authors": "Enno Ruijters, Dennis Guck, Martijn van Noort, Mariëlle Stoelinga",
                    "abstract": "Maintenance is an important way to increase system dependability: timely inspections, repairs and renewals can significantly increase a system's reliability, availability and life time. At the same time, maintenance incurs costs and planned downtime. Thus, good maintenance planning has to balance between these factors. In this paper, we study the effect of different maintenance strategies on the electrically insulated railway joint (EI-joint), a critical asset in railroad tracks for train detection, and a relative frequent cause for train disruptions. Together with experts in maintenance engineering, we have modeled the EI-joint as a fault maintenance tree (FMT), i.e. a fault tree augmented with maintenance aspects. We show how complex maintenance concepts, such as condition-based maintenance with periodic inspections, are naturally modeled by FMTs, and how several key performance indicators, such as the system reliability, number of failures, and costs, can be analysed. The faithfulness of quantitative analyses heavily depend on the accuracy of the parameter values in the models. Here, we have been in the unique situation that extensive data could be collected, both from incident registration databases, as well as from interviews with domain experts from several companies. This made that we could construct a model that faithfully predicts the expected number of failures at system level. Our analysis shows that that the current maintenance policy is close to cost-optimal. It is possible to increase joint reliability, e.g. by performing more inspections, but the additional maintenance costs outweigh the reduced cost of failures.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "维护是提高系统可靠性的重要方法:及时检查、维修和更新可以显著提高系统的可靠性、可用性和寿命。同时，维护会产生成本和计划停机时间。因此，良好的维护计划必须平衡这些因素。在本文中，我们研究了不同维护策略对铁路绝缘接头(EI-joint)的影响，该接头是铁路轨道上用于列车检测的关键资产，也是列车中断的相对频繁的原因。与维护工程专家一起，我们将EI-joint建模为故障维护树(FMT)，即增加了维护方面的故障树。我们展示了FMTs如何自然地模拟复杂的维护概念，如基于状态的定期检查维护，以及如何分析几个关键性能指标，如系统可靠性、故障次数和成本。定量分析的可信度很大程度上取决于模型中参数值的准确性。在这里，我们遇到了独特的情况，可以从事件注册数据库以及与几家公司的领域专家的访谈中收集大量数据。这使得我们可以构建一个模型，忠实地预测系统级的预期故障数。我们的分析表明，当前的维护策略接近成本最优。可以增加接头的可靠性，例如通过进行更多的检查，但是额外的维护成本超过了减少的故障成本。",
                    "title_zh": "通过故障树分析以可靠性为中心的铁路绝缘接头维护:实践经验报告"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2016w.html",
            "conf_title": "46th DSN 2016: Toulouse, France - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7575326/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.68",
                    "title": "Introduction to RADIANCE 2016",
                    "authors": "Ariadne M. B. R. Carvalho, Nuno Antunes, Andrea Ceccarelli, András Zentai",
                    "abstract": "Recent Advances in the DependabIlity AssessmeNt of Complex systEms workshop description.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "复杂系统可靠性评估的最新进展。",
                    "title_zh": "RADIANCE 2016简介"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.27",
                    "title": "Use of Similarity Measure to Suggest the Existence of Duplicate User Stories in the Srum Process",
                    "authors": "R. Barbosa, Ana Estela Antunes da Silva, Regina Moraes",
                    "abstract": "In the Scrum process, Product Backlog consists of a prioritized list of desired software functionalities recorded in the form of user stories. As the software product is developed, new functionalities are discovered and included in the Product Backlog. However, in large-scale projects, duplicate stories may arise because of the large number of generated stories, the lack of communication among team members, and due to the speed of development imposed by the Scrum process. In this case, it is important to detect such story as being duplicate, in order to avoid the rework of the software feature. This paper presents an approach that uses semantic similarity measures to suggest possible cases of duplication between user stories. This alert can help Product Owners and Scrum Masters in the decision about excluding duplicate user stories from the Product Backlog.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在Scrum过程中，产品Backlog由以用户故事形式记录的期望软件功能的优先列表组成。随着软件产品的开发，新的功能被发现并包含在产品待办事项中。然而，在大规模的项目中，由于大量生成的故事，团队成员之间缺乏交流，以及Scrum过程强加的开发速度，重复的故事可能会出现。在这种情况下，为了避免软件特性的返工，检测到这样的故事是重复的是很重要的。本文提出了一种方法，使用语义相似性度量来建议用户故事之间可能的重复情况。这个警告可以帮助产品所有者和Scrum Masters决定从产品Backlog中排除重复的用户故事。",
                    "title_zh": "使用相似性度量来表明在Srum过程中存在重复的用户情景"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.50",
                    "title": "Code Change History and Software Vulnerabilities",
                    "authors": "Marcus Pianco, Baldoino Fonseca, Nuno Antunes",
                    "abstract": "Usually, the most critical modules of the system receive extra attention. But even these modules might be too large to be thoroughly inspected so it is useful to know where to apply the majority of the efforts. Thus, knowing which code changes are more prone to contain vulnerabilities may allow security experts to concentrate on a smaller subset of submitted code changes. In this paper we discuss the change history of functions and its impact on the existence of vulnerabilities. For this, we analyzed the commit history of two software projects widely exposed to attacks (Mozilla and Linux Kernel). Starting from security bugs, we analyzed more than 95k functions (with and without vulnerabilities), and systematized the changes in each function according to a subset of the patterns described in the Orthogonal Defects Classification. The results show that the frequency of changes can allow to distinguish functions more prone to have vulnerabilities.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通常，系统中最关键的模块会受到额外的关注。但是即使是这些模块也可能太大而无法彻底检查，所以知道在哪里应用大部分工作是有用的。因此，知道哪些代码更改更容易包含漏洞可以允许安全专家专注于提交的代码更改的较小子集。在本文中，我们讨论了函数的变化历史及其对漏洞存在的影响。为此，我们分析了两个容易受到攻击的软件项目(Mozilla和Linux内核)的提交历史。从安全漏洞开始，我们分析了超过95k个函数(有和没有漏洞)，并根据正交缺陷分类中描述的模式子集，将每个函数中的变化系统化。结果表明，改变的频率可以允许区分更容易有漏洞的功能。",
                    "title_zh": "代码更改历史和软件漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.23",
                    "title": "Hierarchical Model and Sensitivity Analysis for a Cloud-Based VoD Streaming Service",
                    "authors": "Jamilson Dantas, Rúbens de Souza Matos Júnior, Jean Araujo, Danilo Oliveira, Andre Oliveira, Paulo Romero Martins Maciel",
                    "abstract": "Cloud computing environments provide storage capacity, processing power, and other computational resources in a flexible way, enabling fast adaptation to highly dynamic workloads. Multimedia services, such as video streaming, are examples of applications that can use cloud computing to leverage their provisioning capacity. This way, it is possible to offer a large variety of multimedia content in many formats, so the users will be able to watch videos as they wish, with a proper resolution and quality, according to his preferences and connection speed. Private infrastructures for Video on Demand (VoD) and live video streaming are especially useful for e-learning on large corporations, universities, and governments. Analytical models are effective tools to evaluate the availability of software, hardware, and other computational resources. In this paper, we study a VoD service hosted in a private cloud computing environment. We present availability models considering the VoD streaming server components that are necessary for viewers access. Hierarchical modeling techniques are used to deal with the complexity of representing such system. Sensitivity analysis is used to determine the parameters that cause greatest impact on the availability, identifying which components require attention when attempting to achieve increased availability in a system. The proposed models are useful for planning private cloud infrastructures for VoD services.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云计算环境以灵活的方式提供存储容量、处理能力和其他计算资源，从而能够快速适应高度动态的工作负载。多媒体服务，如视频流，是可以使用云计算来利用其供应能力的应用程序的例子。通过这种方式，可以以多种格式提供多种多样的多媒体内容，因此用户将能够根据自己的喜好和连接速度，以适当的分辨率和质量观看他们想要的视频。视频点播(VoD)和实时视频流的专用基础设施对于大公司、大学和政府的电子学习尤其有用。分析模型是评估软件、硬件和其他计算资源可用性的有效工具。在本文中，我们研究了托管在私有云计算环境中的视频点播服务。我们提出了可用性模型，考虑到视频点播流媒体服务器组件是必要的观众访问。分层建模技术用于处理表示这种系统的复杂性。敏感性分析用于确定对可用性影响最大的参数，确定在试图提高系统可用性时需要注意哪些组件。所提出的模型对于规划VoD服务的私有云基础设施是有用的。",
                    "title_zh": "基于云的视频点播流媒体服务的层次模型及敏感性分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.49",
                    "title": "SOASales: A SOA System for Research Purposes",
                    "authors": "Carla Machado, Cristiana Areias, João Carlos Cunha",
                    "abstract": "Although Service Oriented Architecture (SOA) is a popular approach that is being applied in several business domains, it is still a relevant topic of research regarding the development of new solutions, techniques and methodologies to improve the effectiveness and trustworthiness of such systems. However, the lack of publicly available comprehensive SOA applications, push the researchers to validate their proposals using simplified and limited SOA environments. This paper presents SOASales, a SOA case study for research purposes, which implements an online store that allows consumers to manage accounts and search for products to purchase. This application is composed by several services, distributed through different providers and invoked by different consumers that communicate through an Enterprise Service Bus. The services are implemented using a diversity of technologies and features, following the key SOA characteristics.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然面向服务的体系结构(SOA)是一种流行的方法，正在应用于多个业务领域，但它仍然是一个相关的研究主题，涉及到新解决方案、技术和方法的开发，以提高此类系统的有效性和可信度。然而，缺乏公开可用的全面的SOA应用程序，促使研究人员使用简化和有限的SOA环境来验证他们的提议。本文介绍了SOASales，这是一个用于研究目的的SOA案例研究，它实现了一个在线商店，允许消费者管理帐户和搜索要购买的产品。这个应用程序由几个服务组成，通过不同的提供者分布，由通过企业服务总线通信的不同消费者调用。这些服务是使用多种技术和特性实现的，遵循关键的SOA特征。",
                    "title_zh": "SOASales:用于研究目的的SOA系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.16",
                    "title": "A Bayesian Networks Based Method for Ship Reliability Assessment",
                    "authors": "Hong Dong Wang, Xiaofeng Liang, Hong Yi, Dan Li",
                    "abstract": "Reliability assessment is a key step to reveal whether ships feature an acceptable level of reliability. Ships are typical dynamic systems, and their reliability cannot be evaluated using the static logic based methods, such as the analytic method, multilevel synthesis method and numerical simulation method. Fully considering the characteristics of ships, we proposed a new reliability assessment method based on dynamic Bayesian networks and numerical simulation. The proposed method overcomes the limitations of the analytic method and multilevel synthesis method, as well as provides an effective means for the reliability assessment of ships. The proposed method is also suitable for the reliability assessment of other complex dynamic systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可靠性评估是揭示船舶是否具有可接受的可靠性水平的关键步骤。船舶是典型的动态系统，其可靠性不能用基于静态逻辑的方法进行评估，如解析法、多级综合法和数值模拟法。充分考虑船舶的特点，提出了一种基于动态贝叶斯网络和数值模拟的可靠性评估方法。该方法克服了解析法和多级综合法的局限性，为船舶可靠性评估提供了一种有效手段。该方法也适用于其他复杂动态系统的可靠性评估。",
                    "title_zh": "基于贝叶斯网络的船舶可靠性评估方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.44",
                    "title": "Scalable Robustness",
                    "authors": "Thomas B. Jones, David H. Ackley",
                    "abstract": "Linear relaxation based perturbation analysis (LiRPA) for neural networks, which computes provable linear bounds of output neurons given a certain amount of input perturbation, has become a core component in robustness verification and certified defense. The majority of LiRPA-based methods focus on simple feed-forward networks and need particular manual derivations and implementations when extended to other architectures. In this paper, we develop an automatic framework to enable perturbation analysis on any neural network structures, by generalizing existing LiRPA algorithms such as CROWN to operate on general computational graphs. The flexibility, differentiability and ease of use of our framework allow us to obtain state-of-the-art results on LiRPA based certified defense on fairly complicated networks like DenseNet, ResNeXt and Transformer that are not supported by prior works. Our framework also enables loss fusion, a technique that significantly reduces the computational complexity of LiRPA for certified defense. For the first time, we demonstrate LiRPA based certified defense on Tiny ImageNet and Downscaled ImageNet where previous approaches cannot scale to due to the relatively large number of classes. Our work also yields an open-source library for the community to apply LiRPA to areas beyond certified defense without much LiRPA expertise, e.g., we create a neural network with a probably flat optimization landscape by applying LiRPA to network parameters. Our opensource library is available at https://github.com/KaidiXu/auto_LiRPA.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于线性松弛的神经网络扰动分析(LiRPA)在给定一定量的输入扰动的情况下计算输出神经元的可证明线性界限，已经成为鲁棒性验证和认证防御的核心组成部分。大多数基于LiRPA的方法集中于简单的前馈网络，当扩展到其他架构时，需要特别的手动推导和实现。在本文中，我们开发了一个自动化框架，通过推广现有的LiRPA算法(如CROWN)在一般的计算图上操作，来实现对任何神经网络结构的扰动分析。我们框架的灵活性、可区分性和易用性使我们能够在相当复杂的网络(如DenseNet、ResNeXt和Transformer)上获得基于LiRPA的认证防御的最先进结果，这些网络是以前的工作所不支持的。我们的框架还支持loss fusion，这是一种显著降低认证防御LiRPA计算复杂性的技术。我们第一次在Tiny ImageNet和Downscaled ImageNet上展示了基于LiRPA的认证防御，以前的方法由于类的数量相对较大而无法扩展。我们的工作还为社区提供了一个开源库，以便在没有太多LiRPA专业知识的情况下将LiRPA应用于认证防御以外的领域，例如，我们通过将LiRPA应用于网络参数来创建一个可能具有平坦优化前景的神经网络。我们的开源库可以在https://github.com/KaidiXu/auto_LiRPA.找到",
                    "title_zh": "可扩展的健壮性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.22",
                    "title": "D-MBTDD: An Approach for Reusing Test Artefacts in Evolving System",
                    "authors": "Thais Harumi Ussami, Eliane Martins, Leonardo Montecchi",
                    "abstract": "Agile software development methodologies use an iterative and incremental development in order to handle evolving systems. Consolidated techniques in the field of testing have been applied to these techniques with the main purpose of aiding in the test creation stage. An example is Model-Based Test Driven Development (MBTDD) which joins the concepts of Model-Based Testing (MBT) and Test Driven Development (TDD). However, when iterative and incremental processes are used, problems appear as the consequence of the evolution of the system, such as: how to reuse the test artefacts, and how to select the relevant tests for implementing the new version of the system. In this context, this work proposes a process called D-MBTDD in which the agile development of a system is guided by model-based tests, focusing on helping with the reuse of test artefacts and on the process of identifying tests relevant to development. The information about the modifications between two versions of the test model are used in this approach, which was compared to the Regenerate-All approach, which regenerates test cases along the iterations and does not reuse any of them.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "敏捷软件开发方法使用迭代和增量开发来处理不断发展的系统。测试领域的综合技术已经被应用到这些技术中，主要目的是帮助测试创建阶段。一个例子是基于模型的测试驱动开发(MBTDD ),它结合了基于模型的测试(MBT)和测试驱动开发(TDD)的概念。然而，当使用迭代和增量过程时，系统发展的结果会出现问题，例如:如何重用测试工件，以及如何选择相关的测试来实现系统的新版本。在这种背景下，这项工作提出了一个称为D-MBTDD的过程，在该过程中，系统的敏捷开发由基于模型的测试来指导，重点是帮助重用测试工件，以及识别与开发相关的测试的过程。在这种方法中使用了关于测试模型的两个版本之间的修改的信息，这与全部重新生成方法相比较，后者沿着迭代重新生成测试用例，并且不重用它们中的任何一个。",
                    "title_zh": "D-MBTDD:一种在演化系统中重用测试工件的方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.69",
                    "title": "Introduction to RSDA 2016",
                    "authors": "Antonio Pecchia, Olivier Thonnard",
                    "abstract": "The Third International Workshop on Reliability and Security Data Analysis description.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "第三届可靠性和安全性数据分析描述国际研讨会。",
                    "title_zh": "2016 RSDA青奥会简介"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.45",
                    "title": "Comparing Detection Capabilities of AntiVirus Products: An Empirical Study with Different Versions of Products from the Same Vendors",
                    "authors": "Areej Algaith, Ilir Gashi, Bertrand Sobesto, Michel Cukier, Selman Haxhijaha, Gazmend Bajrami",
                    "abstract": "In this paper we report results of an empirical analysis of the detection capabilities of 9 AntiVirus (AV) products when they were subjected to 3605 malware samples collected on an experimental network over a period of 31 days in NovemberDecember 2013. We compared the detection capabilities of the version of the AV products that the vendors make available for free in VirusTotal versus the full capability products that they make available via their own website. The analysis has been done using externally observable properties of the AV products: namely whether they detect a given malware. The paper reports extensive analysis of the results. A surprising finding of our study was that only one of the vendors had a full capability version which detected all the malware that their VirusTotal version could detect.",
                    "files": {
                        "openAccessPdf": "https://openaccess.city.ac.uk/id/eprint/15503/1/RSDA_AV_Paper_Camera_Ready_v3.pdf"
                    },
                    "abstract_zh": "在本文中，我们报告了对9种防病毒(AV)产品的检测能力进行实证分析的结果，这些产品在2013年11月至12月的31天内接受了在实验网络上收集的3605个恶意软件样本。我们比较了供应商在VirusTotal中免费提供的反病毒产品版本的检测功能，以及他们通过自己的网站提供的全功能产品。使用反病毒产品的外部可观察属性进行分析:即它们是否检测到给定的恶意软件。该文件报告了对结果的广泛分析。我们研究的一个令人惊讶的发现是，只有一家供应商拥有全功能版本，可以检测到他们的VirusTotal版本可以检测到的所有恶意软件。",
                    "title_zh": "比较防病毒产品的检测能力:对同一厂商不同版本产品的实证研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.21",
                    "title": "An Application of Unsupervised Fraud Detection to Passenger Name Records",
                    "authors": "Remi Domingues, Francesco Buonora, Romain Senesi, Olivier Thonnard",
                    "abstract": "Fraud is a threat that most online service providers must address in the development of their systems to ensure an efficient security policy and the integrity of their revenue. If rule-based systems and supervised methods usually provide the best detection and prevention, labelled training datasets are often non-existent and such solutions lack reactivity when facing adaptive fraudsters. Many generic fraud detection solutions have been made available for companies though cannot compete with dedicated internal implementations. This study presents an evaluation of some of the most widely used machine learning algorithms for unsupervised fraud detection applied to travel booking information represented by Passenger Name Records (PNR). The current paper also highlights the use of some aggregation functions relying on fuzzy logic and interpolation as an extension of unsupervised ensemble learning.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01671429/file/data-publi-5058.pdf"
                    },
                    "abstract_zh": "欺诈是大多数在线服务提供商在开发其系统时必须应对的威胁，以确保高效的安全策略和收入的完整性。如果基于规则的系统和监督方法通常提供最佳的检测和预防，则标记的训练数据集通常不存在，并且这种解决方案在面对适应性欺诈者时缺乏反应能力。许多通用的欺诈检测解决方案已经可供公司使用，但无法与专用的内部实施方案竞争。这项研究对一些最广泛使用的用于无监督欺诈检测的机器学习算法进行了评估，这些算法应用于由乘客姓名记录(PNR)表示的旅行预订信息。本文还强调了一些依赖于模糊逻辑和插值的聚合函数的使用，作为无监督集成学习的扩展。",
                    "title_zh": "无监督欺诈检测在乘客姓名记录中的应用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.33",
                    "title": "MimeoDroid: Large Scale Dynamic App Analysis on Cloned Devices via Machine Learning Classifiers",
                    "authors": "Parvez Faruki, Akka Zemmari, Manoj Singh Gaur, Vijay Laxmi, Mauro Conti",
                    "abstract": "The exponential adoption of Android applications (apps) among the users has attracted malware authors to evade the default emulator based dynamic analysis systems. The evolving Android malware behaves benign once it identifies Goldfish emulator, often used for app development and malware analysis. Once a malware identifies the Goldfish virtual device, it behaves benign or prevents malicious code execution. The exponential increase of such stealth malware necessitates a detection approach which coerces the malicious apps to reveal the hidden behavior. To detect malicious apps and characterize their association we propose MimeoDroid (enriched replica of real Android device), a modified virtual clone to coerce the malware to believe being executed on an actual device. We automate relevant feature extraction and classification of Processor, memory usage, Binder IPC transfers, network interaction, battery charging status and manifest permission(s) to detect malicious behavior using Tree based machine learning classifiers. MimeoDroid is a lightweight machine learning based malware analysis and characterization to detect malicious apps that would evade the existing analyzers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Android应用程序(apps)在用户中的指数级采用吸引了恶意软件作者来规避默认的基于仿真器的动态分析系统。不断发展的Android恶意软件一旦识别出金鱼仿真器，就会表现良好，通常用于应用程序开发和恶意软件分析。一旦恶意软件识别出金鱼虚拟设备，它就会表现良好或者阻止恶意代码的执行。这种隐形恶意软件的指数增长需要一种检测方法，该方法迫使恶意应用程序揭示隐藏的行为。为了检测恶意应用程序并描述它们之间的关联，我们提出了MimeoDroid(真实Android设备的丰富副本)，这是一种经过修改的虚拟克隆，可以强制恶意软件相信正在真实设备上执行。我们使用基于树的机器学习分类器，对处理器、内存使用、绑定IPC传输、网络交互、电池充电状态和显示许可的相关特征提取和分类进行自动化，以检测恶意行为。MimeoDroid是一个轻量级的基于机器学习的恶意软件分析和表征，用于检测可以规避现有分析器的恶意应用程序。",
                    "title_zh": "MimeoDroid:通过机器学习分类器对克隆设备进行大规模动态应用程序分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.41",
                    "title": "Error Monitoring for Legacy Mission-Critical Systems",
                    "authors": "Marcello Cinque, Raffaele Della Corte, Stefano Russo",
                    "abstract": "Error data collected at runtime play a key role for dependability analysis and improvement of software systems. The use of monitoring frameworks for legacy mission-critical systems is hindered by limited intervention degree and low intrusiveness requirements. We present the design and experimentation of an error monitoring service for a legacy large-scale critical system in the Air Traffic Control (ATC) domain. We describe the details of the API realized to collect both direct data (event logs, execution traces) and indirect data (system resources' utilization). We present experiments with the ATC industrial case study, showing the efficacy of combining different data sources for error detection and propagation analysis, with an acceptable overhead at high monitoring rates for such a class of systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "运行时收集的错误数据对于软件系统的可信性分析和改进起着关键作用。传统关键任务系统的监控框架的使用受到有限的干预程度和低侵入性要求的阻碍。我们介绍了空中交通管制(ATC)领域中遗留的大规模关键系统的错误监控服务的设计和实验。我们描述了为收集直接数据(事件日志、执行跟踪)和间接数据(系统资源利用率)而实现的API的细节。我们通过ATC工业案例研究展示了组合不同数据源进行错误检测和传播分析的功效，以及此类系统在高监控速率下可接受的开销。",
                    "title_zh": "传统关键任务系统的错误监控"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.46",
                    "title": "SDC is in the Eye of the Beholder: A Survey and Preliminary Study",
                    "authors": "Bo Fang, Panruo Wu, Qiang Guan, Nathan DeBardeleben, Laura Monroe, Sean Blanchard, Zhizong Chen, Karthik Pattabiraman, Matei Ripeanu",
                    "abstract": "Silent data corruptions (SDCs) are one of the most critical issues in modern HPC systems, as they are \"silent\" by definition and raise no warnings to users and application developers that a calculation has been corrupted. A significant amount of effort has been made to characterize, detect, and tolerate SDCs. However, current approaches do not share the same understanding of SDC, hence it is not only difficult to evaluate their effectiveness, but also to compare with each other. This position paper argues that SDCs should be discussed at each layer of the system and are confined within the goal of the approach. We provide a preliminary result to differentiate data corruptions across system layers, and show that application-specific correctness checks can tolerate about 50% of the errors that appear in the application output.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "静默数据损坏(SDC)是现代HPC系统中最关键的问题之一，因为根据定义，它们是“静默的”,不会向用户和应用程序开发人员发出计算已损坏的警告。人们已经做了大量的工作来表征、检测和耐受SDC。然而，当前的方法对SDC没有相同的理解，因此不仅难以评估它们的有效性，而且难以相互比较。这份立场文件认为，应该在系统的每一层讨论SDC，并将其限制在该方法的目标范围内。我们提供了一个初步结果来区分跨系统层的数据损坏，并表明特定于应用程序的正确性检查可以容忍应用程序输出中出现的大约50%的错误。",
                    "title_zh": "旁观者眼中的SDC:调查与初步研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.25",
                    "title": "Classifying Virtual Machine Managers by Overhead",
                    "authors": "Colin S. Murray",
                    "abstract": "Even though Virtual Machine Managers (VMMs) are meant to be transparent, a program may still need to know what VMM is virtualizing their environment. Developers may want to ensure their software only works in particular virtual environments, and users may want to know whether they are the victim of some virtualization-based rootkit. Various methods have been developed for programs to discover whether or not they are executing inside a virtual machine (VM), but current methods for identifying specific VMMs rely entirely on basic heuristics. This work presents a methodology for identifying VMMs based on their usage of shared resources. It has the potential to identify VMMs to the extent that they have unique shared resource usage profiles. A prototype implementation is presented that collects testing routines from existing work on VMM detection and CPU side-channel attacks. Each routine takes a measurement that is sensitive to a VMM's use of some shared resource. Results are presented that show it is possible to observe differences between several VMMs and even between some versions of the same VMM.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "即使虚拟机管理器(VMM)应该是透明的，程序可能仍然需要知道VMM正在虚拟化他们的环境。开发人员可能希望确保他们的软件只在特定的虚拟环境中工作，而用户可能希望知道他们是否是某些基于虚拟化的rootkit的受害者。已经为程序开发了各种方法来发现它们是否正在虚拟机(VM)内执行，但是当前用于识别特定VMM的方法完全依赖于基本的试探法。这项工作提出了一种基于共享资源的使用来识别VMM的方法。它有可能在VMM具有唯一的共享资源使用简档的程度上识别VMM。提出了一个原型实现，它从现有的关于VMM检测和CPU旁路攻击的工作中收集测试例程。每个例程进行一次测量，该测量对VMM使用一些共享资源很敏感。给出的结果表明，有可能观察到几个VMM之间的差异，甚至是同一VMM的一些版本之间的差异。",
                    "title_zh": "按开销对虚拟机管理器进行分类"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.31",
                    "title": "Hunting Killer Tasks for Cloud System through Behavior Pattern Learning",
                    "authors": "Hongyan Tang, Ying Li, Tong Jia, Zhonghai Wu",
                    "abstract": "Motivated by frequent failures in cloud computing systems, we analyze failure frequency and continuity of tasks from the Google cloud cluster, and find what we call killer tasks that suffer from frequent failures and repeated rescheduling. Killer task can be a big concern in cloud systems as it causes unnecessary resource wasting and significant increase of scheduling workloads. In this paper, we investigate characteristics and behavior patterns of killer tasks, then develop an approach to recognize killer tasks at the very early stage of their occurrence so that they can be addressed proactively instead of being rescheduled repeatedly. The empirical results show that our approach performs at 97% of precision in recognizing killer tasks with a maximal 1,164 minutes of lead time and 89% of resource saving for the cloud system on average.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "受云计算系统频繁故障的激励，我们分析了谷歌云集群中任务的故障频率和连续性，并发现了我们所说的遭受频繁故障和重复重新调度的杀手任务。黑仔任务可能是云系统中的一个大问题，因为它会导致不必要的资源浪费和调度工作负载的显著增加。在本文中，我们研究杀手任务的特征和行为模式，然后开发一种在杀手任务出现的最早期识别杀手任务的方法，以便可以主动地解决它们，而不是重复地重新安排。实验结果表明，我们的方法识别杀手任务的准确率为97%，云系统的平均提前时间为1164分钟，资源节省率为89%。",
                    "title_zh": "通过行为模式学习为云系统寻找黑仔任务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.70",
                    "title": "Introduction to DISN 2016",
                    "authors": "Elias P. Duarte Jr., Matti A. Hiltunen, Robert Soulé",
                    "abstract": "The 2nd Workshop on Dependability Issues on SDN and NFV description.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "关于SDN和NFV描述的可靠性问题的第二次研讨会。",
                    "title_zh": "2016 DISN青奥会简介"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.48",
                    "title": "Ground Control to Major Faults: Towards a Fault Tolerant and Adaptive SDN Control Network",
                    "authors": "Liron Schiff, Stefan Schmid, Marco Canini",
                    "abstract": "To provide high availability and fault-tolerance, SDN control planes should be distributed. However, distributed control planes are challenging to design and bootstrap, especially if to be done in-band, without dedicated control network, and without relying on legacy protocols. This paper promotes a distributed systems approach to build and maintain connectivity between a distributed control plane and the data plane. In particular, we make the case for a self-stabilizing distributed control plane, where from any initial configuration, controllers self-organize, and quickly establish a communication channel among themselves. Given the resulting managed control plane, arbitrary network services can be implemented on top. This paper presents a model for the design of such self-stabilizing control planes, and identifies fundamental challenges. Subsequently, we present techniques which can be used to solve these challenges, and implement a plug & play distributed control plane which supports automatic topology discovery and management, as well as flexible controller membership: controllers can be added and removed dynamically. Interestingly, we argue that our approach can readily be implemented in today's OpenFlow protocol. Moreover, our approach comes with interesting security features.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了提供高可用性和容错能力，SDN控制平面应该是分布式的。然而，分布式控制平面的设计和引导具有挑战性，尤其是如果要在带内完成，没有专用控制网络，并且不依赖于传统协议。本文提出了一种分布式系统方法来建立和维护分布式控制平面和数据平面之间的连接。特别是，我们提出了自稳定分布式控制平面的案例，其中从任何初始配置开始，控制器自组织，并在它们之间快速建立通信信道。给定最终的受管控制平面，可以在其上实现任意网络服务。本文介绍了这种自稳定控制平面的设计模型，并确定了基本的挑战。随后，我们介绍了可用于解决这些挑战的技术，并实现了一个即插即用的分布式控制平面，它支持自动拓扑发现和管理，以及灵活的控制器成员资格:控制器可以动态添加和删除。有趣的是，我们认为我们的方法很容易在今天的OpenFlow协议中实现。此外，我们的方法具有有趣的安全特性。",
                    "title_zh": "主要故障的地面控制:走向容错和自适应SDN控制网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.20",
                    "title": "Experience with 3 SDN Controllers in an Enterprise Setting",
                    "authors": "Zhiyuan Teo, Ken Birman, Robbert van Renesse",
                    "abstract": "Interest in OpenFlow and software-defined network (SDNs) has resulted in a boom in SDN hardware and controller offerings, with varying degrees of maturity, popularity and support. However, few studies have been conducted to investigate the interaction between SDN hardware and software, as well as its impact on controller design and implementation. In this paper, we chronicle our experience with deploying two commodity SDN controllers and a new system, IronStack, of our own design in a production enterprise network at Cornell University, and describe the lessons learnt. We also report on several practical limitations of SDN and controller technology, and detail important future challenges for SDN adopters and developers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对OpenFlow和软件定义网络(SDN)的兴趣导致了SDN硬件和控制器产品的繁荣，其成熟度、受欢迎程度和支持程度各不相同。然而，很少有研究调查SDN硬件和软件之间的交互作用，以及其对控制器设计和实施的影响。在本文中，我们记录了在康奈尔大学的生产企业网络中部署我们自己设计的两个商用SDN控制器和一个新系统IronStack的经验，并描述了从中吸取的教训。我们还报告了SDN和控制器技术的一些实际限制，并详细说明了SDN采用者和开发者未来面临的重要挑战。",
                    "title_zh": "在企业环境中使用3个SDN控制器的经验"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.28",
                    "title": "Availability Modelling of Software-Defined Backbone Networks",
                    "authors": "Gianfranco Nencioni, Bjarne E. Helvik, Andrés J. Gonzalez, Poul E. Heegaard, Andrzej Kamisinski",
                    "abstract": "Software-Defined Networking (SDN) promises to improve the programmability and flexibility of networks, but it may also bring new challenges that need to be explored. The main objective of this paper is to present a quantitative assessment of the properties of SDN backbone networks to determine whether they can provide similar availability to the traditional IP backbone networks. To achieve this goal, we have completed the following steps: i) we formalized a two-level availability model that is able to capture the global network connectivity without neglecting the essential details: ii) we proposed Markov models for characterizing the single network elements in both SDN and traditional networks: iii) we carried out an extensive sensitivity analysis of a~national and a~world-wide backbone networks. The results have highlighted the considerable impact of operational and management (O&M) failures on the overall availability of SDN. High O&M failure intensity may reduce the availability of SDN as much as one order of magnitude compared to traditional networks. Moreover, the results show that the impact of software and hardware failures on the overall availability of SDN can be significantly reduced through proper overprovisioning of the SDN controller(s).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(SDN)有望提高网络的可编程性和灵活性，但也可能带来新的挑战，需要加以探索。本文的主要目的是对SDN骨干网的性能进行定量评估，以确定它们是否能够提供与传统IP骨干网相似的可用性。为了实现这一目标，我们完成了以下步骤:I)我们形式化了一个两级可用性模型，该模型能够在不忽略基本细节的情况下捕获全球网络连接性；ii)我们提出了用于表征SDN和传统网络中单个网络元素的马尔可夫模型iii)我们对a～国家和a～全球主干网络进行了广泛的敏感性分析。调查结果强调了运营和管理(O&M)失败对SDN整体可用性的巨大影响。与传统网络相比，高O&M故障强度可能会将SDN的可用性降低一个数量级。此外，结果表明，通过适当过度配置SDN控制器，可以显著降低软件和硬件故障对SDN整体可用性的影响。",
                    "title_zh": "软件定义骨干网络的可用性建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.42",
                    "title": "Routing-Verification-as-a-Service (RVaaS): Trustworthy Routing Despite Insecure Providers",
                    "authors": "Liron Schiff, Kashyap Thimmaraju, Stefan Schmid",
                    "abstract": "Computer networks today typically do not provide any mechanisms to the users to learn, in a reliable manner, which paths have (and have not!) been taken by their packets. Rather, it seems inevitable that as soon as a packet leaves the network card, the user is forced to trust the network provider to forward the packets as expected or agreed upon. This can be undesirable, especially in the light of today's trend toward more programmable networks: after a successful cyber attack on the network management system or Software-Defined Network (SDN) control plane, an adversary in principle has complete control over the network. This paper presents a low-cost and efficient solution to detect misbehaviors and ensure trustworthy routing over untrusted or insecure providers, in particular providers whose management system or control plane has been compromised (e.g., using a cyber attack). We propose Routing-Verification-as-a-Service (RVaaS): RVaaS offers clients a flexible interface to query information relevant to their traffic, while respecting the autonomy of the network provider. RVaaS leverages key features of OpenFlow-based SDNs to combine (passive and active) configuration monitoring, logical data plane verification and actual in-band tests, in a novel manner.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1609.02324"
                    },
                    "abstract_zh": "今天的计算机网络通常不提供任何机制让用户以可靠的方式了解哪些路径有(和没有！)被他们的小包拿走了。相反，似乎不可避免的是，一旦数据包离开网卡，用户就不得不相信网络提供商会按照预期或约定转发数据包。这可能是不可取的，尤其是考虑到当今网络更加可编程的趋势:在对网络管理系统或软件定义网络(SDN)控制平面的成功网络攻击之后，原则上对手已经完全控制了网络。本文提出了一种低成本且高效的解决方案，用于检测不当行为，并确保通过不可信或不安全的提供商的可信路由，特别是其管理系统或控制平面已经受损(例如，使用网络攻击)的提供商。我们提出路由验证即服务(RVaaS): RVaaS为客户端提供了一个灵活的接口来查询与其流量相关的信息，同时尊重网络提供商的自主权。RVaaS利用基于OpenFlow的sdn的关键特性，以一种全新的方式将(被动和主动)配置监控、逻辑数据平面验证和实际带内测试结合起来。",
                    "title_zh": "路由验证即服务(RVaaS):值得信赖的路由，尽管提供者不安全"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.11",
                    "title": "KAR: Key-for-Any-Route, a Resilient Routing System",
                    "authors": "Rodolfo R. Gomes, Alextian B. Liberato, Cristina K. Dominicini, Moisés R. N. Ribeiro, Magnos Martinello",
                    "abstract": "This paper proposes KAR (Key-for-Any-Route), a new intra-domain resilient routing system in which edge-nodes set a route ID to select any existing route as an alternative to safely forward packets to their destination. In KAR routing system, a route is defined as the remainder of the division between a route ID and a set of switch IDs along the path(s) between a pair of nodes. KAR-enabled switches explore the existing routes by using special properties of Residue Number System as our encoding technique. Packets are deviated from the faulty link (liveness condition) with routing deflections. Deflected packets are guided to their original destination due to resilient forwarding paths added to the route ID. Three deflection methods are discussed along emulation experiments. Results show that KAR efficiently allows deflected packets to automatically reach their destination, imposing a bound on packets disordering measured in TCP throughput.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了一种新的域内弹性路由系统KAR (Key-for-Any-Route ),在该系统中，边缘节点设置一个路由ID来选择任何现有的路由作为安全转发数据包到目的地的替代路由。在KAR路由系统中，路由被定义为沿着一对节点之间的路径的路由ID和一组交换机ID之间的划分的余数。支持KAR的交换机通过使用余数系统的特殊属性作为我们的编码技术来探索现有的路由。随着路由偏转，分组偏离故障链路(活动状态)。由于添加到路由ID的弹性转发路径，被偏转的分组被引导到它们的原始目的地。通过仿真实验讨论了三种偏转方法。结果表明，KAR有效地允许被偏转的分组自动到达它们的目的地，对在TCP吞吐量中测量的分组乱序施加一个界限。",
                    "title_zh": "KAR:任何路线的钥匙，一个弹性路由系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.38",
                    "title": "NetCo: Reliable Routing With Unreliable Routers",
                    "authors": "Anja Feldmann, Philipp Heyder, Michael Kreutzer, Stefan Schmid, Jean-Pierre Seifert, Haya Shulman, Kashyap Thimmaraju, Michael Waidner, Jens Sieberg",
                    "abstract": "Software-Defined Networks (SDNs) are typically designed and operated under the assumption that the underlying routers (and switches) are trustworthy. Recent incidents, however, suggest that this assumption is questionable. The possibility of incorrect or even malicious router behavior introduces a wide range of security problems. The problem is exacerbated by the fact that governments and companies do not have the expertise nor budget to build their own trusted high-performance routing hardware. This paper presents NetCo, an approach to build secure routing using insecure routers. NetCo is inspired by the robust combiner concept known from cryptography, and leverages redundancy to compile a secure whole from insecure parts. We present the basic design of NetCo, and report on a prototype implementation in OpenFlow.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(sdn)的设计和运行通常假设底层路由器(和交换机)是可信的。然而，最近的事件表明，这一假设是有问题的。不正确的甚至恶意的路由器行为的可能性引入了广泛的安全问题。政府和公司既没有专业知识也没有预算来构建他们自己的可信高性能路由硬件，这一事实加剧了这一问题。本文介绍了NetCo，一种使用不安全路由器建立安全路由的方法。NetCo的灵感来自密码学中的健壮组合器概念，它利用冗余从不安全的部分编译出一个安全的整体。我们介绍了NetCo的基本设计，并报告了一个在OpenFlow中的原型实现。",
                    "title_zh": "NetCo:使用不可靠路由器的可靠路由"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.71",
                    "title": "Introduction to ReSA4CI 2016",
                    "authors": "Silvia Bonomi, Ilaria Matteucci",
                    "abstract": "Third International Workshop on Reliability and Security Aspects for Critical Infrastructure protection description.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "第三届关键基础设施保护的可靠性和安全性国际研讨会。",
                    "title_zh": "ReSA4CI 2016简介"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.40",
                    "title": "An Architecture for Semi-Automatic Collaborative Malware Analysis for CIs",
                    "authors": "Giuseppe Laurenza, Daniele Ucci, Leonardo Aniello, Roberto Baldoni",
                    "abstract": "Critical Infrastructures (CIs) are among the main targets of activists, cyber terrorists and state sponsored attacks. To protect itself, a CI needs to build and keep updated a domestic knowledge base of cyber threats. It cannot indeed completely rely on external service providers because information on incidents can be so sensible to impact national security. In this paper, we propose an architecture for a malware analysis framework to support CIs in such a challenging task. Given the huge number of new malware produced daily, the architecture is designed so as to automate the analysis to a large extent, leaving to human analysts only a small and manageable part of the whole effort. Such a non-automatic part of the analysis requires a wide range of expertise, usually contributed by more analysts. The architecture enables analysts to work collaboratively to improve the understanding of samples that demand deeper investigations (intra-CI collaboration). Furthermore, the architecture allows to share partial and configurable views of the knowledge base with other interested CIs, in order to collectively obtain a more complete vision of the cyber threat landscape (inter-CI collaboration).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "关键基础设施(CIs)是激进分子、网络恐怖分子和国家支持的攻击的主要目标。为了保护自己，竞争情报部门需要建立并不断更新国内网络威胁知识库。事实上，它不能完全依赖外部服务提供商，因为有关事故的信息可能非常敏感，会影响国家安全。在本文中，我们提出了一个恶意软件分析框架的架构，以支持竞争情报在这样一个具有挑战性的任务。考虑到每天产生的大量新恶意软件，该架构被设计为在很大程度上自动进行分析，只将整个工作的一小部分和可管理的部分留给人类分析师。这样一个非自动化的分析部分需要广泛的专业知识，通常由更多的分析师来贡献。该架构使分析师能够协同工作，以提高对需要更深入调查的样本的理解(CI内协作)。此外，该架构允许与其他感兴趣的CI共享知识库的部分和可配置视图，以便共同获得网络威胁前景的更完整的视图(CI间协作)。",
                    "title_zh": "一种面向CIs的半自动协同恶意软件分析体系结构"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.34",
                    "title": "Diverse Compiling for Software-Based Recovery of Permanent Faults in COTS Processors",
                    "authors": "Andrea Höller, Bernhard Spitzer, Tobias Rauter, Johannes Iber, Christian Kreiner",
                    "abstract": "Digital systems used in critical infrastructures have to fulfill ever higher demands on performance and cost efficiency. Thus, there is the trend to commercial off-the-shelf processors. To ensure a correct functioning of such devices, even after a long time of operation, mechanisms to recover from permanent hardware faults (e.g. due to wear-out effects) are needed. However, there is a lack of flexible low-cost software-based fault mitigation approaches that do not base on a costly exhaustive redundancy. To address this challenge, we show how to adapt the software execution such that the faulty hardware resource is no longer used. We propose to update the embedded device with an adapted binary that is generated on a remote server with diverse compiling. Our experiments demonstrate that this approach allows recovering from 99% of internal memory and 52% of register faults.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "关键基础设施中使用的数字系统必须满足对性能和成本效率的更高要求。因此，出现了商业化现成处理器的趋势。为了确保这种设备的正确运行，即使在长时间运行之后，也需要从永久性硬件故障(例如，由于磨损效应)中恢复的机制。然而，缺乏灵活的低成本的基于软件的故障缓解方法，该方法不基于昂贵的穷举冗余。为了应对这一挑战，我们展示了如何调整软件执行，以便不再使用故障硬件资源。我们建议用在远程服务器上用不同的编译生成的适应的二进制来更新嵌入式设备。我们的实验表明，这种方法允许从99%的内部存储器和52%的寄存器故障中恢复。",
                    "title_zh": "COTS处理器中基于软件的永久故障恢复的多样性编译"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.47",
                    "title": "Quantification and Analysis of Interdependency in Cyber-Physical Systems",
                    "authors": "Koosha Marashi, Sahra Sedigh Sarvestani, Ali R. Hurson",
                    "abstract": "Cyber-physical systems are differentiated from other real-time embedded systems based on the tight intertwining of the cyber infrastructure with the physical components upon which it exerts control. This close interaction manifests as interdependence in operation and failure. This paper aims to determine and quantify the type and extent of dependency in a cyber-physical system using a method inspired by the analytic network process. The method incorporates several steps, namely, identification of failures sequences, and graph-theoretical representation of functional dependencies between components, and finally, calculating dependency indices. We illustrate the proposed approach through application to the IEEE 14-bus power system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络物理系统与其他实时嵌入式系统的区别在于，网络基础设施与其控制的物理组件紧密交织在一起。这种密切的相互作用表现为运作和失败的相互依赖。本文旨在使用一种受网络分析过程启发的方法来确定和量化信息物理系统中依赖性的类型和程度。该方法包括几个步骤，即故障序列的识别，组件间功能依赖的图论表示，以及最后计算依赖指数。我们通过IEEE 14节点电力系统的应用来说明所提出的方法。",
                    "title_zh": "信息物理系统中相互依赖性的量化和分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.32",
                    "title": "On the Feasibility of Distinguishing Between Process Disturbances and Intrusions in Process Control Systems Using Multivariate Statistical Process Control",
                    "authors": "Mikel Iturbe, José Camacho, Iñaki Garitano, Urko Zurutuza, Roberto Uribeetxeberria",
                    "abstract": "Process Control Systems (PCSs) are the operating core of Critical Infrastructures (CIs). As such, anomaly detection has been an active research field to ensure CI normal operation. Previous approaches have leveraged network level data for anomaly detection, or have disregarded the existence of process disturbances, thus opening the possibility of mislabelling disturbances as attacks and vice versa. In this paper we present an anomaly detection and diagnostic system based on Multivariate Statistical Process Control (MSPC), that aims to distinguish between attacks and disturbances. For this end, we expand traditional MSPC to monitor process level and controller level data. We evaluate our approach using the Tennessee-Eastman process. Results show that our approach can be used to distinguish disturbances from intrusions to a certain extent and we conclude that the proposed approach can be extended with other sources of data for improving results.",
                    "files": {
                        "openAccessPdf": "http://ebiltegia.mondragon.edu:8080/xmlui/bitstream/20.500.11984/1184/1/On%20the%20Feasibility%20of%20Distinguishing%20Between%20Process%20Disturbances%20and%20Intrusions%20in%20Process%20Control%20Systems%20using%20Multivariate%20Statistical%20Process%20Control.pdf"
                    },
                    "abstract_zh": "过程控制系统是关键基础设施的运行核心。因此，异常检测一直是保证竞争情报正常运行的一个活跃的研究领域。以前的方法利用网络级数据来进行异常检测，或者忽略了过程干扰的存在，从而有可能将干扰误标为攻击，反之亦然。在本文中，我们提出了一个基于多元统计过程控制(MSPC)的异常检测和诊断系统，旨在区分攻击和干扰。为此，我们扩展了传统的MSPC来监控过程级和控制器级数据。我们使用田纳西-伊斯曼过程来评估我们的方法。结果表明，我们的方法可以在一定程度上区分干扰和入侵，我们的结论是，所提出的方法可以扩展到其他数据源，以改善结果。",
                    "title_zh": "用多元统计过程控制区分过程控制系统中过程干扰和入侵的可行性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.72",
                    "title": "Introduction to SSIV 2016",
                    "authors": "João Carlos Cunha, Kalinka Branco, António Casimiro, Urbano Nunes",
                    "abstract": "2nd International Workshop on Safety and Security of Intelligent Vehicles description.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "第二届智能车辆安全国际研讨会。",
                    "title_zh": "2016 SSIV青奥会简介"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.15",
                    "title": "In-Vehicle Real-Time Fog Computing",
                    "authors": "Hermann Kopetz, Stefan Poledna",
                    "abstract": "Considering the technical advances and economicadvantages of integrated architectures and cloud computing we conjecture that the realization of a real-time cloud, called a fog that provides reliable electronic services with temporalguarantees on board a vehicle efficiently and flexibly will be thelogical next step in the development of an automotive electronic architecture. In this paper we introduce the concept of a time-triggered virtual machine (TTVM) that provides a precisely specified virtual interface between a real-time software component and its underlying hardware infrastructure. The flexible allocation of TTVMs on different node computers provides the means to implement fault-tolerance, evolution and on-line validation effectively in such a time-triggered distributed architecture. In this paper this new architecture and the associated design methodology are explained by referring to an example of a driver assistance system onboard a car.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "考虑到集成架构和云计算的技术进步和经济优势，我们推测实时云(称为fog)的实现将是汽车电子架构发展的下一个逻辑步骤，该实时云能够高效、灵活地提供可靠的车载电子服务和临时保障。在本文中，我们介绍了时间触发虚拟机(TTVM)的概念，它在实时软件组件及其底层硬件基础设施之间提供了一个精确指定的虚拟接口。在这种时间触发的分布式体系结构中，TTVMs在不同节点计算机上的灵活分配提供了有效实现容错、进化和在线验证的手段。在本文中，这种新的架构和相关的设计方法是通过参考一个汽车上的驾驶员辅助系统的例子来解释的。",
                    "title_zh": "车载实时雾计算"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.14",
                    "title": "An Effective Two-Level Redundancy Approach for FlexRay Network Systems",
                    "authors": "Yung-Yuan Chen, Kuen-Long Leu",
                    "abstract": "FlexRay, as a communication protocol for automotive control systems, is developed to fulfill the increasing demand for implementing vehicle electronics with higher safety and more comfort. The applications of FlexRay drive-by-wire systems are often associated with human life, so the reliability issue of FlexRay network systems should be carefully studied. In this paper, we propose an effective two-level redundancy approach for safety-critical FlexRay network systems. The proposed approach demonstrates how to employ the backup nodes, mirrored tasks and task migration to sustain the operation of system when ECUs fail. We then perform the redundancy analysis and develop the analytical reliability models for the assessment of fault-tolerant FlexRay network systems in early design phase. The reliability analysis with various numbers of backup nodes, system sizes and ECU failure rates are conducted and the reliability results are provided and discussed. The contribution of this study is to propose a comprehensive fault-robust methodology with the analytical reliability model to support the development of safety-critical FlexRay network systems with an efficient manner.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "FlexRay作为一种用于汽车控制系统的通信协议，是为了满足日益增长的实现具有更高安全性和更舒适性的车辆电子设备的需求而开发的。FlexRay线控系统的应用往往与人类的生活息息相关，因此需要认真研究FlexRay网络系统的可靠性问题。在本文中，我们为安全关键的FlexRay网络系统提出了一种有效的两级冗余方法。该方法演示了当ECU发生故障时，如何利用备份节点、镜像任务和任务迁移来维持系统的运行。然后，我们执行冗余分析并开发可靠性分析模型，用于在早期设计阶段评估容错FlexRay网络系统。进行了不同备份节点数、系统规模和ECU故障率下的可靠性分析，给出了可靠性结果并进行了讨论。本研究的贡献在于提出了一种全面的故障鲁棒性方法，该方法采用分析可靠性模型，以高效的方式支持安全关键型FlexRay网络系统的开发。",
                    "title_zh": "一种有效的FlexRay网络系统两级冗余方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.26",
                    "title": "Designing Security for In-vehicle Networks: A Body Control Module (BCM) Centered Viewpoint",
                    "authors": "Bogdan Groza, Horatiu-Eugen Gurban, Pal-Stefan Murvay",
                    "abstract": "The overabundance of attacks reported on in-vehicle networks triggered reactions from both the academic research communities and industry professionals. However, designing security for in-vehicle networks is a challenging task and it is yet unclear to what extent current proposals are suitable for real world vehicles. In this work, we advocate the use of a top-down approach in which we analyze the functionalities along with reported attacks. Due to the abundance of in-vehicle services and the associated large number of Electronic Control Units (ECUs), we center our analysis on a key subsystem from the car: the Body Control Module (BCM). The rationale behind choosing this particular module comes from at least three key factors: i) a large number of components that aredirectly linked to the BCM were target of previously reported attacks (e.g., keys and electronic immobilizes, tire sensors, diagnostic ports, etc.), ii) by design, body components are generally exposed to the outside and it is reasonable to assumethat adversaries will frequently have access to peripherals controlled by the BCM, iii) the BCM controls subsystems thatare both attractive from an economic perspective (e.g., accessto the car), or from a safety perspective (e.g., seat-belts, lights, etc.). Our discussion is entailed by a concrete analysis of therisks of reported attacks and preferable security designs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "车载网络上报告的过多攻击引发了学术研究团体和行业专业人士的反应。然而，设计车载网络的安全性是一项具有挑战性的任务，目前还不清楚当前的提议在多大程度上适用于现实世界的车辆。在这项工作中，我们提倡使用自上而下的方法来分析功能以及报告的攻击。由于丰富的车载服务和相关的大量电子控制单元(ECU)，我们将分析集中在汽车的一个关键子系统:车身控制模块(BCM)。选择这种特定模块的基本原理来自至少三个关键因素:I)大量与BCM直接相关的组件是先前报告的攻击的目标(例如，钥匙和电子防盗装置、轮胎传感器、诊断端口等。)，ii)通过设计，车身部件通常暴露在外面，并且有理由假设对手将经常使用由BCM控制的外围设备，iii)BCM控制子系统从经济角度(例如，进入汽车)或安全角度(例如，安全带、灯等)都很有吸引力。).我们的讨论是基于对已报道的攻击风险和更好的安全设计的具体分析。",
                    "title_zh": "设计车载网络的安全性:以车身控制模块(BCM)为中心的观点"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.35",
                    "title": "IEEE 802.11n vs. IEEE 802.15.4: A Study on Communication QoS to Provide Safe FANETs",
                    "authors": "Emerson Alberto Marconato, Jean-Aimé Maxa, Daniel F. Pigatto, Alex S. R. Pinto, Nicolas Larrieu, Kalinka R. L. J. Castelo Branco",
                    "abstract": "Flying Ad hoc Network (FANET) is an infrastructure-less multi-hop radio ad hoc network in which Unmanned Aerial Vehicles (UAVs) and Ground Control Station (GCS) collaborates to forward data traffic. Compared to the standard Mobile Ad hoc NETworks (MANETs), the FANET architecture has some specific features (3D mobility, low UAV density, intermittent network connectivity) that bring challenges to the communication protocol design. Such routing protocol must provide safety by finding an accurate and reliable route between UAVs. This safety can be obtained through the use of agile method during software based routing protocol development (for instance the use of Model Driven Development) by mapping each FANET safety requirement into the routing design process. This process must be completed with a sequential safety validation testing with formal verification tools, standardized simulator (by using real simulation environment) and real-world experiments. In this paper, we considered FANET communication safety by presenting design methodologies and evaluations of FANET routing protocols. We use the LARISSA architecture to guarantee the efficiency and accuracy of the whole system. We also use the model driven development methodology to provide model and code consistency through the use of formal verification tools. To complete the FANET safety validation, OMNeT++ simulations (using real UAVs mobility traces) and real FANET outdoor experiments have been carried out. We confront both results to evaluate routing protocol performances and conclude about its safety consideration.",
                    "files": {
                        "openAccessPdf": "https://hal-enac.archives-ouvertes.fr/hal-01318385/file/output.pdf"
                    },
                    "abstract_zh": "飞行自组织网络(FANET)是一种无基础设施的多跳无线自组织网络，其中无人机(UAV)和地面控制站(GCS)协作转发数据业务。与标准移动自组织网络相比，FANET体系结构具有一些特殊的特征(3D移动性、低无人机密度、间歇性网络连接),这给通信协议设计带来了挑战。这种路由协议必须通过在无人机之间找到准确可靠的路线来提供安全性。这种安全性可以通过在基于软件的路由协议开发期间使用敏捷方法(例如使用模型驱动开发)来获得，通过将每个FANET安全性要求映射到路由设计过程中。这个过程必须通过使用正式验证工具、标准化模拟器(通过使用真实模拟环境)和真实世界实验的顺序安全验证测试来完成。在这篇论文中，我们通过提出FANET路由协议的设计方法和评估来考虑FANET通信的安全性。我们使用LARISSA架构来保证整个系统的效率和准确性。我们还使用模型驱动的开发方法，通过使用正式的验证工具来提供模型和代码的一致性。为了完成FANET安全验证，进行了OMNeT++模拟(使用真实的无人机移动轨迹)和真实的FANET室外实验。我们面对这两个结果来评估路由协议的性能，并总结其安全性的考虑。",
                    "title_zh": "IEEE 802.11n与IEEE 802.15.4:提供安全网络的通信服务质量研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.12",
                    "title": "On the Validation of a UAV Collision Avoidance System Developed by Model-Based Optimization: Challenges and a Tentative Partial Solution",
                    "authors": "Xueyi Zou, Rob Alexander, John A. McDermid",
                    "abstract": "The development of the new generation of airborne collision avoidance system ACAS X adopts a model-based optimization approach, where the collision avoidance logic is automatically generated based on a probabilistic model and a set of preferences. It has the potential for safety benefits and shortening the development cycle, but it poses new challenges for safety assurance. In this paper, we introduce the new development process and explain its key ideas using a simple collision avoidance example. Based on this explanation, we analyze the challenges it poses to safety assurance, with a particular focus on system validation. We then propose a Genetic-Algorithm-based approach that can efficiently search for undesired situations to help the development and validation of the system. We introduce an open-source tool we have developed to support this approach and demonstrate it on searching for challenging situations for ACAS XU.",
                    "files": {
                        "openAccessPdf": "https://eprints.whiterose.ac.uk/103129/1/SSIV_paper_camera_ready.pdf"
                    },
                    "abstract_zh": "新一代机载防撞系统ACAS X的开发采用了基于模型的优化方法，其中防撞逻辑是基于概率模型和一组偏好自动生成的。它具有安全效益和缩短开发周期的潜力，但它对安全保证提出了新的挑战。在本文中，我们介绍了新的开发过程，并使用一个简单的碰撞避免示例来解释其关键思想。基于这一解释，我们分析了它对安全保证带来的挑战，特别关注系统验证。然后，我们提出了一种基于遗传算法的方法，可以有效地搜索不期望的情况，以帮助系统的开发和验证。我们介绍了一个开源工具，我们已经开发了支持这种方法，并展示了它在搜索ACAS徐的挑战性情况。",
                    "title_zh": "基于模型优化研制的无人机防撞系统的验证:挑战和尝试性的部分解决方案"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.30",
                    "title": "Safety Engineering for Autonomous Vehicles",
                    "authors": "Rasmus Adler, Patrik Feth, Daniel Schneider",
                    "abstract": "In safety engineering for non-autonomous vehicles, it is generally assumed that safety is achieved if the vehicle appropriately follows certain control commands from humans such as steering or acceleration commands. This fundamental assumption becomes problematic if we consider autonomous vehicles that decide on their own which behavior is most reasonable in which situation. Safety criticality extends to the decision-making process and the related perception of the environment. These, however, are so complex that they require the application of concepts for intelligence that do not harmonize with traditional safety engineering. In this paper, we investigate these problems and propose a solution.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在非自主车辆的安全工程中，通常假设如果车辆适当地遵循来自人的某些控制命令，例如转向或加速命令，则实现了安全。如果我们考虑自动驾驶汽车在什么情况下自己决定什么行为是最合理的，这个基本假设就变得有问题了。安全临界扩展到决策过程和相关的环境感知。然而，这些是如此复杂，以至于它们需要应用与传统安全工程不协调的智能概念。在本文中，我们研究这些问题并提出解决方案。",
                    "title_zh": "自动驾驶汽车的安全工程"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.60",
                    "title": "A Distributed Avionics Communication Network",
                    "authors": "Paul Boivin Champeaux, David Faura, Marc Gatti, William Terroy",
                    "abstract": "Today, the avionics platforms are developedaccording to the Integrated Modular Avionics (IMA) concept, allowing one processing module to host one or several applications in order to reduce Space, Weight, Power (SWaP) and costs. According to this evolution, network architectures were developed inwhich modules are interconnected and communicate through a deterministic network which should support critical inter system communications and also a part of intra system communications. The favored answer fully compliant with IMA platform properties for the Avionic Data Network architecture is a centralized communication system using several Avionic Switches as centralequipment's compliant to the standard ARINC 664 Part 7, which defines a deterministic switched communication network at 100 Mbps per link using an Ethernet frame structure. However, a centralized communication system for some aircrafts or helicopters requiring a \"small\"Avionics Data Network is a major overhead for the avionics suite in term of size, weight and globallycost like to the fact that to fulfill the constraints of availability and segregation inside the communication system at least a number of 2 or 4 switches shall be used. This negative impact is stressed by the necessity to upload the configuration tables for each location and to monitor A664 part 7 switch as avionics equipment. A promising approach that allows optimizing SWaP (less Size, Weight and Power) than the currentmain A664 Avionic Data Network is the evolution from the centralized communication system to a distributed communication system without anyadditional dedicated communication equipment. Nevertheless, to fulfill issues like data flow latency mastering, segregation, network availability in case of subscriber loss, configuration should beaddressed while keeping the ARINC 664 properties as data flow partitioning, monitoring and frame structure.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "今天，航空电子平台是根据综合模块化航空电子(IMA)概念开发的，允许一个处理模块管理一个或几个应用程序，以减少空间、重量、功率和成本。根据这种发展，开发了网络体系结构，其中模块通过确定性网络互连和通信，该确定性网络应该支持关键的系统间通信以及系统内通信的一部分。对于航空电子数据网络体系结构，完全符合IMA平台特性的有利答案是使用几个航空电子交换机作为中央设备的集中式通信系统符合标准ARINC 664 Part 7，该标准使用以太网帧结构定义了每链路100 Mbps的确定性交换通信网络。然而，对于某些需要“小型”航空电子数据网络的飞机或直升机来说，集中通信系统在尺寸、重量和总体成本方面是航空电子设备组的主要开销，因为为了满足通信系统内部可用性和隔离的限制，至少要使用2或4个交换机。上传每个位置的配置表以及将A664 part 7交换机作为航空电子设备进行监控的必要性加剧了这种负面影响。允许优化SWaP(比当前主A664航空电子数据网络更小的尺寸、重量和功率)的一种有前途的方法是从集中式通信系统发展到分布式通信系统，而不需要任何额外的专用通信设备。然而，为了解决数据流延迟控制、隔离、用户丢失情况下的网络可用性等问题，应该在保持ARINC 664属性(如数据流划分、监控和帧结构)的同时进行配置。",
                    "title_zh": "分布式航空电子通信网络"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.43",
                    "title": "HARP: High Availability Registration Platform for Software Defined Infrastructure",
                    "authors": "Henry Zhu, Sejun Song",
                    "abstract": "The recent networking paradigm changes towards virtualization and the softwareisation of network functions, controls, applications are expected to improve cost efficiency, control accuracy, and deployment flexibility. However, the issue of reliability in softwareisation architecture becomes more complex and poses many critical challenges on the existing network reliability mechanisms in order to achieve the same reliability services. In this paper, we propose and implement a High Availability Registration Platform (HARP) to orchestrate SDN reliability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近的网络模式朝着网络功能、控制和应用的虚拟化和软件化的方向转变，这有望提高成本效率、控制准确性和部署灵活性。然而，软件化架构中的可靠性问题变得更加复杂，并对现有的网络可靠性机制提出了许多严峻的挑战，以实现相同的可靠性服务。在本文中，我们提出并实现了一个高可用性注册平台(HARP)来协调SDN的可靠性。",
                    "title_zh": "HARP:软件定义基础设施的高可用性注册平台"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.37",
                    "title": "Secure Embedded Hypervisor Based Systems for Automotive",
                    "authors": "Stefaan Sonck Thiebaut, Antonio De Rosa, Ralph Sasse",
                    "abstract": "Hypervisors are an existing solution for security challenges in automotive domain. Nevertheless, advancedcybersecurity threats cannot be mitigated without hardware support, further software components, and harmonized security standardization.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虚拟机管理程序是汽车领域安全挑战的现有解决方案。然而，如果没有硬件支持、更多的软件组件和统一的安全标准，高级网络安全威胁是无法缓解的。",
                    "title_zh": "面向汽车行业的安全嵌入式虚拟机管理程序系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.19",
                    "title": "Software Safety Assessment and Probabilities",
                    "authors": "Jean-Paul Blanquart, Philippe Baufreton, Jean-Louis Boulanger, Jean-Louis Camus, Cyrille Comar, Hervé Delseny, Jean Gassino, Emmanuel Ledinot, Philippe Quéré, Bertrand Ricque",
                    "abstract": "In a context where software is more and more pervasive in all systems, and where it is sometimes advocated that software complexity and size seem to provide some relevance to a probabilistic view of software behaviour, several initiatives suggest to change the way to address software in the global system safety assessment. The authors argue that whereas there are many links between safety assessment and probabilities, both at global level and for what concern random causes of failures, there are many reasons why this is not easily applicable to systematic causes in general and software in particular.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在软件在所有系统中越来越普遍的背景下，有时有人主张软件的复杂性和大小似乎与软件行为的概率观点有某种关联，一些倡议建议改变在全球系统安全评估中处理软件的方式。作者认为，尽管安全评估和概率之间有许多联系，无论是在全球层面还是在涉及故障的随机原因时，有许多原因使其不容易适用于一般的系统原因，尤其是软件。",
                    "title_zh": "软件安全评估和概率"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.24",
                    "title": "AUTOSAR for Connected and Autonomous Vehicles: The AUTOSAR Adaptive Platform",
                    "authors": "Simon Fürst, Markus Bechter",
                    "abstract": "New applications like highly automated driving, Car-2-X, software updates over the air, or vehicles as part of the internet of things raise completely new requirements to a software platform for the next generation of ECUs. AUTOSAR as the worldwide leading standardization organization for in-vehicle software bears this challenge and paves the way making vehicles intelligent and adaptive. Based on a set of selected use-cases, identified by the AUTOSAR partners, the challenges and the approach to master requirements for next generation cars are described. The new platform aims to support dynamic deployment of customer applications, to provide an environment for applications that require high-end computing power and to connect deeply embedded and non-AUTOSAR systems in a smooth way while preserving typical features originated in deeply embedded systems like safety, determinism and real-time capabilities. Built around existing standards such as POSIX, the AUTOSAR Adaptive Platform will complement automotive specific functionalities enabling the platform to run in an automotive network.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高度自动化驾驶、Car-2-X、空中软件更新或作为物联网一部分的车辆等新应用对下一代ECU的软件平台提出了全新的要求。作为全球领先的车载软件标准化组织，AUTOSAR承担了这一挑战，并为车辆的智能化和适应性铺平了道路。基于AUTOSAR合作伙伴确定的一组精选用例，描述了挑战和掌握下一代汽车要求的方法。新平台旨在支持客户应用的动态部署，为需要高端计算能力的应用提供环境，并以平稳的方式连接深度嵌入式和非AUTOSAR系统，同时保留源自深度嵌入式系统的典型功能，如安全性、确定性和实时功能。围绕POSIX等现有标准构建的AUTOSAR自适应平台将补充汽车专用功能，使该平台能够在汽车网络中运行。",
                    "title_zh": "面向互联车辆和自动驾驶车辆的AUTOSAR:AUTOSAR自适应平台"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.36",
                    "title": "Evaluation of EEE Reliability Prediction Models for Space Applications",
                    "authors": "S. Bourbouse, Jean-Paul Blanquart, J. F. Gajewski, C. Lahorgue",
                    "abstract": "The purpose of this paper is to report on a one-year study granted early 2015 by ESA/ESTEC to Airbus Defence and Space to identify and analyse the main reliability models available for evaluating the failure rate of each EEE component used in space systems, in order to assess their suitability in the space context for developing an improved reliability prediction approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文件的目的是报告欧空局/ESTEC于2015年初授予空中客车防务和航天公司的一项为期一年的研究，该研究旨在确定和分析可用于评估空间系统中使用的每个EEE部件故障率的主要可靠性模型，以评估这些模型在空间环境中是否适合开发一种改进的可靠性预测方法。",
                    "title_zh": "空间应用的EEE可靠性预测模型的评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.63",
                    "title": "An Uncrewed Aerial Vehicle Attack Scenario and Trustworthy Repair Architecture",
                    "authors": "Kate Highnam, Kevin Angstadt, Kevin Leach, Westley Weimer, Aaron Paulos, Patrick Hurley",
                    "abstract": "With the growing ubiquity of uncrewed aerial vehicles (UAVs), mitigating emergent threats in such systems has become increasingly important. In this short paper, we discuss an indicative class of UAVs and a potential attack scenario in which a benign UAV completing a mission can be compromised by a malicious attacker with an antenna and a commodity computer with open-source ground station software. We attest to the relevance of such a scenario for both enterprise and defense applications. We describe a system architecture for resiliency and trustworthiness in the face of these attacks. Our system is based on the quantitative assessment of trust from domain-specific telemetry data and the application of program repair techniques to UAV flight plans. We conclude with a discussion of restoring trust in post-repair UAV mission integrity.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着无人驾驶飞行器(UAV)越来越普遍，减轻这种系统中的紧急威胁变得越来越重要。在这篇简短的论文中，我们讨论了一类典型的无人机和一种潜在的攻击场景，在这种场景中，一个完成任务的良性无人机可能会被一个恶意攻击者利用一个天线和一台装有开源地面站软件的商用计算机进行攻击。我们证明了这种场景对于企业和国防应用的相关性。我们描述了一个面对这些攻击时具有弹性和可信度的系统架构。我们的系统是基于特定领域遥测数据的信任度的定量评估，以及程序修复技术在无人机飞行计划中的应用。最后，我们讨论了如何恢复对维修后无人机任务完整性的信任。",
                    "title_zh": "一个未审查的飞行器攻击场景和可信赖的修理体系"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.18",
                    "title": "Transformation of Failure Propagation Models into Fault Trees for Safety Evaluation Purposes",
                    "authors": "Moomen Chaari, Wolfgang Ecker, Thomas Kruse, Cristiano Novello, Bogdan-Andrei Tabacaru",
                    "abstract": "In this paper, we apply model-driven techniques to create a link between bottom-up and top-down safety analysis methods. Around MetaFPA, an internal framework for Metamodeling-based Failure Propagation Analysis, we build a safety evaluation environment integrating standard tools used for FMEDA: Failure Modes, Effects, and Diagnostic Analysis (e.g., Excel spreadsheets) and FTA: Fault Tree Analysis (e.g., Isograph's Reliability Workbench™). The environment contains data exchange and conversion utilities and implements an algorithm to synthesize fault trees out of failure propagation models created with MetaFPA. A case study of an Electric Power Steering (EPS) system shows an effort reduction of up to 70% in creating and handling data-intensive failure analysis models compared to manual approaches. Furthermore, the productive deployment of the environment simplifies safety engineering tasks and helps to advance the quality of safety-relevant components and systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们应用模型驱动技术在自底向上和自顶向下的安全分析方法之间建立联系。围绕MetaFPA(基于元模型的故障传播分析的内部框架)，我们构建了一个安全评估环境，集成了用于FMEDA的标准工具:故障模式、影响和诊断分析(如Excel电子表格)和FTA:故障树分析(如Isograph的可靠性工作台)。该环境包含数据交换和转换实用程序，并实现了一种算法，从使用MetaFPA创建的故障传播模型中合成故障树。对电动助力转向(EPS)系统的案例研究表明，与手动方法相比，创建和处理数据密集型故障分析模型的工作量减少了70%。此外，环境的生产性部署简化了安全工程任务，并有助于提高安全相关组件和系统的质量。",
                    "title_zh": "为安全评估目的将故障传播模型转换成故障树"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.59",
                    "title": "The Concept of a Software-Free Resilience Infrastructure for Cyber-Physical Systems",
                    "authors": "Algirdas Avizienis, Rimas Avizienis, Audrius V. Avizienis",
                    "abstract": "This paper presents the architectural concept of a digital system that can be attached as an infrastructure to a \"Client\" system to enhance its resilience. This system, called \"Resilience Infrastructure\" RI, has four attributes. First, the RI is structured as a tree network of Monitor modules that are implemented by hardware and firmware only and can protect one or more Client systems. Second, the RI is separate from the Client. The only connections between them are error messages and data requests from the Client and error responses and data messages from the RI. Third, the RI is generic, that is, it can be attached to any Client that can issue error messages and data requests, and can receive Client-specified error responses and data messages from the Infrastructure. Fourth, the Infrastructure is self-protecting, that is, it is fully fault-tolerant while employing only hardware and firmware. The architecture and fault tolerance of the Resilience Infrastructure are illustrated by an elementary design.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了一个数字系统的架构概念，它可以作为一个基础设施附加到一个“客户端”系统，以增强其弹性。这个系统被称为“弹性基础设施”RI，有四个属性。首先，RI被构造为仅由硬件和固件实现的监视器模块的树形网络，并且可以保护一个或多个客户端系统。第二，RI与客户端是分离的。它们之间仅有的连接是来自客户端的错误消息和数据请求以及来自RI的错误响应和数据消息。第三，RI是通用的，也就是说，它可以连接到任何可以发出错误消息和数据请求的客户机，并且可以从基础结构接收客户机指定的错误响应和数据消息。第四，基础设施是自我保护的，即它是完全容错的，同时仅使用硬件和固件。弹性基础设施的架构和容错通过一个基本设计来说明。",
                    "title_zh": "信息物理系统的无软件弹性基础设施的概念"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.39",
                    "title": "A System for the Security Protection of Embedded Binary Programs",
                    "authors": "Jack W. Davidson, Jason D. Hiser, Anh Nguyen-Tuong, Clark L. Coleman, William H. Hawkins, John C. Knight, Benjamin D. Rodes, Ashlie B. Hocking",
                    "abstract": "Software for which development artifacts are missing is increasingly common and difficult to avoid, including in embedded systems. The lack of development artifacts leaves doubt about whether the software possesses critical security properties and makes enhancement of the software extremely difficult. Embedded systems often have strict resource restrictions/constraints making the application of security enhancements especially difficult. In this paper, we present details of a system that is being developed to provide significant protection against security exploits of embedded systems. The system operates on binary programs. No source code or other development artifacts are required, and the typical size and time constraints of embedded systems are accounted for in the analysis and processing of subject binary programs. Formal verification of security properties is used to eliminate unnecessary security transformations, and transformations are applied by a highly efficient static binary rewriter.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "缺少开发工件的软件越来越常见，并且难以避免，包括在嵌入式系统中。开发工件的缺乏使人们怀疑软件是否拥有关键的安全属性，并使软件的增强变得极其困难。嵌入式系统通常有严格的资源限制/约束，使得安全增强的应用特别困难。在本文中，我们详细介绍了一个正在开发的系统，该系统能够针对嵌入式系统的安全漏洞提供有效的保护。该系统运行二进制程序。不需要源代码或其他开发工件，并且在分析和处理主题二进制程序时考虑了嵌入式系统的典型大小和时间限制。安全属性的形式验证用于消除不必要的安全转换，转换由高效的静态二进制重写器应用。",
                    "title_zh": "嵌入式二进制程序的安全保护系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.64",
                    "title": "Trusted Software Repair for System Resiliency",
                    "authors": "Westley Weimer, Stephanie Forrest, Miryung Kim, Claire Le Goues, Patrick Hurley",
                    "abstract": "We describe ongoing work to increase trust in resilient software systems. Automated software repair techniques promise to increase system resiliency, allowing missions to continue in the face of software defects. While a number of program repair approaches have been proposed, the most scalable and applicable of those techniques can be the most difficult to trust. Using approximate solutions to the oracle problem, we consider three approaches by which trust can be re-established in a post-repair system. Each approach learns or infers a different form of partial model of correct behavior from pre-repair observations; post-repair systems are evaluated with respect to those models. We focus on partial oracles modeled from external execution signals, derived from similar code fragment behavior, and inferred from invariant relations over local variables. We believe these three approaches can provide an expanded assessment of trust in a repaired, resilient system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们描述了正在进行的工作，以增加对弹性软件系统的信任。自动化软件修复技术有望提高系统的弹性，允许任务在面临软件缺陷时继续进行。虽然已经提出了许多程序修复方法，但是这些技术中最可扩展和最适用的可能是最难信任的。使用oracle问题的近似解，我们考虑了三种在修复后系统中重建信任的方法。每种方法从修复前的观察中学习或推断不同形式的正确行为的部分模型；根据这些模型对维修后系统进行评估。我们关注从外部执行信号建模的部分预言，从相似的代码片段行为导出的部分预言，以及从局部变量的不变关系推断的部分预言。我们相信这三种方法可以在修复后的弹性系统中提供扩展的信任评估。",
                    "title_zh": "面向系统弹性的可信软件修复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.29",
                    "title": "Resiliency Challenges in Accelerating Carrier-Grade Networks with SDN",
                    "authors": "Catello Di Martino, Veena B. Mendiratta, Marina Thottan",
                    "abstract": "Today's carrier-grade networks are highly resilient and provide close to 4 9s end-to-end availability for various services. Going forward it is expected that Software Defined Networking (SDN) will be deployed in carrier networks to offer dynamically programmable services with an equivalent, or even higher, expectation of service availability. Though SDN, with the separation of the control and data planes, offers flexibility and programmability it also presents significant challenges with respect to resiliency. In this position paper we present the resiliency challenges for future carrier-grade networks based on SDN. To this end, we first present an analysis of outage data for today's carrier-grade networks to identify critical failure patterns across several network devices and infer network outage impacts. We then describe an architecture to implement future carrier-grade networks leveraging cloud computing and SDN. Finally, based on our findings on today's carrier-grade networks we identify resiliency challenges for SDN based carrier-grade networks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "今天的电信级网络具有高度弹性，能够为各种服务提供接近4个9的端到端可用性。展望未来，预计软件定义网络(SDN)将部署在运营商网络中，以提供具有同等甚至更高服务可用性预期的动态可编程服务。虽然SDN通过控制和数据平面的分离提供了灵活性和可编程性，但它也带来了弹性方面的重大挑战。在这份立场文件中，我们介绍了基于SDN的未来电信级网络面临的弹性挑战。为此，我们首先对当今电信级网络的中断数据进行分析，以确定几个网络设备的关键故障模式，并推断网络中断的影响。然后，我们描述了一种利用云计算和SDN实现未来电信级网络的架构。最后，根据我们对当今电信级网络的调查结果，我们确定了基于SDN的电信级网络面临的弹性挑战。",
                    "title_zh": "利用SDN加速电信级网络的弹性挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.57",
                    "title": "A Triple Core Lock-Step (TCLS) ARM® Cortex®-R5 Processor for Safety-Critical and Ultra-Reliable Applications",
                    "authors": "Xabier Iturbe, Balaji Venu, Emre Ozer, Shidhartha Das",
                    "abstract": "This paper introduces the ARM Triple Core Lock-Step (TCLS) architecture, which builds up on the industry success of the ARM Cortex-R5 Dual-Core Lock-Step (DCLS) processor currently used in safety-critical real-time applications. The TCLS architecture adds a third redundant CPU unit to the DCLS Cortex-R5 system to achieve fail functional capabilities and hence increase the availability of the system. The TCLS architecture allows for transparent, quicker and more reliable resynchronization of the CPUs in the event of an error as the erroneous CPU can be identified by comparing its outputs, and the correct architectural state can be restored from one of the other two functionally correct CPUs. The quick resynchronization is also possible because there is no need to correct the state of the cache memories, which are shared and isolated from the CPUs. As the TCLS architecture provides reliability at the system level, individual CPUs do not need to be fault-tolerant, and can be implemented using commercial technology process that provides higher performance, better energy and cost efficiency than rad-hard process technology. The expectation is that the TCLS could increase reliability in the industrial applications where ARM processors are mainstream (e.g., automotive), as well as in new applications where there is currently no presence of ARM technology (e.g., space).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了ARM三核锁步(TCLS)架构，该架构建立在目前用于安全关键实时应用的ARM Cortex-R5双核锁步(DCLS)处理器的行业成功基础之上。TCLS架构为DCLS Cortex-R5系统增加了第三个冗余CPU单元，以实现故障功能，从而提高系统的可用性。TCLS架构允许在发生错误时对CPU进行透明、更快和更可靠的重新同步，因为可以通过比较其输出来识别错误的CPU，并且可以从其他两个功能正确的CPU之一恢复正确的架构状态。快速再同步也是可能的，因为不需要校正高速缓冲存储器的状态，高速缓冲存储器是共享的并且与CPU隔离。由于TCLS架构提供了系统级的可靠性，因此单个CPU无需具备容错能力，并且可以使用比rad-hard工艺技术提供更高性能、更好能源和成本效益的商业技术工艺来实现。预计TCL可以提高ARM处理器占主流的工业应用(例如汽车)以及目前没有ARM技术的新应用(例如太空)的可靠性。",
                    "title_zh": "面向安全关键和超可靠应用的三核锁步(TCLS) ARM Cortex -R5处理器"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.13",
                    "title": "Improving DRAM Fault Characterization through Machine Learning",
                    "authors": "Elisabeth Baseman, Nathan DeBardeleben, Kurt B. Ferreira, Scott Levy, Steven Raasch, Vilas Sridharan, Taniya Siddiqua, Qiang Guan",
                    "abstract": "As high-performance computing systems continue to grow in scale and complexity, the study of faults and errors is critical to the design of future systems and mitigation schemes. Fault modes in system DRAM are a frequently-investigated key aspect of memory reliability. While current schemes require offline analysis for proper classification, current state-of-the-art mitigation techniques require accurate online prediction for optimal performance. In this work, we explore the predictive performance of an online machine learning-based approach in classifying DRAM fault modes from two leadership-class supercomputing facilities. Our results compare the predictive performance of this online approach with the current rule-based approach based on expert knowledge, finding a 12% predictive performance improvement. We also investigate the universality of our classifiers by evaluating predictive performance using training data from disparate computing systems to achieve a 7% improvement in predictive performance. Our work provides a critical analysis of this online learning technique and can benefit system designers to help inform best practices for dealing with reliability on future systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着高性能计算系统的规模和复杂性不断增长，对故障和错误的研究对于未来系统和缓解方案的设计至关重要。系统DRAM中的故障模式是存储器可靠性的一个经常调查的关键方面。虽然当前的方案需要离线分析来进行正确的分类，但是当前最先进的缓解技术需要精确的在线预测来获得最佳性能。在这项工作中，我们探索了基于在线机器学习的方法在两个领先的超级计算设施中分类DRAM故障模式的预测性能。我们的结果将这种在线方法的预测性能与当前基于专家知识的基于规则的方法进行了比较，发现预测性能提高了12%。我们还通过使用来自不同计算系统的训练数据评估预测性能来研究我们的分类器的通用性，以实现7%的预测性能改进。我们的工作提供了这种在线学习技术的关键分析，并可以使系统设计者受益，以帮助他们了解处理未来系统可靠性的最佳实践。",
                    "title_zh": "通过机器学习改进DRAM故障表征"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.17",
                    "title": "Towards Black-Box Anomaly Detection in Virtual Network Functions",
                    "authors": "Carla Sauvanaud, Kahina Lazri, Mohamed Kaâniche, Karama Kanoun",
                    "abstract": "The maturity of hardware virtualization has motivated communication service providers to apply this paradigm to network services. Virtual Network Functions (VNFs) come from this motivation and refer to any virtual execution environment configured to provide a given network service. VNFs constitute a new paradigm and related dependability evaluation mechanisms are still not thoroughly defined. In this paper we propose a preliminary evaluation of an anomaly detection approach applied to VNFs. Our approach uses a supervised machine learning algorithm. It notably relies on data provided by the underlying hypervisor of the VMs hosting the VNF, making it a black-box approach. Such an approach is actually well suited for infrastructure or telecommunication service providers willing to deploy tools that are easily configurable while reducing deployment costs. We validate our approach with the case study of the vIMS (IP Multimedia Subsystem) implemented by the Clearwater project.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01419016/file/industrial_track_DSN16.pdf"
                    },
                    "abstract_zh": "硬件虚拟化的成熟促使通信服务提供商将这种模式应用于网络服务。虚拟网络功能(VNFs)来源于这一动机，指的是被配置成提供给定网络服务的任何虚拟执行环境。VNFs构成了一个新的范例，相关的可信性评估机制仍然没有完全定义。在本文中，我们提出了一个应用于虚拟网络文件系统的异常检测方法的初步评估。我们的方法使用监督机器学习算法。值得注意的是，它依赖于托管VNF的虚拟机的底层虚拟机管理程序提供的数据，这使它成为一种黑盒方法。这种方法实际上非常适合基础设施或电信服务提供商，他们愿意部署易于配置的工具，同时降低部署成本。我们用Clearwater项目实施的vIMS (IP多媒体子系统)的案例研究来验证我们的方法。",
                    "title_zh": "虚拟网络功能中的黑盒异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.58",
                    "title": "Profiling Memory Vulnerability of Big-Data Applications",
                    "authors": "Navaneeth Rameshan, Robert Birke, Leandro Navarro, Vladimir Vlassov, Bhuvan Urgaonkar, George Kesidis, Martin L. Schmatz, Lydia Y. Chen",
                    "abstract": "Motivated by the increasing popularity of hosting in-memory big-data analytics in cloud, we present a profiling methodology that can understand how different memory subsystems, i.e., cache and memory bandwidth, are susceptible to the impact of interference from co-located applications. We first describe the design of the proposed tool and demonstrate a case study consisting of five Spark applications on real-life data set.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "受在云中托管内存中大数据分析日益流行的推动，我们提出了一种分析方法，可以了解不同的内存子系统(即缓存和内存带宽)如何容易受到位于同一位置的应用程序的干扰影响。我们首先描述了所提出的工具的设计，并展示了一个由真实数据集上的五个Spark应用程序组成的案例研究。",
                    "title_zh": "分析大数据应用程序的内存漏洞"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.53",
                    "title": "Common Safety Method for Risk Evaluation and Assessment (CSM-RA) and Hazard Analysis Tutorial: Managing Effectively Significant Changes in a Railway System",
                    "authors": "Francisco Moreira, Nuno Pedro Silva",
                    "abstract": "Common Safety Method for Risk Evaluation andAssessment (CSM-RA) and Hazard Analysis Tutorial: Managing Effectively Significant Changes in a Railway System.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "风险评估和评价的通用安全方法(CSM-RA)和危险分析指南:有效管理铁路系统中的重大变化。",
                    "title_zh": "风险评估和评价的通用安全方法(CSM-RA)和危险分析指南:有效管理铁路系统中的重大变化"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.51",
                    "title": "DSN 2016 Tutorial: Reliability and Availability Modeling in Practice",
                    "authors": "Kishor S. Trivedi, Andrea Bobbio",
                    "abstract": "In this tutorial we will expose methods used in reliability, availability, performability and survivability modeling and analysis of systems in practice. Non-state-space solution methods are often used to solve reliability block diagrams, fault trees and reliability graphs [1,2,4]. Relatively efficient algorithms are known to handle systems with hundreds of components and have been implemented in many software packages. We will show the usage of these model types through practical examples and via the software package SHARPE [3].",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本教程中，我们将展示在实践中系统的可靠性、可用性、可执行性和生存性建模和分析中使用的方法。非状态空间求解方法通常用于求解可靠性框图、故障树和可靠性图[1，2，4]。已知相对有效的算法可以处理具有数百个组件的系统，并且已经在许多软件包中实现。我们将通过实际例子和软件包SHARPE [3]展示这些模型类型的用法。",
                    "title_zh": "DSN 2016教程:实践中的可靠性和可用性建模"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.55",
                    "title": "Activating Protection and Exercising Recovery Against Large-Scale Outages on the Cloud",
                    "authors": "Long Wang, Harigovind V. Ramasamy, Ruchi Mahindru, Richard E. Harper",
                    "abstract": "Cloud computing provides rapid provisioning, convenient deployment, and simplified management of computing resources and applications with pay-as-you-go pricing models [1]. As more and more workloads are created on the cloud or migrated to the cloud for economic and flexibility reasons, it is important for developers, users, and service providers alike to understand the challenges, opportunities, complexities, and benefits of building dependable systems and applications on the cloud. In this tutorial, we give participants first-hand experience in protecting and recovering against large-scale cloud outages, e.g., failure of an entire cloud site. The tutorial is organized as a full-day activity and is designed to be hands-on. The content is targeted towards a broad audience of users, developers, practitioners, and researchers in the area of cloud computing. The content level is beginner-to-intermediate, suited for anyone with an undergraduate background in computer science (or equivalent) and basic programming skills. In the theory part of the tutorial, we introduce terminology, concepts, and metrics for providing resiliency on a cloud platform. We catalog factors that make building resilient applications on the cloud easy in some cases and particularly complicated in other cases. We present a reference architecture and a standard set of use cases for resiliency on the cloud. The bulk of the tutorial focuses on educating the audience with a series of hands-on exercises. We use an example set of cloud requirements as the starting point, and then guide the participants through the process of creating a protection and recovery plan. The plan covers details such as how to prioritize different workloads based on their criticality during recovery, what protection and recovery technologies should be used, and whether they should be used at the server level or application level. During the hands-on exercises, participants form teams or work individually to access a pre-created cloud virtual infrastructure and applications hosted on the IBM Softlayer cloud [2], which is geographically distributed across multiple continents. Replication and recovery orchestration form the backbone of many cloud resiliency solutions. We guide the participants through the entire life cycle of a cloud resiliency solution: 1) activation of protection on a set of workloads, 2) recovery of protected workloads upon a large-scale outage, 3) failback of protected workloads from the recovery site to the original site upon restoration of the original site, and 4) test of the implemented protection and recovery solution to ensure the implementation conforms to the requirements. Using a real-world orchestration technology, participants activate protection against outages at multiple levels of the cloud stack, orchestrate recovery procedure for a simulated site-level outage, and orchestrate failback to the primary cloud site (simulating the reconstruction of that site). We perform exercises for protecting and recovering both servers and applications using different types of replication technologies. The hands-on exercises are tailored to enable audience members to gain a strong grasp of the practical challenges involved in cloud resiliency, e.g., determining recovery priorities based on business criticality, recovery groups, and coordinated recovery across multiple virtual machines constituting a business application. Through the exercises, we reinforce core design principles and design elements for building resilient cloud applications. We expose the participants to a wide range of protection and recovery options for achieving resiliency against site-level cloud outages. Cloud users can use this experience to make more informed decisions on protecting their workloads against large-scale failures. After the hands-on exercises, we conclude with a survey of commercial and academic solutions, emerging areas, and future research challenges in the area of cloud resiliency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云计算通过现收现付的定价模式提供了计算资源和应用的快速供应、便捷部署和简化管理[1]。由于经济和灵活性的原因，越来越多的工作负载在云上创建或迁移到云上，对于开发人员、用户和服务提供商来说，了解在云上构建可靠的系统和应用程序的挑战、机会、复杂性和好处是非常重要的。在本教程中，我们将为参与者提供针对大规模云中断(例如，整个云站点的故障)进行保护和恢复的第一手经验。本教程是一整天的活动，旨在实践。该内容面向云计算领域的广大用户、开发人员、从业人员和研究人员。内容水平从初级到中级，适合任何具有计算机科学本科背景(或同等学历)和基本编程技能的人。在本教程的理论部分，我们介绍了在云平台上提供弹性的术语、概念和指标。我们列出了一些因素，这些因素使得在云上构建弹性应用程序在某些情况下变得容易，而在其他情况下变得特别复杂。我们提供了一个参考架构和一组标准的云弹性使用案例。本教程的主要内容是通过一系列实践练习来教育观众。我们使用一组示例云需求作为起点，然后指导参与者完成创建保护和恢复计划的过程。该计划涵盖了各种细节，例如如何在恢复期间根据不同工作负载的重要程度确定其优先级，应使用何种保护和恢复技术，以及是在服务器级别还是在应用程序级别使用这些技术。在实践练习中，参与者组成团队或单独工作来访问预先创建的云虚拟基础架构和托管在IBM Softlayer cloud [2]上的应用程序，这些应用程序在地理上分布在多个大洲。复制和恢复流程编排构成了许多云恢复解决方案的支柱。我们指导参与者完成云弹性解决方案的整个生命周期:1)激活对一组工作负载的保护，2)在大规模停机时恢复受保护的工作负载，3)在恢复原始站点时将受保护的工作负载从恢复站点回切到原始站点，以及4)测试实施的保护和恢复解决方案，以确保实施符合要求。使用真实世界的编排技术，参与者在云堆栈的多个级别激活针对中断的保护，为模拟的站点级中断编排恢复程序，并编排回切到主云站点(模拟该站点的重建)。我们使用不同类型的复制技术进行保护和恢复服务器和应用程序的练习。实际操作练习旨在使受众成员能够更好地理解云弹性所面临的实际挑战，例如，根据业务关键程度、恢复组确定恢复优先级，以及跨构成业务应用程序的多个虚拟机进行协调恢复。通过练习，我们强化了构建弹性云应用的核心设计原则和设计元素。我们向参与者展示了广泛的保护和恢复选项，以针对站点级云中断实现弹性。云用户可以利用这一经验做出更明智的决策，保护他们的工作负载免受大规模故障的影响。在动手练习之后，我们总结了云弹性领域的商业和学术解决方案、新兴领域和未来研究挑战。",
                    "title_zh": "针对云上的大规模中断激活保护和实施恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.52",
                    "title": "Measuring Resiliency through Field Data: Techniques, Tools and Challenges",
                    "authors": "Antonio Pecchia, Marcello Cinque, Veena B. Mendiratta",
                    "abstract": "Data collected under real workload conditions provide valuable information about the stresses the systems encounter and their responses to them. Textual/numeric data and log files produced by applications, operating systems, networks, and other monitoring sources play a key role for assessing system reliability and resiliency properties. Practitioners, academia, and industry strongly recognize the inherent value of log data. Data-driven evaluation deepens our understanding of the system dependability behavior, and enables stronger design and better monitoring strategies.The role of log files and data for measuring the dependability of production systems is recognized since many years. Seminal contributions date back to the late 70s, with studies on VAX mainframes [1]. Today, these studies are assuming particular relevance for failure analysis and prediction in industrial systems and networks [2], [3]; logs are the primary source of data available to gain insight on runtime issues in these systems. The understanding that can be gained from logs on today's systems enables improved design and better monitoring and failure prediction strategies for future systems. However, in spite of recent advances, data-driven reliability evaluation still presents challenges due to the scale, complexity and diversity of applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在真实工作负载条件下收集的数据提供了关于系统遇到的压力及其响应的有价值的信息。应用程序、操作系统、网络和其他监控来源生成的文本/数字数据和日志文件在评估系统可靠性和弹性属性方面发挥着关键作用。从业者、学术界和工业界强烈认识到日志数据的内在价值。数据驱动的评估加深了我们对系统可靠性行为的理解，并支持更强的设计和更好的监控策略。多年以来，日志文件和数据在衡量生产系统可靠性方面的作用已经得到认可。开创性的贡献可以追溯到70年代末，对VAX大型机的研究[1]。今天，这些研究被认为与工业系统和网络中的故障分析和预测特别相关[2]，[3]；日志是了解这些系统中运行时问题的主要数据源。从当今系统的日志中获得的理解能够为未来系统提供改进的设计、更好的监控和故障预测策略。然而，尽管最近取得了一些进展，但由于应用的规模、复杂性和多样性，数据驱动的可靠性评估仍然面临挑战。",
                    "title_zh": "通过现场数据测量弹性:技术、工具和挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.54",
                    "title": "Building Highly-Available Distributed SDN Applications with ONOS",
                    "authors": "Ali Al-Shabibi, Brian O'Connor, Thomas Vachuska",
                    "abstract": "Building distributed, scalable network control application is a hard problem. With the help of ONOS and throughout this tutorial the attendees will gain hands on experience in how to build distributed control applications. Furthermore, they will learn to use distributed primitives provided by ONOS to ease their application development.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "构建分布式、可扩展的网络控制应用是一个难题。在ONOS的帮助下，通过本教程，与会者将获得如何构建分布式控制应用程序的实践经验。此外，他们将学习使用ONOS提供的分布式原语来简化他们的应用程序开发。",
                    "title_zh": "使用ONOS构建高可用的分布式SDN应用"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.56",
                    "title": "DSN 2016 Tutorial: Resilience for Scientific Computing: From Theory to Practice",
                    "authors": "Franck Cappello, George Bosilca",
                    "abstract": "Envisioning the future Exascale platforms requires a deep understanding of the impact of faults and a realistic view of the needs in terms of reliability. Reliability has been highlighted as one of the major concerns and the IESP projects an increase in node performance and concurrency by one or two orders of magnitude, which translates, even under the most optimistic circumstances, in at least one order of magnitude direct decrease of the mean time to interruption of capability platforms. Because of this tendency, platform providers, software developers, and high-performance application users who target capability runs, cannot regard the occurrence of interruptions due to a failure as a rare dramatic event, but must consider faults as an inevitable component of the computing eco-system, and design and develop software components that have some form of fault-tolerance integrated at their core.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "展望未来的亿亿级平台需要对故障的影响有深刻的理解，并对可靠性方面的需求有现实的看法。可靠性已被强调为主要关注点之一，IESP计划将节点性能和并发性提高一个或两个数量级，即使在最乐观的情况下，这也意味着功能平台的平均中断时间将直接减少至少一个数量级。由于这种趋势，以能力运行为目标的平台提供商、软件开发商和高性能应用程序用户不能将由于故障导致的中断的发生视为罕见的戏剧性事件，而是必须将故障视为计算生态系统的不可避免的组件，并设计和开发在其核心集成了某种形式的容错的软件组件。",
                    "title_zh": "DSN 2016教程:科学计算的弹性:从理论到实践"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.65",
                    "title": "A Unified Framework for Error Correction in On-chip Memories",
                    "authors": "Frederic Sala, Henry Duwe, Lara Dolecek, Rakesh Kumar",
                    "abstract": "Many techniques have been proposed to improve the reliability of on-chip memories (e.g., caches). These techniques can be broadly characterized as being based on either errorcorrecting codes, side-information from built-in self test (BIST) routines, or hybrid combinations of the two. Although each proposal has been shown to be favorable under a certain set of assumptions and parameters, it is difficult to determine the suitability of such techniques in the overall design space. In this paper, we seek to resolve this problem by introducing a unified general framework representing such schemes. The framework, composed of storage, decoders, costs, and error rates, allows a full exploration of the design space of reliability techniques. We show how existing schemes can be represented in this framework and we use the framework to examine performance in the practical case of high overall and moderate BIST-undetectable fault rates. We show that erasure-based sideinformation schemes are less sensitive to BIST-undetectable errors compared to other techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "已经提出了许多技术来提高片上存储器(例如，高速缓存)的可靠性。这些技术可以概括地描述为基于纠错码、来自内置自测(BIST)例程的边信息或者两者的混合组合。尽管每个方案在一定的假设和参数下都是有利的，但是很难确定这些技术在整个设计空间中的适用性。在本文中，我们试图通过引入一个统一的通用框架来解决这个问题。该框架由存储、解码器、成本和错误率组成，允许充分探索可靠性技术的设计空间。我们展示了如何在该框架中表示现有的方案，并使用该框架来检查在高总体和中等BIST不可检测故障率的实际情况下的性能。我们表明，与其他技术相比，基于擦除的边信息方案对BIST不可检测的错误不太敏感。",
                    "title_zh": "片上存储器纠错的统一框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.66",
                    "title": "Special Session at DSN for the Best Papers from SELSE 2016",
                    "authors": "Alan Wood",
                    "abstract": "The 12th Workshop on Silicon Errors in Logic -- System Effects (SELSE) was held on March 29 -- 30, 2016, in Austin, Texas, USA. Detailed information about SELSE 2016 and previous SELSE workshops, including links to presentations, is available at http://www.selse.org. Three papers were selected as the Best of SELSE papers and are presented in this special DSN session.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "第12届逻辑系统效应中的硅误差研讨会(SELSE)于2016年3月29 - 30日在美国德克萨斯州奥斯汀举行。有关SELSE 2016和之前SELSE研讨会的详细信息，包括演示文稿的链接，可在http://www.selse.org获得。三篇论文被选为SELSE论文中的最佳论文，并在本次DSN特别会议上发表。",
                    "title_zh": "DSN特别会议，评选SELSE 2016最佳论文"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.67",
                    "title": "Software-Defined Error-Correcting Codes",
                    "authors": "Mark Gottscho, Clayton Schoeny, Lara Dolecek, Puneet Gupta",
                    "abstract": "Conventional error-correcting codes (ECCs) and system-level fault-tolerance mechanisms are currently treated as separate abstraction layers. This can reduce the overall efficacy of error detection and correction (EDAC) capabilities, impacting the reliability of memories by causing crashes or silent data corruption. To address this shortcoming, we propose Software-Defined ECC (SWD-ECC), a new class of heuristic techniques to recover from detected but uncorrectable errors (DUEs) in memory. It uses available side information to estimate the original message by first filtering and then ranking the possible candidate codewords for a DUE. SWD-ECC does not incur any hardware or software overheads in the cases where DUEs do not occur.As an exemplar for SWD-ECC, we show through offline analysis on SPEC CPU2006 benchmarks how to heuristically recover from 2-bit DUEs in MIPS instruction memory using a common (39,32) single-error-correcting, double-error-detecting (SECDED) code. We first apply coding theory to compute all of the candidate codewords for a given DUE. Second, we filter out the candidates that are not legal MIPS instructions, increasing the chance of successful recovery. Finally, we choose a valid candidate whose logical operation (e.g., add or load) occurs most frequently in the application binary image. Our results show that on average, 34% of all possible 2-bit DUEs in the evaluated set of instructions can be successfully recovered using this heuristic recovery strategy. If a DUE affects the bit fields used for instruction decoding, we are able to recover correctly up to 99% of the time. We believe these results to be a significant achievement compared to an otherwise-guaranteed crash which can be undesirable in many systems and applications. Moreover, there is room for future improvement of this result with more sophisticated uses of side information. We look forward to future work in this area.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传统的纠错码(ECC)和系统级容错机制目前被视为独立的抽象层。这可能会降低错误检测和纠正(EDAC)功能的整体功效，通过导致崩溃或静默数据损坏来影响内存的可靠性。为了解决这一缺点，我们提出了软件定义的ECC (SWD-ECC)，这是一种新的启发式技术，用于从内存中检测到的但无法纠正的错误(due)中恢复。它使用可用的辅助信息来估计原始消息，首先过滤，然后对DUE的可能候选码字进行排序。在不发生费用的情况下，SWD-ECC不会产生任何硬件或软件开销。作为SWD-ECC的一个示例，我们通过对SPEC CPU2006基准的离线分析，展示了如何使用一个常见的(39，32)单错误纠正、双错误检测(SECDED)代码，从MIPS指令存储器中的2位欠费中进行启发式恢复。我们首先应用编码理论来计算给定DUE的所有候选码字。第二，我们过滤掉不合法的MIPS指令，增加成功恢复的机会。最后，我们选择其逻辑操作(例如，添加或加载)在应用程序二进制映像中出现最频繁的有效候选者。我们的结果表明，平均而言，使用这种启发式恢复策略，可以成功恢复评估的指令集内所有可能的2位到期量的34%。如果DUE影响用于指令解码的位域，我们能够在高达99%的时间内正确恢复。我们相信，与许多系统和应用中不希望出现的保证崩溃相比，这些结果是一项重大成就。此外，通过更复杂地使用边信息，这一结果还有进一步改进的空间。我们期待着这方面的未来工作。",
                    "title_zh": "软件定义的纠错码"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2016.74",
                    "title": "External Assessment of QoS Provisioning in Distributed Cloud Services",
                    "authors": "Kaliappa Nadar Ravindran, Arun Adiththan, Michael Iannelli, Mohammad Rabby",
                    "abstract": "Given a distributed service support system S realized on a cloud (e.g., replicated data services), QoS assessment captures the SLA violations that may arise under various resource depletions and outages faced by S. The issue of less-than-100% guarantee of QoS arises due to the lax control of the underlying cloud resources and components that is typical of third-party providers. Our goal is to reason about how well the system-internal mechanisms are geared to offer a required level of service to the application. We employ computational models of S to determine the optimal feasible output and verify how close is the actual behavior of S to this 'gold-standard'. Case studies from diverse application domains are described to corroborate our assessment methodology.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "给定在云上实现的分布式服务支持系统(例如，复制的数据服务)，QoS评估捕获在S面临的各种资源耗尽和中断的情况下可能出现的SLA违例。由于对底层云资源和组件的松散控制(这是第三方提供商的典型情况),出现了低于100%的QoS保证的问题。我们的目标是推断系统内部机制如何适应为应用程序提供所需的服务级别。我们采用S的计算模型来确定最佳可行输出，并验证S的实际行为与“黄金标准”有多接近。描述了来自不同应用领域的案例研究，以证实我们的评估方法。",
                    "title_zh": "分布式云服务中QoS供应的外部评估"
                }
            ]
        }
    ],
    "2017": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2017.html",
            "conf_title": "47th DSN 2017: Denver, CO, USA",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8019912/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN.2017.28",
                    "title": "Information Leakage in Encrypted Deduplication via Frequency Analysis",
                    "authors": "Jingwei Li, Chuan Qin, Patrick P. C. Lee, Xiaosong Zhang",
                    "abstract": "Encrypted deduplication seamlessly combines encryption and deduplication to simultaneously achieve both data security and storage efficiency. State-of-the-art encrypted deduplication systems mostly adopt a deterministic encryption approach that encrypts each plaintext chunk with a key derived from the content of the chunk itself, so that identical plaintext chunks are always encrypted into identical ciphertext chunks for deduplication. However, such deterministic encryption inherently reveals the underlying frequency distribution of the original plaintext chunks. This allows an adversary to launch frequency analysis against the resulting ciphertext chunks, and ultimately infer the content of the original plaintext chunks. In this paper, we study how frequency analysis practically affects information leakage in encrypted deduplication storage, from both attack and defense perspectives. We first propose a new inference attack that exploits chunk locality to increase the coverage of inferred chunks. We conduct trace-driven evaluation on both real-world and synthetic datasets, and show that the new inference attack can infer a significant fraction of plaintext chunks under backup workloads. To protect against frequency analysis, we borrow the idea of existing performance-driven deduplication approaches and consider an encryption scheme called MinHash encryption, which disturbs the frequency rank of ciphertext chunks by encrypting some identical plaintext chunks into multiple distinct ciphertext chunks. Our trace-driven evaluation shows that MinHash encryption effectively mitigates the inference attack, while maintaining high storage efficiency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "加密重复数据删除将加密和重复数据删除无缝结合，同时实现数据安全性和存储效率。当前技术水平的加密去重系统大多采用确定性加密方法，该方法使用从块本身的内容导出的密钥来加密每个明文块，使得相同的明文块总是被加密成相同的密文块用于去重。然而，这种确定性加密固有地揭示了原始明文块的潜在频率分布。这使得对手能够对得到的密文块进行频率分析，并最终推断出原始明文块的内容。在本文中，我们从攻击和防御两个角度研究了频率分析如何实际影响加密重复数据删除存储中的信息泄漏。我们首先提出了一种新的推断攻击，它利用组块的局部性来增加推断组块的覆盖范围。我们对真实世界和合成数据集进行了跟踪驱动的评估，并表明新的推理攻击可以在备份工作负载下推理出很大一部分明文块。为了防止频率分析，我们借用了现有性能驱动的重复数据删除方法的思想，并考虑了一种称为MinHash加密的加密方案，该加密方案通过将一些相同的明文块加密为多个不同的密文块来扰乱密文块的频率等级。我们的跟踪驱动评估表明，MinHash加密有效地减轻了推理攻击，同时保持了高存储效率。",
                    "title_zh": "基于频率分析的加密重复数据删除中的信息泄漏"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.13",
                    "title": "Privacy Disclosure through Smart Meters: Reactive Power Based Attack and Defense",
                    "authors": "Jingyao Fan, Qinghua Li, Guohong Cao",
                    "abstract": "Smart meters can record fine-grained power consumption data and provide such data to the power supplier through realtime communications. Although smart meters can make power management more efficient and fault-tolerant, they also pose bigger threats to user privacy. Data from smart meters contain fine-grained power consumption information of home appliances and thus can be used to infer the ON/OFF states of home appliances. This problem has received some attention in the literature, however, most of them focus on active power based attacks. This paper focuses on reactive power and demonstrates how attackers can exploit reactive power data to infer appliance usage information. Experiments on real residential smart meter data show that our proposed attack can identify the ON/OFF events of home appliance with high accuracy. To protect users against such attacks, a novel defense technique called Reactive Power Obfuscation (RPO) is proposed. RPO can mask the true reactive power demand from the smart meter by using a capacitor to store and provide reactive power in a controlled manner. We evaluate the performance of RPO based on real household power consumption data. Evaluation results show that the ON/OFF events of home appliances can hardly be revealed from reactive power data when RPO is applied.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "智能电表可以记录精细的功耗数据，并通过实时通信将这些数据提供给电力供应商。虽然智能电表可以使电源管理更加高效和容错，但它们也对用户隐私构成了更大的威胁。来自智能电表的数据包含家用电器的精细功耗信息，因此可用于推断家用电器的开/关状态。这个问题在文献中已经得到了一些关注，然而，它们中的大多数集中在基于主动功率的攻击上。本文重点介绍无功功率，并演示攻击者如何利用无功功率数据来推断电器使用信息。在真实住宅智能电表数据上的实验表明，我们提出的攻击能够以较高的准确率识别家用电器的开关事件。为了保护用户免受此类攻击，提出了一种称为无功功率混淆(RPO)的新型防御技术。RPO可以通过使用电容器以可控方式存储和提供无功功率，来掩盖智能电表的真实无功功率需求。我们基于真实的家庭用电数据来评估RPO的性能。评估结果表明，当应用RPO时，家电的开/关事件很难从无功功率数据中揭示。",
                    "title_zh": "通过智能电表泄露隐私:基于无功功率的攻击和防御"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.26",
                    "title": "What Can We Learn from Four Years of Data Center Hardware Failures?",
                    "authors": "Guosai Wang, Lifei Zhang, Wei Xu",
                    "abstract": "Hardware failures have a big impact on the dependability of large-scale data centers. We present studies on over 290,000 hardware failure reports collected over the past four years from dozens of data centers with hundreds of thousands of servers. We examine the dataset statistically to discover failure characteristics along the temporal, spatial, product line and component dimensions. We specifically focus on the correlations among different failures, including batch and repeating failures, as well as the human operators' response to the failures. We reconfirm or extend findings from previous studies. We also find many new failure and recovery patterns that are the undesirable by-product of the state-of-the-art data center hardware and software design.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "硬件故障对大规模数据中心的可靠性有很大影响。我们对过去四年中从几十个拥有数十万台服务器的数据中心收集的超过290，000份硬件故障报告进行了研究。我们对数据集进行统计分析，以发现时间、空间、产品线和组件维度上的故障特征。我们特别关注不同故障之间的相关性，包括批量故障和重复故障，以及操作员对故障的反应。我们再次确认或扩展了先前研究的发现。我们还发现了许多新的故障和恢复模式，它们是最先进的数据中心硬件和软件设计的不良副产品。",
                    "title_zh": "我们可以从四年的数据中心硬件故障中学到什么？"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.15",
                    "title": "Fast Atomic Multicast",
                    "authors": "Paulo R. Coelho, Nicolas Schiper, Fernando Pedone",
                    "abstract": "Atomic multicast is a communication building block of scalable and highly available applications. With atomic multicast, messages can be ordered and reliably propagated to one or more groups of server processes. Because each message can be multicast to a different set of destinations, distributed message ordering is challenging. Some atomic multicast protocols address this challenge by ordering all messages using a fixed group of processes, regardless of the destination of the messages. To be efficient, however, an atomic multicast protocol must be genuine: only the message sender and destination groups should communicate to order a message. In this paper, we present FastCast, a genuine atomic multicast algorithm that offers unprecedented low time complexity, measured in communication delays. FastCast can order messages addressed to multiple groups in four communication delays, messages addressed to a single group take three communication delays. In addition to proposing a novel atomic multicast protocol, we extensively assess its performance experimentally.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "原子多播是可伸缩和高度可用的应用程序的通信构建块。使用原子多播，消息可以被排序并可靠地传播到一组或多组服务器进程。因为每条消息都可以多播到不同的目的地集合，所以分布式消息排序很有挑战性。一些原子多播协议通过使用一组固定的进程对所有消息进行排序来应对这一挑战，而不考虑消息的目的地。然而，为了提高效率，原子多播协议必须是真实的:只有消息发送者和目的地组应该进行通信以订购消息。在本文中，我们介绍了FastCast，一个真正的原子多播算法，它提供了前所未有的低时间复杂度，以通信延迟来衡量。FastCast可以在四个通信延迟中命令发送给多个组的消息，而发送给单个组的消息需要三个通信延迟。除了提出一个新颖的原子多播协议，我们还通过实验广泛地评估了它的性能。",
                    "title_zh": "快速原子多播"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.35",
                    "title": "Speeding up Consensus by Chasing Fast Decisions",
                    "authors": "Balaji Arun, Sebastiano Peluso, Roberto Palmieri, Giuliano Losa, Binoy Ravindran",
                    "abstract": "This paper proposes CAESAR, a novel multi-leader Generalized Consensus protocol for geographically replicated sites. The main goal of CAESAR is to overcome one of the major limitations of existing approaches, which is the significant performance degradation when application workload produces conflicting requests. CAESAR does that by changing the way a fast decision is taken: its ordering protocol does not reject a fast decision for a client request if a quorum of nodes reply with different dependency sets for that request. The effectiveness of CAESAR is demonstrated through an evaluation study performed on Amazon's EC2 infrastructure using 5 geo-replicated sites. CAESAR outperforms other multi-leader (e.g., EPaxos) competitors by as much as 1.7x in the presence of 30% conflicting requests, and single-leader (e.g., Multi-Paxos) by up to 3.5x.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1704.03319"
                    },
                    "abstract_zh": "本文提出了CAESAR协议，这是一种新的用于地理复制站点的多领导者广义一致性协议。CAESAR的主要目标是克服现有方法的一个主要限制，即当应用程序工作负载产生冲突请求时，性能会显著下降。CAESAR通过改变快速决策的方式来做到这一点:如果节点的法定数量以不同的依赖集回复请求，其排序协议不会拒绝对客户端请求的快速决策。通过使用5个地理复制站点在Amazon的EC2基础设施上执行的评估研究，展示了CAESAR的有效性。在存在30%冲突请求的情况下，CAESAR比其他多领导者(如EPaxos)竞争对手高出1.7倍，比单领导者(如多Paxos)高出3.5倍。",
                    "title_zh": "通过追求快速决策来加速达成共识"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.64",
                    "title": "Secure Causal Atomic Broadcast, Revisited",
                    "authors": "Sisi Duan, Michael K. Reiter, Haibin Zhang",
                    "abstract": "We revisit the problem of preserving causality in Byzantine fault-tolerant (BFT) atomic broadcast protocols, a requirement first proposed by Reiter and Birman (TOPLAS 1994). While over the past three decades, this requirement has been met through the deployment of expensive public-key threshold cryptosystems, we propose three novel, secure causal BFT protocols without using public-key cryptography. We implement and evaluate these protocols, showing that they significantly outperform existing constructions that use threshold cryptosystems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们重新审视拜占庭容错(BFT)原子广播协议中保持因果关系的问题，这是Reiter和Birman (TOPLAS 1994)首先提出的要求。虽然在过去的三十年中，这一要求已经通过部署昂贵的公钥门限密码系统得到满足，但我们提出了三个新的、安全的因果BFT协议，而不使用公钥密码系统。我们实现并评估了这些协议，表明它们明显优于现有的使用门限密码系统的构造。",
                    "title_zh": "安全因果原子广播，再探"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.46",
                    "title": "Reducing the \"Tax\" of Reliability: A Hardware-Aware Method for Agile Data Persistence in Mobile Devices",
                    "authors": "Meng Wang, Huixiang Chen, Tao Li",
                    "abstract": "Nowadays, mobile devices are pervasively used by almost everyone. The majority of mobile devices use embedded-Multi Media Cards (eMMC) as storage. However, the crash-proof mechanism of existing I/O stack has not fully exploited the features of eMMC. In some real usage scenarios, the legacy data persistence procedure may dramatically degrade performance of the system. In response to this, this paper exploits the hardware features of eMMC to improve the efficiency of data persistence while preserving the reliability of current mobile systems. We characterize the existing data persistence scheme and observe that the hardware-agnostic design generates excessive non-critical data and adds expensive barriers in data persistence paths. We alleviate these overheads by leveraging eMMC features. Based on evaluations on real systems, our optimizations achieve 5%-31% performance improvement across a wide range of mobile apps.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，几乎每个人都在普遍使用移动设备。大多数移动设备使用嵌入式多媒体卡(eMMC)作为存储设备。然而，现有I/O栈的防崩溃机制没有充分利用eMMC的特性。在一些真实的使用场景中，遗留数据持久化过程可能会显著降低系统的性能。针对这一点，本文利用eMMC的硬件特性来提高数据持久化的效率，同时保持当前移动系统的可靠性。我们描述了现有的数据持久化方案，并观察到硬件无关的设计产生了过多的非关键数据，并在数据持久化路径中增加了昂贵的障碍。我们通过利用eMMC功能来减少这些开销。基于对真实系统的评估，我们的优化在各种移动应用上实现了5%-31%的性能提升。",
                    "title_zh": "降低可靠性的“税收”:一种在移动设备中实现敏捷数据持久性的硬件感知方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.56",
                    "title": "Exploring the Potential for Collaborative Data Compression and Hard-Error Tolerance in PCM Memories",
                    "authors": "Amin Jadidi, Mohammad Arjomand, Mohammad Khavari Tavana, David R. Kaeli, Mahmut T. Kandemir, Chita R. Das",
                    "abstract": "Limited write endurance is the main obstacle standing in the way of using phase change memory (PCM) in future computing systems. While several wear-leveling and hard-error tolerant techniques have been proposed for improving PCM lifetime, most of these approaches assume that the underlying memory uses a very simple write traffic reduction scheme (e.g., buffering, differential writes). In particular, most PCM prototypes/chips are equipped with an embedded circuit to support differential writes (DW) – on a write, only the bits that differ between the old and new data are updated. With DW, the bit-pattern of updates in a memory block is usually random, which limits the opportunity to exploit the resulting bit pattern for lifetime enhancement at an architecture level (e.g., using techniques such as wear-leveling and hard-error tolerance). This paper focuses on this inefficiency and proposes a solution based on data compression. Employing compression can improve the lifetime of the PCM memory. Using state-of-the-art compression schemes, the size of the compressed data is usually much smaller than the original data written back to memory from the last-level cache on an eviction. By storing data in a compressed format in the target memory block, first, we limit the number of bit flips to fewer memory cells, enabling more efficient intra-line wear-leveling and error recovery, and second, the unused bits in the memory block can be reused as replacements for faulty bits given the reduced size of the (compressed) data. It can also happen that for a portion of the memory blocks, the resulting compressed data is not very small. This can be due to increased data entropy introduced by compression, where the total number of bit flips will be increased over the baseline system. In this paper, we present an approach that provides collaborative operation of data compression, differential writes, wear-leveling and hard-error tolerant techniques targeting PCM memories. We propose approaches that reap the maximum benefits from compression, while also enjoying the benefits of techniques that reduce the number of high-entropy writes. Using an approach that combines different solutions, our mechanism tolerates 2.9× more cell failures per memory line and achieves a 4.3× increase in PCM memory lifetime, relative to our baseline state-of-the-art PCM DIMM memory.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "有限的写耐久性是阻碍在未来计算系统中使用相变存储器(PCM)的主要障碍。虽然已经提出了几种损耗平衡和硬容错技术来提高PCM寿命，但是这些方法中的大多数都假设底层存储器使用非常简单的写流量减少方案(例如，缓冲、差分写)。特别是，大多数PCM原型/芯片都配备了支持差分写入(DW)的嵌入式电路——在写入时，仅更新新旧数据之间的不同位。对于DW，存储器块中更新的位模式通常是随机的，这限制了在架构级别上利用所得位模式来提高寿命的机会(例如，使用诸如损耗平衡和硬错误容限之类的技术)。本文针对这种效率低下的问题，提出了一种基于数据压缩的解决方案。采用压缩可以提高PCM存储器的寿命。使用最先进的压缩方案，压缩数据的大小通常比驱逐时从末级缓存写回内存的原始数据小得多。通过将数据以压缩格式存储在目标存储块中，首先，我们将位翻转的数量限制到更少的存储单元，从而实现更有效的线内损耗平衡和错误恢复；其次，在(压缩)数据的大小减小的情况下，存储块中未使用的位可以重新用作故障位的替换。还可能发生的是，对于一部分存储块，所得到的压缩数据不是非常小。这可能是由于压缩引入的数据熵增加，其中比特翻转的总数将比基准系统增加。在本文中，我们提出了一种针对PCM存储器提供数据压缩、差分写入、损耗均衡和硬容错技术的协作操作的方法。我们提出的方法可以从压缩中获得最大的好处，同时还能享受减少高熵写入次数的技术带来的好处。通过使用一种结合不同解决方案的方法，我们的机制允许每条存储线多2.9倍的单元故障，并实现了PCM存储器寿命的4.3倍增长，相对于我们的基线最先进的PCM DIMM存储器。",
                    "title_zh": "探索PCM存储器中协作数据压缩和硬错误容限的潜力"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.30",
                    "title": "One Bit is (Not) Enough: An Empirical Study of the Impact of Single and Multiple Bit-Flip Errors",
                    "authors": "Behrooz Sangchoolie, Karthik Pattabiraman, Johan Karlsson",
                    "abstract": "Recent studies have shown that technology and voltage scaling are expected to increase the likelihood that particle-induced soft errors manifest as multiple-bit errors. This raises concerns about the validity of using single bit-flips for assessing the impact of soft errors in fault injection experiments. The goal of this paper is to investigate whether multiple-bit errors could cause a higher percentage of silent data corruptions (SDCs) compared to single-bit errors. Based on 2700 fault injection campaigns with 15 benchmark programs, featuring a total of 27 million experiments, our results show that single-bit errors in most cases yields a higher percentage of SDCs compared to multiple-bit errors. However, in 8% of the campaigns we observed a higher percentage of SDCs for multiple-bit errors. For most of these campaigns, the highest percentage of SDCs was obtained by flipping at most 3 bits. Moreover, we propose three ways of pruning the error space based on the results.",
                    "files": {
                        "openAccessPdf": "http://publications.lib.chalmers.se/records/fulltext/248841/local_248841.pdf"
                    },
                    "abstract_zh": "最近的研究表明，预计技术和电压缩放会增加粒子引起的软错误表现为多位错误的可能性。这引起了对在故障注入实验中使用单比特翻转来评估软错误的影响的有效性的关注。本文的目标是调查与单比特错误相比，多比特错误是否会导致更高百分比的静默数据损坏(SDC)。基于15个基准程序的2700次故障注入活动，总共进行了2700万次实验，我们的结果表明，与多位错误相比，大多数情况下单位错误产生的SDC百分比更高。然而，在8%的活动中，我们观察到多位错误的SDC百分比更高。对于这些活动中的大多数，SDC的最高百分比是通过翻转至多3位获得的。此外，我们提出了三种基于结果修剪误差空间的方法。",
                    "title_zh": "一位是不够的:单个和多个位翻转错误影响的实证研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.57",
                    "title": "StatSym: Vulnerable Path Discovery through Statistics-Guided Symbolic Execution",
                    "authors": "Fan Yao, Yongbo Li, Yurong Chen, Hongfa Xue, Tian Lan, Guru Venkataramani",
                    "abstract": "Identifying vulnerabilities in software systems is crucial to minimizing the damages that result from malicious exploits and software failures. This often requires proper identification of vulnerable execution paths that contain program vulnerabilities or bugs. However, with rapid rise in software complexity, it has become notoriously difficult to identify such vulnerable paths through exhaustively searching the entire program execution space. In this paper, we propose StatSym, a novel, automated Statistics-Guided Symbolic Execution framework that integrates the swiftness of statistical inference and the rigorousness of symbolic execution techniques to achieve precision, agility and scalability in vulnerable program path discovery. Our solution first leverages statistical analysis of program runtime information to construct predicates that are indicative of potential vulnerability in programs. These statistically identified paths, along with the associated predicates, effectively drive a symbolic execution engine to verify the presence of vulnerable paths and reduce their time to solution. We evaluate StatSym on four real-world applications including polymorph, CTree, Grep and thttpd that come from diverse domains. Results show that StatSym is able to assist the symbolic executor, KLEE, in identifying the vulnerable paths for all of the four cases, whereas pure symbolic execution fails in three out of four applications due to memory space overrun.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "识别软件系统中的漏洞对于最大限度地减少恶意利用和软件故障造成的损失至关重要。这通常需要正确识别包含程序漏洞或缺陷的易受攻击的执行路径。然而，随着软件复杂性的迅速增加，通过彻底搜索整个程序执行空间来识别这种易受攻击的路径变得非常困难。在本文中，我们提出了StatSym，一种新颖的、自动化的统计引导的符号执行框架，它集成了统计推断的快速性和符号执行技术的严格性，以实现脆弱程序路径发现的精确性、敏捷性和可扩展性。我们的解决方案首先利用程序运行时信息的统计分析来构建指示程序中潜在漏洞的谓词。这些统计识别的路径，连同相关的谓词，有效地驱动符号执行引擎来验证易受攻击路径的存在，并减少它们的解决时间。我们在四个真实世界的应用程序上评估StatSym，包括来自不同领域的polymorph、CTree、Grep和thttpd。结果表明，StatSym能够帮助符号执行器KLEE识别所有四种情况下的易受攻击路径，而纯符号执行在四分之三的应用中由于内存空间溢出而失败。",
                    "title_zh": "StatSym:通过统计引导的符号执行发现易受攻击的路径"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.18",
                    "title": "Dependability-Aware Design Space Exploration for Optimal Synthesis Parameters Tuning",
                    "authors": "Ilya Tuzov, David de Andrés, Juan Carlos Ruiz",
                    "abstract": "This paper studies the impact of logical synthesizers parameters on the performance, power-consumption, area (PPA) and dependability of HW implementations. Deducing optimal synthesis-parameter configurations attending to specific goals is challenging even for simple HW models. The proposal relies on fractional factorial design of experiments to minimize simulation-based fault-injection time. The set of synthesis parameters with an statistically significant impact on PPA and dependability goals is then deduced and regression models are generated to estimate such impact for any synthesis-parameter configuration. Optimal configurations are finally selected attending to specific implementation goals. The whole methodology is automated and applied onto the Xilinx XST synthesizer working on a simplex and TMR version of an enhanced Intel 8051 microcontroller model, but it can be potentially applied to any synthesizer and any HDL-based model. Results show that non-negligible benefits in terms of PPA and dependability can be obtained by simply tuning synthesizer parameters in a proper way.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文研究了逻辑合成器参数对硬件实现的性能、功耗、面积(PPA)和可靠性的影响。即使对于简单的硬件模型，推导出满足特定目标的最佳综合参数配置也是具有挑战性的。该提议依赖于实验的部分因子设计来最小化基于模拟的故障注入时间。然后推导出对PPA和可靠性目标具有统计显著影响的一组合成参数，并生成回归模型来估计任何合成参数配置的这种影响。考虑到具体的实施目标，最终选择最佳配置。整个方法是自动化的，并应用于Xilinx XST频率合成器，在增强型英特尔8051微控制器模型的单工和TMR版本上工作，但它可能应用于任何频率合成器和任何基于HDL的模型。结果表明，通过以适当的方式简单地调谐合成器参数，可以在PPA和可靠性方面获得不可忽略的好处。",
                    "title_zh": "最优综合参数调整的可靠性感知设计空间探索"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.48",
                    "title": "pbSE: Phase-Based Symbolic Execution",
                    "authors": "Qixue Xiao, Yu Chen, Chengang Wu, Kang Li, Junjie Mao, Shize Guo, Yuanchun Shi",
                    "abstract": "The study of software bugs has long been a key area in software security. Dynamic symbolic execution, in exploring the program's execution paths, finds bugs by analyzing all potential dangerous operations. Due to its high coverage and abilities to generate effective testcases, dynamic symbolic execution has attracted wide attention in the research community. However, the success of dynamic symbolic execution is limited due to complex program logic and its difficulty to handle large symbolic data. In our experiments we found that phase-related features of a program often prevents dynamic symbolic execution from exploring deep paths. On the basis of this discovery, we proposed a novel symbolic execution technology guided by program phase characteristics. Compared to KLEE, the most well-known symbolic execution approach, our method is capable of covering more code and discovering more bugs. We designed and implemented pbSE system, which was used to test several commonly used tools and libraries in Linux. Our results showed that pbSE on average covers code twice as much as what KLEE does, and we discovered 21 previously unknown vulnerabilities by using pbSE, out of which 7 are assigned CVE IDs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对软件缺陷的研究长期以来一直是软件安全的一个关键领域。动态符号执行，在探索程序的执行路径时，通过分析所有潜在的危险操作来发现bug。由于其高覆盖率和生成有效测试用例的能力，动态符号执行引起了研究界的广泛关注。然而，由于复杂的程序逻辑及其处理大量符号数据的困难，动态符号执行的成功受到限制。在我们的实验中，我们发现程序中与阶段相关的特性通常会阻止动态符号执行探索深层路径。基于这一发现，我们提出了一种新的由程序阶段特征引导的符号执行技术。与最著名的符号执行方法KLEE相比，我们的方法能够覆盖更多的代码并发现更多的错误。我们设计并实现了pbSE系统，用于测试Linux中几种常用的工具和库。我们的结果显示，pbSE平均覆盖的代码是KLEE的两倍，我们通过使用pbSE发现了21个以前未知的漏洞，其中7个被分配了CVE id。",
                    "title_zh": "pbSE:基于阶段的符号执行"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.12",
                    "title": "IM-Visor: A Pre-IME Guard to Prevent IME Apps from Stealing Sensitive Keystrokes Using TrustZone",
                    "authors": "Chen Tian, Yazhe Wang, Peng Liu, Qihui Zhou, Chengyi Zhang, Zhen Xu",
                    "abstract": "Third-party IME (Input Method Editor) apps are often the preference means of interaction for Android users' input. In this paper, we first discuss the insecurity of IME apps, including the Potentially Harmful Apps (PHA) and malicious IME apps, which may leak users' sensitive keystrokes. The current defense system, such as I-BOX, is vulnerable to the prefix-substitution attack and the colluding attack due to the post-IME nature. We provide a deeper understanding that all the designs with the post-IME nature are subject to the prefix-substitution and colluding attacks. To remedy the above post-IME system's flaws, we propose a new idea, pre-IME, which guarantees that \"Is this touch event a sensitive keystroke?\" analysis will always access user touch events prior to the execution of any IME app code. We designed an innovative TrustZone-based framework named IM-Visor which has the pre-IME nature. Specifically, IM-Visor creates the isolation environment named STIE as soon as a user intends to type on a soft keyboard, then the STIE intercepts, translates and analyzes the user's touch input. If the input is sensitive, the translation of keystrokes will be delivered to user apps through a trusted path. Otherwise, IM-Visor replays non-sensitive keystroke touch events for IME apps or replays non-keystroke touch events for other apps. A prototype of IM-Visor has been implemented and tested with several most popular IMEs. The experimental results show that IM-Visor has small runtime overheads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "第三方IME(输入法编辑器)应用通常是Android用户输入的首选交互方式。在本文中，我们首先讨论了IME应用程序的不安全性，包括潜在有害应用程序(PHA)和恶意IME应用程序，它们可能会泄露用户的敏感按键。当前的防御系统，如I-BOX，由于后IME性质，容易受到前缀替换攻击和共谋攻击。我们提供了一个更深的理解，即所有具有后IME性质的设计都受到前缀替换和共谋攻击。为了弥补上述后IME系统的缺陷，我们提出了一个新的想法，前IME，它保证“这个触摸事件是一个敏感的按键吗？”分析将总是在执行任何IME应用程序代码之前访问用户触摸事件。我们设计了一个基于信任区的创新框架IM-Visor，它具有前IME性质。具体来说，IM-Visor会在用户打算在软键盘上打字时立即创建名为STIE的隔离环境，然后STIE会拦截、转换和分析用户的触摸输入。如果输入是敏感的，按键的翻译将通过一个可信的路径传递给用户应用程序。否则，IM-Visor会重播IME应用程序的非敏感按键触摸事件，或重播其他应用程序的非按键触摸事件。一个IM Visor的原型已经在几个最流行的ime上实现和测试。实验结果表明，IM Visor具有较小的运行时间开销。",
                    "title_zh": "IM-Visor:IME时代之前的一种防护措施，用于防止IME应用程序使用TrustZone窃取敏感的按键"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.45",
                    "title": "Rollback and Forking Detection for Trusted Execution Environments Using Lightweight Collective Memory",
                    "authors": "Marcus Brandenburger, Christian Cachin, Matthias Lorenz, Rüdiger Kapitza",
                    "abstract": "Novel hardware-aided trusted execution environments, as provided by Intel's Software Guard Extensions (SGX), enable to execute applications in a secure context that enforces confidentiality and integrity of the application state even when the host system is misbehaving. While this paves the way towards secure and trustworthy cloud computing, essential system support to protect persistent application state against rollback and forking attacks is missing. In this paper we present LCM – a lightweight protocol to establish a collective memory amongst all clients of a remote application to detect integrity and consistency violations. LCM enables the detection of rollback attacks against the remote application, enforces the consistency notion of fork-linearizability and notifies clients about operation stability. The protocol exploits the trusted execution environment, complements it with simple client-side operations, and maintains only small, constant storage at the clients. This simplifies the solution compared to previous approaches, where the clients had to verify all operations initiated by other clients. We have implemented LCM and demonstrated its advantages with a key-value store application. The evaluation shows that it introduces low network and computation overhead, in particular, a LCM-protected key-value store achieves 0.72x – 0.98x of an SGX-secured key-value store throughput.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1701.00981"
                    },
                    "abstract_zh": "由英特尔软件保护扩展(SGX)提供的新型硬件辅助可信执行环境能够在安全的环境中执行应用，即使主机系统行为不当，也能确保应用状态的机密性和完整性。虽然这为安全可信的云计算铺平了道路，但保护持久应用程序状态免受回滚和分叉攻击的基本系统支持却缺失了。在本文中，我们介绍了LCM——一种轻量级协议，用于在远程应用程序的所有客户端之间建立集体内存，以检测完整性和一致性违规。LCM能够检测针对远程应用程序的回滚攻击，加强分叉线性化的一致性概念，并通知客户端操作稳定性。该协议利用可信执行环境，通过简单的客户端操作对其进行补充，并在客户端仅维护少量的恒定存储。与以前的方法相比，这简化了解决方案，在以前的方法中，客户端必须验证由其他客户端发起的所有操作。我们已经实现了LCM，并通过键值存储应用程序展示了它的优势。评估表明，它引入了较低的网络和计算开销，特别是，LCM保护的键值存储的吞吐量是SGX保护的键值存储的0.72倍到0.98倍。",
                    "title_zh": "使用轻量级集体存储器的可信执行环境的回滚和分叉检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.53",
                    "title": "Secure Tera-scale Data Crunching with a Small TCB",
                    "authors": "Bruno Vavala, Nuno Ferreira Neves, Peter Steenkiste",
                    "abstract": "Outsourcing services to third-party providers comes with a high security cost—to fully trust the providers. Using trusted hardware can help, but current trusted execution environments do not adequately support services that process very large scale datasets. We present LAST-GT, a system that bridges this gap by supporting the execution of self-contained services over a large state, with a small and generic trusted computing base (TCB). LAST-GT uses widely deployed trusted hardware to guarantee integrity and verifiability of the execution on a remote platform, and it securely supplies data to the service through simple techniques based on virtual memory. As a result, LAST-GT is general and applicable to many scenarios such as computational genomics and databases, as we show in our experimental evaluation based on an implementation of LAST-GT on a secure hypervisor. We also describe a possible implementation on Intel SGX.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/835721/files/Secure-Tera-scale-Data-Crunching-with-a-Small-TCB.pdf"
                    },
                    "abstract_zh": "将服务外包给第三方提供商会带来很高的安全成本——完全信任提供商。使用可信硬件会有所帮助，但是当前的可信执行环境不足以支持处理超大规模数据集的服务。我们提出了LAST-GT，它是一个通过支持在一个大的州上执行自包含服务来弥合这一差距的系统，具有一个小的通用可信计算基础(TCB)。LAST-GT使用广泛部署的可信硬件来保证远程平台上执行的完整性和可验证性，并通过基于虚拟内存的简单技术安全地向服务提供数据。因此，LAST-GT是通用的，适用于许多场景，如计算基因组学和数据库，正如我们在基于安全虚拟机管理程序上的LAST-GT实现的实验评估中所示。我们还描述了一种在英特尔SGX上的可能实现。",
                    "title_zh": "利用小型TCB实现万亿级数据处理的安全"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.11",
                    "title": "Concolic Execution on Small-Size Binaries: Challenges and Empirical Study",
                    "authors": "Hui Xu, Yangfan Zhou, Yu Kang, Michael R. Lyu",
                    "abstract": "Concolic execution has achieved great success in many binary analysis tasks. However, it is still not a primary option for industrial usage. A well-known reason is that concolic execution cannot scale up to large-size programs. Many research efforts have focused on improving its scalability. Nonetheless, we find that, even when processing small-size programs, concolic execution suffers a great deal from the accuracy and scalability issues. This paper systematically investigates the challenges that can be introduced even by small-size programs, such as symbolic array and symbolic jump. We further verify that the proposed challenges are non-trivial via real-world experiments with three most popular concolic execution tools: BAP, Triton, and Angr. Among a set of 22 logic bombs we designed, Angr can solve only four cases correctly, while BAP and Triton perform much worse. The results imply that current tools are still primitive for practical industrial usage. We summarize the reasons and release the bombs as open source to facilitate further study.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Concolic execution在许多二进制分析任务中取得了巨大成功。然而，它仍然不是工业应用的主要选择。一个众所周知的原因是concolic执行不能扩展到大型程序。许多研究工作都集中在提高其可扩展性上。尽管如此，我们发现，即使在处理小规模程序时，concolic的执行也会受到准确性和可伸缩性问题的困扰。本文系统地研究了即使是小程序也可能引入的挑战，如符号数组和符号跳转。我们通过三个最流行的concolic执行工具(BAP、Triton和Angr)的真实实验，进一步验证了所提出的挑战并非微不足道。在我们设计的一组22个逻辑炸弹中，Angr只能正确解决4种情况，而BAP和Triton的表现要差得多。结果表明，当前的工具对于实际的工业应用来说仍然是原始的。我们总结原因，将炸弹开源发布，方便进一步研究。",
                    "title_zh": "小型二进制文件的Concolic执行:挑战与实证研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.58",
                    "title": "Towards Automated Discovery of Crash-Resistant Primitives in Binary Executables",
                    "authors": "Benjamin Kollenda, Enes Göktas, Tim Blazytko, Philipp Koppe, Robert Gawlik, Radhesh Krishnan Konoth, Cristiano Giuffrida, Herbert Bos, Thorsten Holz",
                    "abstract": "Many modern defenses rely on address space layout randomization (ASLR) to efficiently hide security-sensitive metadata in the address space. Absent implementation flaws, an attacker can only bypass such defenses by repeatedly probing the address space for mapped (security-sensitive) regions, incurring a noisy application crash on any wrong guess. Recent work shows that modern applications contain idioms that allow the construction of crash-resistant code primitives, allowing an attacker to efficiently probe the address space without causing any visible crash. In this paper, we classify different crash-resistant primitives and show that this problem is much more prominent than previously assumed. More specifically, we show that rather than relying on labor-intensive source code inspection to find a few \"hidden\" application-specific primitives, an attacker can find such primitives semi-automatically, on many classes of real-world programs, at the binary level. To support our claims, we develop methods to locate such primitives in real-world binaries. We successfully identified 29 new potential primitives and constructed proof-of-concept exploits for four of them.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "许多现代防御依靠地址空间布局随机化(ASLR)来有效地将安全敏感元数据隐藏在地址空间中。如果没有实现缺陷，攻击者只能通过重复探测映射(安全敏感)区域的地址空间来绕过这种防御，任何错误的猜测都会导致应用程序崩溃。最近的工作表明，现代应用程序包含允许构建抗崩溃代码原语的习惯用法，允许攻击者有效地探测地址空间，而不会导致任何可见的崩溃。在本文中，我们对不同的抗崩溃原语进行了分类，并表明这个问题比以前假设的更加突出。更具体地说，我们表明，攻击者可以在二进制级别半自动地在许多类真实世界的程序中找到这些原语，而不是依靠劳动密集型的源代码检查来找到一些“隐藏的”特定于应用程序的原语。为了支持我们的主张，我们开发了在现实世界的二进制文件中定位这些原语的方法。我们成功地确定了29个新的潜在原语，并为其中的四个构建了概念验证利用。",
                    "title_zh": "二进制可执行文件中抗崩溃原语的自动发现"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.29",
                    "title": "Function Interface Analysis: A Principled Approach for Function Recognition in COTS Binaries",
                    "authors": "Rui Qiao, R. Sekar",
                    "abstract": "Function recognition is one of the key tasks in binary analysis, instrumentation and reverse engineering. Previous approaches for this problem have relied on matching code patterns commonly observed at the beginning and end of functions. While early efforts relied on compiler idioms and expert-identified patterns, more recent works have systematized the process using machine-learning techniques. In contrast, we develop a novel static analysis based method in this paper. In particular, we combine a low-level technique for enumerating candidate functions with a novel static analysis for determining if these candidates exhibit the properties associated with a function interface. Both control-flow properties (e.g., returning to the location at the stack top at the function entry point) and data-flow properties (e.g., parameter passing via registers and the stack, and the degree of adherence to application-binary interface conventions) are checked. Our approach achieves an F1-score above 99% across a broad range of programs across multiple languages and compilers. More importantly, it achieves a 4x or higher reduction in error rate over best previous results.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "函数识别是二进制分析、仪器仪表和逆向工程中的关键任务之一。以前解决这个问题的方法依赖于匹配通常在函数开始和结束时观察到的代码模式。虽然早期的努力依赖于编译器习惯用法和专家识别的模式，但最近的工作已经使用机器学习技术将该过程系统化。相比之下，本文提出了一种新的基于静态分析的方法。特别地，我们将用于枚举候选函数的低级技术与用于确定这些候选函数是否表现出与函数接口相关联的属性的新颖静态分析相结合。检查控制流属性(例如，返回到函数入口点处堆栈顶部的位置)和数据流属性(例如，通过寄存器和堆栈传递的参数，以及遵守应用程序二进制接口约定的程度)。我们的方法在跨多种语言和编译器的广泛程序中实现了超过99%的F1分数。更重要的是，与以前最好的结果相比，错误率降低了4倍或更多。",
                    "title_zh": "函数接口分析:COTS二进制文件中函数识别的原则方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.31",
                    "title": "Multimodal Indexable Encryption for Mobile Cloud-Based Applications",
                    "authors": "Bernardo Ferreira, João Leitão, Henrique João L. Domingos",
                    "abstract": "In this paper we propose MIE, a Multimodal Indexable Encryption framework that for the first time allows mobile applications to securely outsource the storage and search of their multimodal data (i.e. data containing multiple media formats) to public clouds with privacy guarantees. MIE is designed as a distributed framework architecture, leveraging on shared cloud repositories that can be accessed simultaneously by multiple users. At its core MIE relies on Distance Preserving Encodings (DPE), a novel family of encoding algorithms with cryptographic properties that we also propose. By applying DPE to multimodal data features, MIE enables high-cost clustering and indexing operations to be handled by cloud servers in a privacy-preserving way. Experiments show that MIE achieves better performance and scalability when compared with the state of art, with measurable impact on mobile resources and battery life.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们提出了MIE，这是一个多模态可索引加密框架，首次允许移动应用安全地将其多模态数据(即包含多种媒体格式的数据)的存储和搜索外包给公共云，并保证隐私。MIE被设计为一个分布式框架体系结构，利用多个用户可以同时访问的共享云存储库。其核心MIE依赖于距离保持编码(DPE)，这是一个新的编码算法家族，具有我们也提出的加密属性。通过将DPE应用于多模态数据特性，MIE支持云服务器以保护隐私的方式处理高成本的集群和索引操作。实验表明，与现有技术相比，MIE实现了更好的性能和可扩展性，并对移动资源和电池寿命产生了可测量的影响。",
                    "title_zh": "用于基于移动云的应用的多模式可索引加密"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.37",
                    "title": "Secure Live Migration of SGX Enclaves on Untrusted Cloud",
                    "authors": "Jinyu Gu, Zhichao Hua, Yubin Xia, Haibo Chen, Binyu Zang, Haibing Guan, Jinming Li",
                    "abstract": "The recent commercial availability of Intel SGX (Software Guard eXtensions) provides a hardware-enabled building block for secure execution of software modules in an untrusted cloud. As an untrusted hypervisor/OS has no access to an enclave's running states, a VM (virtual machine) with enclaves running inside loses the capability of live migration, a key feature of VMs in the cloud. This paper presents the first study on the support for live migration of SGX-capable VMs. We identify the security properties that a secure enclave migration process should meet and propose a software-based solution. We leverage several techniques such as two-phase checkpointing and self-destroy to implement our design on a real SGX machine. Security analysis confirms the security of our proposed design and performance evaluation shows that it incurs negligible performance overhead. Besides, we give suggestions on the future hardware design for supporting transparent enclave migration.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "SGX(软件保护扩展)最近的商用为在不可信云中安全执行软件模块提供了一个硬件支持的构建模块。由于不受信任的虚拟机管理程序/操作系统无法访问enclave的运行状态，运行enclave的虚拟机(虚拟机)将失去实时迁移功能，这是云中虚拟机的一项关键功能。本文首次介绍了对支持SGX的虚拟机实时迁移的支持。我们确定安全enclave迁移流程应满足的安全属性，并提出基于软件的解决方案。我们利用诸如两阶段检查点和自毁等技术在真实的SGX机器上实现了我们的设计。安全性分析证实了我们提出的设计的安全性，并且性能评估表明它引起的性能开销可以忽略不计。此外，我们对未来支持透明飞地迁移的硬件设计提出了建议。",
                    "title_zh": "不可信云上SGX飞地的安全实时迁移"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.49",
                    "title": "ContainerLeaks: Emerging Security Threats of Information Leakages in Container Clouds",
                    "authors": "Xing Gao, Zhongshu Gu, Mehmet Kayaalp, Dimitrios Pendarakis, Haining Wang",
                    "abstract": "Container technology provides a lightweight operating system level virtual hosting environment. Its emergence profoundly changes the development and deployment paradigms of multi-tier distributed applications. However, due to the incomplete implementation of system resource isolation mechanisms in the Linux kernel, some security concerns still exist for multiple containers sharing an operating system kernel on a multi-tenancy container cloud service. In this paper, we first present the information leakage channels we discovered that are accessible within the containers. Such channels expose a spectrum of system-wide host information to the containers without proper resource partitioning. By exploiting such leaked host information, it becomes much easier for malicious adversaries (acting as tenants in the container clouds) to launch advanced attacks that might impact the reliability of cloud services. Additionally, we discuss the root causes of the containers' information leakages and propose a two-stage defense approach. As demonstrated in the evaluation, our solution is effective and incurs trivial performance overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "容器技术提供了一个轻量级的操作系统级虚拟主机环境。它的出现深刻地改变了多层分布式应用程序的开发和部署模式。然而，由于Linux内核中系统资源隔离机制的不完全实现，在多租户容器云服务上共享操作系统内核的多个容器仍然存在一些安全问题。在本文中，我们首先介绍了我们发现的可以在容器中访问的信息泄漏通道。这种通道将一系列系统范围的主机信息暴露给容器，而没有适当的资源划分。通过利用这种泄露的主机信息，恶意对手(作为容器云中的租户)更容易发起可能影响云服务可靠性的高级攻击。此外，我们讨论了容器信息泄漏的根本原因，并提出了一个两阶段的防御方法。正如评估中所展示的，我们的解决方案是有效的，并且产生了微不足道的性能开销。",
                    "title_zh": "集装箱漏洞:集装箱云中信息泄漏的新兴安全威胁"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.42",
                    "title": "Athena: A Framework for Scalable Anomaly Detection in Software-Defined Networks",
                    "authors": "Seunghyeon Lee, Jinwoo Kim, Seungwon Shin, Phillip A. Porras, Vinod Yegneswaran",
                    "abstract": "Network-based anomaly detection is a well-mined area of research, with many projects that have produced algorithms to detect suspicious and anomalous activities at strategic points in a network. In this paper, we examine how to integrate an anomaly detection development framework into existing software-defined network (SDN) infrastructures to support sophisticated anomaly detection services across the entire network data plane, not just at network egress boundaries. We present Athena as a new SDN-based software solution that exports a well-structured development interface and provides general purpose functions for rapidly synthesizing a wide range of anomaly detection services and network monitoring functions with minimal programming effort. Athena is a fully distributed application hosting architecture, enabling a unique degree of scalability from prior SDN security monitoring and analysis projects. We discuss example use-case scenarios with Athena's development libraries, and evaluate system performance with respect to usability, scalability, and overhead in real world environments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于网络的异常检测是一个很好的研究领域，许多项目已经产生了检测网络中战略点的可疑和异常活动的算法。在本文中，我们研究了如何将异常检测开发框架集成到现有的软件定义网络(SDN)基础设施中，以支持整个网络数据平面的复杂异常检测服务，而不仅仅是在网络出口边界。我们将Athena展示为一款基于SDN的全新软件解决方案，该解决方案可导出一个结构良好的开发界面，并提供通用功能，以最少的编程工作量快速综合各种异常检测服务和网络监控功能。Athena是一种完全分布式的应用托管架构，与之前的SDN安全监控和分析项目相比，具有独特的可扩展性。我们将讨论Athena开发库的用例场景，并评估系统在现实环境中的可用性、可伸缩性和开销方面的性能。",
                    "title_zh": "Athena:软件定义网络中可扩展的异常检测框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.34",
                    "title": "Multi-level Anomaly Detection in Industrial Control Systems via Package Signatures and LSTM Networks",
                    "authors": "Cheng Feng, Tingting Li, Deeph Chana",
                    "abstract": "We outline an anomaly detection method for industrial control systems (ICS) that combines the analysis of network package contents that are transacted between ICS nodes and their time-series structure. Specifically, we take advantage of the predictable and regular nature of communication patterns that exist between so-called field devices in ICS networks. By observing a system for a period of time without the presence of anomalies we develop a base-line signature database for general packages. A Bloom filter is used to store the signature database which is then used for package content level anomaly detection. Furthermore, we approach time-series anomaly detection by proposing a stacked Long Short Term Memory (LSTM) network-based softmax classifier which learns to predict the most likely package signatures that are likely to occur given previously seen package traffic. Finally, by the inspection of a real dataset created from a gas pipeline SCADA system, we show that an anomaly detection scheme combining both approaches can achieve higher performance compared to various current state-of-the-art techniques.",
                    "files": {
                        "openAccessPdf": "https://orca.cardiff.ac.uk/id/eprint/127039/1/Li_DSN17.pdf"
                    },
                    "abstract_zh": "我们概述了一种用于工业控制系统(ICS)的异常检测方法，该方法结合了对ICS节点之间处理的网络包内容及其时序结构的分析。具体来说，我们利用了ICS网络中所谓的现场设备之间存在的通信模式的可预测性和规律性。通过观察一个系统一段时间而不出现异常，我们开发了一个通用软件包的基线特征数据库。布隆过滤器用于存储签名数据库，然后用于包内容级别异常检测。此外，我们通过提出基于堆叠式长短期记忆(LSTM)网络的softmax分类器来处理时间序列异常检测，该分类器学习预测在给定先前看到的包流量的情况下最可能出现的包签名。最后，通过检查从天然气管道SCADA系统创建的真实数据集，我们表明，与各种当前最先进的技术相比，结合这两种方法的异常检测方案可以实现更高的性能。",
                    "title_zh": "经由包签名和LSTM网络的工业控制系统中的多级异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.55",
                    "title": "Random Walk Based Fake Account Detection in Online Social Networks",
                    "authors": "Jinyuan Jia, Binghui Wang, Neil Zhenqiang Gong",
                    "abstract": "Online social networks are known to be vulnerable to the so-called Sybil attack, in which an attacker maintains massive fake accounts (also called Sybils) and uses them to perform various malicious activities. Therefore, Sybil detection is a fundamental security research problem in online social networks. Random walk based methods, which leverage the structure of an online social network to distribute reputation scores for users, have been demonstrated to be promising in certain real-world online social networks. In particular, random walk based methods have three desired features: they can have theoretically guaranteed performance for online social networks that have the fast-mixing property, they are accurate when the social network has strong homophily property, and they can be scalable to large-scale online social networks. However, existing random walk based methods suffer from several key limitations: 1) they can only leverage either labeled benign users or labeled Sybils, but not both, 2) they have limited detection accuracy for weak-homophily social networks, and 3) they are not robust to label noise in the training dataset. In this work, we propose a new random walk based Sybil detection method called SybilWalk. SybilWalk addresses the limitations of existing random walk based methods while maintaining their desired features. We perform both theoretical and empirical evaluations to compare SybilWalk with previous random walk based methods. Theoretically, for online social networks with the fast-mixing property, SybilWalk has a tighter asymptotical bound on the number of Sybils that are falsely accepted into the social network than all existing random walk based methods. Empirically, we compare SybilWalk with previous random walk based methods using both social networks with synthesized Sybils and a large-scale Twitter dataset with real Sybils. Our empirical results demonstrate that 1) SybilWalk is substantially more accurate than existing random walk based methods for weakhomophily social networks, 2) SybilWalk is substantially more robust to label noise than existing random walk based methods, and 3) SybilWalk is as scalable as the most efficient existing random walk based methods. In particular, on the Twitter dataset, SybilWalk achieves a false positive rate of 1.3% and a false negative rate of 17.3%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "众所周知，在线社交网络容易受到所谓的Sybil攻击，在这种攻击中，攻击者维护大量的虚假帐户(也称为Sybil ),并使用它们来执行各种恶意活动。因此，Sybil检测是在线社交网络中一个基本的安全研究问题。基于随机行走的方法，利用在线社交网络的结构来为用户分配信誉分数，已经被证明在某些现实世界的在线社交网络中是有前途的。特别地，基于随机行走的方法具有三个期望的特征:它们对于具有快速混合属性的在线社交网络可以具有理论上有保证的性能，当社交网络具有强同质化属性时它们是准确的，并且它们可以扩展到大规模在线社交网络。然而，现有的基于随机行走的方法受到几个关键限制:1)它们只能利用标记的良性用户或标记的女巫，而不能两者都利用，2)它们对弱同性社交网络的检测精度有限，以及3)它们对训练数据集中的标签噪声不鲁棒。在这项工作中，我们提出了一个新的随机游走的Sybil检测方法称为SybilWalk。SybilWalk解决了现有的基于随机漫步的方法的局限性，同时保持了它们所期望的特征。我们进行了理论和经验评估，以比较SybilWalk与以前的随机漫步方法。理论上，对于具有快速混合属性的在线社交网络，与所有现有的基于随机漫步的方法相比，SybilsWalk对社交网络中被错误接受的Sybil的数量具有更严格的渐近界限。从经验上来说，我们使用带有合成女巫的社交网络和带有真实女巫的大规模Twitter数据集，将女巫漫步与之前基于随机漫步的方法进行了比较。我们的实验结果表明:1) SybilWalk比现有的基于弱嗜性社交网络的随机漫步的方法更准确，2) SybilWalk比现有的基于随机漫步的方法对标签噪声更鲁棒，以及3) SybilWalk与最有效的现有的基于随机漫步的方法一样可扩展。特别是在Twitter数据集上，SybilWalk实现了1.3%的误报率和17.3%的误报率。",
                    "title_zh": "在线社交网络中基于随机游走的虚假账户检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.17",
                    "title": "Towards Secure and Verifiable Database-Driven Spectrum Sharing",
                    "authors": "Zhili Chen, Lin Chen, Hong Zhong",
                    "abstract": "Database-driven spectrum access is regarded as an effective spectrum redistribution mechanism. However, dialoguing with the spectrum database requires both primary and secondary users to reveal their sensitive data to the spectrum database manager (SDM), leading to serious privacy concerns. In this paper, we show that the SDM can perform database operations (both updates and queries) without knowing any information about the users' sensitive inputs and the database contents, by combining garbled circuits and secret sharing. Our design uses data-oblivious sorting networks to leverage parallelism of query operations, yielding an efficient query algorithm. We further combine secure computations with authentication techniques to get a verification mechanism for correctness checking. As far as we know, our proposal is the first secure and verifiable database-driven spectrum sharing scheme protecting both primary users' (PUs') and secondary users' (SUs') privacies. Finally, we fully implement our system, and demonstrate that even on commodity PC, our implementation suffers mild performance overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "数据库驱动的频谱访问被认为是一种有效的频谱再分配机制。然而，与频谱数据库的对话需要主要和次要用户向频谱数据库管理器(SDM)透露他们的敏感数据，导致严重的隐私问题。本文通过结合乱码电路和秘密共享，证明了SDM可以在不知道用户敏感输入和数据库内容的情况下执行数据库操作(更新和查询)。我们的设计使用数据无关的排序网络来利用查询操作的并行性，从而产生高效的查询算法。我们进一步将安全计算与认证技术相结合，得到一个用于正确性检查的验证机制。据我们所知，我们的建议是第一个安全和可验证的数据库驱动的频谱共享方案，保护主用户和次用户的隐私。最后，我们完全实现了我们的系统，并证明即使在商用PC上，我们的实现也遭受了轻微的性能开销。",
                    "title_zh": "面向安全和可验证的数据库驱动的频谱共享"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.24",
                    "title": "Implicit Smartphone User Authentication with Sensors and Contextual Machine Learning",
                    "authors": "Wei-Han Lee, Ruby B. Lee",
                    "abstract": "Authentication of smartphone users is important because a lot of sensitive data is stored in the smartphone and the smartphone is also used to access various cloud data and services. However, smartphones are easily stolen or co-opted by an attacker. Beyond the initial login, it is highly desirable to re-authenticate end-users who are continuing to access security-critical services and data. Hence, this paper proposes a novel authentication system for implicit, continuous authentication of the smartphone user based on behavioral characteristics, by leveraging the sensors already ubiquitously built into smartphones. We propose novel context-based authentication models to differentiate the legitimate smartphone owner versus other users. We systematically show how to achieve high authentication accuracy with different design alternatives in sensor and feature selection, machine learning techniques, context detection and multiple devices. Our system can achieve excellent authentication performance with 98.1% accuracy with negligible system overhead and less than 2.4% battery consumption.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1708.09754"
                    },
                    "abstract_zh": "智能手机用户的身份验证非常重要，因为智能手机中存储了大量敏感数据，并且智能手机还用于访问各种云数据和服务。然而，智能手机很容易被攻击者窃取或盗用。除了初始登录之外，非常需要对持续访问安全关键型服务和数据的最终用户进行重新身份认证。因此，本文提出了一种新的认证系统，通过利用智能手机中已经普遍内置的传感器，基于行为特征对智能手机用户进行隐式、连续的认证。我们提出了新的基于上下文的认证模型来区分合法的智能手机所有者和其他用户。我们系统地展示了如何通过传感器和特征选择、机器学习技术、上下文检测和多种设备中的不同设计方案来实现高认证准确性。我们的系统可以实现98.1%准确率的出色认证性能，系统开销可以忽略不计，电池功耗不到2.4%。",
                    "title_zh": "利用传感器和上下文机器学习的隐式智能手机用户认证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.21",
                    "title": "Sensor-Based Implicit Authentication of Smartphone Users",
                    "authors": "Wei-Han Lee, Ruby B. Lee",
                    "abstract": "Authentication of smartphone users is important because a lot of sensitive data is stored in the smartphone and the smartphone is also used to access various cloud data and services. However, smartphones are easily stolen or co-opted by an attacker. Beyond the initial login, it is highly desirable to re-authenticate end-users who are continuing to access security-critical services and data. Hence, this paper proposes a novel authentication system for implicit, continuous authentication of the smartphone user based on behavioral characteristics, by leveraging the sensors already ubiquitously built into smartphones. We propose novel context-based authentication models to differentiate the legitimate smartphone owner versus other users. We systematically show how to achieve high authentication accuracy with different design alternatives in sensor and feature selection, machine learning techniques, context detection and multiple devices. Our system can achieve excellent authentication performance with 98.1% accuracy with negligible system overhead and less than 2.4% battery consumption.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "智能手机用户的身份验证非常重要，因为智能手机中存储了大量敏感数据，并且智能手机还用于访问各种云数据和服务。然而，智能手机很容易被攻击者窃取或盗用。除了初始登录之外，非常需要对持续访问安全关键型服务和数据的最终用户进行重新身份认证。因此，本文提出了一种新的认证系统，通过利用智能手机中已经普遍内置的传感器，基于行为特征对智能手机用户进行隐式、连续的认证。我们提出了新的基于上下文的认证模型来区分合法的智能手机所有者和其他用户。我们系统地展示了如何通过传感器和特征选择、机器学习技术、上下文检测和多种设备中的不同设计方案来实现高认证准确性。我们的系统可以实现98.1%准确率的出色认证性能，系统开销可以忽略不计，电池功耗不到2.4%。",
                    "title_zh": "基于传感器的智能手机用户隐式认证"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.52",
                    "title": "REMAX: Reachability-Maximizing P2P Detection of Erroneous Readings in Wireless Sensor Networks",
                    "authors": "Varun Badrinath Krishna, Michael J. Rausch, Benjamin E. Ujcich, Indranil Gupta, William H. Sanders",
                    "abstract": "Wireless sensor networks (WSNs) should collect accurate readings to reliably capture an environment's state. However, readings may become erroneous because of sensor hardware failures or degradation. In remote deployments, centrally detecting those reading errors can result in many message transmissions, which in turn dramatically decreases sensor battery life. In this paper, we address this issue through three main contributions. First, we propose REMAX, a peer-to-peer (P2P) error detection protocol that extends the WSN's life by minimizing message transmissions. Second, we propose a low-overhead error detection approach that helps minimize communication complexity. Third, we evaluate our approach via a trace-driven, discrete-event simulator, using two datasets from real WSN deployments that measure indoor air temperature and seismic wave amplitude. Our results show that REMAX can accurately detect errors and extend the WSN's reachability (effective lifetime) compared to the centralized approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "无线传感器网络(WSNs)应该收集准确的读数，以可靠地捕捉环境的状态。然而，由于传感器硬件故障或退化，读数可能会出错。在远程部署中，集中检测这些读数错误可能会导致许多消息传输，从而大大缩短传感器电池寿命。在本文中，我们通过三个主要贡献来解决这个问题。首先，我们提出了REMAX，一种对等(P2P)错误检测协议，它通过最小化消息传输来延长WSN的寿命。其次，我们提出了一种低开销的错误检测方法，有助于最小化通信复杂性。第三，我们通过跟踪驱动的离散事件模拟器评估我们的方法，使用来自测量室内空气温度和地震波振幅的真实WSN部署的两个数据集。我们的结果表明，与集中式方法相比，REMAX可以准确地检测错误并延长WSN的可达性(有效寿命)。",
                    "title_zh": "REMAX:无线传感器网络中可达性最大化的P2P错误读数检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.23",
                    "title": "Agora: A Dependable High-Performance Coordination Service for Multi-cores",
                    "authors": "Rainer Schiekofer, Johannes Behl, Tobias Distler",
                    "abstract": "Coordination services are essential building blocks of today's data centers as they provide processes of distributed applications with means to reliably exchange data. Consequently, coordination services must deliver high performance to ensure that they do not become a bottleneck for the applications depending on them. Unfortunately, the design of existing services such as ZooKeeper prevents them from scaling with the number of cores on a machine. In this paper, we address this problem with Agora, a high-performance coordination service that is able to both effectively and efficiently utilize multi-core machines. Agora relies on a primary-backup replication architecture that partitions the workload on each server to achieve parallelism while still providing similar consistency guarantees as ZooKeeper. Our evaluation shows that Agora scales with the number of cores and thus can fully utilize the network resources available.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "协调服务是当今数据中心的重要组成部分，因为它们为分布式应用程序的流程提供了可靠交换数据的方法。因此，协调服务必须提供高性能，以确保它们不会成为依赖它们的应用程序的瓶颈。不幸的是，现有服务(如ZooKeeper)的设计阻止了它们随机器内核数量的增加而扩展。在本文中，我们通过Agora来解决这一问题，Agora是一种高性能的协调服务，能够有效且高效地利用多核机器。Agora依赖于主备份复制架构，该架构在每台服务器上划分工作负载以实现并行性，同时仍提供与ZooKeeper类似的一致性保证。我们的评估表明，Agora随着内核数量的增加而扩展，因此可以充分利用可用的网络资源。",
                    "title_zh": "Agora:面向多核的可靠高性能协调服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.43",
                    "title": "Load-Optimal Local Fast Rerouting for Resilient Networks",
                    "authors": "Yvonne-Anne Pignolet, Stefan Schmid, Gilles Trédan",
                    "abstract": "Reliable and highly available computer networks must implement resilient fast rerouting mechanisms: upon a link or node failure, an alternative route is determined quickly, without involving the network control plane. Designing such fast failover mechanisms capable of dealing with multiple concurrent failures however is challenging, as failover rules need to be installed proactively, i.e., ahead of time, without knowledge of the actual failures happening at runtime. Indeed, only little is known today about the design of resilient routing algorithms. This paper presents a deterministic local failover mechanism which we prove to result in a minimum network load for a wide range of communication patterns, solving an open problem. Our mechanism relies on the key insight that resilient routing essentially constitutes a distributed algorithm without coordination. Accordingly, we build upon the theory of combinatorial designs and develop a novel deterministic failover mechanism based on symmetric block design theory which tolerates a maximal number of Ω(n) link failures in an n-node network and in the worst-case, while always ensuring routing connectivity. In particular, we show that at least Ω(ϕ2) link failures are needed to generate a maximum link load of at least ϕ, which matches an existing bound on the number of link failures needed for an optimal failover scheme. We complement our formal analysis with simulations, showing that our approach outperforms prior schemes not only in the worst-case.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01644555/file/dsn17failover.pdf"
                    },
                    "abstract_zh": "可靠且高度可用的计算机网络必须实现弹性快速重路由机制:在链路或节点故障时，快速确定替代路由，而不涉及网络控制平面。然而，设计这种能够处理多个并发故障的快速故障转移机制是具有挑战性的，因为故障转移规则需要主动地安装，即提前安装，而不知道运行时发生的实际故障。事实上，目前对弹性路由算法的设计知之甚少。本文提出了一种确定性的本地故障转移机制，我们证明了这种机制可以在广泛的通信模式下产生最小的网络负载，解决了一个公开的问题。我们的机制依赖于一个关键的观点，即弹性路由本质上构成了一个没有协调的分布式算法。因此，我们在组合设计理论的基础上，开发了一种基于对称块设计理论的新的确定性故障转移机制，该机制在n节点网络中以及在最坏情况下容忍最大数量的ω(n)链路故障，同时总是确保路由连通性。特别地，我们表明至少需要ω(ϕ2)个链路故障来产生至少ϕ的最大链路负载，这与最优故障转移方案所需的链路故障数量的现有界限相匹配。我们用仿真来补充我们的形式分析，表明我们的方法不仅在最坏的情况下也优于先前的方案。",
                    "title_zh": "弹性网络中负载最优的局部快速重路由"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.62",
                    "title": "JMake: Dependable Compilation for Kernel Janitors",
                    "authors": "Julia Lawall, Gilles Muller",
                    "abstract": "The Linux kernel is highly configurable, and thus, in principle, any line of code can be included or excluded from the compiled kernel based on configuration operations. Configurability complicates the task of a kernel janitor, who cleans up faults across the code base. A janitor may not be familiar with the configuration options that trigger compilation of a particular code line, leading him to believe that a fix has been compile-checked when this is not the case. We propose JMake, a mutation-based tool for signaling changed lines that are not subjected to the compiler. JMake shows that for most of the 12,000 file-modifying commits between Linux v4.3 and v4.4 the configuration chosen by the kernel allyesconfig option is sufficient, once the janitor chooses the correct architecture. For most commits, this check requires only 30 seconds or less. We then characterize the situations in which changed code is not subjected to compilation in practice.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01555711/file/jmake.pdf"
                    },
                    "abstract_zh": "Linux内核是高度可配置的，因此，原则上，任何一行代码都可以根据配置操作包含在编译后的内核中，或者从编译后的内核中排除。可配置性使内核管理员的任务变得复杂，他负责清理代码库中的错误。管理员可能不熟悉触发特定代码行编译的配置选项，导致他认为已经对某个修复进行了编译检查，而事实并非如此。我们提出了JMake，一种基于突变的工具，用于发出不服从编译器的变更行的信号。JMake表明，对于Linux v4.3和v4.4之间的12，000个文件修改提交中的大多数，一旦管理员选择了正确的架构，内核allyesconfig选项选择的配置就足够了。对于大多数提交，这种检查只需要30秒或更少。然后，我们描述了在实践中修改后的代码没有经过编译的情况。",
                    "title_zh": "JMake:内核监控程序的可靠编译"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.63",
                    "title": "Counting in the Dark: DNS Caches Discovery and Enumeration in the Internet",
                    "authors": "Amit Klein, Haya Shulman, Michael Waidner",
                    "abstract": "Domain Name System (DNS) is a fundamental element of the Internet providing lookup services for end users as well as for a multitude of applications, systems and security mechanisms that depend on DNS, such as antispam defences, routing security, firewalls, certificates and more. Caches constitute a critical component of DNS, allowing to improve efficiency and reduce latency and traffic in the Internet. Understanding the behaviour, configurations and topologies of caches in the DNS platforms in the Internet is important for efficiency and security of Internet users and services. In this work we present methodologies for efficiently discovering and enumerating the caches of the DNS resolution platforms in the Internet. We apply our techniques and methodologies for studying caches in popular DNS resolution platforms in the Internet. Our study includes networks of major ISPs, enterprises and professionally managed open DNS resolvers. The results of our Internet measurements shed light on architectures and configurations of the caches in DNS resolution platforms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "域名系统(DNS)是互联网的一个基本元素，为最终用户以及众多依赖于DNS的应用程序、系统和安全机制(如反垃圾邮件防御、路由安全、防火墙、证书等)提供查找服务。缓存是DNS的重要组成部分，可以提高效率，减少互联网中的延迟和流量。了解互联网DNS平台中缓存的行为、配置和拓扑对于互联网用户和服务的效率和安全性非常重要。在这项工作中，我们提出了有效地发现和枚举互联网中DNS解析平台的缓存的方法。我们应用我们的技术和方法来研究互联网上流行的DNS解析平台中的缓存。我们的研究包括主要的ISP、企业和专业管理的开放DNS解析器的网络。我们的互联网测量结果揭示了DNS解析平台中缓存的架构和配置。",
                    "title_zh": "黑暗中的计数:互联网中的DNS缓存发现和枚举"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.39",
                    "title": "Entropy-Based Security Analytics: Measurements from a Critical Information System",
                    "authors": "Marcello Cinque, Raffaele Della Corte, Antonio Pecchia",
                    "abstract": "Critical information systems strongly rely on event logging techniques to collect data, such as housekeeping/error events, execution traces and dumps of variables, into unstructured text logs. Event logs are the primary source to gain actionable intelligence from production systems. In spite of the recognized importance, system/application logs remain quite underutilized in security analytics when compared to conventional and structured data sources, such as audit traces, network flows and intrusion detection logs. This paper proposes a method to measure the occurrence of interesting activity (i.e., entries that should be followed up by analysts) within textual and heterogeneous runtime log streams. We use an entropy-based approach, which makes no assumptions on the structure of underlying log entries. Measurements have been done in a real-world Air Traffic Control information system through a data analytics framework. Experiments suggest that our entropy-based method represents a valuable complement to security analytics solutions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "关键信息系统非常依赖事件日志记录技术来收集数据，例如整理/错误事件、执行跟踪和变量转储，并将其保存到非结构化的文本日志中。事件日志是从生产系统获取可操作情报的主要来源。尽管系统/应用程序日志具有公认的重要性，但与传统的结构化数据源(如审计跟踪、网络流量和入侵检测日志)相比，它在安全分析中仍未得到充分利用。本文提出了一种方法来测量文本和异构运行时日志流中有趣活动的发生(即，分析师应该跟踪的条目)。我们使用基于熵的方法，这种方法对底层日志条目的结构没有任何假设。通过数据分析框架，在真实世界的空中交通管制信息系统中进行了测量。实验表明，我们基于熵的方法是对安全分析解决方案的宝贵补充。",
                    "title_zh": "基于熵的安全分析:对关键信息系统的测量"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.19",
                    "title": "Exploring the Long Tail of (Malicious) Software Downloads",
                    "authors": "Babak Rahbarinia, Marco Balduzzi, Roberto Perdisci",
                    "abstract": "In this paper, we present a large-scale study of global trends in software download events, with an analysis of both benign and malicious downloads, and a categorization of events for which no ground truth is currently available. Our measurement study is based on a unique, real-world dataset collected at Trend Micro containing more than 3 million in-the-wild web-based software download events involving hundreds of thousands of Internet machines, collected over a period of seven months. Somewhat surprisingly, we found that despite our best efforts and the use of multiple sources of ground truth, more than 83% of all downloaded software files remain unknown, i.e. cannot be classified as benign or malicious, even two years after they were first observed. If we consider the number of machines that have downloaded at least one unknown file, we find that more than 69% of the entire machine/user population downloaded one or more unknown software file. Because the accuracy of malware detection systems reported in the academic literature is typically assessed only over software files that can be labeled, our findings raise concerns on their actual effectiveness in large-scale real-world deployments, and on their ability to defend the majority of Internet machines from infection. To better understand what these unknown software files may be, we perform a detailed analysis of their properties. We then explore whether it is possible to extend the labeling of software downloads by building a rule-based system that automatically learns from the available ground truth and can be used to identify many more benign and malicious files with very high confidence. This allows us to greatly expand the number of software files that can be labeled with high confidence, thus providing results that can benefit the evaluation of future malware detection systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们对软件下载事件的全球趋势进行了大规模研究，对良性和恶意下载进行了分析，并对目前尚无事实依据的事件进行了分类。我们的测量研究基于趋势科技收集的独特的真实数据集，该数据集包含超过300万个基于网络的野外软件下载事件，涉及数十万台互联网计算机，收集时间超过七个月。有点令人惊讶的是，我们发现，尽管我们尽了最大努力并使用了多种来源的基本事实，但所有下载的软件文件中仍有超过83%是未知的，也就是说，即使在首次观察到它们两年后，也无法将其分类为良性或恶意。如果我们考虑已经下载了至少一个未知文件的机器的数量，我们发现超过69%的整个机器/用户群体下载了一个或多个未知软件文件。由于学术文献中报告的恶意软件检测系统的准确性通常仅通过可以标记的软件文件进行评估，因此我们的发现引起了人们对它们在大规模现实世界部署中的实际有效性以及它们保护大多数互联网机器免受感染的能力的关注。为了更好地理解这些未知的软件文件，我们对它们的属性进行了详细的分析。然后，我们探索是否有可能通过构建一个基于规则的系统来扩展软件下载的标记，该系统可以从可用的基础事实中自动学习，并可以用于以非常高的置信度识别更多良性和恶意文件。这使我们能够极大地扩展能够以高置信度标记的软件文件的数量，从而提供有利于评估未来恶意软件检测系统的结果。",
                    "title_zh": "探索(恶意)软件下载的长尾"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.33",
                    "title": "Ghost Installer in the Shadow: Security Analysis of App Installation on Android",
                    "authors": "Yeonjoon Lee, Tongxin Li, Nan Zhang, Soteris Demetriou, Mingming Zha, XiaoFeng Wang, Kai Chen, Xiao-yong Zhou, Xinhui Han, Michael Grace",
                    "abstract": "Android allows developers to build apps with app installation functionality themselves with minimal restriction and support like any other functionalities. Given the critical importance of app installation, the security implications of the approach can be significant. This paper reports the first systematic study on this issue, focusing on the security guarantees of different steps of the App Installation Transaction (AIT). We demonstrate the serious consequences of leaving AIT development to individual developers: most installers (e.g., Amazon AppStore, DTIgnite, Baidu) are riddled with various security-critical loopholes, which can be exploited by attackers to silently install any apps, acquiring dangerous-level permissions or even unauthorized access to system resources. Surprisingly, vulnerabilities were found in all steps of AIT. The attacks we present, dubbed Ghost Installer Attack (GIA), are found to pose a realistic threat to Android ecosystem. Further, we developed both a user-app-level and a system-level defense that are innovative and practical.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Android允许开发者像其他功能一样，在最少的限制和支持下，自己构建具有应用安装功能的应用。鉴于应用程序安装的至关重要性，这种方法的安全含义可能非常重要。本文首次系统地研究了这一问题，重点研究了应用程序安装交易(AIT)不同步骤的安全保障。我们展示了将AIT开发留给个体开发人员的严重后果:大多数安装程序(例如，Amazon AppStore、DTIgnite、百度)都充满了各种安全关键漏洞，攻击者可以利用这些漏洞静默安装任何应用程序，获得危险级别的权限，甚至未经授权访问系统资源。令人惊讶的是，AIT的所有步骤都发现了漏洞。我们提出的攻击被称为Ghost Installer攻击(GIA)，被发现对Android生态系统构成了现实威胁。此外，我们开发了创新实用的用户应用级和系统级防御。",
                    "title_zh": "影子下的Ghost安装程序:Android上应用安装的安全性分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.14",
                    "title": "DyDroid: Measuring Dynamic Code Loading and Its Security Implications in Android Applications",
                    "authors": "Zhengyang Qu, Shahid Alam, Yan Chen, Xiaoyong Zhou, Wangjun Hong, Ryan D. Riley",
                    "abstract": "Android has provided dynamic code loading (DCL) since API level one. DCL allows an app developer to load additional code at runtime. DCL raises numerous challenges with regards to security and accountability analysis of apps. While previous studies have investigated DCL on Android, in this paper we formulate and answer three critical questions that are missing from previous studies: (1) Where does the loaded code come from (remotely fetched or locally packaged), and who is the responsible entity to invoke its functionality? (2) In what ways is DCL utilized to harden mobile apps, specifically, application obfuscation? (3) What are the security risks and implications that can be found from DCL in off-the-shelf apps? We design and implement DyDroid, a system which uses both dynamic and static analysis to analyze dynamically loaded code. Dynamic analysis is used to automatically exercise apps, capture DCL behavior, and intercept the loaded code. Static analysis is used to investigate malicious behavior and privacy leakage in that dynamically loaded code. We have used DyDroid to analyze over 46K apps with little manual intervention, allowing us to conduct a large-scale measurement to investigate five aspects of DCL, such as source identification, malware detection, vulnerability analysis, obfuscation analysis, and privacy tracking analysis. We have several interesting findings. (1) 27 apps are found to violate the content policy of Google Play by executing code downloaded from remote servers. (2) We determine the distribution, pros/cons, and implications of several common obfuscation methods, including DEX encryption/loading. (3) DCL's stealthiness enables it to be a channel to deploy malware, and we find 87 apps loading malicious binaries which are not detected by existing antivirus tools. (4) We found 14 apps that are vulnerable to code injection attacks due to dynamically loading code which is writable by other apps. (5) DCL is mainly used by third-party SDKs, meaning that app developers may not know what sort of sensitive functionality is injected into their apps.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Android从API一级开始就提供了动态代码加载(DCL)。DCL允许应用开发者在运行时加载额外的代码。DCL在应用程序的安全性和责任分析方面提出了许多挑战。虽然以前的研究已经调查了Android上的DCL，但在本文中，我们阐述并回答了以前的研究中遗漏的三个关键问题:(1)加载的代码来自哪里(远程获取或本地打包)，谁是调用其功能的负责实体？(DCL以何种方式被用来强化移动应用，特别是应用混淆？(3)从现成应用中的DCL可以发现哪些安全风险和影响？我们设计并实现了DyDroid，一个同时使用动态和静态分析来分析动态加载代码的系统。动态分析用于自动运行应用程序，捕获DCL行为，并拦截加载的代码。静态分析用于调查动态加载代码中的恶意行为和隐私泄露。我们使用DyDroid分析了超过46K个应用程序，几乎没有人工干预，使我们能够进行大规模测量，以调查DCL的五个方面，如来源识别、恶意软件检测、漏洞分析、混淆分析和隐私跟踪分析。我们有几个有趣的发现。(1)发现27款应用通过执行从远程服务器下载的代码，违反了Google Play的内容政策。(2)我们确定了几种常见混淆方法的分布、优缺点和含义，包括DEX加密/加载。(3) DCL的隐蔽性使其成为部署恶意软件的渠道，我们发现87个应用程序加载了现有反病毒工具无法检测到的恶意二进制文件。(4)我们发现14个应用程序由于动态加载可由其他应用程序写入的代码而容易受到代码注入攻击。(5) DCL主要由第三方SDK使用，这意味着应用程序开发人员可能不知道他们的应用程序中注入了什么样的敏感功能。",
                    "title_zh": "DyDroid:测量Android应用程序中的动态代码加载及其安全含义"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.40",
                    "title": "JGRE: An Analysis of JNI Global Reference Exhaustion Vulnerabilities in Android",
                    "authors": "Yacong Gu, Kun Sun, Purui Su, Qi Li, Yemian Lu, Lingyun Ying, Dengguo Feng",
                    "abstract": "Android system applies a permission-based security model to restrict unauthorized apps from accessing system services, however, this security model cannot constrain authorized apps from sending excessive service requests to exhaust the limited system resource allocated for each system service. As references from native code to a Java object, JNI Global References (JGR) are prone to memory leaks, since they are not automatically garbage collected. Moreover, JGR exhaustion may lead to process abort or even Android system reboot when the victim process could not afford the JGR requests triggered by malicious apps through inter-process communication. In this paper, we perform a systematic study on JGR exhaustion (JGRE) attacks against all system services in Android. Our experimental results show that among the 104 system services in Android 6.0.1, 32 system services have 54 vulnerabilities. Particularly, 22 system services can be successfully attacked without any permission support. After reporting those vulnerabilities to Android security team and getting confirmed, we study the existing ad hoc countermeasures in Android against JGRE attacks. Surprisingly, among the 10 system services that have been protected, 8 system services are still vulnerable to JGRE attacks. Finally, we develop an effective defense mechanism to defeat all identified JGRE attacks by adopting Android's low memory killer (LMK) mechanism.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Android系统采用基于权限的安全模型来限制未经授权的应用程序访问系统服务，然而，这种安全模型不能限制授权的应用程序发送过多的服务请求来耗尽分配给每个系统服务的有限系统资源。作为从本机代码到Java对象的引用，JNI全局引用(JGR)容易发生内存泄漏，因为它们不会被自动垃圾收集。此外，当受害进程无法承受恶意应用程序通过进程间通信触发的JGR请求时，JGR耗尽可能导致进程中止甚至Android系统重启。在本文中，我们对安卓系统中针对所有系统服务的JGR穷举(JGRE)攻击进行了系统的研究。我们的实验结果显示，在Android 6.0.1的104个系统服务中，有32个系统服务存在54个漏洞。特别是，22个系统服务可以在没有任何权限支持的情况下被成功攻击。在向Android安全团队报告这些漏洞并得到确认后，我们研究了Android中针对JGRE攻击的现有特别对策。令人惊讶的是，在已经被保护的10个系统服务中，8个系统服务仍然容易受到JGRE攻击。最后，我们开发了一种有效的防御机制，通过采用Android的低内存杀手(LMK)机制来击败所有已识别的JGRE攻击。",
                    "title_zh": "JGRE:安卓系统中JNI全局引用耗尽漏洞分析"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.22",
                    "title": "I Know Nothing about You But Here is What You Might Like",
                    "authors": "Rachid Guerraoui, Anne-Marie Kermarrec, Rhicheek Patra, Mahammad Valiyev, Jingjing Wang",
                    "abstract": "Recommenders widely use collaborative filtering schemes. These schemes, however, threaten privacy as user profiles are made available to the service provider hosting the recommender and can even be guessed by curious users who analyze the recommendations. Users can encrypt their profiles to hide them from the service provider and add noise to make them difficult to guess. These precautionary measures hamper latency and recommendation quality. In this paper, we present a novel recommender, X-REC, enabling an effective collaborative filtering scheme to ensure the privacy of users against the service provider (system-level privacy) or other users (user-level privacy). X-REC builds on two underlying services: X-HE, an encryption scheme designed for recommenders, and X-NN, a neighborhood selection protocol over encrypted profiles. We leverage uniform sampling to ensure differential privacy against curious users. Our extensive evaluation demonstrates that X-REC provides (1) recommendation quality similar to non-private recommenders, and (2) significant latency improvement over privacy-aware alternatives.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "推荐器广泛使用协同过滤方案。然而，这些方案威胁到隐私，因为用户简档被提供给托管推荐器的服务提供商，并且甚至可能被分析推荐的好奇用户猜到。用户可以加密他们的个人资料，对服务提供商隐藏，并添加噪音，使他们难以猜测。这些预防措施会影响延迟和推荐质量。在本文中，我们提出了一种新颖的推荐器X-REC，它能够实现一种有效的协同过滤方案，以确保用户的隐私不受服务提供商(系统级隐私)或其他用户(用户级隐私)的侵犯。X-REC建立在两个基础服务之上:X-HE，一个为推荐者设计的加密方案，以及X-NN，一个基于加密配置文件的邻居选择协议。我们利用统一采样来确保不同好奇用户的不同隐私。我们的广泛评估表明，X-REC提供了(1)与非私人推荐者相似的推荐质量，以及(2)与隐私感知替代方案相比显著的延迟改进。",
                    "title_zh": "我对你一无所知，但这是你可能会喜欢的"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.47",
                    "title": "What You See is Not What You Get! Thwarting Just-in-Time ROP with Chameleon",
                    "authors": "Ping Chen, Jun Xu, Zhisheng Hu, Xinyu Xing, Minghui Zhu, Bing Mao, Peng Liu",
                    "abstract": "Address space randomization has long been used for counteracting code reuse attacks, ranging from conventional ROP to sophisticated Just-in-Time ROP. At the high level, it shuffles program code in memory and thus prevents malicious ROP payload from performing arbitrary operations. While effective in mitigating attacks, existing randomization mechanisms are impractical for real-world applications and systems, especially considering the significant performance overhead and potential program corruption incurred by their implementation. In this paper, we introduce CHAMELEON, a practical defense mechanism that hinders code reuse attacks, particularly Just-in-Time ROP attacks. Technically speaking, CHAMELEON instruments program code, randomly shuffles code page addresses and minimizes the attack surface exposed to adversaries. While this defense mechanism follows in the footprints of address space randomization, our design principle focuses on using randomization to obstruct code page disclosure, making the ensuing attacks infeasible. We implemented a prototype of CHAMELEON on Linux operating system and extensively experimented it in different settings. Our theoretical and empirical evaluation indicates the effectiveness and efficiency of CHAMELEON in thwarting Just-in-Time ROP attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "地址空间随机化长期以来一直被用于对抗代码重用攻击，从传统的ROP到复杂的实时ROP。在高层次上，它打乱了内存中的程序代码，从而防止恶意ROP有效载荷执行任意操作。虽然在减轻攻击方面是有效的，但是现有的随机化机制对于现实世界的应用和系统是不切实际的，尤其是考虑到它们的实现所导致的显著的性能开销和潜在的程序损坏。在这篇文章中，我们介绍了变色龙，一个实用的防御机制，阻止代码重用攻击，特别是即时ROP攻击。从技术上来说，变色龙工具程序代码，随机打乱代码页地址，并尽量减少暴露给对手的攻击面。虽然这种防御机制遵循地址空间随机化的足迹，但我们的设计原则侧重于使用随机化来阻止代码页泄露，从而使随后的攻击不可行。我们在Linux操作系统上实现了一个变色龙原型，并在不同的环境下进行了广泛的实验。我们的理论和实证评估表明，变色龙在挫败即时ROP攻击的有效性和效率。",
                    "title_zh": "你看到的不是你得到的！用变色龙挫败准时ROP"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.54",
                    "title": "DynaMiner: Leveraging Offline Infection Analytics for On-the-Wire Malware Detection",
                    "authors": "Birhanu Eshete, V. N. Venkatakrishnan",
                    "abstract": "Web-borne malware continues to be a major threat on the Web. At the core of malware infection are for-crime toolkits that exploit vulnerabilities in browsers and their extensions. When a victim host gets infected, the infection dynamics is often buried in benign traffic, which makes the task of inferring malicious behavior a non-trivial exercise. In this paper, we leverage web conversation graph analytics to tap into the rich dynamics of the interaction between a victim and malicious host(s) without the need for analyzing exploit payload. Based on insights derived from infection graph analytics, we formulate the malware detection challenge as a graph-analytics based learning problem. The key insight of our approach is the payload-agnostic abstraction and comprehensive analytics of malware infection dynamics pre-, during-, and post-infection. Our technique leverages 3 years of infection intelligence spanning 9 popular exploit kit families. Our approach is implemented in a tool called DynaMiner and evaluated on infection and benign HTTP traffic. DynaMiner achieves a 97.3% true positive rate with false positive rate of 1.5%. Our forensic and live case studies suggest the effectiveness of comprehensive graph abstraction malware infection. In some instances, DynaMiner detected unknown malware 11 days earlier than existing AV engines.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络传播的恶意软件仍然是网络上的主要威胁。恶意软件感染的核心是犯罪工具包，它们利用浏览器及其扩展中的漏洞。当受害主机被感染时，感染动态通常隐藏在良性流量中，这使得推断恶意行为的任务变得非常重要。在本文中，我们利用web对话图分析来挖掘受害者和恶意主机之间丰富的交互动态，而无需分析漏洞有效载荷。基于从感染图分析得出的见解，我们将恶意软件检测挑战公式化为基于图分析的学习问题。我们方法的关键见解是对感染前、感染中和感染后的恶意软件感染动态进行与负载无关的抽象和全面分析。我们的技术利用了3年的感染智能，涵盖9个流行的漏洞利用套件系列。我们的方法在一个名为DynaMiner的工具中实现，并对感染和良性HTTP流量进行了评估。DynaMiner取得了97.3%的真阳性率和1.5%的假阳性率。我们的法医和现场案例研究表明，全面的图形抽象恶意软件感染的有效性。在某些情况下，DynaMiner比现有的反病毒引擎早11天检测到未知的恶意软件。",
                    "title_zh": "DynaMiner:利用离线感染分析进行在线恶意软件检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.41",
                    "title": "Statistical Model Checking for Hybrid Petri Nets with Multiple General Transitions",
                    "authors": "Carina Pilch, Anne Remke",
                    "abstract": "The modeling formalism of hybrid Petri nets allows investigating the dependability of e.g. critical infrastructures with hybrid characteristics. Hybrid Petri nets can model random delays with so-called general transitions. Approaches for analyzing such Petri nets are available for models with one or two general transitions, which change the discrete marking of the system by firing only once. We extend the formalism to more general transitions that possibly fire multiple times. This work provides a definition of the probability space for the evolution of hybrid Petri nets over time and presents an efficient approach to discrete-event simulation. Statistical Model Checking techniques are introduced to verify complex properties on hybrid Petri nets. The presented methods are implemented in Java and we show their feasibility in a case study that also serves to validate our results.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "混合Petri网的建模形式允许研究例如具有混合特征的关键基础设施的可靠性。混合Petri网可以用所谓的一般转换来模拟随机延迟。分析这种Petri网的方法可用于具有一个或两个一般转移的模型，这些转移通过仅触发一次来改变系统的离散标记。我们将形式主义扩展到可能多次触发的更一般的转换。这项工作为混合Petri网随时间的演化提供了概率空间的定义，并为离散事件模拟提供了一种有效的方法。引入统计模型检验技术来验证混合Petri网的复杂性质。提出的方法用Java实现，我们在一个案例研究中展示了它们的可行性，同时也验证了我们的结果。",
                    "title_zh": "具有多重一般变迁的混合Petri网的统计模型检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.32",
                    "title": "Deadline-Aware Multipath Communication: An Optimization Problem",
                    "authors": "Laurent Chuat, Adrian Perrig, Yih-Chun Hu",
                    "abstract": "Multipath communication not only allows improved throughput but can also be used to leverage different path characteristics to best fulfill each application's objective. In particular, certain delay-sensitive applications, such as real-time voice and video communications, can usually withstand packet loss and aim to maximize throughput while keeping latency at a reasonable level. In such a context, one hard problem is to determine along which path the data should be transmitted or retransmitted. In this paper, we formulate this problem as a linear optimization, show bounds on the performance that can be obtained in a multipath paradigm, and show that path diversity is a strong asset for improving network performance. We also discuss how these theoretical limits can be approached in practice and present simulation results.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1706.05867"
                    },
                    "abstract_zh": "多路径通信不仅可以提高吞吐量，还可以利用不同的路径特性来最好地实现每个应用的目标。特别是，某些延迟敏感型应用，如实时语音和视频通信，通常能够承受数据包丢失，并致力于最大化吞吐量，同时将延迟保持在合理的水平。在这种情况下，一个难题是确定数据应该沿哪条路径传输或重传。在本文中，我们将这个问题公式化为一个线性优化，展示了在多路径范例中可以获得的性能界限，并展示了路径分集对于提高网络性能是一个强大的资产。我们还讨论了如何在实践中达到这些理论极限，并给出了模拟结果。",
                    "title_zh": "截止期感知的多径通信:一个优化问题"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.61",
                    "title": "Regular: Attacker-Induced Traffic Flow Instability in a Stream of Semi-Automated Vehicles",
                    "authors": "Daniel D. Dunn, Samuel A. Mitchell, Imran Sajjad, Ryan M. Gerdes, Rajnikant Sharma, Ming Li",
                    "abstract": "We show that a stream of automated vehicles traveling along the highway can be destabilized to catastrophic effect through modification of the control laws of individual vehicles. Specifically, one active attacker who introduces errors, in addition to one or many passive attackers who amplify the error, may, by the modification of a single parameter, induce oscillatory traffic jams that cause delay, driver discomfort, excess energy expenditure, and increased risk of accidents that could result in serious injury or death. We determine the conditions under which an attacker(s) is able to violate the primary design criterion of automated vehicle streams, known as string stability, to guarantee system instability. Furthermore, we prove that once the stream has been destabilized it will continually deviate from the desired state, even in the absence of additional input to the system—i.e. the jammed condition will self-perpetuate. Through a comparison with a behavioral human driver model, this work demonstrates that automated vehicle systems are more vulnerable to disruption than their non-automated counterparts. The postulated attack is demonstrated on a scaled system and identification of attackers is discussed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们证明了通过修改单个车辆的控制律，沿着高速公路行驶的一系列自动车辆可以不稳定到灾难性的效果。具体而言，除了一个或多个放大错误的被动攻击者之外，一个引入错误的主动攻击者可能通过修改单个参数来引发振荡交通堵塞，从而导致延迟、驾驶员不适、过度的能量消耗以及可能导致严重伤害或死亡的事故风险增加。我们确定攻击者能够违反自动车流的主要设计标准(称为字符串稳定性)以保证系统不稳定的条件。此外，我们证明了一旦流变得不稳定，它将继续偏离期望的状态，甚至在没有对系统的额外输入的情况下——即，堵塞状态将自我延续。通过与行为人类驾驶员模型的比较，这项工作证明了自动车辆系统比非自动车辆系统更容易受到干扰。假设的攻击在一个规模较大的系统上演示，并讨论攻击者的识别。",
                    "title_zh": "常规:在半自动车辆流中由攻击者引起的交通流不稳定性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.50",
                    "title": "Smart Maintenance via Dynamic Fault Tree Analysis: A Case Study on Singapore MRT System",
                    "authors": "Yan Liu, Yue Wu, Zbigniew Kalbarczyk",
                    "abstract": "Urban railway systems, as the most heavily used systems in daily life, suffer from frequent service disruptions resulting millions of affected passengers and huge economic losses. Maintenance of the systems is done by maintaining individual devices in fixed cycles. It is time consuming, yet not effective. Thus, to reduce service failures through smart maintenance is becoming one of the top priorities of the system operators. In this paper, we propose a data driven approach that is to decide maintenance cycle based on estimating the mean time to failure of the system. There are two challenges: 1) as a cyber physical system, hardwares of cyber components (like signalling devices) fail more frequently than physical components (like power plants), 2) as a system of systems, functional dependency exists not only between components within a sub-system but also between different sub-systems, for example, a train relies on traction power system to operate. To meet the challenges, a Dynamic Fault Tree (DFT) based approach is adopted for the expressiveness of the modelling formalism and an efficient tool support by DFTCalc. Our case study shows interesting results that the Singapore Massive Rapid Train (MRT) system is likely to fail in 20 days from the full functioning status based on the manufacture data.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "城市铁路系统作为日常生活中使用最频繁的系统，经常遭受服务中断，导致数百万受影响的乘客和巨大的经济损失。系统的维护是通过以固定的周期维护单个设备来完成的。这很费时间，但效率不高。因此，通过智能维护减少服务故障正成为系统运营商的首要任务之一。本文提出了一种数据驱动的方法，即通过估计系统的平均无故障时间来决定维修周期。有两个挑战:1)作为一个网络物理系统，网络组件的硬件(如信号设备)比物理组件(如发电厂)更容易发生故障，2)作为一个系统的系统，功能依赖不仅存在于子系统内的组件之间，而且存在于不同的子系统之间，例如，一列火车依靠牵引供电系统运行。为了应对这一挑战，采用了基于动态故障树的方法来表达建模的形式和DFTCalc提供的有效工具支持。我们的案例研究显示了有趣的结果:根据制造数据，新加坡大规模快速列车(MRT)系统可能在20天内从完全运行状态失效。",
                    "title_zh": "基于动态故障树分析的智能维护:新加坡捷运系统案例研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.16",
                    "title": "RL-BLH: Learning-Based Battery Control for Cost Savings and Privacy Preservation for Smart Meters",
                    "authors": "Jinkyu Koo, Xiaojun Lin, Saurabh Bagchi",
                    "abstract": "An emerging solution to privacy issues in smart grids is battery-based load hiding (BLH) that uses a rechargeable battery to decouple the meter readings from user activities. However, existing BLH algorithms have two significant limitations: (1) Most of them focus on flattening high-frequency variation of usage profile only, thereby still revealing a low-frequency shape, (2) Otherwise, they assume to know a statistical model of usage pattern. To overcome these limitations, we propose a new BLH algorithm, named RL-BLH. The RL-BLH hides both low-frequency and high-frequency usage patterns by shaping the meter readings to rectangular pulses. The RL-BLH learns a decision policy for choosing pulse magnitudes on the fly without prior knowledge of usage pattern. The decision policy is designed to charge and discharge the battery in the optimal way to maximize cost savings. We also provide heuristics to shorten learning time and improve cost savings.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "智能电网中隐私问题的新兴解决方案是基于电池的负载隐藏(BLH)，它使用可充电电池将电表读数与用户活动分离。然而，现有的BLH算法有两个明显的局限性:(1)它们中的大多数只关注平坦化使用简档的高频变化，从而仍然揭示低频形状，(2)否则，它们假设知道使用模式的统计模型。为了克服这些限制，我们提出了一种新的BLH算法，命名为RL-BLH。RL-BLH通过将仪表读数整形为矩形脉冲来隐藏低频和高频使用模式。RL-BLH学习用于在没有使用模式的先验知识的情况下即时选择脉冲幅度的决策策略。决策策略旨在以最佳方式对电池进行充电和放电，以最大限度地节约成本。我们还提供启发式方法来缩短学习时间和提高成本节约。",
                    "title_zh": "RL-BLH:基于学习的电池控制，用于智能电表的成本节约和隐私保护"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.60",
                    "title": "Compromising Security of Economic Dispatch in Power System Operations",
                    "authors": "Devendra Shelar, Pengfei Sun, Saurabh Amin, Saman A. Zonouz",
                    "abstract": "Power grid operations rely on the trustworthy operation of critical control center functionalities, including the so-called Economic Dispatch (ED) problem. The ED problem is a large-scale optimization problem that is periodically solved by the system operator to ensure the balance of supply and load while maintaining reliability constraints. In this paper, we propose a semantics-based attack generation and implementation approach to study the security of the ED problem.1 Firstly, we generate optimal attack vectors to transmission line ratings to induce maximum congestion in the critical lines, resulting in the violation of capacity limits. We formulate a bilevel optimization problem in which the attacker chooses manipulations of line capacity ratings to maximinimize the percentage line capacity violations under linear power flows. We reformulate the bilevel problem as a mixed integer linear program that can be solved efficiently. Secondly, we describe how the optimal attack vectors can be implemented in commercial energy management systems (EMSs). The attack explores the dynamic memory space of the EMS, and replaces the true line capacity ratings stored in data regions with the optimal attack vectors. In contrast to the well-known false data injection attacks to control systems that require compromising distributed sensors, our approach directly implements attacks to the control center server. Our experimental results on benchmark power systems and five widely utilized EMSs show the practical feasibility of our attack generation and implementation approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "电网运行依赖于关键控制中心功能的可靠运行，包括所谓的经济调度(ed)问题。ED问题是一个大规模优化问题，由系统运营商定期解决，以确保供应和负载的平衡，同时保持可靠性约束。本文提出了一种基于语义的攻击生成和实现方法来研究ed问题的安全性。首先，我们生成传输线路额定值的最优攻击向量，以诱导关键线路发生最大拥塞，从而导致容量限制的违反。我们提出了一个双层优化问题，其中攻击者选择操纵线路容量额定值来最大限度地减小线性潮流下的线路容量违规百分比。我们将双层问题转化为一个可以有效求解的混合整数线性规划。其次，我们描述了如何在商业能源管理系统(EMSs)中实现最佳攻击向量。该攻击利用EMS的动态存储空间，并用最佳攻击向量替换存储在数据区中的真实线路容量额定值。与众所周知的需要折衷分布式传感器的对控制系统的虚假数据注入攻击相反，我们的方法直接对控制中心服务器实施攻击。在基准电力系统和五个广泛使用的ems上的实验结果表明了我们的攻击生成和实现方法的实际可行性。",
                    "title_zh": "电力系统运行中危及经济调度安全的问题"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.25",
                    "title": "Fex: A Software Systems Evaluator",
                    "authors": "Oleksii Oleksenko, Dmitrii Kuvaiskii, Pramod Bhatotia, Christof Fetzer",
                    "abstract": "Software systems research relies on experimental evaluation to assess the effectiveness of newly developed solutions. However, the existing evaluation frameworks are rigid (do not allow creation of new experiments), often simplistic (may not reveal issues that appear in real-world applications), and can be inconsistent (do not guarantee reproducibility of experiments across platforms). This paper presents Fex, a software systems evaluation framework that addresses these limitations. Fex is extensible (can be easily extended with custom experiment types), practical (supports composition of different benchmark suites and real-world applications), and reproducible (it is built on container technology to guarantee the same software stack across platforms). We show that Fex achieves these design goals with minimal end-user effort - for instance, adding Nginx web-server to evaluation requires only 160 LoC. Going forward, we discuss the architecture of the framework, explain its interface, show common usage scenarios, and evaluate the efforts for writing various custom extensions.",
                    "files": {
                        "openAccessPdf": "https://www.pure.ed.ac.uk/ws/files/36906179/main_21.pdf"
                    },
                    "abstract_zh": "软件系统研究依靠实验评估来评估新开发的解决方案的有效性。然而，现有的评估框架是僵化的(不允许创建新的实验)，往往过于简单(可能无法揭示现实应用中出现的问题)，并且可能不一致(不保证跨平台实验的可重复性)。本文介绍了Fex，一个解决这些限制的软件系统评估框架。Fex是可扩展的(可以通过自定义实验类型轻松扩展)、实用的(支持不同基准套件和真实应用程序的组合)和可复制的(它建立在容器技术上，以保证跨平台的相同软件堆栈)。我们展示了Fex以最小的最终用户努力实现了这些设计目标——例如，将Nginx web服务器添加到评估中只需要160 LoC。接下来，我们将讨论该框架的架构，解释其接口，展示常见的使用场景，并评估编写各种定制扩展的工作。",
                    "title_zh": "Fex:一种软件系统评估工具"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.38",
                    "title": "Demonstrating a Tool for Injection Attack Prevention in MySQL",
                    "authors": "Iberia Medeiros, Miguel Beatriz, Nuno Ferreira Neves, Miguel Correia",
                    "abstract": "Despite the significant efforts put in building more secure web applications, cases of high impact breaches continue to appear. Vulnerabilities in web applications are often created due to inconsistencies in the way SQL queries are believed to be run and the way they are actually executed by a Database Management System (DBMS). This paper presents a demonstration of SEPTIC, a mechanism that detects and blocks injection attacks inside the DBMS. The demonstration considers a scenario of a non-trivial PHP web application, backed by a MySQL DBMS, which was modified to include SEPTIC. It presents how SEPTIC blocks injection attacks without compromising the application correctness and performance. In addition, SEPTIC is compared to alternative approaches, such as sanitizations carried out with standard functions provided language and a web application firewall.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管在构建更安全的web应用程序方面付出了巨大的努力，但高影响的违规案例仍不断出现。web应用程序中的漏洞通常是由于SQL查询的运行方式与数据库管理系统(DBMS)实际执行的方式不一致而造成的。本文演示了一种检测和阻止DBMS内部注入攻击的机制——化粪池系统。该演示考虑了一个由MySQL DBMS支持的非平凡PHP web应用程序的场景，该应用程序被修改为包含化粪池系统。它展示了如何在不影响应用程序正确性和性能的情况下阻止注入攻击。此外，还将化粪池系统与其他替代方法进行了比较，如使用标准功能提供语言和web应用程序防火墙进行净化。",
                    "title_zh": "在MySQL中演示防止注入攻击的工具"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.27",
                    "title": "Zipr: Efficient Static Binary Rewriting for Security",
                    "authors": "William H. Hawkins, Jason D. Hiser, Michele Co, Anh Nguyen-Tuong, Jack W. Davidson",
                    "abstract": "To quickly patch security vulnerabilities there has been keen interest in securing binaries in situ. Unfortunately, the state of the art in static binary rewriting does not allow the transformed program to be both space and time efficient. A primary limitation is that leading static rewriters require that the original copy of the code remains in the transformed binary, thereby incurring file size overhead of at least 100%. This paper presents Zipr, a static binary rewriter that removes this limitation and enables both space and time efficient transformation of arbitrary binaries. We describe results from applying Zipr in the DARPA Cyber Grand Challenge (CGC), the first fully automated cyber-hacking contest. The CGC rules penalized competitors for producing a patched binary whose on-disk size was 20% larger than the original, whose CPU utilization was 5% more than the original, and whose memory use was 5% more than the original. Zipr's efficiency enabled our automated system, Xandra, to apply both code diversity and control flow integrity security techniques to secure challenge binaries provided by DARPA, resulting in Xandra having the best security score in the competition, remaining within the required space and time performance envelope, and winning a $1M cash prize.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了快速修补安全漏洞，人们对就地保护二进制文件非常感兴趣。不幸的是，静态二进制重写的技术水平不允许转换后的程序在空间和时间上都是高效的。一个主要的限制是领先的静态重写器要求代码的原始副本保持在转换后的二进制中，从而导致至少100%的文件大小开销。本文介绍了Zipr，它是一个静态二进制重写器，消除了这一限制，能够在空间和时间上高效地转换任意二进制文件。我们描述了在DARPA网络大挑战(CGC)中应用Zipr的结果，这是第一次全自动的网络黑客竞赛。CGC规则惩罚竞争对手生产一个补丁二进制文件，其磁盘大小比原来大20%，CPU利用率比原来高5%，内存使用比原来高5%。Zipr的效率使我们的自动化系统Xandra能够应用代码多样性和控制流完整性安全技术来保护DARPA提供的挑战二进制文件，从而使Xandra在竞争中获得最佳安全分数，保持在所需的空间和时间性能范围内，并赢得了100万美元的现金奖励。",
                    "title_zh": "Zipr:安全的高效静态二进制重写"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.59",
                    "title": "ATTAIN: An Attack Injection Framework for Software-Defined Networking",
                    "authors": "Benjamin E. Ujcich, Uttam Thakore, William H. Sanders",
                    "abstract": "Software-defined networking (SDN) has recently attracted interest as a way to provide cyber resiliency because of its programmable and logically centralized nature. However, the security of the SDN architecture itself against malicious attacks is not well understood and must be ensured in order to provide cyber resiliency to systems that use SDNs. In this paper, we present ATTAIN, an attack injection framework for OpenFlow-based SDN architectures. First, we define an attack model that relates system components to an attacker's capability to influence control plane behavior. Second, we define an attack language for writing control plane attacks that can be used to evaluate SDN implementations. Third, we describe an attack injector architecture that actuates attacks in networks. Finally, we evaluate our framework with an enterprise network case study by writing and running attacks with popular SDN controllers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(SDN)由于其可编程和逻辑集中的特性，最近作为一种提供网络弹性的方式引起了人们的兴趣。然而，SDN架构本身抵御恶意攻击的安全性并未得到很好的理解，必须确保这一点，以便为使用SDN的系统提供网络弹性。在本文中，我们提出了一个基于OpenFlow的SDN架构的攻击注入框架。首先，我们定义一个攻击模型，将系统组件与攻击者影响控制平面行为的能力联系起来。其次，我们定义了一种用于编写控制平面攻击的攻击语言，可以用来评估SDN实施。第三，我们描述了在网络中激发攻击的攻击注入器体系结构。最后，我们通过使用流行的SDN控制器编写和运行攻击，用一个企业网络案例研究来评估我们的框架。",
                    "title_zh": "获得:一个用于软件定义网络的攻击注入框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.44",
                    "title": "The Balance Attack or Why Forkable Blockchains are Ill-Suited for Consortium",
                    "authors": "Christopher Natoli, Vincent Gramoli",
                    "abstract": "Most blockchain systems are forkable in that they require participants to agree on a chain out of multiple possible branches of blocks. In this paper, we identify a new form of attack, called the Balance attack, against these forkable blockchain systems. The novelty of this attack consists of delaying network communications between multiple subgroups of nodes with balanced mining power. Our theoretical analysis captures the tradeoff between the network delay and the mining power of the attacker needed to double-spend in the GHOST protocol with high probability. We quantify our analysis in the settings of the Ethereum testnet of the R3 consortium where we show that a single machine needs to delay messages for 20 minutes to double spend while a coalition with a third of the mining power would simply need 4 minutes to double spend with 94% of success. We experiment the attack in our private Ethereum chain before arguing for a non-forkable blockchain design to protect against Balance attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大多数区块链系统是可分叉的，因为它们需要参与者同意由多个可能的分支块组成的链。在这篇文章中，我们发现了一种新的攻击形式，称为平衡攻击，针对这些分叉的区块链系统。这种攻击的新颖性在于延迟了具有平衡挖掘能力的多个节点子组之间的网络通信。我们的理论分析捕获了网络延迟和攻击者的挖掘能力之间的权衡，攻击者需要以高概率在GHOST协议中花费双倍的时间。我们在R3联盟的以太坊测试网的设置中量化了我们的分析，其中我们显示单台机器需要延迟消息20分钟才能双倍花费，而拥有三分之一采矿能力的联盟只需要4分钟就可以双倍花费，成功率为94%。我们在我们的私人以太坊链中试验了攻击，然后论证了一个不可分叉的区块链设计来防止平衡攻击。",
                    "title_zh": "平衡攻击或为什么分叉区块链不适合财团"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.10",
                    "title": "Voiceprint: A Novel Sybil Attack Detection Method Based on RSSI for VANETs",
                    "authors": "Yuan Yao, Bin Xiao, Gaofei Wu, Xue Liu, Zhiwen Yu, Kailong Zhang, Xingshe Zhou",
                    "abstract": "Vehicular Ad Hoc Networks (VANETs) enable vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications that bring many benefits and conveniences to improve the road safety and drive comfort in future transportation systems. Sybil attack is considered one of the most risky threats in VANETs since a Sybil attacker can generate multiple fake identities with false messages to severely impair the normal functions of safety-related applications. In this paper, we propose a novel Sybil attack detection method based on Received Signal Strength Indicator (RSSI), Voiceprint, to conduct a widely applicable, lightweight and full-distributed detection for VANETs. To avoid the inaccurate position estimation according to predefined radio propagation models in previous RSSI-based detection methods, Voiceprint adopts the RSSI time series as the vehicular speech and compares the similarity among all received time series. Voiceprint does not rely on any predefined radio propagation model, and conducts independent detection without the support of the centralized infrastructure. It has more accurate detection rate in different dynamic environments. Extensive simulations and real-world experiments demonstrate that the proposed Voiceprint is an effective method considering the cost, complexity and performance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "车载自组织网络(VANETs)实现了车辆对车辆(V2V)和车辆对基础设施(V2I)的通信，为未来交通系统中提高道路安全性和驾驶舒适性带来了许多好处和便利。Sybil攻击被认为是VANETs中最危险的威胁之一，因为Sybil攻击者可以生成多个带有虚假消息的虚假身份，从而严重损害安全相关应用的正常功能。本文提出了一种新的基于接收信号强度指标(RSSI)声纹的Sybil攻击检测方法，对VANETs进行一种广泛适用的、轻量级的、全分布式的检测。为了避免先前基于RSSI的检测方法根据预定义的无线电传播模型进行不准确的位置估计，声纹采用RSSI时间序列作为车辆语音，并比较所有接收到的时间序列之间的相似性。声纹不依赖于任何预定义的无线电传播模型，并且在没有集中式基础设施支持的情况下进行独立检测。在不同的动态环境下具有更准确的检测率。大量的模拟和真实世界的实验表明，考虑到成本、复杂度和性能，所提出的声纹是一种有效的方法。",
                    "title_zh": "声纹:一种新的基于RSSI的VANETs Sybil攻击检测方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.51",
                    "title": "Analysing Selfishness Flooding with SEINE",
                    "authors": "Guido Lena Cota, Sonia Ben Mokhtar, Gabriele Gianini, Ernesto Damiani, Julia Lawall, Gilles Muller, Lionel Brunie",
                    "abstract": "Selfishness is one of the key problems that confronts developers of cooperative distributed systems (e.g., file-sharing networks, voluntary computing). It has the potential to severely degrade system performance and to lead to instability and failures. Current techniques for understanding the impact of selfish behaviours and designing effective countermeasures remain manual and time-consuming, requiring multi-domain expertise. To overcome these difficulties, we propose SEINE, a simulation framework for rapid modelling and evaluation of selfish behaviours in a cooperative system. SEINE relies on a domain-specific language (SEINE-L) for specifying selfishness scenarios, and provides semi-automatic support for their implementation and study in a state-of-the-art simulator. We show in this paper that (1) SEINE-L is expressive enough to specify fifteen selfishness scenarios taken from the literature, (2) SEINE is accurate in predicting the impact of selfishness compared to real experiments, and (3) SEINE substantially reduces the development effort compared to traditional manual approaches.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01581628/file/Seine_DSN17_CR.pdf"
                    },
                    "abstract_zh": "自私是合作分布式系统(例如，文件共享网络、自愿计算)的开发者面临的关键问题之一。它有可能严重降低系统性能，并导致不稳定和故障。当前用于理解自私行为的影响和设计有效对策的技术仍然是手工的和耗时的，需要多领域的专业知识。为了克服这些困难，我们提出了赛纳，一个快速模拟和评估合作系统中自私行为的模拟框架。SEINE依赖于特定领域语言(SEINE-L)来指定自私场景，并在最先进的模拟器中为其实现和研究提供半自动支持。我们在本文中展示了(1) SEINE-L的表达能力足以指定取自文献的十五种自私场景，(2)与真实实验相比，SEINE在预测自私的影响方面是准确的，以及(3)与传统的手动方法相比，SEINE大大减少了开发工作。",
                    "title_zh": "用围网分析自私泛滥"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.20",
                    "title": "Detecting Passive Cheats in Online Games via Performance-Skillfulness Inconsistency",
                    "authors": "Daiping Liu, Xing Gao, Mingwei Zhang, Haining Wang, Angelos Stavrou",
                    "abstract": "As the most commonly used bots in first-person shooter (FPS) online games, aimbots are notoriously difficult to detect because they are completely passive and resemble excellent honest players in many aspects. In this paper, we conduct the first field measurement study to understand the status quo of aimbots and how they play in the wild. For data collection purpose, we devise a novel and generic technique called baittarget to accurately capture existing aimbots from the two most popular FPS games. Our measurement reveals that cheaters who use aimbots cannot play as skillful as excellent honest players in all aspects even though aimbots can help them to achieve very high shooting performance. To characterize the unskillful and blatant nature of cheaters, we identify seven features, of which six are novel, and these features cannot be easily mimicked by aimbots. Leveraging this set of features, we propose an accurate and robust server-side aimbot detector called AimDetect. The core of AimDetect is a cascaded classifier that detects the inconsistency between performance and skillfulness of aimbots. We evaluate the efficacy and generality of AimDetect using the real game traces. Our results show that AimDetect can capture almost all of the aimbots with very few false positives and minor overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为第一人称射击游戏(FPS)网络游戏中最常用的机器人，aimbots是出了名的难以检测，因为它们完全被动，并且在许多方面都类似于优秀的诚实玩家。在本文中，我们进行了第一次实地测量研究，以了解aimbots的现状以及它们在野外是如何玩耍的。出于数据收集的目的，我们设计了一种新的通用技术，称为baittarget，以准确地从两个最流行的FPS游戏中捕获现有的aimbots。我们的测量显示，使用aimbots的骗子无法在所有方面都像优秀诚实的球员一样熟练，即使aimbots可以帮助他们实现非常高的投篮表现。为了描述骗子不熟练和明目张胆的本质，我们确定了七个特征，其中六个是新颖的，这些特征不能被aimbots轻易模仿。利用这一组特性，我们提出了一个精确而健壮的服务器端aimbot检测器，称为AimDetect。AimDetect的核心是一个级联分类器，用于检测aimbots的性能和技能之间的不一致。我们使用真实的游戏痕迹来评估AimDetect的有效性和通用性。我们的结果表明，AimDetect可以捕获几乎所有的aimbots，只有很少的误报和较小的开销。",
                    "title_zh": "基于表现技能不一致性的网络游戏被动作弊检测"
                },
                {
                    "url": "https://doi.org/10.1109/DSN.2017.36",
                    "title": "Analyzing Operational Behavior of Stateful Protocol Implementations for Detecting Semantic Bugs",
                    "authors": "Md. Endadul Hoque, Omar Chowdhury, Sze Yiu Chau, Cristina Nita-Rotaru, Ninghui Li",
                    "abstract": "Network protocol implementations must comply with their specifications that include properties describing the correct operational behavior of the protocol in response to different temporal orderings of network events. Due to inconsistent interpretations of the specification, developers can unknowingly introduce semantic bugs, which cause the implementations to violate the respective properties. Detecting such bugs in stateful protocols becomes significantly difficult as their operations depend on their internal state machines and the complex interactions between the protocol logic. In this paper, we present an automated tool to help developers analyze their protocol implementations and detect semantic bugs violating the temporal properties of the protocols. Given an implementation, our tool (1) extracts the implemented finite state machine (FSM) of the protocol from the source code by symbolically exploring the code and (2) determines whether the extracted FSM violates given temporal properties by using an off-the-shelf model checker. We demonstrated the efficacy of our tool by applying it on 6 protocol implementations. We detected 11 semantic bugs (2 with security implications) when we analyzed these implementations against properties obtained from their publicly available specifications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络协议实现必须符合它们的规范，这些规范包括描述响应于网络事件的不同时间顺序的协议的正确操作行为的属性。由于对规范的解释不一致，开发人员可能会不知不觉地引入语义错误，这导致实现违反了各自的属性。检测有状态协议中的这种缺陷变得非常困难，因为它们的操作依赖于它们的内部状态机和协议逻辑之间的复杂交互。在本文中，我们提出了一个自动化工具来帮助开发人员分析他们的协议实现，并检测违反协议时间属性的语义错误。给定一个实现，我们的工具(1)通过象征性地探索代码，从源代码中提取协议的实现的有限状态机(FSM ),以及(2)通过使用现成的模型检查器，确定提取的FSM是否违反给定的时间属性。我们通过在6个协议实现上应用我们的工具，展示了它的有效性。当我们根据从公开可用的规范中获得的属性来分析这些实现时，我们检测到了11个语义错误(2个有安全隐患)。",
                    "title_zh": "分析有状态协议实现的操作行为以检测语义错误"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2017w.html",
            "conf_title": "47th DSN 2017: Denver, CO, USA - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8020727/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.51",
                    "title": "SSIV 2017 Welcome",
                    "authors": "João Carlos Cunha, Kalinka Branco, António Casimiro, Urbano Nunes",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "",
                    "title_zh": "SSIV 2017 欢迎"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.43",
                    "title": "Safe Landing of Fixed Wing UAVs",
                    "authors": "Pranav Jetley, P. B. Sujit, Srikanth Saripalli",
                    "abstract": "Fixed-wing unmanned aerial vehicles (UAVs) are used in several applications from agriculture to search and rescue. An interesting feature of these vehicles is their ability to deploy by hand and easy recovery with belly landing. However, as the payload of the vehicle increases, they become heavier, and hence these vehicles need to be launched in the traditional manner on a small runway with wheels. The most difficult part of the UAV mission is landing as any deviation from the desired trajectory can lead to a crash. One way to increase the safety of landing is to know when to abort the landing. For this, we need to compute the feasibility region online and determine if the vehicle can achieve the landing or not. If not, then abort landing. We designed a 3D LQR based landing controller that accurately lands the vehicle on a runway and also compute the safety regions to determine safe landing of the UAV. Through extensive simulations, we demonstrate the conditions under which a UAV is able to land safely. Further, we also extend this to linearly moving landing pads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "固定翼无人驾驶飞行器(UAV)用于从农业到搜索和救援的多种应用中。这些飞行器的一个有趣的特点是它们能够手动展开，并且易于腹部着地回收。然而，随着运载工具有效载荷的增加，它们变得更重，因此这些运载工具需要以传统方式在带轮子的小跑道上发射。无人机任务中最困难的部分是着陆，因为任何偏离预期轨迹的行为都会导致坠机。增加着陆安全性的一种方法是知道何时中止着陆。为此，我们需要在线计算可行性区域，并确定车辆是否能够实现着陆。如果没有，那就中止着陆。我们设计了一个基于3D LQR的着陆控制器，它可以精确地将飞行器降落在跑道上，并计算安全区域以确定无人机的安全着陆。通过大量的模拟，我们展示了无人机能够安全着陆的条件。此外，我们还将其扩展到线性移动着陆垫。",
                    "title_zh": "固定翼无人机的安全着陆"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.45",
                    "title": "Byzantine Agreement Service for Cooperative Wireless Embedded Systems",
                    "authors": "Wenbo Xu, Martin Wegner, Lars C. Wolf, Rüdiger Kapitza",
                    "abstract": "Recently there is a number of scenarios such as vehicle platooning, UAV swarms and cooperative robots, where a group of autonomous entities needs to make joint decisions to operate effectively. Distributed agreement protocols can play a key role to establish a common view on context parameters and to coordinate joint actions. Due to the harsh environmental conditions in some of these scenarios and their safety critical nature such protocols need to tolerate arbitrary faults and even malicious attacks.This paper presents a framework for Byzantine fault tolerant agreement for small-sized groups of autonomous, wirelessly connected systems. It focuses, besides providing support for general purpose value agreement, on the agreement of distributed sensor readings. The latter enables to establish a joint view on context conditions, thereby building the basis for joint coordinated actions. As classical Byzantine fault tolerant agreement protocols require 3t + 1 participants to tolerate t faulty nodes, we also consider a hybrid fault model by utilizing a trusted subsystem, which can only be subject to crashes. The latter reduces the required group size for agreement to 2t + 1 nodes and reduces the message complexity of the protocol, which is essential for the targeted scenarios. The experiment results show that the trusted subsystem can effectively increase the efficiency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近出现了许多场景，如车辆排队、无人机群和合作机器人，其中一组自治实体需要做出联合决策来有效地操作。分布式协定协议可以在建立关于上下文参数的共同观点和协调联合行动方面发挥关键作用。由于这些场景中的恶劣环境条件以及它们的安全关键特性，这种协议需要容忍任意故障甚至恶意攻击。本文提出了一个拜占庭容错协议框架，适用于小型自治无线连接系统。除了为通用值协议提供支持之外，它还关注分布式传感器读数的协议。后者有助于建立对背景条件的共同看法，从而为联合协调行动奠定基础。由于经典的拜占庭容错协议要求3t + 1个参与者容忍t个故障节点，因此我们还考虑了一个利用可信子系统的混合故障模型，该模型只能承受崩溃。后者将协议所需的组大小减少到2t + 1个节点，并降低了协议的消息复杂度，这对于目标场景是必不可少的。实验结果表明，可信子系统能有效提高效率。",
                    "title_zh": "协同无线嵌入式系统的拜占庭协议服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.14",
                    "title": "Assuring Fully Autonomous Vehicles Safety by Design: The Autonomous Vehicle Control (AVC) Module Strategy",
                    "authors": "Caroline Bianca Santos Tancredi Molina, Jorge Rady de Almeida Jr., Lucio Flavio Vismari, Rodrigo Ignacio R. Gonzalez, Jamil Kalil Naufal Jr., João Batista Camargo Jr.",
                    "abstract": "Massive investment in 'intelligent' vehicle technologies is going to turn autonomous vehicles into reality in a few years. The insertion of this intelligence at the road vehicles is expected to cause a reduction in traffic accidents due to the mitigation of human drivers errors and imperfections by computerized autopilots. However, autonomous vehicles shall mitigate the existing hazards at the roadway transportation systems while not creating new hazards. Thus, some critical aspects need to be better considered, such as how to ensure safety in this new vehicle paradigm. There is no specific method to analyze and assure the safety levels of the autonomous vehicle system. Despite the ISO 26262 - a new safety standard that specifies requirements and activities throughout the road vehicles development lifecycle - it cannot be applied to the autonomous road vehicles scope. This paper proposes a design strategy that may be used at the architecture design level of autonomous vehicles that may facilitate the development, analysis and, consequently, safety level assuring. The main idea is to implement an independent module - the Autonomous Vehicle Control (AVC) - that is going to both interact with the vehicle's systems and create a protection layer that is independent of the way the vehicle's system was developed. So, the AVC could be used with any autonomous vehicle system and could be tested individually. This strategy is based on both recommended practices published by Society of Automotive Engineers (SAE) and on approaches used on other transportation system domains. Another important point is that the proposed module will be intended, in principle, for fully autonomous cars (high levels of driving automation). So, it is expected that, in the future, the proposed module can be used to develop a safety software standard or to suit the existing ones to the needs of autonomous road vehicles.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对“智能”汽车技术的大量投资将在几年内将自动驾驶汽车变成现实。由于计算机化自动驾驶减轻了人类驾驶员的错误和缺陷，在道路车辆上插入这种智能有望导致交通事故的减少。然而，自动驾驶汽车应减轻道路运输系统的现有危险，同时不会产生新的危险。因此，需要更好地考虑一些关键方面，例如如何在这种新的车辆模式中确保安全。没有特定的方法来分析和保证自主车辆系统的安全水平。尽管ISO 26262是一项新的安全标准，规定了道路车辆开发生命周期中的要求和活动，但它不能应用于自动道路车辆范围。本文提出了一种设计策略，可用于自主车辆的架构设计层面，有助于开发、分析，从而确保安全水平。主要想法是实现一个独立的模块-自动车辆控制(AVC) -它将与车辆系统交互，并创建一个独立于车辆系统开发方式的保护层。因此，AVC可以用于任何自动车辆系统，并可以单独测试。该策略基于汽车工程师协会(SAE)发布的推荐做法和其他运输系统领域使用的方法。另一个要点是，原则上，提议的模块将用于完全自动驾驶的汽车(高水平的驾驶自动化)。因此，预计在未来，所提出的模块可用于开发安全软件标准或使现有标准适应自动道路车辆的需求。",
                    "title_zh": "通过设计确保全自动驾驶汽车的安全性:自动驾驶汽车控制(AVC)模块策略"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.44",
                    "title": "Deterministic Ethernet: Addressing the Challenges of Asynchronous Sensing in Sensor Fusion Systems",
                    "authors": "Ayhan Mehmed, Sasikumar Punnekkat, Wilfried Steiner",
                    "abstract": "In this paper, we study the cause of out-of-sequence measurements (OOSM) and their effect on Kalman filter based multi-sensor fusion systems. We explore the current available solutions for handling of OOSM and pinpoint how the absence of precise measurement timestamps does not allow the correct chronological order of sensor measurements. The processing of such, out-of-order measurements, leads to negative-time measurement updates in the sensor fusion process, which in turn leads to a wrong representation of the environment.Furthermore, we present methods for achieving precise measurement timestamps. We explore the suitability of set of communication standards for improving the timestamp precision. In particular we focus on IEEE 802.1AS, IEEE 802.1Qav, Qbv and SAE AS6802 standards that enable deterministic communication over IEEE802.3 standard Ethernet. We present theoretical performance studies and comparison of the said communication standards.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文研究了无序量测(OOSM)的成因及其对基于卡尔曼滤波的多传感器融合系统的影响。我们探索了当前可用于处理OOSM的解决方案，并指出精确测量时间戳的缺乏如何不允许传感器测量的正确时间顺序。这种无序测量的处理导致传感器融合过程中的负时间测量更新，这又导致环境的错误表示。此外，我们提出了实现精确测量时间戳的方法。我们探讨了一套通信标准对提高时间戳精度的适用性。我们特别关注IEEE 802.1AS、IEEE 802.1Qav、Qbv和SAE AS6802标准，这些标准支持通过IEEE802.3标准以太网进行确定性通信。我们提出了理论性能研究和上述通信标准的比较。",
                    "title_zh": "确定性以太网:应对传感器融合系统中异步检测的挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.42",
                    "title": "Towards Adaptive Fault Tolerance on ROS for Advanced Driver Assistance Systems",
                    "authors": "Matthieu Amy, Jean-Charles Fabre, Michaël Lauer",
                    "abstract": "The use of over-the-air updates has attracted very much interest these last few years with the software-intensive development of embedded systems in the car industry. The development of autonomous driving and ADAS (Advanced Driver Assistance Systems) renders over-the-air updates mandatory, for both user satisfaction and economic reasons. How to make sure that remote updates of critical ADAS do not have an impact on safety? This is the question we tackle in our work with a major car manufacturer. This paper is a progress report. We summarize our approach involving AFT (Adaptive Fault Tolerance) implemented on ROS (Robot Operating System), describe the simulation platform we have developed to experiment and validate over-the-air updates of ADAS and AFT, and finally draw some lessons learnt and perspectives.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01707514/file/DSN-SSIV2017-%20V-final.pdf"
                    },
                    "abstract_zh": "随着汽车行业嵌入式系统的软件密集型开发，无线更新的使用在最近几年引起了极大的兴趣。出于用户满意度和经济原因，自动驾驶和ADAS(高级驾驶员辅助系统)的发展使得空中更新成为强制性的。如何确保关键ADAS的远程更新不会对安全造成影响？这是我们在与一家大型汽车制造商的合作中遇到的问题。本文是一份进度报告。我们总结了我们在ROS(机器人操作系统)上实现的AFT(自适应容错)方法，描述了我们开发的用于实验和验证ADAS和AFT空中更新的仿真平台，最后总结了一些经验教训和展望。",
                    "title_zh": "面向高级驾驶员辅助系统的ROS自适应容错"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.22",
                    "title": "Threat Intelligence for Bluetooth-Enabled Systems with Automotive Applications: An Empirical Study",
                    "authors": "Madeline Cheah, Jeremy W. Bryans, Daniel S. Fowler, Siraj Ahmed Shaikh",
                    "abstract": "Modern vehicles are opening up, with wireless interfaces such as Bluetooth integrated in order to enable comfort and safety features. Furthermore a plethora of aftermarket devices introduce additional connectivity which contributes to the driving experience. This connectivity opens the vehicle to potentially malicious attacks, which could have negative consequences with regards to safety. In this paper, we survey vehicles with Bluetooth connectivity from a threat intelligence perspective to gain insight into conditions during real world driving. We do this in two ways: firstly, by examining Bluetooth implementation in vehicles and gathering information from inside the cabin, and secondly, using war-nibbling (general monitoring and scanning for nearby devices). We find that as the vehicle age decreases, the security (relatively speaking) of the Bluetooth implementation increases, but that there is still some technological lag with regards to Bluetooth implementation in vehicles. We also find that a large proportion of vehicles and aftermarket devices still use legacy pairing (and are therefore more insecure), and that these vehicles remain visible for sufficient time to mount an attack (assuming some premeditation and preparation). We demonstrate a real-world threat scenario as an example of the latter. Finally, we provide some recommendations on how the security risks we discover could be mitigated.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代车辆正在开放，集成了蓝牙等无线接口，以实现舒适和安全功能。此外，过多的售后设备带来了额外的连接，有助于驾驶体验。这种连接使车辆容易受到潜在的恶意攻击，这可能对安全造成负面影响。在本文中，我们从威胁情报的角度调查了具有蓝牙连接的车辆，以深入了解现实世界驾驶中的情况。我们通过两种方式做到这一点:首先，通过检查车辆中的蓝牙实现并从驾驶室内收集信息，其次，使用war-nibbling(对附近设备的一般监控和扫描)。我们发现，随着车龄的减少，蓝牙实现的安全性(相对而言)增加了，但是在车辆中实现蓝牙仍然存在一些技术滞后。我们还发现，很大一部分车辆和售后设备仍然使用传统配对(因此更不安全)，并且这些车辆在足够长的时间内保持可见以发动攻击(假设有一些预谋和准备)。作为后者的一个例子，我们展示了一个真实世界的威胁场景。最后，我们就如何降低我们发现的安全风险提供了一些建议。",
                    "title_zh": "汽车应用蓝牙系统的威胁情报:一项实证研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.52",
                    "title": "RADIANCE Welcome",
                    "authors": "Nuno Antunes, Ariadne M. B. R. Carvalho, Andrea Ceccarelli",
                    "abstract": "Welcome Message",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "欢迎信息",
                    "title_zh": "光芒迎宾"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.18",
                    "title": "Discovering and Mitigating New Attack Paths Using Graphical Security Models",
                    "authors": "Jin Bum Hong, Dong Seong Kim",
                    "abstract": "To provide a comprehensive security analysis of modern networked systems, we need to take into account the combined effects of existing vulnerabilities and zero-day vulnerabilities. In addition to them, it is important to incorporate new vulnerabilities emerging from threats such as BYOD, USB file sharing. Consequently, there may be new dependencies between system components that could also create new attack paths, but previous work did not take into account those new attack paths in their security analysis (i.e., not all attack paths are taken into account). Thus, countermeasures may not be effective, especially against attacks exploiting the new attack paths. In this paper, we propose a Unified Vulnerability Risk Analysis Module (UV-RAM) to address the aforementioned problems by taking into account the combined effects of those vulnerabilities and capturing the new attack paths. The three main functionalities of UV-RAM are: (i) to discover new dependencies and new attack paths, (ii) to incorporate new vulnerabilities introduced and zero-day vulnerabilities into security analysis, and (iii) to formulate mitigation strategies for hardening the networked system. Our experimental results demonstrate and validate the effectiveness of UV-RAM.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了对现代网络系统进行全面的安全分析，我们需要考虑现有漏洞和零日漏洞的综合影响。除此之外，纳入来自BYOD、USB文件共享等威胁的新漏洞也很重要。因此，系统组件之间可能存在新的依赖关系，这也可能产生新的攻击路径，但是先前的工作没有在其安全性分析中考虑这些新的攻击路径(即，没有考虑所有的攻击路径)。因此，对策可能无效，尤其是针对利用新攻击路径的攻击。在本文中，我们提出了一个统一的漏洞风险分析模块(UV-RAM ),通过考虑这些漏洞的综合影响和捕捉新的攻击路径来解决上述问题。UV-RAM的三个主要功能是:(I)发现新的依赖关系和新的攻击路径，(ii)将引入的新漏洞和零日漏洞纳入安全分析，以及(iii)为强化网络系统制定缓解策略。实验结果证明了UV-RAM的有效性。",
                    "title_zh": "使用图形安全模型发现和缓解新的攻击路径"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.37",
                    "title": "Evaluating Security and Availability of Multiple Redundancy Designs when Applying Security Patches",
                    "authors": "Mengmeng Ge, Huy Kang Kim, Dong Seong Kim",
                    "abstract": "In most of modern enterprise systems, redundancy configuration is often considered to provide availability during the part of such systems is being patched. However, the redundancy may increase the attack surface of the system. In this paper, we model and assess the security and capacity oriented availability of multiple server redundancy designs when applying security patches to the servers. We construct (1) a graphical security model to evaluate the security under potential attacks before and after applying patches, (2) a stochastic reward net model to assess the capacity oriented availability of the system with a patch schedule. We present our approach based on case study and model-based evaluation for multiple design choices. The results show redundancy designs increase capacity oriented availability but decrease security when applying security patches. We define functions that compare values of security metrics and capacity oriented availability with the chosen upper/lower bounds to find design choices that satisfy both security and availability requirements.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1705.00128"
                    },
                    "abstract_zh": "在大多数现代企业系统中，冗余配置通常被认为是在这种系统的一部分被修补时提供可用性。然而，冗余可能会增加系统的攻击面。在本文中，我们对在服务器上应用安全补丁时，多服务器冗余设计的安全性和面向容量的可用性进行了建模和评估。我们构建了(1)一个图形化的安全模型来评估应用补丁前后系统在潜在攻击下的安全性，(2)一个随机奖励网模型来评估系统在补丁调度下的容量可用性。我们提出了我们的方法基于案例研究和基于模型的评估多种设计选择。结果表明，冗余设计提高了面向容量的可用性，但在应用安全补丁时降低了安全性。我们定义了将安全性指标和面向容量的可用性的值与所选的上/下限进行比较的函数，以找到满足安全性和可用性要求的设计选择。",
                    "title_zh": "应用安全补丁时评估多冗余设计的安全性和可用性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.26",
                    "title": "Quantitative Evaluation of QoS Prediction in IoT",
                    "authors": "Gary White, Andrei Palade, Christian Cabrera, Siobhán Clarke",
                    "abstract": "Internet of Things (IoT) applications, are typically built from services provided by heterogeneous devices, which are potentially resource constrained and/or mobile. These services and applications are widespread and a key research question is how to predict user side quality of service (QoS), to ensure optimal selection and composition of services. Invoking all available IoT services for evaluation is impractical due to the exponential growth in these services. To assess the current state of the art related to this research question we conduct a quantitative evaluation of QoS prediction approaches, particularly those that use matrix factorisation (MF) for collaborative QoS prediction. These approaches derive from the collaborative filtering model used in recommender systems, which avoids the problems of many other QoS prediction approaches of requiring additional invoking of available IoT components on behalf of the user. We conduct comprehensive experiments based on a real-world large-scale QoS dataset as well as a transformation of this dataset to more closely estimate IoT services, to show the prediction accuracy of these approaches. We also give a demonstration of how they can be used in a small scale example.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "物联网(IoT)应用通常由异构设备提供的服务构建而成，这些设备可能会受到资源限制和/或具有移动性。这些服务和应用广泛存在，一个关键的研究问题是如何预测用户侧的服务质量(QoS ),以确保服务的最佳选择和组合。调用所有可用的物联网服务进行评估是不切实际的，因为这些服务呈指数级增长。为了评估与该研究问题相关的当前技术水平，我们对QoS预测方法进行了定量评估，特别是那些使用矩阵分解(MF)进行协作QoS预测的方法。这些方法源自推荐系统中使用的协同过滤模型，该模型避免了许多其他QoS预测方法需要代表用户额外调用可用物联网组件的问题。我们基于真实世界的大规模QoS数据集以及该数据集的转换进行了全面的实验，以更接近地估计物联网服务，从而显示这些方法的预测准确性。我们还演示了如何在一个小规模的例子中使用它们。",
                    "title_zh": "物联网服务质量预测的量化评估"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.23",
                    "title": "An Integrated Approach for Resilience in Industrial Control Systems",
                    "authors": "Johannes Iber, Tobias Rauter, Michael Krisper, Christian Kreiner",
                    "abstract": "New generations of industrial control systems offer higher performance, they are distributed, and it is very likely that they are internet connected in one way or another. These trends raise new challenges in the contexts of reliability and security. We propose a novel approach that tackles the complexity of industrial control systems at design time and run time. At design time our target is to ease the configuration and verification of controller configurations through model-driven engineering techniques together with the contract-based design paradigm. At run time the information from design time is reused in order to support a modular and distributed self-adaptive software system that aims to increase reliability and security. The industrial setting of the presented approach are control devices for hydropower plant units.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "新一代工业控制系统提供更高的性能，它们是分布式的，并且很可能以某种方式与互联网相连。这些趋势在可靠性和安全性方面提出了新的挑战。我们提出了一种新的方法，在设计时和运行时处理工业控制系统的复杂性。在设计时，我们的目标是通过模型驱动的工程技术和基于契约的设计范例来简化控制器配置的配置和验证。在运行时，来自设计时的信息被重用，以便支持旨在增加可靠性和安全性的模块化和分布式自适应软件系统。所提出的方法的工业设置是用于水力发电厂单元的控制设备。",
                    "title_zh": "工业控制系统弹性的综合方法"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.28",
                    "title": "Towards an Ontology-Based Definition of Data Anonymization Policy for Cloud Computing and Big Data",
                    "authors": "Roberta Mayumi Matsunaga, Ivan Ricarte, Tânia Basso, Regina Moraes",
                    "abstract": "The considerable increase in the use of cloud computing and big data solutions requires the use of advanced technologies to ensure data security, privacy and dependability. One of the possible solutions is the use of data anonymization techniques, which performs an important role in data privacy protection. There are several techniques and algorithms to implement data anonymization. However, specifications and guidelines to guide and standardize the use of these resources are needed. These guidelines, called anonymization policies, are considered an important asset in organizations that want to protect their customer personal data. Although the use of data anonymization brings great benefits, there are no clear directions for data anonymization policies, which ends up lim- iting its adoption by companies and organizations. This work presents a generic anonymization policy to be used in cloud and big data platforms. It also presents a draft ontology with explicit formal specifications for data anonymization policies. This ontology has three main intentions: (i) to standardize the use of data anonymization policies; (ii) share common understanding of the structure of data anonymization among people; (iii) enable reuse of data anonymization policies. In this work, an ongoing study case within the EUBra-BIGSEA project will be implemented.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云计算和大数据解决方案的使用大幅增加，需要使用先进技术来确保数据的安全性、隐私性和可靠性。一种可能的解决方案是使用数据匿名化技术，这在数据隐私保护中起着重要作用。有几种技术和算法可以实现数据匿名化。但是，需要规范和指南来指导和标准化这些资源的使用。这些准则被称为匿名化政策，被认为是希望保护客户个人数据的组织的重要资产。虽然数据匿名化的使用带来了巨大的好处，但数据匿名化政策没有明确的方向，这最终限制了公司和组织对数据匿名化的采用。这项工作提出了一个通用的匿名化政策，用于云和大数据平台。它还提出了一个本体草案，为数据匿名化策略提供了明确的正式规范。这个本体有三个主要意图:(I)规范数据匿名化策略的使用；㈡分享人们对数据匿名化结构的共同理解；㈢实现数据匿名化政策的再利用。在这项工作中，将实施EUBra-BIGSEA项目中的一个正在进行的研究案例。",
                    "title_zh": "面向云计算和大数据的基于本体的数据匿名化策略定义"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.33",
                    "title": "MARITACA: From Textual Use Case Descriptions to Behavior Models",
                    "authors": "Leydi Erazo, Eliane Martins, Juliana Galvani Greghi",
                    "abstract": "It is well known in Software Engineering that the cost of eliminating requirements faults increases when these faults are revealed. Therefore, it is important to express requirements in a way that it would be possible to validate them as early as possible in the development cycle. Use Cases (UC) are a popular format to represent requirements. On the other hand, states machines are a notation amenable for verification, either using for example, model-checking or model animation, and also are a popular notation for model-based test case derivation. However, building a state machine from pure textual requirements is not trivial for most practitioners, in particular, a model with properties that allow them to be handled by a tool. UCs are described in pure natural language, in general, and the manual extraction of state machine models from them can be time-consuming and error-prone. In this work, we present an approach that helps the extraction of state machine models from UC descriptions. These descriptions are in the form of a semi-structured language, instead of pure textual form. The goal is to provide practitioners with a preliminary version of a state model that can be further refined to become input for tools like test case generators. As a proof of concept, a prototyping tool, MARITACA, was developed that uses Natural Language Processing techniques to extract the state machines. The text also shows a validation of the model obtained from the tool, to demonstrate the applicability of the approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "众所周知，在软件工程中，消除需求错误的成本会随着这些错误的暴露而增加。因此，以一种在开发周期中尽可能早地验证需求的方式来表达需求是很重要的。用例(UC)是一种表示需求的流行格式。另一方面，状态机是一种易于验证的符号，例如使用模型检查或模型动画，也是一种基于模型的测试用例派生的流行符号。然而，对于大多数从业者来说，从纯文本需求中构建一个状态机并不简单，特别是一个具有允许工具处理它们的属性的模型。一般来说，UC是用纯自然语言描述的，从其中手动提取状态机模型可能很耗时并且容易出错。在这项工作中，我们提出了一种方法，有助于从UC描述中提取状态机模型。这些描述是以半结构化语言的形式，而不是纯文本的形式。目标是为从业者提供一个状态模型的初步版本，它可以被进一步细化，成为测试用例生成器等工具的输入。作为概念验证，开发了一个原型工具MARITACA，它使用自然语言处理技术来提取状态机。本文还展示了从工具中获得的模型的验证，以展示该方法的适用性。",
                    "title_zh": "MARITACA:从文本用例描述到行为模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.19",
                    "title": "RSVP: Soft Error Resilient Power Savings at Near-Threshold Voltage Using Register Vulnerability",
                    "authors": "Li Tan, Nathan DeBardeleben, Qiang Guan, Sean Blanchard, Michael Lang",
                    "abstract": "With the ever-growing scaling of computing capability, computing systems like supercomputers and embedded systems are bounded by limited power nowadays. Upon the mutually constrained nature between power efficiency and resilience, trade-offs of them have been extensively studied for achieving the optimal performance-power ratio, either under a certain power cap, or within the requirement of quality metrics of applications. Theoretically, running programs in the low-power mode of computational components (e.g., CPU/GPU) can lead to increasing on-chip failure rates in terms of register-level susceptibility to soft errors. However, experimentally, such errors may not arise due to register vulnerability - errors occur at non-vulnerable register access intervals are invalidated and thus will not propagate to later execution. In this work, leveraging register vulnerability, we investigate the validity of failure rates in computing systems at Near-Threshold Voltage (NTV), and empirically evaluate the practice of achieving optimal power savings without incurring observable number of soft errors during program runs. We propose the framework of RegiSter Vulnerability based Power efficiency (RSVP) for reliable and power efficient computing. Experimental results for a wide spectrum of applications on a power-aware simulated platform demonstrate the power saving capability of RSVP, by 11.2% on average, without incurring runtime soft errors at the optimal NTV level for power savings.",
                    "files": {
                        "openAccessPdf": "https://permalink.lanl.gov/object/tr?what=info:lanl-repo/lareport/LA-UR-17-25325"
                    },
                    "abstract_zh": "随着计算能力的不断增长，像超级计算机和嵌入式系统这样的计算系统现在受到有限的功率的限制。基于功率效率和弹性之间的相互约束性质，已经广泛地研究了它们的折衷，以在特定功率上限下或者在应用的质量度量的要求内实现最佳的性能功率比。理论上，在计算组件(例如，CPU/GPU)的低功率模式下运行程序会导致在寄存器级对软错误的易感性方面增加片上故障率。然而，在实验上，这种错误可能不会由于寄存器易受攻击性而出现，在不容易受攻击的寄存器访问间隔出现的错误被无效，因此不会传播到以后的执行。在这项工作中，利用寄存器漏洞，我们研究了计算系统在近阈值电压(NTV)下故障率的有效性，并根据经验评估了在程序运行期间实现最佳节能而不导致可观察到的软错误数量的实践。我们提出了基于寄存器脆弱性的功率效率(RSVP)框架，用于可靠和功率有效的计算。在功率感知模拟平台上对各种应用的实验结果表明，RSVP的功率节省能力平均为11.2%，并且在最佳NTV功率节省水平下不会导致运行时软错误。",
                    "title_zh": "RSVP:利用寄存器漏洞在接近阈值电压下实现软错误弹性节能"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.10",
                    "title": "Software-Defined HoneyNet: Towards Mitigating Link Flooding Attacks",
                    "authors": "Jinwoo Kim, Seungwon Shin",
                    "abstract": "Over the past years, Link Flooding Attacks (LFA) have been introduced as new network threats. LFA is indirect DDoS attack that selectively floods intermediate links, while legacy DDoS attacks directly aim at end points. As a result, a wide area is isolated from the outside of networks. In the legacy network, mitigating LFA is a challenge since an attacker can successfully construct the link map that contains entire network topology via traceroute. Some previous works have been proposed, but, they are ex-post countermeasures that react after LFA occurred. In this paper, we present SDHoneyNet, a SDN based system which exposes fake topology to attackers. We find potential bottleneck links by computing the static metric, which is Betweenness Centrality (BC) of the network topology given by the SDN controller. Also, we calculate the dynamic metric, which is Consumed Bandwidth Rate (CBR) of each link by collecting OF's port statistics. With these two attributes, SDHoneyNet finds a minimum intersection set containing the nodes that have both high static and dynamic metrics. Then, it deploys the honey topology where the node degree follows a power-law distribution, to mimic complex networks. We leverage software switches to easily build and deploy the honey topology. We implement the prototype of SDHoneyNet as an SDN application (2,000 lines of Java code) on the ONOS controller.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在过去的几年中，链接泛滥攻击(LFA)作为新的网络威胁被引入。LFA是选择性泛洪中间链路的间接DDoS攻击，而传统DDoS攻击直接针对端点。因此，很大一部分区域被隔离在网络之外。在传统网络中，缓解LFA是一项挑战，因为攻击者可以通过traceroute成功构建包含整个网络拓扑的链路映射。一些先前的工作已经被提出，但是，他们是在LFA发生之后反应的事后对策。在本文中，我们提出了SDHoneyNet，一个基于SDN的系统，它向攻击者暴露虚假的拓扑结构。我们通过计算静态度量来发现潜在的瓶颈链路，该静态度量是由SDN控制器给出的网络拓扑的中间中心性(BC)。此外，我们还通过收集的端口统计数据来计算动态度量，即每条链路的消耗带宽率(CBR)。通过这两个属性，SDHoneyNet找到了一个最小交集，它包含了具有高静态和动态指标的节点。然后，它部署蜂蜜拓扑，其中节点度遵循幂律分布，以模拟复杂网络。我们利用软件交换机来轻松构建和部署蜂蜜拓扑。我们在ONOS控制器上将SDHoneyNet的原型实现为SDN应用程序(2000行Java代码)。",
                    "title_zh": "软件定义的蜜网:缓解链接泛滥攻击"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.11",
                    "title": "TDSC: Two-Stage DDoS Detection and Defense System Based on Clustering",
                    "authors": "Shuang Wei, Yijing Ding, Xinhui Han",
                    "abstract": "Distributed Denial-of-Service(DDoS) attack continues to be one of the most serious problems in the Internet. Without advance warning, DDoS attack can knock down the targeted server in a short period of time by exhausting the computing and communicating resources of the victim. In this paper, we propose a two-stage DDoS detection and defense system called TDSC. In the first stage, we divide the input flows into 4 parts and use the cluster size distribution analysis to detect the attack. Since we use cluster analysis as the basic detection algorithm, TDSC can separate the DDoS attacks from the legitimate flash crowd easily. In the first stage, we also extract traffic features of the attack from the cluster containing most of the DDoS traffic. With the DDoS attack features output by the first stage, TDSC can filter the attack traffic out in the second stage. We test the effectiveness of TDSC on the MIT Lincoln Laboratory 2000 LLS DDOS 1.0 Dataset(a.k.a. MIT LLS DDOS 1.0 Dataset). Results show that TDSC can detect the DDoS attack in 6 seconds and extract the features which can describe the attack traffic accurately. And with the traffic features calculated by the first stage, TDSC can filter out 99.89% of the attack traffic in the second stage.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分布式拒绝服务攻击仍然是互联网上最严重的问题之一。在没有预先警告的情况下，DDoS攻击可以通过耗尽受害者的计算和通信资源，在短时间内击倒目标服务器。在本文中，我们提出了一个两阶段的DDoS检测和防御系统，称为TDSC。在第一阶段，我们将输入流分成4部分，并使用聚类大小分布分析来检测攻击。由于我们使用聚类分析作为基本的检测算法，TDSC可以很容易地将DDoS攻击从合法的flash人群中分离出来。在第一阶段，我们还从包含大部分DDoS流量的集群中提取攻击的流量特征。通过第一阶段输出的DDoS攻击特征，TDSC可以在第二阶段过滤掉攻击流量。我们在麻省理工学院林肯实验室2000 LLS DDOS 1.0数据集(又名麻省理工学院LLS DDOS 1.0数据集)上测试了TDSC的有效性。实验结果表明，TDSC可以在6秒内检测出DDoS攻击，并提取出能够准确描述攻击流量的特征。通过第一阶段计算的流量特征，TDSC可以在第二阶段过滤掉99.89%的攻击流量。",
                    "title_zh": "TDSC:基于聚类的两阶段DDoS检测与防御系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.12",
                    "title": "The Many Conflicting Visions of 'Safety Case'",
                    "authors": "Patrick J. Graydon",
                    "abstract": "Safety cases and other assurance cases have been produced, reviewed, researched, and written about for decades [1]. Definitions of safety case agree on principles such as the use of evidence and (recently) the central role of argument. But the literature seemingly reflects both multiple forms and multiple visions of safety case. Each vision is a school of thought on what safety cases are, what value they deliver to which stakeholders, and how they generate that value. We hypothesize that (1) the community uses several different visions of safety case and (2) no one safety case form suits all visions. If both hypotheses are true, identifying and distinguishing the visions will facilitate more productive research and policymaking. In this paper, we identify both seven existing visions and five inconsistencies in what they demand of arguments. We have not identified a complete set of visions and are not the first to note apparent differences in the use of the term safety case [2]. We do not claim to perfectly capture any school of thought on safety cases. Our contribution lies in (i) identifying a divergence of meanings that seems to be frustrating research and policy making and (ii) beginning to define the common language and hypotheses needed for fruitful research.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全案例和其他保证案例已经产生、审查、研究和撰写了几十年[1]。安全案例的定义在诸如证据的使用和(最近)论证的中心作用等原则上是一致的。但文献似乎反映了安全案例的多种形式和多种视角。每个愿景都是关于什么是安全案例、它们向哪些利益相关者交付什么价值以及它们如何产生价值的思想流派。我们假设:( 1)社区使用几种不同的安全案例观点;( 2)没有一种安全案例形式适合所有观点。如果这两个假设都是真的，识别和区分愿景将有助于更有成效的研究和决策。在本文中，我们确定了七个现有的观点和五个不一致的论点。我们还没有确定一套完整的愿景，也不是第一个注意到术语“安全案例”使用上的明显差异的人[2]。我们并不声称完美地抓住了安全案例的任何学派。我们的贡献在于:( I)识别似乎阻碍研究和决策的含义分歧;( ii)开始定义卓有成效的研究所需的共同语言和假设。",
                    "title_zh": "“安全案例”的许多相互矛盾的观点"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.13",
                    "title": "RFID Tag Grouping Protocols Made Private",
                    "authors": "Yudai Komori, Kazuya Sakai, Satoshi Fukumoto",
                    "abstract": "In large-scale RFID systems, tag grouping is crucial for scalable object management and effective data access. However, in reality, not only the performance, but also security and privacy in RFID systems are of great concern. While there are a number of works for securing tag authentication protocols, to the best of our knowledge, the problem of private tag grouping is yet to be addressed. To tackle this issue, in this paper, we first build an indistinguishability-based privacy model using random oracles. Then, we propose a set of private grouping protocols based on the existing solutions, namely private traditional polling grouping (PrivTPG), private enhanced polling grouping (PrivEPG), and Bloom filter-based grouping (PrivBFG).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在大规模RFID系统中，标签分组对于可扩展的对象管理和有效的数据访问至关重要。然而，在现实中，RFID系统中不仅性能，而且安全和隐私都是非常令人关注的。尽管有许多保护标签认证协议的工作，但就我们所知，私有标签分组的问题仍有待解决。为了解决这个问题，本文首先使用随机预言建立了一个基于不可区分性的隐私模型。然后，我们在现有解决方案的基础上提出了一套私有分组协议，即私有传统轮询分组(PrivTPG)、私有增强轮询分组(PrivEPG)和基于Bloom filter的分组(PrivBFG)。",
                    "title_zh": "RFID标签分组协议成为私有协议"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.15",
                    "title": "Off-Path Caching for File Versioning in Named Data Networking",
                    "authors": "Mamoru Ohara, Satoshi Fukumoto",
                    "abstract": "Named-Data Networking (NDN) is one of promising architecture for achieving information-centric networking (ICN), in which users can access information by name without knowing where it is. File versioning is expected to be introduced in NDN, however there have been practically no work. %for file versioning in NDN. In this study, we apply an optimal resource allocation model, which was analytically derived in our previous work, to NDN systems in order to introduce file versioning. For preliminary purpose, we in this article compare two resource allocation policies using a simulatior. Our optimal resource allocation policy shows better performance as expected.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "命名数据网络(NDN)是实现以信息为中心的网络(ICN)的一种有前途的体系结构，在这种体系结构中，用户可以通过名字访问信息，而不知道它在哪里。NDN有望引入文件版本控制，但实际上还没有任何工作。%用于NDN的文件版本控制。在这项研究中，我们将一个优化的资源分配模型应用于NDN系统，以引入文件版本控制，该模型是在我们以前的工作中通过分析得出的。出于初步目的，我们在本文中使用模拟器比较了两种资源分配策略。我们的最优资源分配策略显示了预期的更好的性能。",
                    "title_zh": "命名数据网络中用于文件版本控制的路径外缓存"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.34",
                    "title": "Portable SDN Testbed Prototype",
                    "authors": "Joshua A. Alcorn, Scott Melton, C. Edward Chow",
                    "abstract": "Software Defined Networking (SDN) is a fieldof research that promises to change the landscape oftraditional network topology and management. Researchers and early adopters need adequate SDNtesting facilities. Industry is responding with embeddedsupport for SDN in their enterprise grade networkhardware, but is cost prohibitive for many research testenvironments. An alternative is to use software simulatednetwork topology tools that arguably do not emulate realworldbehavior. Our solution is to build a low cost, portable, standaloneSDN testbed. Called SDN On-The-Go (OTG), the testbedsupports many configurations for pseudo real-world SDNexperiments. SDN OTG is a self-contained testbed thatcan also be used as a portable teaching device, moved fromclassroom to classroom or taken home for privateresearch. We achieved repeatability factor 10 timesgreater than simulation based testing. Our SDN OTGphysical testbed weighs about twenty pounds, costs aroundone thousand US dollars, provides repeatable data, andcan be setup as a fully functional SDN testbed in a coupleof minutes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(SDN)是一个有望改变传统网络拓扑和管理的研究领域。研究人员和早期采用者需要足够的测试设备。业界正在他们的企业级网络硬件中为SDN提供嵌入式支持，但对于许多研究测试环境来说，成本过高。另一种方法是使用软件模拟的网络拓扑工具，这些工具可能无法模拟真实世界的行为。我们的解决方案是构建一个低成本、便携、独立的DN测试平台。该测试平台名为SDN On-The-Go (OTG ),支持多种伪真实SDN实验配置。SDN OTG是一个独立的测试平台，也可以用作便携式教学设备，在教室之间移动或带回家进行私人研究。我们实现了比基于模拟的测试大10倍的可重复性。我们的SDN OTGphysical testbed重约20磅，成本约1000美元，提供可重复的数据，可以在几分钟内设置为全功能的SDN testbed。",
                    "title_zh": "便携式SDN试验床原型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.36",
                    "title": "A Framework for SDN Network Evaluation",
                    "authors": "Joshua A. Alcorn, Scott Melton, C. Edward Chow",
                    "abstract": "Unauthorized access of personal or proprietary information seems to be a routine. A better understanding of the health of our networks can help us identify network anomalies that indicate malicious activity and other latent, systemic issues. Software-Defined Networks (SDN) enable the collection of network operational and configuration data that are not readily available, if available at all, from traditional networks. By accumulating and analyzing a time series data repository (TSDR) of SDN and traditional network metrics along with operational and configuration data we can establish known behavior and security patterns for specific network paths and segments. By comparing these patterns with data gathered at the time of use we can assess the dependability and security of the network path or segment being used. Our research provides a framework for a broad range of capabilities for administrators to use as well as for automated protection services. To narrow the scope of our research, this paper focuses on a subset of those capabilities as they apply to the analysis of a specific network path at the time of use or inspection. We developed a service that inspects a network path before and after sending sensitive information and compares this inspection to our known behavior and security patterns to provide a user with a dependability assessment of that specific network path. This dependability assessment allows users to decide whether a network path is secure enough for sending their information. Our research proposes techniques for a network path analysis service that can be used to identify latent systemic network problems, facilitate a more dependable network and to prevent the theft of information by malicious actors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "未经授权访问个人或专有信息似乎是一种惯例。更好地了解我们网络的健康状况有助于我们识别表明恶意活动和其他潜在系统性问题的网络异常。软件定义网络(SDN)支持收集网络运行和配置数据，而这些数据在传统网络中是不容易获得的。通过积累和分析SDN和传统网络指标的时间序列数据存储库(TSDR)以及运营和配置数据，我们可以为特定网络路径和网段建立已知的行为和安全模式。通过将这些模式与使用时收集的数据进行比较，我们可以评估正在使用的网络路径或网段的可靠性和安全性。我们的研究为管理员使用的广泛功能以及自动化保护服务提供了一个框架。为了缩小我们的研究范围，本文重点介绍这些功能的一个子集，因为它们适用于在使用或检查时对特定网络路径的分析。我们开发了一种服务，可以在发送敏感信息之前和之后检查网络路径，并将这种检查与我们已知的行为和安全模式进行比较，从而为用户提供特定网络路径的可靠性评估。这种可靠性评估允许用户决定网络路径对于发送他们的信息是否足够安全。我们的研究提出了网络路径分析服务的技术，可用于识别潜在的系统网络问题，促进更可靠的网络，并防止恶意行为者窃取信息。",
                    "title_zh": "SDN网络评估框架"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.38",
                    "title": "Document Faults: An Extension of the Taxonomy of Dependable and Secure Computing",
                    "authors": "Algirdas Avizienis",
                    "abstract": "An extension of the established taxonomy of dependable and secure computing is presented. Document faults are dormant faults in published scientific and technical documents. The documents consist of text and non-text parts. The classification and removal of text faults is discussed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "提出了对已建立的可靠和安全计算分类的扩展。文献错误是已发表的科技文献中潜伏的错误。文档由文本和非文本部分组成。讨论了文本错误的分类和去除。",
                    "title_zh": "文档错误:可靠和安全计算分类的扩展"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.49",
                    "title": "Opportunities and Challenges of Third-Party Sustainment of Critical Software in Dependable Systems",
                    "authors": "Kate Gill, Rob Ashmore",
                    "abstract": "Software sustainment is an important part of delivering a long-term dependable system. There are good reasons to consider sustainment being undertaken by a third party (i.e. not the original developer). This brief paper identifies these reasons, as well as enablers to and barriers against third party software sustainment. It is concluded that third party sustainment should not be viewed as a last resort; instead, it should be proactively considered as a potentially valuable approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件维护是交付长期可靠系统的重要组成部分。有充分的理由考虑由第三方(即不是最初的开发商)进行维护。这篇简短的文章指出了这些原因，以及第三方软件维护的促成因素和障碍。得出的结论是，第三方维持不应被视为最后手段；相反，它应该被积极地视为一种潜在的有价值的方法。",
                    "title_zh": "可信系统中关键软件第三方支持的机遇和挑战"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.16",
                    "title": "RT Level vs. Microarchitecture-Level Reliability Assessment: Case Study on ARM(R) Cortex(R)-A9 CPU",
                    "authors": "Athanasios Chatzidimitriou, Manolis Kaliorakis, Dimitris Gizopoulos, Maurizio Iacaruso, Mauro Pipponzi, Riccardo Mariani, Stefano Di Carlo",
                    "abstract": "Reliability1assessment has always been a major concern in the design of computing systems. The results of the assessment highlight and guide enhancements which trigger redesign cycles; thus early and accurate reliability assessment is of profound importance. For the purposes of early reliability analysis, abstract models of the design (which are available in early design stages) are typically used. These models, however, may not be completely accurate compared to the actual final design. Existing literature has not quantified this inaccuracy, through a comparison between Register-Transfer-Level (RTL) and microarchitecture-level reliability assessment on the same commercial microprocessor design. In this paper, we perform reliability assessment using statistical fault-injection on the RTL and Microarchitectural models of the same commercial ARM® Cortex®-A9 processor. The assessment was performed using the same benchmark workloads and equivalent configurations of the hardware structures. The results show that, compared to RTL model, the almost 200x faster microarchitectural model reports an average difference of 0.7 percentile units (10%) on the vulnerability estimation of register file and 3 percentile units (20%) on the vulnerability estimation of L1 data cache.",
                    "files": {
                        "openAccessPdf": "https://iris.polito.it/bitstream/11583/2692797/2/PID4775745.pdf"
                    },
                    "abstract_zh": "可靠性评估一直是计算系统设计中的主要关注点。评估结果强调并指导触发重新设计周期的改进；因此，早期和准确的可靠性评估是非常重要的。出于早期可靠性分析的目的，通常使用设计的抽象模型(在早期设计阶段可用)。然而，与实际的最终设计相比，这些模型可能并不完全准确。现有的文献还没有通过在相同的商用微处理器设计上比较寄存器传输级(RTL)和微架构级可靠性评估来量化这种不准确性。在本文中，我们使用统计故障注入对同一款商用ARM Cortex -A9处理器的RTL和微架构模型进行了可靠性评估。评估是使用相同的基准工作负载和等效的硬件结构配置进行的。结果表明，与RTL模型相比，快了近200倍的微体系结构模型在寄存器文件的漏洞估计上报告了0.7个百分点单位(10%)的平均差异，在L1数据缓存的漏洞估计上报告了3个百分点单位(20%)的平均差异。",
                    "title_zh": "RT级与微架构级可靠性评估:ARM Cortex-A9 CPU案例研究"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.29",
                    "title": "Faster Exact Reliability Computation",
                    "authors": "Vincent Debieux, Yvonne-Anne Pignolet, Thanikesavan Sivanthi",
                    "abstract": "High reliability guarantees are a prerequisite for any critical infrastructure. In complex systems, the computation of the probability to provide a service is difficult and hence time consuming. To this end, this article presents an improved method for exact reliability computation by exploiting the existence of articulation points in graphs representing the dependency function such systems. Evaluated on generalized block graphs with many articulation points, this method provides a speed-up of 50% to 85% in general. When the network does not contain articulation points, the overhead in memory and computation time is negligible in comparison to an existing method.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高可靠性保证是任何关键基础设施的先决条件。在复杂的系统中，计算提供服务的概率是困难的，因此也是耗时的。为此，本文提出了一种改进的精确可靠性计算方法，该方法利用了表示这类系统依赖函数的图中接合点的存在性。在具有许多接合点的广义块图上评估，该方法通常提供50%到85%的加速。当网络不包含关节点时，与现有方法相比，存储器和计算时间的开销可以忽略不计。",
                    "title_zh": "更快的精确可靠性计算"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.35",
                    "title": "Providing Resiliency to Orchestration and Automation Engines in Hybrid Cloud",
                    "authors": "Long Wang, Harigovind V. Ramasamy, Alexei Karve, Richard E. Harper",
                    "abstract": "Hybrid cloud environments have seen a rapid rise in recent years. An essential part of a hybrid cloud is its ability to orchestrate the allocation, provisioning, and management of different compute resources spanning multiple cloud systems, and drive these operations across multiple cloud systems in an automated way. The Orchestration and Automation Engines (OAEs) of a hybrid cloud must themselves be highly available for ensuring high resiliency of the hybrid cloud. We present our experience in providing resiliency to the OAEs of a real-world hybrid cloud in this paper. The presentation includes the resiliency architecture of the OAEs, solutions that deal with errors ranging from software component crash to configuration/metadata error and data corruption, experimental results and our lessons learned from the practical experience.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，混合云环境迅速崛起。混合云的一个重要部分是它能够协调跨多个云系统的不同计算资源的分配、供应和管理，并以自动化的方式跨多个云系统驱动这些操作。混合云的编排和自动化引擎(oae)本身必须高度可用，以确保混合云的高弹性。在本文中，我们展示了我们在为真实世界混合云的oae提供弹性方面的经验。该演示包括OAEs的弹性架构、处理从软件组件崩溃到配置/元数据错误和数据损坏等各种错误的解决方案、实验结果以及我们从实践中获得的经验教训。",
                    "title_zh": "为混合云中的流程编排和自动化引擎提供弹性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.20",
                    "title": "Uptime-Optimized Cloud Architecture as a Brokered Service",
                    "authors": "Sreekrishnan Venkateswaran, Santonu Sarkar",
                    "abstract": "Enterprise workloads usually call for an uptime service level agreement (SLA) at the pain of contractual penalty in the event of slippage. Often, the strategy is to introduce ad-hoc HA (High Availability) mechanisms in response. Implemented solutions that we surveyed do not mathematically map their availability model to the required uptime SLA and to any expected penalty payout. In most client cases that we observed, this either resulted in an over-engineered solution that had more redundancies than was required, or in an inadequate solution that could potentially slip on the system uptime SLA stipulated in the contract. In this paper, we propose a framework backed by a model, to automatically determine the HA-enabled solution with the least TCO (total cost of ownership) for a given uptime SLA and slippage penalty. We attempt to establish that our work is best implemented as a brokered service that recommends an uptime-optimized cloud architecture.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2205.05403"
                    },
                    "abstract_zh": "企业工作负载通常需要正常运行时间服务水平协议(SLA ),否则会受到合同惩罚。通常，策略是引入专门的HA(高可用性)机制作为响应。我们调查的已实施解决方案没有从数学上将其可用性模型映射到所需的正常运行时间SLA和任何预期的罚款支出。在我们观察到的大多数客户案例中，这要么导致过度设计的解决方案，其冗余多于所需，要么导致不充分的解决方案，可能会违反合同中规定的系统正常运行时间SLA。在本文中，我们提出了一个由模型支持的框架，在给定的正常运行时间SLA和延误损失的情况下，以最小的TCO(总拥有成本)自动确定启用HA的解决方案。我们试图证明，我们的工作最好作为推荐正常运行时间优化的云架构的代理服务来实现。",
                    "title_zh": "运行时间优化的云架构作为代理服务"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.25",
                    "title": "Enhancing Anomaly Diagnosis of Automatic Train Supervision System Based on Operation Log",
                    "authors": "Yan Li, Binbin Chen, Vincent W. Zheng, William G. Temple, Zbigniew Kalbarczyk, Yue Wu",
                    "abstract": "Automatic train supervision (ATS) systems are designed to improve the reliability of train services. An ATS system coordinates the trains and other systems in a metro and records alarms if faults occur. In this work, we propose a context-aware anomaly diagnosis tool to analyze the underlying causes of alarms for ATS system. Using 61-day data collected from an operational ATS system, we apply our diagnosis tool to conduct systematic analysis of the alarms and identify interesting correlations among different assets and events. Our analysis shows that the alarms can be correlated with certain system events if they are in the same operations or the assets associated with them belong to the same or linked systems. These results can improve the efficiency of anomaly diagnosis and maintenance for metro system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动列车监控(ATS)系统旨在提高列车服务的可靠性。ATS系统协调地铁中的列车和其他系统，并在发生故障时记录警报。在这项工作中，我们提出了一个上下文感知异常诊断工具来分析ATS系统报警的潜在原因。使用从运行中的ATS系统收集的61天数据，我们应用我们的诊断工具对警报进行系统分析，并识别不同资产和事件之间有趣的相关性。我们的分析表明，如果警报在相同的操作中，或者与它们相关联的资产属于相同的或链接的系统，则它们可以与某些系统事件相关联。这些结果可以提高地铁系统异常诊断和维护的效率。",
                    "title_zh": "基于运行日志加强列车自动监控系统异常诊断"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.39",
                    "title": "Automating DRAM Fault Mitigation By Learning From Experience",
                    "authors": "Elisabeth Baseman, Nathan DeBardeleben, Kurt B. Ferreira, Vilas Sridharan, Taniya Siddiqua, Olena Tkachenko",
                    "abstract": "Current practice for mitigating DRAM hardwarefaults is to simply discard the entire faulty DIMM. However, this becomes increasingly expensive and wasteful as the priceof memory hardware increases and moves physically closer toprocessing units. Accurately characterizing memory faults inreal-time in order to pre-empt future potentially catastrophicfailures is crucial to conserving resources by blacklisting smallaffected regions of memory rather than discarding an entirehardware component. We further evaluate and extend a machinelearning method for DRAM fault characterization introduced inprior work by Baseman et al. at Los Alamos National Laboratory. We report on the usefulness of a variety of training sets, usinga set of production-relevant metrics to evaluate the method ondata from a leadership-class supercomputing facility. We observean increase in percent of faults successfully mitigated as well asa decrease in percent of wasted blacklisted pages, regardless oftraining set, when using the learned algorithm as compared to ahuman-expert, deterministic, and rule-based approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "减轻DRAM硬件故障的当前实践是简单地丢弃整个有故障的DIMM。然而，随着内存硬件价格的上涨和物理上向处理单元靠近，这变得越来越昂贵和浪费。通过将小块受影响的内存区域列入黑名单而不是丢弃整个硬件组件，实时准确地描述内存故障的特征，以预先阻止未来潜在的灾难性故障，这对于节约资源至关重要。我们进一步评估和扩展了Baseman等人在洛斯阿拉莫斯国家实验室的前期工作中引入的用于DRAM故障表征的机器学习方法。我们报告了各种训练集的有用性，使用一组与生产相关的指标对来自领先超级计算设施的数据评估该方法。我们观察到，与人类专家、确定性和基于规则的方法相比，使用学习算法时，无论训练集如何，成功缓解的错误百分比增加，浪费的黑名单页面百分比减少。",
                    "title_zh": "通过从经验中学习来自动化DRAM故障缓解"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.31",
                    "title": "FUsing Hybrid Remote Attestation with a Formally Verified Microkernel: Lessons Learned",
                    "authors": "Karim Eldefrawy, Norrathep Rattanavipanon, Gene Tsudik",
                    "abstract": "Remote Attestation (RA) allows a trusted entity (verifier) to securely measure internal state of a remote untrusted device (prover). RA can be used to establish a static or dynamic root of trust in embedded and cyber-physical systems. There are 3 types of RA designs: hardware-based, software-based, and hybrid, each with its own benefits and drawbacks. This paper presents the first hybrid RA design (HYDRA) that builds upon formally verified software components that ensure memory isolation and protection, as well as enforce memory access controls. HYDRA obtains these properties by using the formally verified seL4 microkernel. We instantiate HYDRA on a popular commodity platform and assess its performance via experiments; we show that HYDRA can attest 10MB of memory in less than 500msec. The paper also discusses the challenges facing development of HYDRA and the lessons learned.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "远程证明(RA)允许可信实体(验证者)安全地测量远程不可信设备(证明者)的内部状态。RA可用于在嵌入式和网络物理系统中建立静态或动态的信任根。RA设计有3种类型:基于硬件的、基于软件的和混合的，每种都有自己的优点和缺点。本文介绍了第一个混合RA设计(HYDRA ),它构建在经过正式验证的软件组件之上，可确保内存隔离和保护，并实施内存访问控制。HYDRA通过使用正式验证的seL4微内核获得这些属性。我们在一个流行的商品平台上实例化HYDRA，并通过实验评估其性能；我们展示了HYDRA可以在不到500毫秒的时间内测试10MB的内存。本文还讨论了HYDRA开发面临的挑战和经验教训。",
                    "title_zh": "将混合远程证明与正式验证的微内核相融合:经验教训"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.17",
                    "title": "MAS: Mobile-Apps Assessment and Analysis System",
                    "authors": "Chia-Wei Tien, Tse-Yung Huang, Ting-Chun Huang, Wei-Ho Chung, Sy-Yen Kuo",
                    "abstract": "Mobile apps are widely adopted in daily life, and contain increasing security flaws. Many regulatory agencies and organizations have announced security guidelines for app development. However, most security guidelines involving technicality and compliance with this requirement is not easily feasible. Thus, we propose Mobile Apps Assessment and Analysis System (MAS), an automatic security validation system to improve guideline compliance. MAS combines static and dynamic analysis techniques, which can be used to verify whether android apps meet the security guideline requirements. We implemented MAS in practice and verified 143 real-world apps produced by the Taiwan government. Besides, we also validated 15,000 popular apps collected from Google Play Store produced in three countries. We found that most apps contain at least three security issues. Finally, we summarize the results and list the most common security flaws for consideration in further app development.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "移动应用在日常生活中被广泛采用，并且包含越来越多的安全缺陷。许多监管机构和组织已经宣布了应用程序开发的安全指南。然而，大多数涉及技术细节和符合这一要求的安全指南并不容易实现。因此，我们提出了移动应用评估和分析系统(MAS ),这是一个自动安全验证系统，用于提高指南合规性。MAS结合了静态和动态分析技术，可用于验证android应用程序是否符合安全指南要求。我们在实践中实现了MAS，并验证了台湾政府制作的143个真实世界的app。此外，我们还验证了从谷歌Play商店收集的15，000个来自三个国家的流行应用程序。我们发现大多数应用程序至少包含三个安全问题。最后，我们总结了结果，并列出了最常见的安全缺陷，供进一步开发应用程序时参考。",
                    "title_zh": "MAS:移动应用评估和分析系统"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.32",
                    "title": "A Visit to the Jungle of Terminology",
                    "authors": "Algirdas Avizienis",
                    "abstract": "The goal of this short study is to compare nine widely used concepts: reliability, robustness, survivability, trust- worthiness, high confidence, high assurance, fault management, self-healing, and resilience to the concept of dependability as it is presented with a taxonomy in the 2004 paper \"Basic concepts and taxonomy of dependable and secure computing\". The study also considers the representation of those concepts in the general taxonomy of computer science and engineering \"ACM Computing Classification, 2012 Revision\".",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "这个简短研究的目标是比较9个广泛使用的概念:可靠性、健壮性、生存性、值得信任性、高置信度、高保证、故障管理、自我修复和弹性，以及2004年论文“可靠和安全计算的基本概念和分类”中提出的可靠性概念。该研究还考虑了这些概念在计算机科学和工程通用分类法“ACM计算分类，2012年修订版”中的表示。",
                    "title_zh": "术语丛林之旅"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.24",
                    "title": "Modeling Error Propagation in Programs",
                    "authors": "Guanpeng Li",
                    "abstract": "As technology keeps scaling, hardware fault rates are predicted to increase in future computer system. Traditional methods use hardware-only techniques that are energy hungry. Researchers have proposed selective software techniques to tolerate hardware faults at lower costs. However, figuring out which instructions to protect for a target fault coverage can be time- consuming through fault injections. Many proposals have tried to solve the problem, but they suffer either lack of accuracy or scalability issue, and are hence difficult to deploy in practice. In my PhD work, I am proposing a systematic model for error propagation in programs that is both scalable and accurate. The method models error propagation from static instruction-level, control-flow-level and memory-levels. Preliminary results show that our proposed method is able to accurately predict the Silent Data Corruption (SDC) rate of programs without fault injections, thus making it scalable.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着技术的不断发展，预计未来计算机系统的硬件故障率将会增加。传统方法使用高能耗的纯硬件技术。研究人员提出了选择性软件技术，以较低的成本容忍硬件故障。然而，通过故障注入，找出保护目标故障覆盖率的指令可能是耗时的。许多提议试图解决这个问题，但是它们要么缺乏准确性，要么存在可伸缩性问题，因此在实践中难以部署。在我的博士论文中，我提出了一个程序中错误传播的系统模型，它既可扩展又精确。该方法从静态指令级、控制流级和存储器级对错误传播进行建模。初步结果表明，我们提出的方法能够在没有故障注入的情况下准确预测程序的静默数据损坏(SDC)率，从而使其具有可扩展性。",
                    "title_zh": "模拟程序中的错误传播"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.30",
                    "title": "Automated Program Diversity Using Program Synthesis",
                    "authors": "Abraham Chan",
                    "abstract": "Software monocultures are susceptible to large scalesecurity attacks as attacks on a single node can be effortlesslyscaled out to the rest of the system. Program diversity hasbeen explored as a means of defending systems from mass scalesecurity attacks and system failures. Existing diversity techniqueshave focused on reordering code blocks to alter the controlflow graph. In contrast, we focus on algorithmic diversity. Wepresent an algorithmic diversity approach that is fully automatedend to end by adopting techniques in program synthesis. Wedemonstrate how our approach can be deployed as a defenceagainst code reuse attacks and against common software faults.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件单一文化容易受到大规模的安全攻击，因为对单个节点的攻击可以轻而易举地扩展到系统的其余部分。程序多样性已经被探索作为一种保护系统免受大规模安全攻击和系统故障的手段。现有的分集技术集中在重新排序代码块以改变控制流图。相比之下，我们关注算法的多样性。我们提出了一种算法多样性的方法，这种方法通过采用程序综合的技术，是完全自动化的。我们演示了如何部署我们的方法来防御代码重用攻击和常见的软件错误。",
                    "title_zh": "使用程序合成的自动化程序多样性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.21",
                    "title": "Student Research Paper: Evaluation of the Dependability of Critical Infrastructures Using Hybrid Petri Nets with Random Variables and Stochastic Simulation",
                    "authors": "Carina Pilch",
                    "abstract": "The focus of my Phd project is on the evaluation of the dependability of critical infrastructures, e.g. energy distribution and gas networks. The modeling formalism of hybrid Petri nets with random variables forms the basis of our modeling approach. We plan to rigorously evaluate dependability using discrete-event simulation and methods of Statistical Model Checking and extend existing approaches with methods of rare-event simulation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我博士项目的重点是评估关键基础设施的可靠性，如能源分配和天然气网络。具有随机变量的混合Petri网的建模形式构成了我们建模方法的基础。我们计划使用离散事件模拟和统计模型检验方法严格评估可靠性，并使用罕见事件模拟方法扩展现有方法。",
                    "title_zh": "学生研究论文:使用具有随机变量和随机模拟的混合Petri网评估关键基础设施的可靠性"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.27",
                    "title": "Enabling Low Degraded Read Latency and Fast Recovery for Erasure Coded Cloud Storage Systems",
                    "authors": "Peng Li",
                    "abstract": "Compared to 3-way replication, which incurs triple storage costs for data availability and reliability, erasure coding has emerged as a good alternative to ensure data safety with significantly lower storage overhead for large-scale cloud storage systems. However, this results in high degraded read latency and long reconstruction time owing to higher disk and network traffic where unavailable data are erasure coded. In this paper, we aim to improve the recovery performance for coded data when failure occurs, by shortening the reconstruction time and degraded read latency. Two optimization methods are proposed: (a) proactive data migration using drive failure prediction, (b) reactive recovery optimization when failures actually occur. This paper includes the current research direction and the future work that the author aims to perform in the next years. These results show that the reconstruction time of unavailable data could be reduced by these optimizations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "与三向复制相比，三向复制会导致数据可用性和可靠性的三倍存储成本，擦除编码是一种很好的替代方法，可以确保数据安全，并显著降低大规模云存储系统的存储开销。但是，这导致读取延迟严重降低，重建时间长，因为在不可用数据被擦除编码的情况下，磁盘和网络流量更高。在本文中，我们旨在通过缩短重建时间和降低读取延迟来提高失败时编码数据的恢复性能。提出了两种优化方法:(a)使用驱动器故障预测的主动数据迁移，(b)当故障实际发生时的被动恢复优化。本文包括当前的研究方向和作者在未来几年的工作目标。这些结果表明，这些优化可以减少不可用数据的重建时间。",
                    "title_zh": "实现擦除编码云存储系统的低降级读取延迟和快速恢复"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.46",
                    "title": "Special Session at DSN for the Best Papers from SELSE 2017",
                    "authors": "Alan Wood",
                    "abstract": "The 12th Workshop on Silicon Errors in Logic - System Effects (SELSE) was held on March 21-22, 2017, in Boston, MA , USA. Detailed information about SELSE 2017 and previous SELSE workshops, including links to presentations, is available at http://www.selse.org. Three papers were selected as the Best of SELSE papers and are presented in this special DSN session.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "第十二届逻辑系统效应(SELSE)硅误差研讨会于2017年3月21-22日在美国马萨诸塞州波士顿举行。有关SELSE 2017和之前SELSE研讨会的详细信息，包括演示文稿的链接，可在http://www.selse.org获得。三篇论文被选为SELSE论文中的最佳论文，并在本次DSN特别会议上发表。",
                    "title_zh": "DSN特别会议，评选SELSE 2017最佳论文"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.47",
                    "title": "Evaluation and Mitigation of Soft-Errors in Neural Network-Based Object Detection in Three GPU Architectures",
                    "authors": "Fernando Fernandes dos Santos, Lucas Draghetti, Lucas Weigel, Luigi Carro, Philippe O. A. Navaux, Paolo Rech",
                    "abstract": "In this paper, we evaluate the reliability of the You Only Look Once (YOLO) object detection framework. We have exposed to controlled neutron beams GPUs designed with three different architectures (Kepler, Maxwell, and Pascal) running Darknet, a Convolutional Neural Network for automotive applications, detecting objects in both Caltech and Visual Object Classes data sets. By analyzing the neural network corrupted output, we can distinguish between tolerable errors and critical errors, i.e., errors that could impact on real-time system execution.Additionally, we propose an Algorithm-Based Fault-Tolerance (ABFT) strategy to apply to the matrix multiplication kernels of neural networks able to detect and correct 50% to 60% of radiation induced corruptions. We experimentally validate our hardening solution and compare its efficiency and efficacy with the available ECC.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们评估的可靠性，你只看一次(YOLO)对象检测框架。我们已经接触了采用三种不同架构(开普勒、麦克斯韦和帕斯卡)设计的受控中子束GPU，这些GPU运行Darknet，这是一种用于汽车应用的卷积神经网络，可检测加州理工学院和视觉对象类数据集中的对象。通过分析神经网络被破坏的输出，我们可以区分可容忍的错误和关键错误，即可能影响实时系统执行的错误。此外，我们提出了一种基于算法的容错(ABFT)策略，以应用于能够检测和纠正50%到60%的辐射引起的损坏的神经网络的矩阵乘法核。我们通过实验验证了我们的加固解决方案，并将其效率和功效与可用的ECC进行了比较。",
                    "title_zh": "三种GPU架构中基于神经网络的对象检测软错误的评估和减轻"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.48",
                    "title": "DRAM Scaling Error Evaluation Model Using Various Retention Time",
                    "authors": "Seong-Lyong Gong, Jungrae Kim, Mattan Erez",
                    "abstract": "As process technology scales down, DRAMs become less reliable since current DRAM protection schemes cannot address scaling-induced errors effectively. In prior related work, faulty DRAM cells or inherent faults have been considered as permanent and easily detectable during manufacturing process. However, due to scaling, more errors occur intermittently during system operations and exacerbate DRAM reliability. To consider the increasing intermittent errors due to scaling, we propose a new error model using DRAM’s Variable Retention Time (VRT). Our model effectively describes latent inherent faults, which lead to intermittent errors, in addition to the permanent inherent faults. We also introduce an efficient methodology to accelerate simulations even with a myriad of inherent faults. We present parameter sweep results to provide better understanding or insight regarding DRAM scaling errors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着工艺技术按比例缩小，DRAM变得不太可靠，因为当前的DRAM保护方案不能有效地解决按比例缩小引起的错误。在先前的相关工作中，有缺陷的DRAM单元或固有缺陷被认为是永久性的，并且在制造过程中容易检测到。然而，由于缩放，更多的错误在系统操作期间间歇地发生，并且恶化了DRAM的可靠性。为了考虑由于缩放而增加的间歇性错误，我们提出了一个新的使用DRAM的可变保持时间(VRT)的错误模型。除了永久性固有故障之外，我们的模型有效地描述了导致间歇性错误的潜在固有故障。我们还介绍了一种有效的方法来加速模拟，即使有无数的固有故障。我们提供参数扫描结果，以便更好地理解或洞察DRAM缩放误差。",
                    "title_zh": "使用不同保持时间的DRAM缩放误差评估模型"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W.2017.50",
                    "title": "Deep Healing: Ease the BTI and EM Wearout Crisis by Activating Recovery",
                    "authors": "Xinfei Guo, Mircea R. Stan",
                    "abstract": "The down-scaling of CMOS technologies into the nano-regime and the advent of the Internet of Things (IoT) era jointly conspire to elevate wearout effects to the status of major reliability threats. Bias temperature instability (BTI) and Electromigration (EM) are two of the dominant wearout mechanisms which affect transistors and on-chip interconnect, respectively. Both phenomena have been shown to exhibit partial recovery, but this property has been treated only as a side effect until now since passive recovery is slow and ineffective due to the permanent portion of wearout. In this paper, we propose and demonstrate that recovery for both wearout mechanisms can be further activated and accelerated, such that the permanent portion of wearout can be fully eliminated by using in-time scheduled recovery. We show that the explored recovery properties can be utilized effectively for reducing the wearout-induced design margins, this approach introducing a new design dimension by reducing the effects of wearout in a fundamental way. A novel circuit scheme and potential implementations at the system level that can assist both BTI and EM recovery are also detailed in the paper.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "CMOS技术向纳米领域的缩小和物联网(IoT)时代的到来共同将损耗效应提升到主要可靠性威胁的地位。偏置温度不稳定性(BTI)和电迁移(EM)是分别影响晶体管和片上互连的两种主要损耗机制。这两种现象都显示出部分恢复，但是这种特性直到现在都只被视为副作用，因为由于磨损的永久部分，被动恢复是缓慢和无效的。在本文中，我们提出并证明了两种磨损机制的恢复都可以被进一步激活和加速，这样，通过使用及时的计划恢复，可以完全消除磨损的永久部分。我们表明，探索的恢复特性可以有效地用于减少磨损引起的设计余量，这种方法通过从根本上减少磨损的影响，引入了一种新的设计尺寸。本文还详细介绍了一种新颖的电路方案和系统级的潜在实现方案，这种方案可以帮助实现BTI和电磁恢复。",
                    "title_zh": "深度治疗:通过激活恢复来缓解BTI和新兴市场的疲惫危机"
                }
            ]
        }
    ],
    "2023": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2023s.html",
            "conf_title": "53rd DSN 2023: Porto, Portugal - Supplemental Volume",
            "conf_url": "https://doi.org/10.1109/DSN-S58398.2023",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00014",
                    "title": "Byzantine State Machine Replication in the Age of Blockchains: Fundamentals and Recent Results (Tutorial)",
                    "authors": "Alysson Neves Bessani",
                    "abstract": "The success of Bitcoin and other blockchains led to a renewed interest in Byzantine fault-tolerant (BFT) state machine replication (SMR) protocols, with many innovations coming both from industry and academia.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "区块链时代的拜占庭国家机器复制:基础和最新结果(教程)",
                    "abstract_zh": "比特币和其他区块链的成功引发了人们对拜占庭容错(BFT)状态机复制(SMR)协议的新兴趣，许多创新来自工业界和学术界。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00015",
                    "title": "Quantum Computing Reliability: Problems, Tools, and Potential Solutions",
                    "authors": "Edoardo Giusto, Emanuele Dri, Bartolomeo Montrucchio, Betis Baheri, Qiang Guan, Devesh Tiwari, Paolo Rech",
                    "abstract": "Quantum computing is a new computational paradigm, expected to revolutionize the computing field in the next few years. Qubits, the atomic units of a quantum circuit, exploit the quantum physics properties to increase the parallelism and speed of computation. Unfortunately, qubits are both intrinsically noisy and highly susceptible to external sources of faults, such as ionizing radiation. The latest discoveries highlight a much higher radiation sensitivity of qubits than traditional transistors and identify a much more complex fault model than bit-flip. The observed error rate is so high that researchers are questioning the large-scale adoption of quantum computers. The reliability and dependability community is asked to act to find innovative solutions to improve the reliability of quantum applications. This tutorial aims at providing the DSN community with the tools to do so and to train the attendees on quantum fault injection.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "量子计算的可靠性:问题、工具和潜在的解决方案",
                    "abstract_zh": "量子计算是一种新的计算范式，预计将在未来几年内彻底改变计算领域。量子位是量子电路的原子单位，它利用量子物理特性来提高计算的并行性和速度。不幸的是，量子位元本身就有杂讯，而且很容易受到外部错误来源的影响，例如游离辐射。最新发现强调了量子位比传统晶体管更高的辐射灵敏度，并识别了比比特翻转更复杂的故障模型。观察到的错误率如此之高，以至于研究人员开始质疑量子计算机的大规模采用。可靠性和可信性团体被要求寻找创新的解决方案来提高量子应用的可靠性。本教程旨在为DSN社区提供这样做的工具，并对参与者进行量子故障注入培训。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00016",
                    "title": "Tutorial: Using the seL4 Microkernel",
                    "authors": "Gernot Heiser, Ivan Velickovic",
                    "abstract": "The seL4 microkernel [3] is the first general-purpose operating system (OS) kernel with a formal proof of implementation correctness. By now, its verification covers functional correctness to the binary (taking the compiler out of the trust chain), proofs of security enforcement and worst-case execution-time bounds, and span three architectures (32-bit Arm and 64-bit RISC-V and x86) [1]. All this while featuring unbeaten performance. seL4 is now being deployed in safety- and security-critical systems around the world, and is backed by the non-profit seL4 Foundation [2].",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "教程:使用seL4微内核",
                    "abstract_zh": "seL4微内核[3]是第一个具有实现正确性正式证明的通用操作系统(OS)内核。到目前为止，它的验证涵盖了二进制文件的功能正确性(将编译器从信任链中取出)、安全实施的证明和最坏情况下的执行时间界限，并跨越三种架构(32位Arm和64位RISC-V和x86) [1]。所有这些都体现了无与伦比的性能。seL4现在被部署在世界各地的安全和安全关键系统中，并得到非营利seL4基金会的支持[2]。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00017",
                    "title": "Awesome Trusted Execution Environment",
                    "authors": "Luigi Coppolino, Giovanni Mazzeo, Luigi Romano",
                    "abstract": "While protection of data at-rest and data in-transit can be achieved using standard technologies, the protection of data in-use is still, to a large extent, an open issue. Multiple techniques enable the protection of data processing in untrusted environments, but the one which is gaining the largest consensus is unarguably Trusted Execution Environments. In this tutorial, we focus on a specific TEE technology offering, namely Intel SGX. We discuss key features of Intel SGX – including: secure enclaves, remote attestation, and sealed storage – and present different methods and tools that can be used to make data computation secure, at an acceptable cost in terms of performance penalty.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "令人惊叹的可信执行环境",
                    "abstract_zh": "虽然使用标准技术可以保护静态数据和传输中的数据，但保护使用中的数据在很大程度上仍然是一个未解决的问题。多种技术能够在不可信的环境中保护数据处理，但是获得最大共识的一种技术是无可争议的可信执行环境。在本教程中，我们将重点介绍一种特定的TEE技术产品，即英特尔SGX。我们讨论了SGX的主要特性，包括:安全飞地、远程认证和密封存储，并展示了可用于确保数据计算安全的不同方法和工具，同时在性能损失方面的成本也是可接受的。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00018",
                    "title": "HIRN: A Hierarchical Intent Refinement Approach for Dependable Network Slicing with Multi-path Resource Allocation",
                    "authors": "Zhixian Chu, Lingqi Guo, Jingyu Wang, Qi Qi, Zirui Zhuang, Haifeng Sun, Cheng Zhou",
                    "abstract": "The critical task for the sixth-generation wireless communication network is to provide on-demand services in all scenarios. However, the complexity and diversity of network scenarios have widened the underlying strategy differences of abstract intentions under different network states, making it challenging to simultaneously ensure the level of intelligence and automation in network autonomy. To tackle this challenge, we propose a hierarchical intent refinement framework that decomposes natural language user intent through multi-level, ultimately generating fine-grained network slicing templates and designing a multi-path resource allocation algorithm based on mixed integer linear programming to adapt to the underlying template. The algorithm fully utilizes network resources according to user intent and network application scenario characteristics, maximizing the global network revenue. Experiments demonstrate that in resource-scarce scenarios, our approach improves network revenue by over 40% compared to typical single-path approaches and generates policy with an average speed of under 500 ms in medium-sized network scenarios, providing dependable support for on-demand services.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "HIRN:面向多路径资源分配的可信网络切片的分层意图细化方法",
                    "abstract_zh": "第六代无线通信网络的关键任务是在所有场景中提供按需服务。然而，网络场景的复杂性和多样性扩大了不同网络状态下抽象意图的底层策略差异，使得同时确保网络自治的智能和自动化水平具有挑战性。为了应对这一挑战，我们提出了一种分层意图细化框架，通过多级分解自然语言用户意图，最终生成细粒度的网络切片模板，并设计了一种基于混合整数线性规划的多路径资源分配算法来适应底层模板。该算法根据用户意图和网络应用场景特征，充分利用网络资源，最大化全局网络收益。实验表明，在资源稀缺的场景下，与典型的单路径方法相比，我们的方法将网络收入提高了40%以上，并且在中等规模的网络场景下生成策略的平均速度低于500 ms，为按需服务提供了可靠的支持。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00019",
                    "title": "Data Shower in Electronics Manufacturing: Measuring Wi-Fi 4, Wi-Fi 6, and 5G SA behavior in production assembly lines",
                    "authors": "Gabriel Fré, Bilghean Erman, Catello Di Martino",
                    "abstract": "Reliable, low-latency and high-performance 5G access is one of the key pillars sustaining the vision of industry 4.0 and of the reconfigurable factory of the future. This work contributes to the body of empirical knowledge on how a live 5G networks perform in a production factory environment. The analysis focuses on implementing a ”data shower” use case in a production Electronics assembly line which consists of in Over The Air (OTA) download of the firmware for the boards being assembled in the assembly line. Results include a comparison between Wi-Fi 4, Wi-Fi 6 and 5G SA in terms of capability of the network to serve concurrent OTA firmware connections, as well as in terms network resiliency expressed as the probability of complying with the latency requirements of the implemented use case while serving a variable number of OTA firmware download processes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "电子制造中的数据淋浴:测量生产装配线中的Wi-Fi 4、Wi-Fi 6和5G SA行为",
                    "abstract_zh": "可靠、低延迟和高性能的5G接入是支撑工业4.0和未来可重构工厂愿景的关键支柱之一。这项工作有助于丰富关于5G网络如何在生产工厂环境中运行的经验知识。该分析侧重于在电子产品装配线上实施“数据淋浴”用例，包括为装配线上装配的电路板下载固件。结果包括Wi-Fi 4、Wi-Fi 6和5G SA在网络服务并发OTA固件连接的能力方面的比较，以及在网络弹性方面的比较，网络弹性表示为在服务可变数量的OTA固件下载过程时符合所实施用例的延迟要求的概率。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00020",
                    "title": "Hard Disk Drive Failure Analysis and Prediction: An Industry View",
                    "authors": "Zach Miller, Olusiji Medaiyese, Madhavan Ravi, Alex Beatty, Fred Lin",
                    "abstract": "Storage media devices are fundamental to Meta’s hardware infrastructure, which supports a diverse family of applications such as Facebook, Instagram, and WhatsApp. Understanding the factors that impact the reliability of storage devices is important for setting application expectations on specifications such as throughput, latency, and read/write success rate. Improving hardware reliability helps us meet those expectations.In this paper, we examine the impact that age and workload have on the annualized failure rate (AFR) of Hard Disk Drives (HDDs), one of the most used types of storage devices for Meta’s applications. We analyze the correlation based on data collected from our production hardware fleet. In our datacenter environment, we observe that HDD AFR increases as either age or lifetime cumulative workload increases. We discuss the difference between the AFR curves and the projections that manufacturers make using statistical modeling. Additionally, we use a decision tree-based predictive machine learning (ML) model, XGBoost, for analyzing the correlation between the SMART (Self-Monitoring, Analysis, and Reporting Technology) metrics and the health of HDDs. Through this study, we observe that age and workload-related SMART parameters are most correlated to the health of a drive based on the trained ML model. More so, we identify that the difference of SMART metrics over a 30-day time window could improve the prediction performance for HDD failures.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "硬盘驱动器故障分析和预测:行业观点",
                    "abstract_zh": "存储媒体设备是Meta的硬件基础设施的基础，它支持脸书、Instagram和WhatsApp等多样化的应用程序系列。了解影响存储设备可靠性的因素对于设置应用程序对吞吐量、延迟和读/写成功率等规格的预期非常重要。提高硬件可靠性有助于我们满足这些期望。在本文中，我们研究了年龄和工作负载对硬盘驱动器(HDD)年故障率(AFR)的影响，硬盘驱动器是Meta应用程序中最常用的存储设备类型之一。我们根据从我们的生产硬件设备中收集的数据来分析相关性。在我们的数据中心环境中，我们观察到硬盘AFR随着年龄或生命周期累积工作负载的增加而增加。我们讨论了AFR曲线和制造商使用统计模型做出的预测之间的差异。此外，我们使用基于决策树的预测机器学习(ML)模型XGBoost来分析SMART(自我监控、分析和报告技术)指标与硬盘运行状况之间的相关性。通过这项研究，我们观察到年龄和工作负荷相关的SMART参数与基于训练的ML模型的驱动器的健康最相关。此外，我们发现30天时间窗口内SMART指标的差异可以提高HDD故障的预测性能。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00021",
                    "title": "ACE: An Analog Cell Emulator for Dependability Study of NAND Flash Memory",
                    "authors": "Jeoungwon Lee, Heekwon Park, Gunhee Choi, Bryan S. Kim, Seehwan Yoo, Jaedong Lee, Jongmoo Choi",
                    "abstract": "Reliability is one of the primary concerns in modern SSD designs. Despite the benefits of high performance, low power consumption, and increased density, the vendors struggle with the reliability of user data due to various sources of analog noise. There were consorted efforts and studies to improve the reliability issues in SSDs, but we still need experimenting tools that present analog states of errors. To address this issue, we propose a novel NAND flash memory emulator, called ACE (Analog Cell Emulator), that uses threshold voltages for dependability studies. The proposed emulator maintains data as analog values through threshold voltage modeling, enabling emulation of endurance, retention, and disturbance errors of flash memory. To reduce the emulation overhead, metadata in a cell, page, and block are managed separately, and emulation is performed while reading rather than periodic error emulation. We evaluate the accuracy of ACE by comparing its signal with that of actual devices, with the results indicating that the signal differences are up to 4.3%. Additionally, we analyze two reliability enhancement techniques, ECC (Error Correction Code) and read-retry, using ACE with adjusted reference voltages. This analysis, which could not be feasible with existing emulators, demonstrates the advantages of the proposed analog emulator.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "ACE:一种用于NAND闪存可靠性研究的模拟单元仿真器",
                    "abstract_zh": "可靠性是现代SSD设计的主要关注点之一。尽管具有高性能、低功耗和更高密度的优势，但由于各种模拟噪声源，供应商仍难以保证用户数据的可靠性。有很多努力和研究来改善固态硬盘的可靠性问题，但我们仍然需要实验工具来呈现模拟状态的错误。为了解决这个问题，我们提出了一种新的NAND闪存仿真器，称为ACE(模拟单元仿真器)，它使用阈值电压进行可靠性研究。所提出的仿真器通过阈值电压建模将数据保持为模拟值，从而能够仿真闪存的耐久性、保持力和干扰误差。为了减少仿真开销，单元、页面和块中的元数据被分开管理，并且在读取时执行仿真，而不是周期性错误仿真。我们通过将ACE的信号与实际设备的信号进行比较来评估ACE的准确性，结果表明信号差异最大为4.3%。此外，我们分析了两种可靠性增强技术，ECC(纠错码)和读重试，使用调整参考电压的ACE。这种分析用现有的仿真器是不可行的，它展示了所提出的模拟仿真器的优点。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00022",
                    "title": "EXPERT: EXPloiting DRAM ERror Types to Improve the Effective Forecasting Coverage in the Field",
                    "authors": "Xiangjun Peng, Zheng Huang, Alex Cantrell, Bihua Shu, Ke Ke Xie, Yi Li, Yu Li, Li Jiang, Qiang Xu, Ming-Chang Yang",
                    "abstract": "DRAM failures, which are mostly caused by DRAM uncorrectable errors (UCEs), are one of the most critical factors for reliable services in computing systems. Prior work demonstrates the potential to utilize machine learning techniques for forecasting DRAM UCEs. However, they do not have the knowledge that different DRAM UCEs can be classified into different types. To this end, we obtain the first field dataset from a large datacenter of Alibaba Cloud, with the labels of different UCE types. Then, we propose EXPERT, a design to exploit such information to improve the effective forecasting coverage of DRAM UCEs. Finally, we evaluate the effectiveness of our approach against two state-of-the-art forecaster designs in the field, and the results show that EXPERT achieves up to 18.43% improvements on the effective coverage in terms of F1-Score.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "专家:利用DRAM错误类型提高该领域的有效预测覆盖率",
                    "abstract_zh": "DRAM故障大多是由DRAM不可纠正错误(uce)引起的，是计算系统中可靠服务的最关键因素之一。先前的工作展示了利用机器学习技术预测灾难的潜力。然而，他们不知道不同的DRAM可以分为不同的类型。为此，我们从阿里云的一个大型数据中心获得了第一个字段数据集，带有不同UCE类型的标签。然后，我们提出了专家设计，利用这些信息来提高DRAM的有效预测覆盖率。最后，我们针对该领域中的两个最先进的预测器设计评估了我们的方法的有效性，结果表明EXPERT在F1-Score的有效覆盖上实现了高达18.43%的改进。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00023",
                    "title": "An Integrated Runtime Verification and Simulation Testbed for UAM Hazard Assessment",
                    "authors": "Alexander Will, Aidan G. Collins, Robert Grizzard, Smitha Gautham, Patrick Martin, Evan Dill, Carl R. Elks",
                    "abstract": "Urban Air Mobility (UAM) is an emerging transport solution for passengers or cargo at lower altitudes within urban and suburban areas using electric Vertical Take-off and Landing (eVTOL) air vehicles. The complexity of UAM technology strains design-time safety-assurance methods, which is driving the use of dynamic monitoring methods such as runtime verification to ensure safety of intended functionality (SOTIF). Although cyber-physical system (CPS) testing and design-assurance literature exists [1], there is little focus on UAM testbed concepts that evaluate runtime safety assurance. Such testbeds would help ensure safety coverage across a range of failure scenarios. In this paper, we present a new testbed architecture that systematically integrates formal runtime verification methods and tools into an Unmanned Aerial Vehicle (UAV) flight simulator. The value of this testbed is to help evaluate and transition in-time hazard detection and mitigation methods (in realistic operational contexts) to higher levels of technology maturity. To the best of our knowledge this is the first testbed that integrates formal runtime verification tools into a eVTOL simulation testbed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "UAM危险评估的综合运行时验证和模拟试验台",
                    "abstract_zh": "城市空中交通(UAM)是一种新兴的运输解决方案，使用电动垂直起降(电动垂直起降)飞行器在城市和郊区的较低高度运送乘客或货物。UAM技术的复杂性限制了设计时安全保证方法，这推动了动态监控方法的使用，如运行时验证以确保预期功能的安全性(SOTIF)。尽管存在信息物理系统(CPS)测试和设计保证文献[1]，但很少关注评估运行时安全保证的UAM测试床概念。这种试验台将有助于确保安全覆盖一系列故障场景。在本文中，我们提出了一种新的测试床架构，该架构将正式的运行时验证方法和工具系统地集成到无人机飞行模拟器中。该试验台的价值在于帮助评估及时的危险检测和缓解方法(在实际操作环境中)并将其转化为更高水平的技术成熟度。据我们所知，这是第一个将正式的运行时验证工具集成到电动垂直起降模拟测试床中的测试床。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00024",
                    "title": "Towards Automated Generation of Smart Grid Cyber Range for Cybersecurity Experiments and Training",
                    "authors": "Daisuke Mashima, Muhammad M. Roomi, Bennet Ng, Zbigniew Kalberczyk, S. M. Suhail Hussain, Ee-Chien Chang",
                    "abstract": "Assurance of cybersecurity is crucial to ensure dependability and resilience of smart power grid systems. In order to evaluate the impact of potential cyber attacks, to assess deployability and effectiveness of cybersecurity measures, and to enable hands-on exercise and training of personals, an interactive, virtual environment that emulates the behaviour of a smart grid system, namely smart grid cyber range, has been demanded by industry players as well as academia. A smart grid cyber range is typically implemented as a combination of cyber system emulation, which allows interactivity, and physical system (i.e., power grid) simulation that are tightly coupled for consistent cyber and physical behaviours. However, its design and implementation require intensive expertise and efforts in cyber and physical aspects of smart power systems as well as software/system engineering. While many industry players, including power grid operators, device vendors, research and education sectors are interested, availability of the smart grid cyber range is limited to a small number of research labs. To address this challenge, we have developed a framework for modelling a smart grid cyber range using an XML-based language, called SG-ML, and for “compiling” the model into an operational cyber range with minimal engineering efforts. The modelling language includes standardized schema from IEC 61850 and IEC 61131, which allows industry players to utilize their existing configurations. The SG-ML framework aims at making a smart grid cyber range available to broader user bases to facilitate cybersecurity R&D and hands-on exercises.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "面向网络安全实验和培训的智能电网网络范围的自动生成",
                    "abstract_zh": "网络安全保障对于确保智能电网系统的可靠性和弹性至关重要。为了评估潜在网络攻击的影响，评估网络安全措施的可部署性和有效性，以及实现人员的实际操作练习和培训，行业参与者和学术界一直需要一种模拟智能电网系统行为的交互式虚拟环境，即智能电网网络范围。智能电网cyber range通常由cyber system emulation(支持交互性)和physical system(即电网)simulation(紧密耦合以实现一致的网络和物理行为)组成。然而，其设计和实施需要智能电力系统的网络和物理方面以及软件/系统工程方面的大量专业知识和努力。虽然包括电网运营商、设备供应商、研究和教育部门在内的许多行业参与者对此感兴趣，但智能电网网络范围的可用性仅限于少数研究实验室。为了应对这一挑战，我们开发了一个框架，使用基于XML的语言SG-ML对智能电网网络范围进行建模，并通过最少的工程工作将模型“编译”成可操作的网络范围。建模语言包括来自IEC 61850和IEC 61131的标准化模式，允许行业参与者利用他们现有的配置。SG-ML框架旨在为更广泛的用户群提供智能电网网络范围，以促进网络安全R&D和实践练习。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00025",
                    "title": "Large-Scale Application of Fault Injection into PyTorch Models -an Extension to PyTorchFI for Validation Efficiency",
                    "authors": "Ralf Gräfe, Qutub Syed Sha, Florian Geissler, Michael Paulitsch",
                    "abstract": "Transient or permanent faults in hardware can render the output of Neural Networks (NN) incorrect without user-specific traces of the error, i.e. silent data errors (SDE). On the other hand, modern NNs also possess an inherent redundancy that can tolerate specific faults. To establish a safety case, it is necessary to distinguish and quantify both types of corruptions. To study the effects of hardware (HW) faults on software (SW) in general and NN models in particular, several fault injection (FI) methods have been established in recent years. Current FI methods focus on the methodology of injecting faults but often fall short of accounting for large-scale FI tests, where many fault locations based on a particular fault model need to be analyzed in a short time. Results need to be concise, repeatable, and comparable.To address these requirements and enable fault injection as the default component in a machine learning development cycle, we introduce a novel fault injection framework called PyTorchALFI (Application Level Fault Injection for PyTorch) based on PyTorchFI. PyTorchALFI provides an efficient way to define randomly generated and reusable sets of faults to inject into PyTorch models, defines complex test scenarios, enhances data sets, and generates test KPIs while tightly coupling fault-free, faulty, and modified NN. In this paper, we provide details about the definition of test scenarios, software architecture, and several examples of how to use the new framework to apply iterative changes in fault location and number, compare different model modifications, and analyze test results.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "PyTorch模型中断层注入的大规模应用PyTorchFI验证效率的扩展",
                    "abstract_zh": "硬件中的瞬时或永久故障会导致神经网络(NN)的输出不正确，而没有用户特定的错误痕迹，即无声数据错误(SDE)。另一方面，现代神经网络还具有固有的冗余，可以容忍特定的故障。为了建立安全案例，有必要区分和量化这两种类型的损坏。为了研究硬件故障对软件特别是神经网络模型的影响，近年来建立了几种故障注入方法。当前的FI方法集中在注入故障的方法上，但是经常不能考虑大规模FI测试，其中需要在短时间内分析基于特定故障模型的许多故障位置。结果需要简洁、可重复和可比较。为了解决这些需求，并使故障注入成为机器学习开发周期中的默认组件，我们引入了一种基于PyTorchFI的新型故障注入框架PyTorchALFI(PyTorch的应用级故障注入)。PyTorchALFI提供了一种有效的方法来定义随机生成的和可重用的故障集，以注入到PyTorch模型中，定义复杂的测试场景，增强数据集，并生成测试KPI，同时紧密耦合无故障、有故障和修改的NN。在本文中，我们详细介绍了测试场景的定义、软件架构，以及如何使用新框架在故障位置和数量方面应用迭代变化、比较不同的模型修改以及分析测试结果的几个示例。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00026",
                    "title": "Characterization and Exploration of Latch Checkers for Efficient RAS Protection",
                    "authors": "Karthik Swaminathan, Ramon Bertran, Doug Balazich, Alper Buyuktosunoglu, Arvind Haran, Sean M. Carey, Karl Anderson, Hans M. Jacobson, Matthias Pflanz, Pradip Bose",
                    "abstract": "Reliability has been, and continues to be a key consideration in the design of the IBM Z mainframe processors, and this has resulted in industry-leading performance with little-to-no downtime. In this paper, we analyze the various hardware reliability mechanisms that make the processor resilient to transient errors, and the checker architecture that enables their detection and correction. We characterize the error checking logic in the processor based on a detailed analysis of the actual design. Based on hardware measurements on a real Z processor, we then determine the error checkers that are critical from a timing standpoint. We propose algorithms that optimize checker selection without affecting either the RAS coverage or the detection of timing errors. Finally, we examine further potential runtime optimizations of checkers based on the logic utilization in representative benchmarks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "用于有效RAS保护的锁存检查器的表征和探索",
                    "abstract_zh": "可靠性已经并将继续是IBM Z大型机处理器设计中的一个关键考虑因素，这导致了业界领先的性能和很少甚至没有停机时间。在本文中，我们分析了使处理器能够应对瞬时错误的各种硬件可靠性机制，以及能够检测和纠正这些错误的checker架构。我们基于对实际设计的详细分析来描述处理器中的错误检查逻辑。基于实际Z处理器上的硬件测量，我们然后确定从时序角度来看至关重要的错误检查器。我们提出了优化检验器选择的算法，而不影响RAS覆盖或定时误差的检测。最后，我们基于典型基准中的逻辑利用率，进一步研究了checkers的潜在运行时优化。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00027",
                    "title": "IEEE 802.1AS Multi-Domain Aggregation for Virtualized Distributed Real-Time Systems",
                    "authors": "Jan Ruh, Wilfried Steiner, Gerhard Fohler",
                    "abstract": "Cyber-physical systems like cars, mobile agriculture machines, or duty vehicles are increasingly connected to public networks. Thus, in addition to their inherent fault-tolerance requirements, there is a pressing need to design these systems cost-effectively to withstand cyber-attacks, i.e., to ensure cyber resiliency. This paper implements a cyber-resilient clock synchronization architecture that features fault-tolerant dependent clocks and a fault-tolerant average (FTA) using standardized protocols (e.g., IEEE 802.1AS) and open-source software (e.g., ACRN hypervisor). Our experiments show how OS diversification can improve the cyber resiliency of the FTA. Furthermore, our 24 h fault injection experiment demonstrates the robustness of the architecture against fail-silent grandmaster clocks and clock synchronization virtual machines. Therefore our architecture can serve as proof of concept to extend commercial offerings.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "IEEE 802.1AS虚拟化分布式实时系统的多域聚合",
                    "abstract_zh": "汽车、移动农业机械或执勤车辆等网络物理系统越来越多地连接到公共网络。因此，除了其固有的容错要求之外，还迫切需要设计这些系统，以经济高效地抵御网络攻击，即确保网络弹性。本文采用标准化协议(如IEEE 802.1AS)和开源软件(如ACRN系统管理程序)，实现了一种具有网络弹性的时钟同步架构，该架构具有容错相关时钟和容错平均值(FTA)。我们的实验展示了操作系统多样化如何提高FTA的网络弹性。此外，我们的24 h故障注入实验证明了该架构对故障静默总控时钟和时钟同步虚拟机的鲁棒性。因此，我们的架构可以作为扩展商业产品的概念验证。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00028",
                    "title": "ECHAIN: Securing Electronic Device Provenance through Privacy-Preserving Consortium Blockchains",
                    "authors": "Abdullah Al-Mamun, Dongfang Zhao",
                    "abstract": "A conventional electronic device provenance is vulnerable to several attacks due to the limited traceability of transactions and a lack of unclonable device identities. Although electronic chip identification (ECID) has been suggested to improve security, discussion on ECID data management and users’ privacy preservation in such a decentralized device provenance management system is insufficient. In this work, we propose a framework named ECHAIN. The novelties include: (1) it uses uniquely hashed electronic chip identification (ECIDs) to maintain the security of sensitive ECID data; (2) it allows most transactions processed in parallel with a part of blockchain nodes participating to maximize the system efficiency; and (3) it employs ECID-based PKI keyless encryption to protect users’ privacy from the blockchain system. A prototype system is implemented and deployed on a 58-node consortium blockchain. Compared with the conventional solutions, experiments show that ECHAIN incurs less than 10% overhead when registering electronic devices while delivering up to $5\\times$ higher transaction throughput.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "ECHAIN:通过区块链隐私保护联盟保护电子设备来源",
                    "abstract_zh": "由于交易的有限可追溯性和缺乏不可克隆的设备身份，传统的电子设备来源容易受到几种攻击。虽然电子芯片识别(ECID)已经被建议用来提高安全性，但是关于在这样一个分散的设备起源管理系统中的ECID数据管理和用户隐私保护的讨论是不充分的。在这项工作中，我们提出了一个框架名为ECHAIN。创新之处包括:(1)它使用独特的哈希电子芯片识别(ECIDs)来维护敏感的ECID数据的安全性；(2)允许大部分事务并行处理，部分区块链节点参与，最大化系统效率；以及(3)它采用基于ECID的PKI无钥匙加密来保护用户的隐私免受区块链系统的攻击。原型系统是实施和部署在一个58个节点的财团区块链。与传统解决方案相比，实验表明，ECHAIN在注册电子设备时产生的开销不到10%,而交易吞吐量却提高了5倍。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00029",
                    "title": "Partitioned Containers: Towards Safe Clouds for Industrial Applications",
                    "authors": "Marco Barletta, Marcello Cinque, Luigi De Simone, Raffaele Della Corte, Giorgio Farina, Daniele Ottaviano",
                    "abstract": "In this paper, we propose the concept of Partitioned Containers, born from the convergence between containers and partitioning hypervisors. While the former is a key virtualization technology for cloud platforms, the latter is attracting interest in industrial settings, since they can provide strong isolation between applications, as mandated by safety standards. Our idea is to combine the advantages of both, fostering the adoption of cloud technologies in industrial settings toward a “container-everywhere” vision. The paper proposes an architecture and the challenges for the realization of the concept.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "分区容器:走向工业应用的安全云",
                    "abstract_zh": "在本文中，我们提出了分区容器的概念，它产生于容器和分区管理程序之间的融合。虽然前者是云平台的关键虚拟化技术，但后者正在吸引工业环境的兴趣，因为它们可以按照安全标准的要求在应用程序之间提供强大的隔离。我们的想法是结合两者的优势，促进云技术在工业环境中的采用，实现“无处不在的容器”愿景。本文提出了一个体系结构和实现这一概念的挑战。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00030",
                    "title": "How to Resuscitate a Sick VM in the Cloud",
                    "authors": "Xuhua Ding",
                    "abstract": "A guest virtual machine in a cloud platform may fall “sick” when its kernel encounters a fatal low-level bug or is subverted by an adversary. The VM owner is hence likely to lose her control over it due to a kernel hang or being denied of remote accesses. While the VM can be rebooted with the assistance from the cloud server, the owner not only faces service disruption but also is left with no opportunity to make an in-depth diagnosis and forensics on the spot, not to mention a live rectification. Currently, the cloud service provider has neither incentive nor the technology to assist owners to resuscitate their falling VMs. In this paper, we propose a new cloud service termed VMCare-As-A-Service (VaaS) with the vision that the owner of a sick VM applies her tools running on a special VM to repair it. VaaS demands innovative cloud technologies for the unique infrastructure support as well as new software security techniques for attacks neutralization and runtime rectification upon a running and corrupted kernel. We examine the ensuing research challenges and present several preliminary approaches to kindle the interests from the community.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "如何在云中复苏生病的虚拟机",
                    "abstract_zh": "当云平台中的客户虚拟机的内核遇到致命的低级错误或被对手破坏时，它可能会“生病”。因此，由于内核挂起或远程访问被拒绝，VM所有者可能会失去对它的控制。虽然虚拟机可以在云服务器的帮助下重新启动，但所有者不仅面临服务中断，而且没有机会在现场进行深入的诊断和取证，更不用说实时整改了。目前，云服务提供商既没有动力也没有技术来帮助所有者挽救他们正在下降的虚拟机。在本文中，我们提出了一种新的云服务，称为VMCare-As-A-Service (VaaS ),其愿景是生病虚拟机的所有者应用其在特殊虚拟机上运行的工具来修复它。VaaS需要创新的云技术来支持独特的基础架构，以及新的软件安全技术来中和攻击和在运行和损坏的内核上进行运行时纠正。我们研究了随之而来的研究挑战，并提出了几个初步的方法来点燃社区的兴趣。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00031",
                    "title": "Towards Rehosting Embedded Applications as Linux Applications",
                    "authors": "Jayashree Srinivasan, Sai Ritvik Tanksalkar, Paschal C. Amusuo, James C. Davis, Aravind Machiry",
                    "abstract": "Dynamic analysis of embedded firmware is a necessary capability for many security tasks, e.g., vulnerability detection. Rehosting is a technique that enables dynamic analysis by facilitating the execution of firmware in a host environment decoupled from the actual hardware. Current rehosting techniques focus on high-fidelity execution of the entire firmware. Consequently, these techniques try to execute firmware in an emulated environment, with precise models of hardware (i.e., peripheral) interactions. However, these techniques are hard to scale and have various drawbacks.We propose a novel take on rehosting by focusing on the application components and their interactions with the firmware without the need to model hardware dependencies. We achieve this by rehosting the embedded application as a Linux application. In addition to avoiding precise peripheral modeling, our rehosting technique enables the use of existing dynamic analysis techniques on these embedded applications. We provide an overview of our approach and demonstrate its feasibility on three real-world embedded applications. Our testing of these rehosted applications found 2 previously unknown defects in driver components. We discuss challenges in automating our process and present possible future research directions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "将嵌入式应用程序重新托管为Linux应用程序",
                    "abstract_zh": "嵌入式固件的动态分析是许多安全任务(例如漏洞检测)的必要功能。主机再集成是一种通过在与实际硬件分离的主机环境中促进固件的执行来实现动态分析的技术。当前的再集成技术集中于整个固件的高保真执行。因此，这些技术试图在仿真环境中执行固件，具有硬件(即外围设备)交互的精确模型。然而，这些技术很难扩展，并且有各种各样的缺点。我们提出了一种全新的再集成方法，通过关注应用组件及其与固件的交互，而无需对硬件依赖性进行建模。我们通过将嵌入式应用程序作为Linux应用程序进行重新托管来实现这一点。除了避免精确的外围建模之外，我们的再集成技术允许在这些嵌入式应用上使用现有的动态分析技术。我们概述了我们的方法，并在三个真实的嵌入式应用上演示了它的可行性。我们对这些重新托管的应用程序的测试在驱动程序组件中发现了2个以前未知的缺陷。我们讨论了自动化过程中的挑战，并提出了未来可能的研究方向。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00032",
                    "title": "rgpdOS: GDPR Enforcement By The Operating System",
                    "authors": "Alain Tchana, Raphael Colin, Adrien Le Berre, Vincent Berger, Benoît Combemale, Ludovic Pailler",
                    "abstract": "Currently, it is very hard for companies driven by personal data to make their applications GDPR-compliant, especially if those applications were developed before the GDPR was established. We present rgpdOS, a GDPR-aware operating system that aims to bring GDPR-compliance to every application, while requiring minimal changes to application code.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "rgpdOS:由操作系统执行的GDPR",
                    "abstract_zh": "目前，由个人数据驱动的公司很难让他们的应用程序符合GDPR标准，尤其是如果这些应用程序是在GDPR成立之前开发的。我们展示了rgpdOS，这是一个支持GDPR的操作系统，旨在使每个应用程序都符合GDPR标准，同时只需对应用程序代码进行最小的更改。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00033",
                    "title": "Attacks on tomorrow's virtual world",
                    "authors": "Iliès Benhabbour, Yérom-David Bromberg, Marc Dacier, Sven Dietrich, Rodrigo Miragaia Rodrigues, Paulo Esteves Veríssimo",
                    "abstract": "The gaming industry is booming, as is the size of its market, which has seen a growth surge. This increase goes hand in hand with the growing popularity of online games, including massively multiplayer ones, a trend that is continuing and is expected to grow even more in the coming years. These gaming environments lay the foundations of what is likely to be tomorrow’s Metaverse. Whatever systemic flaws or vulnerabilities they have will most likely be carried over, if not addressed properly now. Inspired by a class of attacks that disrupt the game synchronization between players, we propose a thought-provoking reflection, claiming that these issues cannot be addressed by the classical body of knowledge in dependable or secure distributed systems. We offer ideas for research plans to move forward, using the games as a concrete experimentation platform but keeping in mind the broader impact of these issues.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "对未来虚拟世界的攻击",
                    "abstract_zh": "博彩业正在蓬勃发展，其市场规模也在快速增长。这种增长与包括大型多人游戏在内的在线游戏的日益流行密切相关，这一趋势仍在持续，预计在未来几年将会进一步增长。这些游戏环境为未来的元宇宙奠定了基础。如果现在不妥善解决，无论它们有什么系统性缺陷或弱点，都很可能会遗留下来。受一类破坏玩家之间游戏同步的攻击的启发，我们提出了一个发人深省的思考，声称这些问题无法通过可靠或安全的分布式系统中的经典知识体系来解决。我们为推进研究计划提供思路，将奥运会作为一个具体的实验平台，但要牢记这些问题的更广泛影响。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00034",
                    "title": "Skynet: a Cyber-Aware Intrusion Tolerant Overseer",
                    "authors": "Tadeu Freitas, João Soares, Manuel Eduardo Correia, Rolando Martins",
                    "abstract": "The increasing level of sophistication of cyber attacks which are employing cross-cutting strategies that leverage multi-domain attack surfaces, including but not limited to, software defined networking poisoning, biasing of machine learning models to suppress detection, exploiting software (development), and leveraging system design deficiencies.While current defensive solutions exist, they only partially address multi-domain and multi-stage attacks, thus rendering them ineffective to counter the upcoming generation of attacks. More specifically, we argue that a disruption is needed to approach separated knowledge domains, namely Intrusion Tolerant systems, cybersecurity, and machine learning.We argue that current solutions tend to address different concerns/facets of overlapping issues and they tend to make strong assumptions of supporting infrastructure, e.g., assuming that event probes/metrics are not compromised.To address these issues, we present Skynet, a platform that acts as a secure overseer that merges traditional roles of SIEMs with conventional orchestrators while being rooted on the fundamentals introduced by previous generations of intrusion tolerant systems. Our goal is to provide an open-source intrusion tolerant platform that can dynamically adapt to known and unknown security threats in order to reduce potential vulnerability windows.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "天网:网络感知入侵容忍监督",
                    "abstract_zh": "网络攻击日益复杂，采用跨领域策略，利用多领域攻击面，包括但不限于软件定义的网络中毒、偏向机器学习模型以抑制检测、利用软件(开发)和利用系统设计缺陷。虽然存在当前的防御解决方案，但是它们仅部分地解决了多域和多阶段攻击，从而使得它们无法有效对抗即将到来的下一代攻击。更具体地说，我们认为需要一种破坏来接近分离的知识领域，即入侵容忍系统、网络安全和机器学习。我们认为，当前的解决方案倾向于解决重叠问题的不同关注点/方面，并且它们倾向于对支持基础设施做出强有力的假设，例如，假设事件探测/度量没有受到损害。为了解决这些问题，我们提出了Skynet，这是一个充当安全监督者的平台，它将SIEMs的传统角色与传统的编排器相结合，同时植根于前几代入侵容忍系统引入的基础之上。我们的目标是提供一个开源的入侵容忍平台，它可以动态地适应已知和未知的安全威胁，以减少潜在的漏洞窗口。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00035",
                    "title": "Fault Independence in Blockchain",
                    "authors": "Jiangshan Yu",
                    "abstract": "Byzantine Fault-Tolerant (BFT) protocols have been proposed to tolerate malicious behaviors in state machine replications. With classic BFT protocols, the total number of replicas is known and fixed a priori. The resilience of BFT protocols, i.e., the number of tolerated Byzantine replicas (denoted f), is derived from the total number of replicas according to the quorum theory. To guarantee that an attacker cannot control more than f replicas, so to guarantee safety, it is vital to ensure fault independence among all replicas. This in practice is achieved by enforcing diverse configurations of replicas, i.e., each replica has a unique configuration, avoiding f fault compromises more than f replicas. While managing replica diversity in BFT protocols has been studied in permissioned environments with a small number of replicas, no prior work has discussed the fault independence in a permissionless environment (such as public blockchains) where anyone can join and leave the system at any time. This is particularly challenging due to the following two facts. First, with permissionless environment, any one can join as a replica at any time and no global coordinator can be relied on to manage replica diversity. Second, while great progress has been made to scale consensus algorithms to thousands of replicas, the replica diversity cannot provide fault independence at this scale, limiting practical and meaningful resilience. This paper provides the first discussion on the impact of fault independence on permissionless blockchains, provides discussions on replica configuration diversity, quantifies replica diversity by using entropy, and defines optimal fault independence.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "区块链中的故障独立性",
                    "abstract_zh": "拜占庭容错(BFT)协议已经被提出来容忍状态机复制中的恶意行为。对于经典的BFT协议，副本的总数是已知的，并且是先验固定的。BFT协议的弹性，即可容忍的拜占庭副本的数量(表示为f ),是根据法定人数理论从副本的总数中得出的。为了保证攻击者不能控制多于f个副本，从而保证安全性，确保所有副本之间的故障独立性是至关重要的。这在实践中是通过实施副本的不同配置来实现的，即，每个副本具有唯一的配置，避免f个故障损害多于f个副本。虽然已经在具有少量副本的许可环境中研究了管理BFT协议中的副本多样性，但是没有先前的工作讨论在任何人可以在任何时间加入和离开系统的无许可环境(例如公共区块链)中的故障独立性。由于以下两个事实，这尤其具有挑战性。首先，在无许可环境中，任何人都可以在任何时候作为副本加入，并且不能依赖全局协调器来管理副本多样性。第二，虽然在将一致性算法扩展到数千个副本方面已经取得了很大进展，但是副本多样性无法在这种规模上提供故障独立性，从而限制了实际和有意义的弹性。本文首次讨论了故障独立性对无权限区块链的影响，讨论了副本配置多样性，用熵量化了副本多样性，并定义了最佳故障独立性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00036",
                    "title": "How to Learn Collaboratively - Federated Learning to Peer-to-Peer Learning and What's at Stake",
                    "authors": "Atul Sharma, Joshua C. Zhao, Wei Chen, Qiang Qiu, Saurabh Bagchi, Somali Chaterji",
                    "abstract": "Standard ML relies on training using a centrally collected dataset, while collaborative learning techniques such as Federated Learning (FL) enable data to remain decentralized at client locations. In FL, a central server coordinates the training process, reducing computation and communication expenses for clients. However, this centralization can lead to server congestion and heightened risk of malicious activity or data privacy breaches. In contrast, Peer-to-Peer Learning (P2PL) is a fully decentralized system where nodes manage both local training and aggregation tasks. While P2PL promotes privacy by eliminating the need to trust a single node, it also results in increased computation and communication costs, along with potential difficulties in achieving consensus among nodes. To address the limitations of both FL and P2PL, we propose a hybrid approach called Hubs-and-Spokes Learning (HSL). In HSL, hubs function similarly to FL servers, maintaining consensus but exerting less control over spokes. This paper argues that HSL’s design allows for greater availability and privacy than FL, while reducing computation and communication costs compared to P2PL. Additionally, HSL maintains consensus and integrity in the learning process.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "如何协作学习——从联合学习到对等学习以及其中的利害关系",
                    "abstract_zh": "标准ML依赖于使用集中收集的数据集进行训练，而联合学习(FL)等协作学习技术使数据能够在客户端位置保持分散。在佛罗里达州，一个中央服务器协调训练过程，减少客户的计算和通信费用。但是，这种集中化会导致服务器拥塞，并增加恶意活动或数据隐私泄露的风险。相比之下，对等学习(P2PL)是一个完全分散的系统，其中节点管理本地训练和聚集任务。虽然P2PL通过消除信任单个节点的需要来促进隐私，但它也导致计算和通信成本的增加，以及在节点之间达成共识的潜在困难。为了解决FL和P2PL的局限性，我们提出了一种称为中心辐射式学习(HSL)的混合方法。在HSL中，集线器的功能类似于FL服务器，保持一致，但对辐条的控制较少。本文认为，HSL的设计比FL具有更高的可用性和隐私性，同时与P2PL相比降低了计算和通信成本。此外，HSL在学习过程中保持共识和完整性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00037",
                    "title": "Automatic Generation of Distributed Algorithms with Generative AI",
                    "authors": "Diogo Vaz, David R. Matos, Miguel L. Pardal, Miguel Correia",
                    "abstract": "Fault-tolerant distributed algorithms such as Reliable Broadcast, Causal Broadcast, Total Order Broadcast, and Consensus, are at the core of many modern distributed systems. However, the development of distributed algorithms by humans is a laborious and complex process. This work presents a novel approach to generating distributed algorithms using Generative Artificial Intelligence that allows for automating the process of generating such algorithms. The paper also summarizes our initial results on using the approach to generate Reliable Broadcast algorithms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "用生成人工智能自动生成分布式算法",
                    "abstract_zh": "容错分布式算法，如可靠广播、因果广播、全序广播和一致性，是许多现代分布式系统的核心。然而，由人类开发分布式算法是一个费力而复杂的过程。这项工作提出了一种使用生成式人工智能生成分布式算法的新方法，允许自动生成这种算法的过程。本文还总结了我们使用该方法生成可靠广播算法的初步结果。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00038",
                    "title": "Machine Learning on Public Intrusion Datasets: Academic Hype or Concrete Advances in NIDS?",
                    "authors": "Marta Catillo, Antonio Pecchia, Umberto Villano",
                    "abstract": "The number of papers on network intrusion detection based on machine and deep learning is growing at an unprecedented rate. Most of these papers follow a well-consolidated pattern: (i) proposal of an intrusion detection system based on machine (deep) learning, (ii) learning-testing with one (more) public intrusion dataset(s), (iii) achievement of outstanding detection performance. Is the intrusion detection problem solved? Unfortunately, no. This paper shares a deep reflection on the major limitations of public intrusion datasets and related machine learning experiments, which greatly diminish the findings documented by the literature. At the end of the day, in spite of the academic hype and the increasingly-complex machine and deep learning exercises around, the role of public datasets in advancing intrusion detection of real-world networks remains questionable. The way existing intrusion datasets are collected, released and used by the community should be approached with extreme caution. This paper provides concrete hints for the construction of future intrusion detection datasets and more rigorous machine learning experiments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "公共入侵数据集上的机器学习:学术炒作还是NIDS的具体进展？",
                    "abstract_zh": "基于机器和深度学习的网络入侵检测的论文数量正以前所未有的速度增长。这些论文中的大多数都遵循一个很好的整合模式:(I)基于机器(深度)学习的入侵检测系统的建议，(ii)用一个(或多个)公共入侵数据集进行学习测试，(iii)实现出色的检测性能。入侵检测问题解决了吗？不幸的是，没有。这篇论文分享了对公共入侵数据集和相关机器学习实验的主要限制的深刻反思，这些限制极大地削弱了文献记录的发现。归根结底，尽管有学术炒作和日益复杂的机器和深度学习练习，公共数据集在推进现实世界网络的入侵检测方面的作用仍然值得怀疑。社区收集、发布和使用现有入侵数据集的方式应该非常谨慎。本文为未来入侵检测数据集的构建和更严格的机器学习实验提供了具体的提示。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00039",
                    "title": "No Free Wireless Charge: Covert Channels via Wireless Charging on Mobile Devices",
                    "authors": "Wei-Yang Chiu, Weizhi Meng, Brooke Lampe",
                    "abstract": "Manufacturers and users have embraced the shift from wired to wireless technologies—a shift that promises convenience, reduced cabling, and modernization. Manufacturers cut costs by cutting down on wiring; meanwhile, users experience increased accessibility and mobility on their wireless devices. Naturally, wireless media does not come with wires, but it does come with strings attached. In a wireless world, when device A talks to device B, communication is no longer physically constrained to the two of them. Instead, the communication channel is shared by many devices, opening up avenues for eavesdropping and interception.Wireless charging, which has become de facto functionality on many types of smart devices, is not immune to this phenomenon. Qi, the leading standard in this domain, provides a communication protocol that is unencrypted and insecure. In fact, the Qi standard enables several new means of wireless charging attack. In this paper, we propose three novel attacks on wireless charging stations, named LeakyCharge, SneakyCharge and CheatyCharge. Two are supply chain attacks, while the third would allow an adversary to perform random attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "没有免费的无线充电:通过移动设备上的无线充电的隐蔽通道",
                    "abstract_zh": "制造商和用户已经接受了从有线到无线技术的转变——这种转变带来了便利、减少布线和现代化。制造商通过减少布线来降低成本；同时，用户在其无线设备上体验到更高的可访问性和移动性。自然，无线媒体不附带电线，但它有附带条件。在无线世界中，当设备A与设备B通话时，通信不再局限于两者之间。相反，许多设备共享通信信道，这为窃听和截取打开了方便之门。无线充电已经成为许多类型的智能设备的事实上的功能，也不能幸免于这种现象。Qi是该领域的领先标准，它提供了一种不加密且不安全的通信协议。事实上，Qi标准启用了几种新的无线充电攻击手段。本文提出了三种针对无线充电站的新型攻击，分别命名为LeakyCharge、SneakyCharge和CheatyCharge。两种是供应链攻击，而第三种将允许对手进行随机攻击。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00040",
                    "title": "Big Data, Transmission Errors, and the Internet",
                    "authors": "Susmit Shannigrahi, Craig Partridge",
                    "abstract": "A cursory look at the Internet protocol stack shows error checking capability almost at every layer, and yet, a slowly growing set of results show that a surprising fraction of big data transfers over TCP/IP are failing. As we have dug into this problem, we have come to realize that nobody is paying much attention to the causes of transmission errors in the Internet. Rather, they have typically resorted to file-level retransmissions. Given the exponential growth in data sizes, this approach is not sustainable. Furthermore, while there has been considerable progress in understanding error codes and how to choose or create error codes that offer sturdy error protection, the Internet has not made use of this new science. We propose a set of new ideas that look at paths forward to reduce error rates and better protect big data. We also propose a new file transfer protocol that efficiently handles errors and minimizes retransmissions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "大数据、传输错误和互联网",
                    "abstract_zh": "粗略地看一下互联网协议栈，几乎每一层都有错误检查功能，然而，越来越多的结果显示，TCP/IP上的大数据传输失败的比例惊人。随着我们对这个问题的深入研究，我们逐渐意识到，没有人太注意互联网中传输错误的原因。相反，它们通常采用文件级重新传输。鉴于数据量的指数级增长，这种方法是不可持续的。此外，虽然在理解错误代码以及如何选择或创建提供可靠错误保护的错误代码方面已经取得了相当大的进步，但是互联网还没有利用这一新的科学。我们提出了一系列新想法，着眼于降低错误率和更好地保护大数据的前进道路。我们还提出了一个新的文件传输协议，有效地处理错误和减少重传。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00041",
                    "title": "Enhancing Honeypot Fidelity with Real-Time User Behavior Emulation",
                    "authors": "Songsong Liu, Shu Wang, Kun Sun",
                    "abstract": "Honeypot is an effective tool widely adopted in security systems, providing rich information to lure attackers. However, honeypots are not foolproof and can be detected by sophisticated attackers via specific features, e.g., the lack of real user activities. In this paper, we propose HoneyMustard, a real-time application-level user behavior emulation framework to enhance the fidelity of honeypots. HoneyMustard can emulate GUI-based user activities in the honeypots by a remote desktop connection. Because attackers can only observe the remote connection during the emulation, HoneyMustard can conceal the emulator as a normal service so that it achieves real-time user emulation without being detected. The user activities are emulated by reproducing real user operations or converting application manuals, ensuring that attackers can observe logical activities at an application level. We implement a prototype of HoneyMustard and evaluate the decoy effectiveness and overhead. The experimental results show that our solution can effectively improve the fidelity of honeypots with a low overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "通过实时用户行为仿真增强蜜罐保真度",
                    "abstract_zh": "蜜罐是安全系统中广泛采用的有效工具，它提供丰富的信息来引诱攻击者。然而，蜜罐并不是万无一失的，并且可能被老练的攻击者通过特定的特征检测到，例如缺乏真实的用户活动。在本文中，我们提出了HoneyMustard，一个实时应用级用户行为仿真框架，以提高蜜罐的保真度。HoneyMustard可以通过远程桌面连接模拟蜜罐中基于GUI的用户活动。由于攻击者在仿真过程中只能观察到远程连接，因此HoneyMustard可以将仿真器隐藏为正常服务，从而实现实时用户仿真而不被检测到。通过再现真实的用户操作或转换应用程序手册来模拟用户活动，确保攻击者能够观察到应用程序级别的逻辑活动。我们实现了一个HoneyMustard原型，并评估了诱饵的有效性和开销。实验结果表明，该方案能以较低的开销有效提高蜜罐的保真度。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00042",
                    "title": "An Experimental Analysis of RowHammer in HBM2 DRAM Chips",
                    "authors": "Ataberk Olgun, Majd Osseiran, Abdullah Giray Yaglikçi, Yahya Can Tugrul, Haocong Luo, Steve Rhyner, Behzad Salami, Juan Gómez-Luna, Onur Mutlu",
                    "abstract": "RowHammer (RH) is a significant and worsening security, safety, and reliability issue of modern DRAM chips that can be exploited to break memory isolation. Therefore, it is important to understand real DRAM chips’ RH characteristics. Unfortunately, no prior work extensively studies the RH vulnerability of modern 3D-stacked high-bandwidth memory (HBM) chips, which are commonly used in modern GPUs.In this work, we experimentally characterize the RH vulnerability of a real HBM2 DRAM chip. We show that 1) different 3D-stacked channels of HBM2 memory exhibit significantly different levels of RH vulnerability (up to 79 % difference in bit error rate), 2) the DRAM rows at the end of a DRAM bank (rows with the highest addresses) exhibit significantly fewer RH bitflips than other rows, and 3) a modern HBM2 DRAM chip implements undisclosed RH defenses that are triggered by periodic refresh operations. We describe the implications of our observations on future RH attacks and defenses and discuss future work for understanding RH in 3D-stacked memories.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "HBM2 DRAM芯片中行锤的实验分析",
                    "abstract_zh": "RowHammer (RH)是现代DRAM芯片的一个重大且日益恶化的安全性、安全性和可靠性问题，可被利用来打破存储器隔离。因此，了解真实DRAM芯片的RH特性非常重要。不幸的是，没有先前的工作广泛地研究了现代3D堆叠高带宽存储器(HBM)芯片的RH脆弱性，该芯片通常用于现代GPU中。在这项工作中，我们通过实验表征了一个真实的HBM2 DRAM芯片的RH脆弱性。我们发现1)HB m2存储器的不同3D堆叠通道表现出显著不同的RH脆弱性水平(误码率差异高达79 %)，2)DRAM存储体末端的DRAM行(具有最高地址的行)表现出比其他行明显更少的RH位翻转，以及3)现代HBM2 DRAM芯片实现了由定期刷新操作触发的未公开的RH防御。我们描述了我们的观察对未来RH攻击和防御的影响，并讨论了理解3D堆叠记忆中RH的未来工作。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00043",
                    "title": "The Path to Fault- and Intrusion-Resilient Manycore Systems on a Chip",
                    "authors": "Ali Shoker, Paulo Esteves Veríssimo, Marcus Völp",
                    "abstract": "The hardware computing landscape is changing. What used to be distributed systems can now be found on a chip with highly configurable, diverse, specialized and general purpose units. Such Systems-on-a-Chip (SoC) are used to control today’s cyber-physical systems, being the building blocks of critical infrastructures. They are deployed in harsh environments and are connected to the cyberspace, which makes them exposed to both accidental faults and targeted cyberattacks. This is in addition to the changing fault landscape that continued technology scaling, emerging devices and novel application scenarios will bring. In this paper, we discuss how the very features—distributed, parallelized, reconfigurable, heterogeneous—that cause many of the imminent and emerging security and resilience challenges, also open avenues for their cure though SoC replication, diversity, rejuvenation, adaptation, and hybridization. We show how to leverage these techniques at different levels across the entire SoC hardware/software stack, calling for more research on the topic.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "故障和入侵弹性多核片上系统之路",
                    "abstract_zh": "硬件计算领域正在发生变化。过去的分布式系统现在可以在具有高度可配置、多样化、专用和通用单元的芯片上找到。这种片上系统(SoC)用于控制当今的网络物理系统，是关键基础设施的构建模块。它们被部署在恶劣的环境中，并连接到网络空间，这使它们既暴露于意外故障，也暴露于有针对性的网络攻击。除此之外，持续的技术升级、新兴设备和新颖的应用场景也将带来不断变化的断层景观。在本文中，我们讨论了造成许多迫在眉睫的和新出现的安全和弹性挑战的特性(分布式、并行化、可重新配置、异构)如何通过SoC复制、多样性、再生、适应和混合来解决这些问题。我们展示了如何在整个SoC硬件/软件堆栈的不同级别利用这些技术，呼吁对该主题进行更多的研究。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00044",
                    "title": "Investigating the Impact of High-Level Software Design on Low-Level Hardware Fault Resilience",
                    "authors": "Bohan Zhang, Lishan Yang, Guanpeng Li, Hui Xu",
                    "abstract": "Silent Data Corruptions (SDCs) have become an insurmountable issue that threatens the system reliability. General strategies for protecting programs from SDCs, such as dual modular redundancy, incur intolerable overheads. Another strategy is Algorithm-Based Fault Tolerance which is highly bounded to the specific algorithm and hard to generalize. In this study, we find different implementations of the same algorithm may lead to very different SDC probabilities. We conduct a characterization study to quantify the differences and investigate the root causes. The insights we derive could help and guide the developers in software engineering domain to design programs that is naturally resilient.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "调查高级软件设计对低级硬件故障恢复能力的影响",
                    "abstract_zh": "静默数据损坏已经成为威胁系统可靠性的不可克服的问题。保护程序免受SDC攻击的一般策略，如双模冗余，会招致不可容忍的开销。另一种策略是基于算法的容错，它高度受限于特定的算法，很难推广。在这项研究中，我们发现同一算法的不同实现可能导致非常不同的SDC概率。我们进行了一项特征研究，以量化差异并调查根本原因。我们得到的见解可以帮助和指导软件工程领域的开发人员设计出具有自然弹性的程序。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00045",
                    "title": "Assurance of Software-Intensive Medical Devices: What About Mental Harm?",
                    "authors": "Jose Luis de la Vara, Barbara Gallina, Antonio Fernández-Caballero, José Pascual Molina, Arturo S. García, Clara Ayora",
                    "abstract": "Interdisciplinary synergies are arising from the growing usage of software, e.g., between dependability assurance and mental health. In a context in which software-intensive medical devices are used for the treatment of mental illnesses such as schizophrenia, it is important to consider mental harm when dealing with and justifying system dependability. However, we are not aware of any publication on system assurance that has paid attention to mental harm in detail. This emerging idea should be considered for the success of the devices. We discuss why and how mental harm should be addressed for assurance of software-intensive medical devices, considering hazard and risk analysis, system compliance, dependability justification, and assurance evidence collection. We draw from prior more general work and from system examples for which mental health plays a major role.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "软件密集型医疗设备的保证:精神伤害怎么办？",
                    "abstract_zh": "跨学科的协同作用是由于软件的使用越来越多，例如，在可靠性保证和心理健康之间。在软件密集型医疗设备用于治疗精神疾病(如精神分裂症)的背景下，在处理和论证系统可靠性时，考虑精神伤害是非常重要的。然而，我们不知道有任何关于系统保障的出版物详细关注过精神伤害。这种新兴的想法应该被认为是设备的成功。我们讨论了在软件密集型医疗设备的保证中为什么以及如何处理精神伤害，考虑了危害和风险分析、系统合规性、可靠性论证和保证证据收集。我们从先前更一般的工作和精神健康起主要作用的系统例子中得出结论。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00046",
                    "title": "Tailoring and Verification of the Trust Boundaries in a Heterogeneous TEE Landscape",
                    "authors": "Anna Galanou",
                    "abstract": "Confidential computing services enable users to run or use applications in Trusted Execution Environments (TEEs) leveraging secure hardware, like Intel SGX or AMD SEV, and verify them by performing remote attestation. Typically this process is very rigid and not always aligned with the trust assumptions of the users regarding the hardware identities, stakeholders and software that are considered trusted. In our work, we enable the users to tailor their trust boundaries according to their security concerns and remotely attest the different TEEs specifically based on those.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "异构TEE环境中信任边界的裁剪和验证",
                    "abstract_zh": "机密计算服务使用户能够在利用安全硬件的可信执行环境(tee)中运行或使用应用，如英特尔SGX或AMD SEV，并通过执行远程证明来验证它们。通常，该过程非常严格，并且不总是与用户关于被认为可信的硬件身份、利益相关者和软件的信任假设相一致。在我们的工作中，我们使用户能够根据他们的安全顾虑定制他们的信任边界，并基于这些来远程证明不同的tee。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00047",
                    "title": "Enhancing IoT Security and Privacy with Trusted Execution Environments and Machine Learning",
                    "authors": "Peterson Yuhala",
                    "abstract": "With the increasing popularity of Internet of Things (IoT) devices, security concerns have become a major challenge: confidential information is constantly being transmitted (sometimes inadvertently) from user devices to untrusted cloud services. This work proposes a design to enhance security and privacy in IoT based systems by isolating hardware peripheral drivers in a trusted execution environment (TEE), and leveraging secure machine learning classification techniques to filter out sensitive data, e.g., speech, images, etc. from the associated peripheral devices before it makes its way to an untrusted party in the cloud.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "利用可信执行环境和机器学习增强物联网安全性和隐私性",
                    "abstract_zh": "随着物联网(IoT)设备的日益普及，安全问题已成为一大挑战:机密信息不断从用户设备传输(有时是无意的)到不可信的云服务。这项工作提出了一种设计，通过在可信执行环境(TEE)中隔离硬件外设驱动程序，并利用安全机器学习分类技术过滤掉敏感数据，如语音、图像等，来增强基于物联网的系统的安全性和隐私性。在它到达云中不可信的一方之前，从相关联的外围设备接收信息。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00048",
                    "title": "Advancing Blockchain Security: from Vulnerability Detection to Transaction Revocation",
                    "authors": "Fernando Richter Vidal, Naghmeh Ivaki, Nuno Laranjeiro",
                    "abstract": "Smart contracts are software built with immature development tools and/or by developers who usually resort to smart contract-specific languages like Solidity, with which they tend to lack adequate expertise. Despite the existence of tools for vulnerability detection, recent works have shown they are ineffective and fail to prevent vulnerable contracts from being deployed. As a result, the blockchain is full of immutable bugs associated with incorrect information that may need to be revoked. This Ph.D. aims at advancing the security of blockchain applications by creating a security assurance framework composed of tools and techniques for building blockchain systems on which we can rely. The objective is two-fold: i) detection of vulnerabilities in smart contracts and ii) handling the generally inevitable presence of undetected residual faults and vulnerabilities in smart contracts. Thus, we aim at accomplishing: i) the creation of a representative and reusable vulnerability model for blockchain systems; ii) the definition of a vulnerability injection approach for blockchain systems; iii) the proposal of a benchmark for smart contract vulnerability detection tools; iv) the proposal of techniques for creating effective smart contract vulnerability detection tools, based on an ensemble of heterogeneous tools; and finally v) the proposal of automatic techniques for efficient and secure blockchain transaction revocation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "推进区块链安全:从漏洞检测到交易撤销",
                    "abstract_zh": "智能合约是由不成熟的开发工具和/或开发人员构建的软件，开发人员通常求助于智能合约专用语言，如Solidity，他们往往缺乏足够的专业知识。尽管存在漏洞检测工具，但最近的工作表明它们是无效的，并且不能防止易受攻击的契约被部署。因此，区块链充满了与可能需要撤销的不正确信息相关联的不可变错误。该博士学位旨在通过创建一个安全保证框架来提高区块链应用程序的安全性，该框架由用于构建我们可以依赖的区块链系统的工具和技术组成。目标是双重的:I)检测智能合约中的漏洞，以及ii)处理智能合约中通常不可避免地存在的未检测到的残留错误和漏洞。因此，我们的目标是完成:I)为区块链系统创建一个有代表性的和可重复使用的脆弱性模型；ii)区块链系统漏洞注入方法的定义；iii)智能合同漏洞检测工具基准的提议；iv)基于异构工具的集合，提出用于创建有效的智能合同漏洞检测工具的技术；以及最后v)用于高效和安全的区块链交易撤销的自动技术的提议。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00049",
                    "title": "Towards PHP Vulnerability Detection at an Intermediate Language Level",
                    "authors": "Paulo Antunes, Ibéria Medeiros, Nuno Neves",
                    "abstract": "Web applications are a prime target for malicious actors to obtain private user information, such as credit card numbers and other sensitive details. Over the years, the number of vulnerabilities and attacks has increased, demonstrating that current solutions have shortcomings. For example, they can be prone to error or require too much resources/time from developers (or security analysts) to deliver results. This paper presents a new approach to detect vulnerabilities in web applications written in PHP by analyzing their representation in an Intermediate Language (IL) and simulating the execution through a new data structure.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "面向中间语言级别的PHP漏洞检测",
                    "abstract_zh": "Web应用程序是恶意行为者获取私人用户信息(如信用卡号和其他敏感信息)的主要目标。多年来，漏洞和攻击的数量不断增加，表明当前的解决方案存在缺陷。例如，他们可能容易出错，或者需要开发人员(或安全分析师)花费太多的资源/时间来交付结果。本文提出了一种新的方法来检测用PHP编写的web应用程序中的漏洞，方法是分析它们在中间语言(IL)中的表示，并通过一种新的数据结构来模拟执行。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00050",
                    "title": "A Workflow for Distributed and Resilient Attack Graph Generation",
                    "authors": "Alessandro Palma, Silvia Bonomi",
                    "abstract": "Among the existing attack models, Attack Graphs (AGs) represent a powerful abstraction to capture the notion of multi-step attacks i.e., ensembles of sequential vulnerability exploits taken by an attacker with a specific objective. A well-known issue in using AGs is their poor scalability due to the complexity of generating and analyzing all existing attack paths. To this aim, we propose a workflow for a more efficient generation of attack paths in a distributed and resilient manner. We describe the general workflow, emphasizing the research challenges and providing few preliminary solutions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "分布式弹性攻击图生成工作流",
                    "abstract_zh": "在现有的攻击模型中，攻击图(AGs)是一个强大的抽象概念，用于捕获多步攻击的概念，即攻击者为达到特定目标而采取的连续漏洞利用的集合。使用AGs的一个众所周知的问题是，由于生成和分析所有现有攻击路径的复杂性，它们的可扩展性很差。为此，我们提出了一个工作流，以分布式和弹性的方式更有效地生成攻击路径。我们描述了一般的工作流程，强调了研究的挑战，并提供了一些初步的解决方案。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00051",
                    "title": "Automating Vulnerability Management in the Software Development Lifecycle",
                    "authors": "Horacio L. França, César Alexandre Teixeira, Nuno Laranjeiro",
                    "abstract": "Managing the presence of vulnerabilities in software can be a time and resource consuming process. The advancements in machine learning (ML) over the past few years have allowed us to automate parts of the software development lifecycle, including the identification of vulnerabilities starting from bug reports. However, such approaches have known gaps generally related with subpar effectiveness. In this PhD, we intend to propose a vulnerability management framework aiming at four main objectives: i) highly effective vulnerability identification starting from bug reports; ii) detailed vulnerability classification; iii) prediction of main aspects related with the correction (e.g., defect triage); and iv) recommending corrections based on the detailed knowledge obtained in the previous phases.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "软件开发生命周期中漏洞管理的自动化",
                    "abstract_zh": "管理软件中漏洞的存在可能是一个耗费时间和资源的过程。过去几年中机器学习(ML)的进步已经允许我们自动化软件开发生命周期的一部分，包括从错误报告开始识别漏洞。然而，这种方法具有通常与低效率相关的已知差距。在这篇博士论文中，我们打算提出一个针对四个主要目标的漏洞管理框架:I)从错误报告开始的高效漏洞识别；㈡详细的脆弱性分类；iii)与纠正相关的主要方面的预测(例如，缺陷分类)；以及iv)基于在先前阶段获得的详细知识推荐校正。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00052",
                    "title": "Techniques and Tools for Runtime Security Monitoring and Analysis of Microservices",
                    "authors": "Jessica Castro, Nuno Laranjeiro, Marco Vieira",
                    "abstract": "Microservice architectures are highly scalable, flexible, and manageable applications. However, their distributed nature and high service granularity increase the challenge of monitoring and identifying attacks. Protecting microservice applications and developing security solutions capable of dealing with unique microservice characteristics is essential. This Ph.D. work aims to develop innovative solutions for enhancing the security of microservice applications at runtime. Through extensive research, the project will explore techniques for monitoring and detecting potential attacks in microservice scenarios at application-layer, considering the existing challenges. Thus, when a possible attack is detected, adaptation actions can be triggered to mitigate the threats improving application security.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "微服务运行时安全监控和分析的技术和工具",
                    "abstract_zh": "微服务架构是高度可扩展、灵活且易于管理的应用。然而，它们的分布式特性和高服务粒度增加了监控和识别攻击的挑战。保护微服务应用和开发能够处理独特微服务特征的安全解决方案至关重要。这项博士工作旨在开发创新的解决方案，以增强微服务应用在运行时的安全性。通过广泛的研究，该项目将探索在应用层微服务场景中监控和检测潜在攻击的技术，同时考虑现有的挑战。因此，当检测到可能的攻击时，可以触发适应动作来减轻威胁，从而提高应用安全性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00053",
                    "title": "Multi-Consistency Transactional Support for Function-as-a-Service",
                    "authors": "Rafael Soares, Luís Rodrigues",
                    "abstract": "We propose to design and implement a framework to support the concurrent execution of transactions with different consistency levels in Function-as-a-Service (FaaS) environments. The goal is to allow functionalities that have weak consistency requirements to execute efficiently, with minimal coordination, while, at the same time, allow functionalities that have strong consistency requirements to access the same data. We wish to explore what techniques may be leveraged to implement such a framework, what consistency levels should be supported, and how they can be supported efficiently in existing FaaS environments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "对功能即服务的多一致性事务支持",
                    "abstract_zh": "我们建议设计并实现一个框架，以支持在功能即服务(FaaS)环境中并发执行具有不同一致性级别的事务。目标是允许具有弱一致性需求的功能以最少的协调高效地执行，同时允许具有强一致性需求的功能访问相同的数据。我们希望探索可以利用哪些技术来实现这样一个框架，应该支持什么样的一致性级别，以及如何在现有的FaaS环境中有效地支持它们。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00054",
                    "title": "Rich and Expressive Specification of Continuous-Learning Cyber-Physical Systems",
                    "authors": "Thomas Flinkow, Barak A. Pearlmutter, Rosemary Monahan",
                    "abstract": "Neural networks are being applied to a growing variety of applications, including safety-critical domains like autonomous vehicles and aircraft, due to their ability to approximate complex functions from limited datasets and adapt by continuing to learn from real-world data after deployment.Ensuring dependability in cyber-physical systems with neural network controllers requires verification beyond linear input-output constraints and local robustness of the network in isolation and must address uncertainties introduced by learning and network behaviour on unseen data, especially when continuous learning after deployment is allowed. Verification of these continuous-learning cyber-physical systems requires assessing probabilistic, temporal, and behavioural specifications that express concepts like resilience and other key properties.Our research seeks to develop strategies and associated tooling for rigorously specifying continuous-learning cyber-physical systems and verifying them against rich and expressive specifications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "不断学习的信息物理系统的丰富和表达规范",
                    "abstract_zh": "神经网络正被应用于越来越多的应用领域，包括自动驾驶汽车和飞机等安全关键领域，因为它们能够从有限的数据集逼近复杂的函数，并在部署后通过继续从真实世界的数据中学习来适应。在具有神经网络控制器的信息物理系统中确保可靠性需要超越线性输入-输出约束和孤立网络的局部鲁棒性的验证，并且必须解决由学习和网络行为对看不见的数据引入的不确定性，特别是当部署后允许连续学习时。验证这些持续学习的网络物理系统需要评估概率、时间和行为规范，这些规范表达了弹性和其他关键属性等概念。我们的研究旨在开发策略和相关工具，用于严格指定持续学习的信息物理系统，并根据丰富和有表现力的规范对其进行验证。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00055",
                    "title": "AutoLock: Automatic Design of Logic Locking with Evolutionary Computation",
                    "authors": "Zeng Wang, Lilas Alrahis, Dominik Sisejkovic, Ozgur Sinanoglu",
                    "abstract": "Logic locking protects the integrity of hardware designs throughout the integrated circuit supply chain. However, recent machine learning (ML)-based attacks have challenged its fundamental security, initiating the requirement for the design of learning-resilient locking policies. A promising ML-resilient locking mechanism hides within multiplexer-based locking. Nevertheless, recent attacks have successfully breached these state-of-the-art locking schemes, making it ever more complex to manually design policies that are resilient to all existing attacks. In this project, for the first time, we propose the automatic design exploration of logic locking with evolutionary computation (EC)—a set of versatile black-box optimization heuristics inspired by evolutionary mechanisms. The project will evaluate the performance of EC-designed logic locking against various types of attacks, starting with the latest ML-based link prediction. Additionally, the project will provide guidelines and best practices for using EC-based logic locking in practical applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "AutoLock:基于进化计算的逻辑锁自动设计",
                    "abstract_zh": "逻辑锁定保护整个集成电路供应链中硬件设计的完整性。然而，最近基于机器学习(ML)的攻击对其基本安全性提出了挑战，引发了设计学习弹性锁定策略的需求。一种有前途的ML弹性锁定机制隐藏在基于多路复用器的锁定中。然而，最近的攻击已经成功地突破了这些最先进的锁定方案，使得手动设计能够抵御所有现有攻击的策略变得更加复杂。在这个项目中，我们首次提出了用进化计算(EC)进行逻辑锁定的自动设计探索——一组由进化机制启发的通用黑盒优化试探法。该项目将评估EC设计的逻辑锁定对各种类型攻击的性能，从最新的基于ML的链接预测开始。此外，该项目将为在实际应用中使用基于EC的逻辑锁定提供指导和最佳实践。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00056",
                    "title": "Exploring the Environmental Benefits of In-Process Isolation for Software Resilience",
                    "authors": "Merve Gülmez, Thomas Nyman, Christoph Baumann, Jan Tobias Mühlberg",
                    "abstract": "Memory-related errors remain an important cause of software vulnerabilities. While mitigation techniques such as using memory-safe languages are promising solutions, these do not address software resilience and availability. In this paper, we propose a solution to build resilience against memory attacks into software, which contributes to environmental sustainability and security.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "探索进程内隔离对软件弹性的环境益处",
                    "abstract_zh": "与内存相关的错误仍然是软件漏洞的重要原因。虽然使用内存安全语言等缓解技术是很有前途的解决方案，但这些技术并没有解决软件的弹性和可用性问题。在本文中，我们提出了一种在软件中构建抵御内存攻击的解决方案，这有助于环境的可持续性和安全性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00057",
                    "title": "Secure Compiler Framework to Design Fault Attack Resistant Software",
                    "authors": "Keerthi K., Chester Rebeiro",
                    "abstract": "Fault injection attacks are a potent class of physical attacks where an injected fault during the execution of a cryptosystem is exploited to retrieve the secret key. The success of the fault attack depends on the software implementation and the underlying hardware. While there are several tools to detect vulnerable locations, none of them consider all the influencing aspects that, include the cipher algorithm, its implementation, and the underlying hardware. In this paper, we propose a three-stage secure compiler framework that automatically identifies exploitable instructions, quantifies exploitability, and adds countermeasures. It can enable tradeoffs based on performance requirements and the user’s security requirements. We demonstrate the versatility of the framework by evaluating nine different block cipher implementations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "设计抗错误攻击软件的安全编译器框架",
                    "abstract_zh": "故障注入攻击是一种强有力的物理攻击，在这种攻击中，利用密码系统执行过程中注入的故障来获取密钥。故障攻击的成功取决于软件实现和底层硬件。虽然有几种工具可以检测易受攻击的位置，但没有一种工具考虑到了所有的影响因素，包括加密算法、加密算法的实现和底层硬件。在本文中，我们提出了一个三阶段的安全编译器框架，该框架自动识别可利用的指令，量化可利用性，并添加对策。它可以实现基于性能需求和用户安全需求的折衷。我们通过评估九种不同的分组密码实现来展示该框架的通用性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00058",
                    "title": "Beyond Detection: Securing Robotic Vehicles",
                    "authors": "Pritam Dash, Karthik Pattabiraman",
                    "abstract": "Autonomous Robotic Vehicles (RV) such as drones and rovers rely exclusively on sensors to perceive their physical states, and plan their trajectory using specialized algorithms. Physical attacks such as sensor tampering and spoofing can feed erroneous sensor measurements through physical channels that may disrupt RVs, and result in mission failures. Prior work in this area is largely limited to attack detection. However, detection alone is not a complete solution, as it does not ensure safety. We propose a novel control framework to mitigate physical attacks against RVs, and ensure safety and security. Our framework allows RVs to operate safely despite malicious attacks, can easily integrate with the RV’s control loop and trajectory planning algorithms, and do not require any changes to the hardware.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "超越检测:保护机器人车辆",
                    "abstract_zh": "无人驾驶飞机和漫游车等自主机器人车辆(RV)完全依赖传感器来感知它们的物理状态，并使用专门的算法来规划它们的轨迹。诸如传感器篡改和欺骗之类的物理攻击会通过物理信道提供错误的传感器测量结果，这可能会破坏RVs，并导致任务失败。这一领域的现有工作很大程度上局限于攻击检测。然而，检测本身并不是一个完整的解决方案，因为它不能确保安全。我们提出了一种新的控制框架来减轻对RVs的物理攻击，并确保安全性。我们的框架允许RVs在恶意攻击的情况下安全运行，可以轻松地与RV的控制回路和轨迹规划算法集成，并且不需要对硬件进行任何更改。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00059",
                    "title": "Towards Transient Fault Mitigation Techniques Optimized for Compressed Neural Networks",
                    "authors": "Alessio Colucci",
                    "abstract": "In the last decades, Neural Networks have become widespread in many applications, leading to improved performance in the form of compressed neural networks. However, these compressed neural networks have not been analyzed in terms of resilience to transient faults, and faults per transistor have been constantly increasing along with scaling technology nodes. Therefore, we need novel analysis and mitigation techniques which are optimized for compressed neural networks. We propose a 4-step methodology to design and test optimized toolset, algorithms, fault effect models and mitigations, covering the first two steps and marking the path for the remaining two.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "面向压缩神经网络优化的瞬态故障缓解技术",
                    "abstract_zh": "在过去的几十年中，神经网络在许多应用中变得广泛，导致压缩神经网络形式的性能改善。然而，这些压缩的神经网络还没有在对瞬时故障的弹性方面进行分析，并且每个晶体管的故障已经随着技术节点的缩放而不断增加。因此，我们需要为压缩神经网络优化的新的分析和缓解技术。我们提出了一个4步方法来设计和测试优化的工具集、算法、故障影响模型和缓解措施，涵盖了前两步，并为剩下的两步指明了道路。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00060",
                    "title": "Bayesian Network Reliability Modeling for Three-version Machine Learning Systems",
                    "authors": "Qiang Wen, Fumio Machida",
                    "abstract": "Machine learning (ML) is widely used in intelligent software systems. However, the uncertain outputs from ML models can lead to undesirable consequences in safety-critical applications. To improve system reliability, we propose N-version ML architectures combining multiple inputs with multiple ML models to decide the system output by voting. The reliability of N-version ML systems can be characterized by two diversity measures; input diversity and model diversity. In this study, we consider Bayesian Networks (BNs) for modeling the reliability of N-version ML systems outputs through multiple dependent diversity parameters. We present a preliminary BNs reliability model for a three-version ML system. Finally, we discuss the potential extension of the approach and issues for modeling large-scale systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "三版本机器学习系统的贝叶斯网络可靠性建模",
                    "abstract_zh": "机器学习广泛应用于智能软件系统中。然而，ML模型的不确定输出在安全关键应用中会导致不良后果。为了提高系统的可靠性，我们提出了N版本的最大似然结构，将多个输入和多个最大似然模型结合起来，通过投票来决定系统的输出。N版本最大似然系统的可靠性可以通过两种多样性度量来表征；输入多样性和模型多样性。在这项研究中，我们考虑贝叶斯网络(BNs)通过多个相关的多样性参数来模拟N版本ML系统输出的可靠性。我们提出了一个三版本ML系统的初步BNs可靠性模型。最后，我们讨论了大规模系统建模的方法和问题的潜在扩展。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00061",
                    "title": "Programmable SEL Test Monitoring System for Radiation Hardness Assurance",
                    "authors": "Daniele Rizzieri, Sarah Azimi, Luca Sterpone, Corrado De Sio, Thomas Borel, Viyas Gupta, Margherita Cardi",
                    "abstract": "In the continued miniaturization of electronic devices, certain advantages in terms of power consumption, performances, and physical area occupation correspond to an increased susceptibility to highly charged radiation particle interactions. Therefore, it is nowadays extremely important to assess Radiation Hardness Assurance (RHA) procedures in order to guarantee that a certain system is suitable to be used in extreme environmental conditions such as deep space. When performing these measurements, the design and development of dedicated fault monitoring systems to be used as support architecture during the radiation tests are heavily time and budget-consuming operations. The present paper describes a programmable Single Event Latch-up (SEL) monitoring system capable of supporting experimenters on the test of several heterogeneous electronic devices ranging from microcontrollers up to individual MOSFETs. The proposed solution has been successfully verified during a heavy-ion radiation test campaign. The experimental results achieved during the radiation test campaigns are described and commented on.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "用于辐射硬度保证的可编程SEL测试监控系统",
                    "abstract_zh": "在电子设备的持续小型化中，在功耗、性能和物理面积占用方面的某些优势对应于对高电荷辐射粒子相互作用的敏感性增加。因此，如今评估辐射硬度保证(RHA)程序以保证某个系统适合用于极端环境条件(如深空)是极其重要的。当执行这些测量时，在辐射测试期间用作支持架构的专用故障监测系统的设计和开发是非常耗费时间和预算的操作。本文描述了一种可编程单粒子闩锁(SEL)监控系统，该系统能够支持实验人员对从微控制器到单个MOSFETs的多种异构电子器件进行测试。所提出的解决方案已经在重离子辐射测试活动中得到成功验证。描述并评论了辐射试验活动中取得的实验结果。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00062",
                    "title": "Design with low complexity fine-grained Dual Core Lock-Step (DCLS) RISC-V processors",
                    "authors": "Pegdwende Romaric Nikiema, Angeliki Kritikakou, Marcello Traiola, Olivier Sentieys",
                    "abstract": "Embedded systems in critical domains require both hard real-time and reliable execution. Real-time execution requires bounds in the worst-case execution time, while reliable execution is under threat, as systems are becoming more and more sensitive to transient faults. Thus, systems should be enhanced with fault-tolerant mechanisms with bounded error detection and correction overhead. Such mechanisms are typically based on redundancy at different granularity levels. Coarse-grained granularity has low comparison overhead, but may jeopardize timing guarantees. Fine-grained granularity immediately detects and corrects the error, but its implementation has increased design complexity. To mitigate this design complexity, we leverage high-level specification languages to design intrusive fine-grained lockstep processors based on the use of shadow registers and rollback, with bounded error detection and correction time, being appropriate for critical systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "采用低复杂度细粒度双核锁步(DCLS) RISC-V处理器进行设计",
                    "abstract_zh": "关键领域中的嵌入式系统需要硬实时和可靠的执行。实时执行要求在最坏情况下的执行时间有限制，而可靠的执行受到威胁，因为系统对瞬时故障越来越敏感。因此，应该用具有有限错误检测和纠正开销的容错机制来增强系统。这种机制通常基于不同粒度级别的冗余。粗粒度的比较开销较低，但可能会危及时间保证。细粒度可以立即检测并纠正错误，但是它的实现增加了设计的复杂性。为了降低这种设计复杂性，我们利用高级规范语言来设计基于使用影子寄存器和回滚的侵入式细粒度锁步处理器，具有有限的错误检测和纠正时间，适用于关键系统。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-S58398.2023.00063",
                    "title": "Towards Reliability Assessment of Systolic Arrays against Stuck-at Faults",
                    "authors": "Udit Kumar Agarwal, Abraham Chan, Ali Asgari, Karthik Pattabiraman",
                    "abstract": "Neural Networks are ubiquitously used in safety-critical applications such as autonomous vehicles and medical diagnostics. The increasing complexity and compute-intensiveness of deep neural networks (DNN) have motivated the need for DNN accelerators like Google’s Tensor Processing Unit (TPU) to accelerate convolution and matrix multiplication operations. At its core, a TPU consists of a 2-Dimensional array of Multiply and Accumulation Units, called a systolic array, which is susceptible to permanent (e.g., stuck-at faults in the data path) and transient hardware faults (e.g., radiation-induced). We propose an RTL-level fault injection (FI) framework for systolic arrays. Using this framework, we characterize the software effect of errors (called Fault Patterns) induced by stuck-at faults within the multiply and accumulation units of the systolic array. We further analyze the effect of different data flows mapping schemes (output and weight stationery), operation types (convolution and matrix multiplication), and operation configurations (e.g., input size, convolution kernel size). Through the FI experiments, we categorized the fault patterns for stuck-at faults into well-defined classes based on their spatial patterns.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "针对固定故障的脉动阵列可靠性评估",
                    "abstract_zh": "神经网络广泛用于安全关键应用，如自动驾驶汽车和医疗诊断。深度神经网络(DNN)日益增长的复杂性和计算密集度推动了对DNN加速器的需求，如谷歌的张量处理单元(TPU)，以加速卷积和矩阵乘法运算。在其核心，TPU由乘法和累加单元的二维阵列组成，称为脉动阵列，其易受永久(例如，数据路径中的固定故障)和瞬时硬件故障(例如，辐射引起的)的影响。我们提出了一个用于脉动阵列的RTL级故障注入(FI)框架。使用这个框架，我们描述了由脉动阵列的乘法和累加单元内的固定故障引起的错误(称为故障模式)的软件效应。我们进一步分析不同数据流映射方案(输出和权重文具)、操作类型(卷积和矩阵乘法)和操作配置(例如，输入大小、卷积核大小)的影响。通过FI实验，我们根据固定型故障的空间模式将故障模式分类为定义明确的类别。"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2023.html",
            "conf_title": "53rd DSN 2023: Porto, Portugal",
            "conf_url": "https://doi.org/10.1109/DSN58367.2023",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00006",
                    "title": "Message from the DSN 2023 Program Chairs",
                    "authors": "Onur Mutlu, Xavier Défago",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "来自DSN 2023计划主席的信息",
                    "abstract_zh": ""
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00015",
                    "title": "SHATTER: Control and Defense-Aware Attack Analytics for Activity-Driven Smart Home Systems",
                    "authors": "Nur Imtiazul Haque, Maurice Ngouen, Mohammad Ashiqur Rahman, A. Selcuk Uluagac, Laurent Njilla",
                    "abstract": "Modern smart home control systems utilize realtime occupancy and activity monitoring to ensure control efficiency, occupants' comfort, and optimal energy consumption. Moreover, adopting machine learning-based anomaly detection models (ADMs) enhances security and reliability. However, sufficient system knowledge allows adversaries/attackers to alter sensor measurements through stealthy false data injection (FDI) attacks. Although ADMs limit attack scopes, the availability of information like occupants' location, conducted activities, and alteration capability of smart appliances increase the attack surface. Therefore, performing an attack space analysis of modern home control systems is crucial to design robust defense solutions. However, state-of-the-art analyzers do not consider contemporary control and defense solutions and generate trivial attack vectors. To address this, we propose a control and defense-aware novel attack analysis framework for a modern smart home control system, efficiently extracting ADM rules. We verify and validate our framework using a state-of-the-art dataset and a prototype testbed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "粉碎:针对活动驱动的智能家居系统的控制和防御感知攻击分析",
                    "abstract_zh": "现代智能家居控制系统利用实时居住和活动监控来确保控制效率、居住者的舒适度和最佳能耗。此外，采用基于机器学习的异常检测模型(ADMs)增强了安全性和可靠性。然而，足够的系统知识允许对手/攻击者通过隐蔽的虚假数据注入(FDI)攻击来改变传感器测量。尽管ADM限制了攻击范围，但诸如居住者的位置、进行的活动和智能设备的改变能力等信息的可用性增加了攻击面。因此，对现代家庭控制系统进行攻击空间分析对于设计强大的防御解决方案至关重要。然而，最先进的分析器不考虑当代的控制和防御解决方案，并且生成琐碎的攻击向量。为了解决这个问题，我们为现代智能家居控制系统提出了一个控制和防御感知的新型攻击分析框架，有效地提取ADM规则。我们使用最先进的数据集和原型测试床来验证我们的框架。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00016",
                    "title": "SecDDR: Enabling Low-Cost Secure Memories by Protecting the DDR Interface",
                    "authors": "Ali Fakhrzadehgan, Prakash Ramrakhyani, Moinuddin K. Qureshi, Mattan Erez",
                    "abstract": "The security goals of cloud providers and users include memory confidentiality and integrity, which requires implementing replay attack protection (RAP). RAP can be achieved using integrity trees or mutually authenticated channels. Integrity trees incur significant performance overheads and are impractical for protecting large memories. Mutually authenticated channels have been proposed only for packetized memory interfaces that address only a very small niche domain, require fundamental changes to memory system architecture, and assume fully-trusted modules. We propose SecDDR, a low-cost RAP that targets direct-attached memories, like DDRx. SecDDR avoids memory-side data authentication, and thus, only adds a small amount of logic to memory components and does not change the underlying DDR protocol, making it practical for widespread adoption. In contrast to prior mutual authentication proposals, which require trusting the entire memory module, SecDDR targets untrusted modules by placing its limited security logic on the DRAM die (or package) of the ECC chip. Our evaluation shows that SecDDR performs within 1% of an encryption-only memory without RAP and that SecDDR provides 18.8% and 7.8% average performance improvements (up to 190.4% and 24.8%) relative to a 64-ary integrity tree and an authenticated channel, respectively.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "SecDDR:通过保护DDR接口实现低成本安全存储器",
                    "abstract_zh": "云提供商和用户的安全目标包括内存机密性和完整性，这需要实现重放攻击保护(RAP)。RAP可以使用完整性树或相互认证的通道来实现。完整性树会导致显著的性能开销，并且对于保护大容量存储器是不切实际的。相互认证的信道仅被提议用于分组化的存储器接口，其仅寻址非常小的利基域，需要对存储器系统架构进行根本改变，并且假定完全可信的模块。我们提出SecDDR，这是一种针对直接连接内存(如DDRx)的低成本RAP。SecDDR避免了存储器端的数据认证，因此，仅向存储器组件添加了少量的逻辑，并且不改变底层的DDR协议，这使得它能够被广泛采用。与要求信任整个存储器模块的先前的相互认证提议相反，SecDDR通过将其有限的安全逻辑放置在ECC芯片的DRAM管芯(或封装)上来针对不信任的模块。我们的评估表明，相对于64元完整性树和认证通道，SecDDR的性能仅比没有RAP的纯加密存储器提高了1%,并且SecDDR分别提供了18.8%和7.8%的平均性能改善(高达190.4%和24.8%)。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00017",
                    "title": "Devils in Your Apps: Vulnerabilities and User Privacy Exposure in Mobile Notification Systems",
                    "authors": "Jiadong Lou, Xiaohan Zhang, Yihe Zhang, Xinghua Li, Xu Yuan, Ning Zhang",
                    "abstract": "Witnessing the blooming adoption of push notifications on mobile devices, this new message delivery paradigm has become pervasive in diverse applications. Accompanying with its broad adoption, the potential security risks and privacy exposure issues raise public concerns regarding its great social impacts. This paper conducts the first attempt to exploit the mobile notification ecosystem. By dissecting its structural elements and implementation process, a comprehensive vulnerability analysis is conducted towards the complete flow of mobile notification from platform enrollment to messaging. Meanwhile, for privacy exposure, we first examine the implementation of privacy policy compliance by proposing a three-level inspection approach to guide our analysis. Then, our top-down methods from documentation analysis, application network traffic study, to static analysis expose the illicit data collection behaviors in released applications. In addition, we uncover the potential privacy inference resulted from the notification monitoring. To support our analysis, we conduct empirical studies on 12 most popular notification platforms and perform static analysis over 30,000+ applications. We discover: 1) six platforms either provide ambiguous KEY naming rules or offer vulnerable messaging APIs; 2) privacy policy compliance implementations are either stagnated at the documentation stages (8 of 12 platforms) or never implemented in apps, resulting in billions of users suffering from privacy exposure; and 3) some apps can stealthily monitor notification messages delivering to other apps, potentially incurring user privacy inference risks. Our study raises the urgent demand for better regulations of mobile notification deployment.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "应用程序中的魔鬼:移动通知系统中的漏洞和用户隐私暴露",
                    "abstract_zh": "见证了移动设备上推送通知的蓬勃发展，这种新的消息传递范式在各种应用程序中变得无处不在。随着其被广泛采用，潜在的安全风险和隐私暴露问题引起了公众对其巨大社会影响的关注。本文首次尝试开发移动通知生态系统。通过剖析其结构元素和实现过程，对移动通知从平台注册到消息传递的完整流程进行了全面的漏洞分析。同时，对于隐私暴露，我们首先通过提出三级检查方法来检查隐私策略遵从的实施，以指导我们的分析。然后，我们从文档分析、应用程序网络流量研究到静态分析的自上而下的方法揭露了已发布应用程序中的非法数据收集行为。此外，我们还揭示了由通知监控导致的潜在隐私推断。为了支持我们的分析，我们对12个最流行的通知平台进行了实证研究，并对30，000多个应用程序进行了静态分析。我们发现:1)六个平台要么提供模糊的密钥命名规则，要么提供易受攻击的消息传递APIs2)隐私政策合规性实施要么停滞在文档阶段(12个平台中的8个)，要么从未在应用中实施，导致数十亿用户遭受隐私暴露；3)一些应用程序可以秘密监控发送到其他应用程序的通知消息，这可能会导致用户隐私推断风险。我们的研究提出了更好的移动通知部署规则的迫切需求。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00018",
                    "title": "Breaking Geographic Routing Among Connected Vehicles",
                    "authors": "Zizheng Liu, Shaan Shekhar, Chunyi Peng",
                    "abstract": "Geographic routing for connected vehicles enables vehicles and roadside infrastructure to exchange information about traffic conditions and road hazards based on their geographic positions. Its security is thus critical to traffic efficiency and road safety. In this paper, we conduct a security analysis of one standardized geographic routing protocol - GeoNetworking-and unfortunately find that its packet forwarding algorithms are vulnerable to two simple attacks. The first inter-area interception attack disturbs the victim vehicle's routing decision making and intercepts packets transmitted from one area to another. The second intra-area blockage attack intervenes packet forwarding within an area by impersonating a packet forwarder in a contention based flooding process; The attacker injects fake packets to its nearby peers and prevents vehicles within an area from receiving the broadcast packets. We use an open-source simulator to evaluate the effectiveness of proof-of-concept attacks and assess their attack damages under the settings released in public field tests. The first attack achieves an inter-area interception rate up to 99.9% (>35% in all test cases); The second attack reaches an intra-area packet blockage rate between 35% and 39%, which implies that about one-third vehicles within an area fail to receive broadcast packets. These attacks cause unnecessary traffic jams and collisions which could be avoided if GeoNetworking is properly secured. We further propose standard-compatible solutions to mitigating both attacks and conduct a preliminary evaluation to validate their effectiveness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "打破互联车辆之间的地理路由",
                    "abstract_zh": "互联车辆的地理路由使车辆和路边基础设施能够根据其地理位置交换有关交通状况和道路危险的信息。因此，其安全性对于交通效率和道路安全至关重要。在本文中，我们对一个标准化的地理路由协议GeoNetworking进行了安全分析，不幸地发现它的数据包转发算法容易受到两种简单的攻击。第一种区域间拦截攻击扰乱受害车辆的路由决策，并拦截从一个区域传输到另一个区域的数据包。第二种区域内阻塞攻击通过在基于竞争的泛洪过程中模仿分组转发器来干预区域内的分组转发；攻击者向其附近的对等方注入假数据包，并阻止一个区域内的车辆接收广播数据包。我们使用开源模拟器来评估概念验证攻击的有效性，并在公开现场测试中发布的设置下评估它们的攻击损害。第一次攻击实现了高达99.9%的区域间拦截率(在所有测试案例中> 35%)；第二种攻击达到35%和39%之间的区域内分组阻塞率，这意味着一个区域内大约三分之一的车辆无法接收广播分组。这些攻击会造成不必要的交通堵塞和碰撞，如果地理网络得到适当保护，这些都是可以避免的。我们进一步提出标准兼容的解决方案来减轻这两种攻击，并进行初步评估，以验证其有效性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00019",
                    "title": "NPTSN: RL-Based Network Planning with Guaranteed Reliability for In-Vehicle TSSDN",
                    "authors": "Weijiang Kong, Majid Nabi, Kees Goossens",
                    "abstract": "To achieve strict reliability goals with lower redundancy cost, Time-Sensitive Software-Defined Networking (TSSDN) enables run-time recovery for future in-vehicle networks. While the recovery mechanisms rely on network planning to establish reliability guarantees, existing network planning solutions are not suitable for TSSDN due to its domain-specific scheduling and reliability concerns. The sparse solution space and expensive reliability verification further complicate the problem. We propose NPTSN, a TSSDN planning solution based on deep Reinforcement Learning (RL). It represents the domain-specific concerns with the RL environment and constructs solutions with an intelligent network generator. The network generator iteratively proposes TSSDN solutions based on a failure analysis and trains a decision-making neural network using a modified actor-critic algorithm. Extensive performance evaluations show that NPTSN guarantees reliability for more test cases and shortens the decision trajectory compared to state-of-the-art solutions. It reduces the network cost by up to 6.8x in the performed experiments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "NPTSN:基于RL的车载TSSDN网络规划",
                    "abstract_zh": "为了以更低的冗余成本实现严格的可靠性目标，时间敏感型软件定义网络(TSSDN)支持未来车载网络的运行时恢复。虽然恢复机制依赖于网络规划来建立可靠性保证，但是现有的网络规划解决方案由于其特定于域的调度和可靠性考虑而不适用于TSSDN。稀疏的解空间和昂贵的可靠性验证使问题进一步复杂化。我们提出了基于深度强化学习的TSSDN规划解决方案NPTSN。它代表了与RL环境相关的特定领域，并使用智能网络生成器构建解决方案。网络生成器基于故障分析迭代地提出TSSDN解决方案，并使用改进的actor-critic算法训练决策神经网络。广泛的性能评估表明，与最先进的解决方案相比，NPTSN保证了更多测试用例的可靠性，并缩短了决策轨迹。在所进行的实验中，它将网络成本降低了6.8倍。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00020",
                    "title": "Get Your Cyber-Physical Tests Done! Data-Driven Vulnerability Assessment of Robotic Aerial Vehicles",
                    "authors": "Aolin Ding, Matthew Chan, Amin Hass, Nils Ole Tippenhauer, Shiqing Ma, Saman A. Zonouz",
                    "abstract": "The rapid growth of robotic aerial vehicles (RAVs) has attracted extensive interest in numerous public and civilian applications, from flying drones to quadrotors. Security of RAV systems is posting greater challenges as RAV controller software becomes more complex and exposes a growing attack surface. Memory isolation techniques, which virtually separate the memory space and conduct hardware-based memory access control, are believed to prevent the attacker from compromising the entire system by exploiting one memory vulnerability. In this paper, we propose Ares, a new variable-level vulnerability assessment framework to explore deeper bugs from a combined cyber-physical perspective. We present a data-driven method to illustrate that, despite state-of-the-art memory isolation efforts, RAV systems are still vulnerable to physics-aware data manipulation attacks. We augment RAV control states with intermediate state variables by tracing accessible control parameters and vehicle dynamics within the same isolated memory region. With this expanded state variable space, we apply multivariate statistical analysis to investigate inter-variable quantitative data dependencies and search for vulnerable state variables. Ares utilizes a reinforcement learning-based method to show how an attacker can exploit memory bugs and parameter defects in a legitimate memory view and elaborately craft adversarial variable values to disrupt a RAV's safe operations. We demonstrate the feasibility and capability of Ares on the widely-used ArduPilot RAV framework. Our extensive empirical evaluation shows that the attacker can leverage these vulnerable state variables to achieve various RAV failures during real-time operation, and even evade existing defense solutions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "完成你的网络物理测试！数据驱动的机器人飞行器易损性评估",
                    "abstract_zh": "从无人驾驶飞机到四旋翼飞行器，机器人飞行器(rav)的快速发展吸引了众多公共和民用应用的广泛兴趣。随着RAV控制器软件变得越来越复杂，暴露出越来越多的攻击面，RAV系统的安全性面临着更大的挑战。内存隔离技术虚拟地分隔内存空间并进行基于硬件的内存访问控制，被认为可以防止攻击者通过利用一个内存漏洞来危害整个系统。在本文中，我们提出了Ares，一种新的可变级别漏洞评估框架，从综合的网络物理角度探索更深层次的漏洞。我们提出了一种数据驱动的方法来说明，尽管有最先进的内存隔离措施，RAV系统仍然容易受到物理感知数据操作的攻击。我们通过在同一个隔离的存储区域内跟踪可访问的控制参数和车辆动态，用中间状态变量来增加RAV控制状态。有了这个扩展的状态变量空间，我们应用多元统计分析来研究变量间的定量数据相关性，并搜索易受攻击的状态变量。Ares利用一种基于强化学习的方法来展示攻击者如何利用合法内存视图中的内存错误和参数缺陷，并精心编制敌对变量值来破坏RAV的安全操作。我们在广泛使用的ArduPilot RAV框架上演示了Ares的可行性和能力。我们的大量经验评估表明，攻击者可以利用这些易受攻击的状态变量在实时操作期间实现各种RAV故障，甚至逃避现有的防御解决方案。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00021",
                    "title": "Compiler-Implemented Differential Checksums: Effective Detection and Correction of Transient and Permanent Memory Errors",
                    "authors": "Christoph Borchert, Horst Schirmeier, Olaf Spinczyk",
                    "abstract": "The detection of memory errors is common practice in safety-critical software, for example in the automotive and avionics industry. International safety standards recommend using checksums for protecting critical data in computer memories. Typical implementations verify the checksum before data access and recompute it after modification using the same algorithm. However, we show that this approach can sometimes dramatically worsen the reliability of computer systems with regard to transient memory faults, and also permanent faults remain undetected. A solution with significant conceptual advantages is constituted by differential checksum algorithms, which update the respective checksum without full recomputation on data modification. We present a compiler-based solution that inserts differential checksums into C/C++ data structures automatically to cope with their increased complexity. An extensive fault-injection campaign with the TACLeBench benchmark collection shows that differential checksums reduce silent data corruptions by 95% on average whereas non-differential checksums turn out to be mostly ineffective because they introduce a window of vulnerability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "编译器实现的差分校验和:有效检测和纠正暂时和永久内存错误",
                    "abstract_zh": "检测内存错误是安全关键软件中的常见做法，例如在汽车和航空电子行业。国际安全标准建议使用校验和来保护计算机内存中的关键数据。典型的实现在数据访问之前验证校验和，并在修改之后使用相同的算法重新计算校验和。然而，我们发现，这种方法有时会显著降低计算机系统在瞬时内存故障方面的可靠性，并且永久故障也不会被检测到。具有显著概念优势的解决方案由差分校验和算法构成，该算法更新各自的校验和，而无需对数据修改进行完全重新计算。我们提出了一个基于编译器的解决方案，它自动将差分校验和插入到C/C++数据结构中，以应对其日益增加的复杂性。TACLeBench基准测试收集的广泛故障注入活动表明，差异校验和平均减少了95%的静默数据损坏，而非差异校验和则证明是无效的，因为它们引入了一个漏洞窗口。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00022",
                    "title": "PT-Guard: Integrity-Protected Page Tables to Defend Against Breakthrough Rowhammer Attacks",
                    "authors": "Anish Saxena, Gururaj Saileshwar, Jonas Juffinger, Andreas Kogler, Daniel Gruss, Moinuddin K. Qureshi",
                    "abstract": "Page tables enforce process isolation in systems. Rowhammer attacks break process isolation by flipping bits in DRAM to tamper page tables and achieving privilege escalation. Moreover, new Rowhammer attacks break existing mitigations. We seek to protect systems against such breakthrough attacks. We present PT-Guard, an integrity protection mechanism for page tables. PT-Guard uses unused bits in Page Table Entries (PTE) to embed a Message Authentication Code (MAC) for the PTE cacheline without any storage overhead. These unused bits arise from PTEs supporting petabytes of physical memory while systems targeted by Rowhammer use at-most terabytes of mem-ory. By storing and verifying MACs for PTEs, PT-Guard detects arbitrary bit-flips in PTEs. Moreover, PT-Guard also provides best-effort correction of faulty-PTEs leveraging value locality. PT-Guard protects page tables from breakthrough Rowhammer attacks with negligible hardware changes, no DRAM storage, <72 bytes of SRAM, 1.3% slowdown, and no software changes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "PT-Guard:完整性保护的页表，用于防御突破性的Rowhammer攻击",
                    "abstract_zh": "页表加强了系统中的进程隔离。Rowhammer攻击通过翻转DRAM中的位来篡改页表并实现权限提升，从而打破进程隔离。此外，新的Rowhammer攻击打破了现有的缓解措施。我们寻求保护系统免受此类突破性攻击。我们提出了PT-Guard，一种页表完整性保护机制。PT-Guard使用页表条目(PTE)中未使用的位来为PTE缓存行嵌入消息认证码(MAC ),而不会产生任何存储开销。这些未使用的位来自支持Pb物理内存的pte，而Rowhammer的目标系统最多使用TB内存。通过存储和验证pte的MAC，PT-Guard可以检测pte中的任意位翻转。此外，PT-Guard还提供了利用值局部性的故障pte的最大努力校正。PT-Guard可保护页表免受突破性的Rowhammer攻击，硬件变化可忽略不计，无DRAM存储，SRAM < 72字节，速度降低1.3%，且无软件变化。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00023",
                    "title": "Don't Knock! Rowhammer at the Backdoor of DNN Models",
                    "authors": "M. Caner Tol, Saad Islam, Andrew J. Adiletta, Berk Sunar, Ziming Zhang",
                    "abstract": "State-of-the-art deep neural networks (DNNs) have been proven to be vulnerable to adversarial manipulation and backdoor attacks. Backdoored models deviate from expected behavior on inputs with predefined triggers while retaining performance on clean data. Recent works focus on software simulation of backdoor injection during the inference phase by modifying network weights, which we find often unrealistic in practice due to restrictions in hardware. In contrast, in this work for the first time, we present an end-to-end backdoor injection attack realized on actual hardware on a classifier model using Rowhammer as the fault injection method. To this end, we first investigate the viability of backdoor injection attacks in real-life deployments of DNNs on hardware and address such practical issues in hardware implementation from a novel optimization perspective. We are motivated by the fact that vulnerable memory locations are very rare, device-specific, and sparsely distributed. Consequently, we propose a novel network training algorithm based on constrained optimization to achieve a realistic backdoor injection attack in hardware. By modifying parameters uniformly across the convolutional and fully-connected layers as well as optimizing the trigger pattern together, we achieve state-of-the-art attack performance with fewer bit flips. For instance, our method on a hardware-deployed ResNet-20 model trained on CIFAR-10 achieves over 89% test accuracy and 92% attack success rate by flipping only 10 out of 2.2 million bits.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "不要敲门！Rowhammer在DNN模型的后门",
                    "abstract_zh": "最先进的深度神经网络(DNNs)已被证明容易受到恶意操纵和后门攻击。后门模型偏离具有预定义触发器的输入的预期行为，同时保留干净数据的性能。最近的工作集中在通过修改网络权重在推断阶段进行后门注入的软件模拟，我们发现由于硬件的限制，这在实践中常常是不现实的。相比之下，在这项工作中，我们第一次提出了一个端到端的后门注入攻击，它是在一个分类器模型上使用Rowhammer作为故障注入方法在实际硬件上实现的。为此，我们首先研究了后门注入攻击在硬件上DNNs的实际部署中的可行性，并从新颖的优化角度解决了硬件实现中的这种实际问题。我们的动机是，易受攻击的内存位置非常罕见，特定于设备，并且分布稀疏。因此，我们提出了一种新的基于约束优化的网络训练算法，以在硬件上实现逼真的后门注入攻击。通过统一修改卷积层和全连接层的参数，同时优化触发模式，我们可以实现最先进的攻击性能，同时减少比特翻转。例如，我们在CIFAR-10上训练的硬件部署的ResNet-20模型上的方法通过仅翻转220万位中的10位实现了超过89%的测试准确性和92%的攻击成功率。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00024",
                    "title": "Micro Replication",
                    "authors": "Tobias Distler, Michael Eischer, Laura Lawniczak",
                    "abstract": "",
                    "files": {
                        "openAccessPdf": "https://www.nature.com/articles/s41598-022-09634-7.pdf"
                    },
                    "title_zh": "微复制",
                    "abstract_zh": ""
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00025",
                    "title": "Heron: Scalable State Machine Replication on Shared Memory",
                    "authors": "Mojtaba Eslahi-Kelorazi, Long Hoang Le, Fernando Pedone",
                    "abstract": "The paper introduces Heron, a state machine replication system that delivers scalable throughput and microsecond latency. Heron achieves scalability through partitioning (sharding) and microsecond latency through a careful design that leverages one-sided RDMA primitives. Heron significantly improves the throughput and latency of applications when compared to message passing-based replicated systems. But it really shines when executing multi-partition requests, where objects in multiple partitions are accessed in a request, the Achilles heel of most partitioned systems. We implemented Heron and evaluated its performance extensively. Our experiments show that Heron reduces the latency of coordinating linearizable executions to the level of microseconds and improves the performance of executing complex workloads by one order of magnitude in comparison to state-of-the-art S-SMR systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "Heron:共享内存上的可扩展状态机复制",
                    "abstract_zh": "本文介绍了Heron，这是一个状态机复制系统，可提供可扩展的吞吐量和微秒级延迟。Heron通过利用单侧RDMA原语的精心设计，实现了分区(分片)和微秒延迟的可扩展性。与基于消息传递的复制系统相比，Heron显著提高了应用程序的吞吐量和延迟。但是在执行多分区请求时，它确实很出色，在这种情况下，在一个请求中访问多个分区中的对象，这是大多数分区系统的致命弱点。我们实现了Heron并广泛评估了它的性能。我们的实验表明，与最先进的S-SMR系统相比，Heron将协调线性化执行的延迟降低到微秒级，并将执行复杂工作负载的性能提高了一个数量级。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00026",
                    "title": "Analyzing the Performance of the Inter-Blockchain Communication Protocol",
                    "authors": "João Otávio Massari Chervinski, Diego Kreutz, Xiwei Xu, Jiangshan Yu",
                    "abstract": "With the increasing demand for communication between blockchains, improving the performance of cross-chain communication protocols becomes an emerging challenge. We take a first step towards analyzing the limitations of cross-chain communication protocols by comprehensively evaluating Cosmos Network's Inter-Blockchain Communication Protocol. To achieve our goal we introduce a novel framework to guide empirical evaluations of cross-chain communication protocols. We implement an instance of our framework as a tool to evaluate the IBC protocol. Our findings highlight several challenges, such as high transaction confirmation latency, bottlenecks in the blockchain's RPC implementation and concurrency issues that hinder the scalability of the cross-chain message relayer. We also demonstrate how to reduce the time required to complete cross-chain transfers by up to 70% when submitting large amounts of transfers. Finally, we discuss challenges faced during deployment with the objective of contributing to the development and advancement of cross-chain communication.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "区块链间通信协议的性能分析",
                    "abstract_zh": "随着区块链之间通信需求的增加，提高跨链通信协议的性能成为一个新的挑战。我们通过全面评估Cosmos Network的区块链间通信协议，朝着分析跨链通信协议的局限性迈出了第一步。为了实现我们的目标，我们引入了一个新的框架来指导跨链通信协议的经验评估。我们实现了一个框架实例作为评估IBC协议的工具。我们的发现强调了几个挑战，如高事务确认延迟，区块链RPC实现中的瓶颈和阻碍跨链消息中继器可伸缩性的并发问题。我们还展示了在提交大额转账时，如何将完成跨链转账所需的时间减少70%。最后，我们讨论了部署过程中面临的挑战，目的是促进跨链通信的发展和进步。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00027",
                    "title": "MalAder: Decision-Based Black-Box Attack Against API Sequence Based Malware Detectors",
                    "authors": "Xiaohui Chen, Lei Cui, Hui Wen, Zhi Li, Hongsong Zhu, Zhiyu Hao, Limin Sun",
                    "abstract": "The API call sequence based malware detectors have proven to be promising, especially when incorporated with deep neural networks (DNNs). Several adversarial attack methods are proposed to fool these detectors by introducing undetectable perturbations into normal samples. However, in real-world scenarios, the malware detector provides only the predicted label for a given sample, without exposing its network architecture or output probability, making it challenging for adversarial attacks under the decision-based black-box. Existing work in this area typically relies on random-based methods that suffer high costs and low attack success rates. To address these limitations, we propose a novel decision-based black-box attack against API sequence based malware detectors, called MalAder. Our approach aims to improve the attack success rate as well as query efficiency through a directional perturbation algorithm. First, it utilizes attention-based API ranking to assess the importance of API calls in the context of different API sequences. This assessment guides the insertion position for perturbation. Then, the perturbation is carried out using benign distance perturbing, which gradually shortens the semantic distance from adversarial API sequences to a set of benign samples. Finally, our algorithm iteratively generates adversarial malware samples by performing perturbations. In addition, we have implemented MalAder and evaluated its performance against two classic malware detectors. The results show that MalAder outperforms state-of-the-art decision-based black-box adversarial attacks, proving its effectiveness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "MalAder:针对基于API序列的恶意软件检测器的基于决策的黑盒攻击",
                    "abstract_zh": "基于API调用序列的恶意软件检测器已被证明是有前途的，尤其是当与深度神经网络(DNNs)结合时。提出了几种对抗性攻击方法，通过在正常样本中引入不可检测的扰动来欺骗这些检测器。然而，在现实世界的场景中，恶意软件检测器只提供给定样本的预测标签，而不暴露其网络架构或输出概率，这使得基于决策的黑盒下的对抗性攻击具有挑战性。该领域的现有工作通常依赖于基于随机的方法，这些方法成本高，攻击成功率低。为了解决这些限制，我们提出了一种新的基于决策的针对基于API序列的恶意软件检测器的黑盒攻击，称为MalAder。我们的方法旨在通过方向扰动算法提高攻击成功率和查询效率。首先，它利用基于注意力的API排序来评估不同API序列上下文中API调用的重要性。这种评估指导了扰动的插入位置。然后，使用良性距离扰动进行扰动，这逐渐缩短了从对立API序列到良性样本集的语义距离。最后，我们的算法通过执行扰动迭代地生成敌对的恶意软件样本。此外，我们已经实现了MalAder，并针对两个经典的恶意软件检测器评估了它的性能。实验结果表明，MalAder优于当前最先进的基于决策的黑盒对抗攻击，证明了其有效性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00028",
                    "title": "Tabby: Automated Gadget Chain Detection for Java Deserialization Vulnerabilities",
                    "authors": "Xingchen Chen, Baizhu Wang, Ze Jin, Yun Feng, Xianglong Li, Xincheng Feng, Qixu Liu",
                    "abstract": "Java is one of the preferred options of modern developers and has become increasingly more prominent with the prevalence of the open-source culture. Thanks to the serialization and deserialization features, Java programs have the flexibility to transmit object data between multiple components or systems, which significantly facilitates development. However, the features may also allow the attackers to construct gadget chains and lead to Java deserialization vulnerabilities. Due to the highly flexible and customizable nature of Java deserialization, finding an exploitable gadget chain is complicated and usually costs researchers a great deal of effort to confirm the vulnerability. To break such a dilemma, in this paper, we introduced Tabby, a highly accurate framework that leverages the Soot framework and Neo4j graph database for finding Java deserialization gadget chains. We leveraged Tabby to analyze 248 Jar files, found 80 practical gadget chains, and received 7 CVE-IDs from Xstream and Apache Dubbo. They both improved the security design to deal with potential security risks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "tabby:Java反序列化漏洞的自动小工具链检测",
                    "abstract_zh": "Java是现代开发人员的首选之一，随着开源文化的流行，它变得越来越重要。得益于序列化和反序列化特性，Java程序可以灵活地在多个组件或系统之间传输对象数据，这极大地方便了开发。但是，这些功能也可能允许攻击者构建小工具链，并导致Java反序列化漏洞。由于Java反序列化的高度灵活性和可定制性，寻找可利用的小工具链是复杂的，并且通常需要研究人员花费大量精力来确认漏洞。为了打破这样的困境，在本文中，我们介绍了Tabby，这是一个高度精确的框架，它利用Soot框架和Neo4j图形数据库来查找Java反序列化小工具链。我们利用Tabby分析了248个Jar文件，发现了80个实用的小工具链，并从Xstream和Apache Dubbo收到了7个CVE id。他们都改进了安全设计，以应对潜在的安全风险。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00029",
                    "title": "TagClass: A Tool for Extracting Class-Determined Tags from Massive Malware Labels via Incremental Parsing",
                    "authors": "Yongkang Jiang, Gaolei Li, Shenghong Li",
                    "abstract": "VirusTotal is widely used for malware annotation by providing malware labels from a large set of anti-malware engines. A long-standing challenge in using these inconsistent labels is extracting class-determined tags. In this paper, we present Tagclass,a tool based on incremental parsing to associate tags with their corresponding family, behavior, and platform classes. Tagclasstreats behavior and platform tags as locators and achieves incremental parsing by introducing and iterating the following two algorithms: 1) location first search, which hits family tags using locators, and 2) co-occurrence first search, which finds new locators by family tags. Experiments across two benchmark datasets indicate Tagclassoutperforms existing methods, improving the parsing accuracy by 21% and 28%, respectively. To the best of our knowledge, Tagclassis the first tag class-determined malware label parsing tool, which would pave the way for research on crowdsourcing malware annotation. Tagclasshas been released to the community 11https://github.com/crowdma/tagclass.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "TagClass:通过增量解析从大量恶意软件标签中提取类别确定标签的工具",
                    "abstract_zh": "VirusTotal通过提供来自大量反恶意软件引擎的恶意软件标签，广泛用于恶意软件注释。使用这些不一致标签的一个长期挑战是提取类别确定的标签。在本文中，我们介绍了Tagclass，这是一个基于增量解析的工具，用于将标签与其对应的系列、行为和平台类相关联。tag class将行为和平台标签视为定位器，并通过引入和迭代以下两种算法来实现增量解析:1)位置优先搜索，使用定位器找到家族标签；2)共现优先搜索，通过家族标签找到新的定位器。在两个基准数据集上的实验表明，tag class优于现有方法，解析精度分别提高了21%和28%。据我们所知，tag class是第一个确定标签类别的恶意软件标签解析工具，这将为众包恶意软件注释的研究铺平道路。tagclass已发布到社区11 https://github . com/crowd ma/tag class。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00030",
                    "title": "Āpta: Fault-tolerant object-granular CXL disaggregated memory for accelerating FaaS",
                    "authors": "Adarsh Patil, Vijay Nagarajan, Nikos Nikoleris, Nicolai Oswald",
                    "abstract": "As cloud workloads increasingly adopt the fault-tolerant Function-as-a-Service (FaaS) model, demand for improved performance has increased. Alas, the performance of FaaS applications is heavily bottlenecked by the remote object store in which FaaS objects are maintained. We identify that the upcoming CXL-based cache-coherent disaggregated memory is a promising technology for maintaining FaaS objects. Our analysis indicates that CXL's low-latency, high-bandwidth access characteristics coupled with compute-side caching of objects, provides significant performance potential over an in-memory RDMA-based object store. We observe however that CXL lacks the requisite level of fault-tolerance necessary to operate at an inter-server scale within the datacenter. Furthermore, its cache-line granular accesses impose inefficiencies for object-granular data store accesses. We propose Āpta, a CXL-based object-granular memory interface for maintaining FaaS objects. Āpta's key innovation is a novel fault-tolerant coherence protocol for keeping the cached objects consistent without compromising availability in the face of compute server failures. Our evaluation of Āpta using 6 full FaaS application workflows (totaling 26 functions) indicates that it outperforms a state-of-the-art fault-tolerant object caching protocol on an RDMA-based system by 21-90% and an uncached CXL-based system by 15-42%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "pta:用于加速FaaS的容错对象粒度CXL分解内存",
                    "abstract_zh": "随着云工作负载越来越多地采用容错功能即服务(FaaS)模型，提高性能的需求也在增加。唉，FaaS应用程序的性能受到维护FaaS对象的远程对象存储的严重限制。我们发现，即将推出的基于CXL的缓存一致分解内存是一种很有前途的维护FaaS对象的技术。我们的分析表明，CXL的低延迟、高带宽访问特性与对象的计算端缓存相结合，提供了超越内存中基于RDMA的对象存储的巨大性能潜力。然而，我们观察到CXL缺乏在数据中心内服务器间规模运行所需的容错能力。此外，其缓存行粒度访问导致对象粒度数据存储访问效率低下。我们提出了pta，一个用于维护FaaS对象的基于CXL的对象粒度内存接口。pta的主要创新是一种新颖的容错一致性协议，用于在计算服务器出现故障时保持缓存对象的一致性，而不影响可用性。我们使用6个完整的FaaS应用程序工作流(总共26个函数)对pta进行了评估，结果表明，在基于RDMA的系统上，它的性能比一流的容错对象缓存协议高出21-90%，在基于CXL的非缓存系统上，它的性能比后者高出15-42%。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00031",
                    "title": "HiMFP: Hierarchical Intelligent Memory Failure Prediction for Cloud Service Reliability",
                    "authors": "Qiao Yu, Wengui Zhang, Paolo Notaro, Soroush Haeri, Jorge Cardoso, Odej Kao",
                    "abstract": "In large-scale datacenters, memory failure is one of the leading causes of server crashes, and uncorrectable error (UCE) is the major fault type indicating defects of memory modules. Existing approaches tend to predict UCEs using Correctable Errors (CE). However, bit-level CE information has not been completely discussed in previous works and CEs with error bit patterns are strongly correlated with UCE occurrences. In this paper, we present a novel Hierarchical Intelligent Memory Failure Prediction (HiMFP) framework which can predict UCEs on multiple levels of the memory system and associate with memory recovery techniques. Particularly, we leverage CE addresses on multiple levels of memory, especially bit-level, and construct machine learning models based on spatial and temporal CE information. Results of algorithm evaluation using real-world datasets indicate that HiMFP significantly enhances the prediction performance compared with the baseline algorithm. Overall, Virtual Machines (VM) interruptions caused by UCEs can be reduced by around 45% using HiMFP.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "HiMFP:面向云服务可靠性的分层智能内存失效预测",
                    "abstract_zh": "在大规模数据中心中，内存故障是服务器崩溃的主要原因之一，不可修复错误(UCE)是指示内存模块缺陷的主要故障类型。现有的方法倾向于使用可校正误差(CE)来预测UCEs。然而，在先前的工作中没有完全讨论比特级CE信息，并且具有错误比特模式的CE与UCE出现强烈相关。在本文中，我们提出了一个新的层次智能内存失效预测框架，该框架可以预测内存系统多个层次上的失效，并与内存恢复技术相结合。特别地，我们利用多级存储器上的CE地址，尤其是位级，并基于空间和时间CE信息构建机器学习模型。使用真实数据集的算法评估结果表明，与基线算法相比，HiMFP显著提高了预测性能。总体而言，使用HiMFP可以将由uce导致的虚拟机(VM)中断减少45%左右。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00032",
                    "title": "SGX Switchless Calls Made Configless",
                    "authors": "Peterson Yuhala, Michael Paper, Timothée Zerbib, Pascal Felber, Valerio Schiavoni, Alain Tchana",
                    "abstract": "Intel's software guard extensions (SGX) provide hardware enclaves to guarantee confidentiality and integrity for sensitive code and data. However, systems leveraging such security mechanisms must often pay high performance overheads. A major source of this overhead is SGX enclave transitions which induce expensive cross-enclave context switches. The Intel SGX SDK mitigates this with a switchless call mechanism for transitionless cross-enclave calls using worker threads. Intel's SGX switchless call implementation improves performance but provides limited flexibility: developers need to statically fix the system configuration at build time, which is error-prone and misconfigurations lead to performance degradations and waste of CPU resources. ZC-Switchless is a configless and efficient technique to drive the execution of SGX switchless calls. Its dynamic approach optimises the total switchless worker threads at runtime to minimise CPU waste. The experimental evaluation shows that ZC-Switchless obviates the performance penalty of misconfigured switchless systems while minimising CPU waste.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "SGX无交换机呼叫进行无配置",
                    "abstract_zh": "英特尔软件保护扩展(SGX)提供硬件飞地，以保证敏感代码和数据的机密性和完整性。然而，利用这种安全机制的系统通常必须支付高性能开销。这种开销的一个主要来源是SGX飞地转换，这会导致昂贵的跨飞地上下文切换。英特尔SGX SDK通过使用工作线程的无切换跨域调用机制缓解了这一问题。英特尔的SGX无交换呼叫实现提高了性能，但灵活性有限:开发人员需要在构建时静态地固定系统配置，这很容易出错，错误配置会导致性能下降和CPU资源浪费。ZC无交换是一种无需配置的高效技术，用于驱动SGX无交换呼叫的执行。它的动态方法优化了运行时的无交换机工作线程总数，以最大限度地减少CPU浪费。实验评估表明，ZC无交换避免了错误配置的无交换系统的性能损失，同时最大限度地减少了CPU浪费。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00033",
                    "title": "Poisoning Online Learning Filters by Shifting on the Move",
                    "authors": "Wesley Joon-Wie Tann, Ee-Chien Chang",
                    "abstract": "The recent advancements in machine learning have led to a wave of interest in adopting online learning approaches for long-standing attack mitigation issues. In particular, DDoS attacks remain a significant threat to network service availability. These attacks have been well investigated under the assumption that malicious traffic originates from a single attack profile. Based on this premise, malicious traffic characteristics are assumed to be considerably different from legitimate traffic. In this paper, we introduce a poisoning attack that takes a contextual generative approach to generate shifting malicious traffic, studying its effects on online deep-learning DDoS filters. We investigate an adverse scenario where the attacker is “crafty”, switching profiles during attacks and generating erratic attack traffic. This elusive attacker manipulates contexts derived using stochastic modeling that capture the distributions of network traffic to poison the filters. To this end, we present a generative model MimicShift, capable of efficiently shifting its attack while retaining the originating traffic's intrinsic properties. Comprehensive experiments show that online learning filters are highly susceptible to poisoning attacks, sometimes faltering to 100% false-negative rates on the evaluation datasets.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "通过在移动中转移来毒害在线学习过滤器",
                    "abstract_zh": "机器学习的最新进展引发了对采用在线学习方法来解决长期存在的攻击缓解问题的兴趣。特别是，DDoS攻击仍然是网络服务可用性的重大威胁。在假定恶意流量来自单一攻击模式的情况下，这些攻击已经得到了充分的研究。基于这一前提，恶意流量的特征被认为与合法流量有很大不同。在本文中，我们介绍了一种采用上下文生成方法来生成移动恶意流量的中毒攻击，研究了它对在线深度学习DDoS过滤器的影响。我们研究了一个不利的场景，其中攻击者非常“狡猾”，在攻击期间切换配置文件并生成不稳定的攻击流量。这种难以捉摸的攻击者操纵使用随机建模获得的上下文，捕获网络流量的分布来毒害过滤器。为此，我们提出了一个生成模型MimicShift，它能够有效地转移攻击，同时保留原始流量的固有属性。全面的实验表明，在线学习过滤器非常容易受到中毒攻击，有时在评估数据集上达到100%的假阴性率。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00034",
                    "title": "YODA: Covert Communication Channel over Public DNS Resolvers",
                    "authors": "Sandip Saha, Sareena Karapoola, Chester Rebeiro, V. Kamakoti",
                    "abstract": "Enterprises are increasingly migrating to public domain name system (DNS) resolvers for reliability, cost optimizations, and, most importantly, improved security and user privacy. The integrated threat intelligence feeds at these resolvers enable easy identification and blocking of malicious exploits that use DNS queries. However, we observe that the shared local caches at these public DNS resolvers enable covert communication channels from otherwise secure enterprises accessible to any remote adversary, thus cautioning the migration to public DNS resolvers. We present YODA, a covert communication channel via public DNS resolvers that can exfiltrate sensitive information from a victim enterprise to a remote adversary. Unlike prior works, YODA overloads DNS queries for popular domains to transfer the data without revealing any identity of the adversary. Consequently, YODA cannot be blocked by domain name filtering. We demonstrate our attack on public DNS resolvers such as Google, Cloudflare, Quad9, OpenDNS, and LibreDNS. Our evaluations show that the adversary can achieve a bandwidth of 480bps with desktop devices.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "YODA:公共DNS解析器上的隐蔽通信通道",
                    "abstract_zh": "出于可靠性、成本优化以及最重要的改进安全性和用户隐私的考虑，企业越来越多地迁移到公共域名系统(DNS)解析器。这些解析器中集成的威胁情报源可以轻松识别和阻止使用DNS查询的恶意利用。然而，我们观察到，这些公共DNS解析器上的共享本地缓存使得来自其他安全企业的隐蔽通信信道可被任何远程对手访问，从而警告迁移到公共DNS解析器。我们介绍YODA，一个通过公共DNS解析器的隐蔽通信通道，它可以将敏感信息从受害企业泄露给远程对手。与以前的工作不同，YODA过载了对流行域名的DNS查询，以在不暴露对手身份的情况下传输数据。因此，域名过滤无法阻止YODA。我们展示了我们对诸如Google、Cloudflare、Quad9、OpenDNS和LibreDNS等公共DNS解析器的攻击。我们的评估表明，对手可以通过桌面设备实现480bps的带宽。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00035",
                    "title": "Targeted Privacy Attacks by Fingerprinting Mobile Apps in LTE Radio Layer",
                    "authors": "Jaejong Baek, Pradeep Kumar Duraisamy Soundrapandian, Sukwha Kyung, Ruoyu Wang, Yan Shoshitaishvili, Adam Doupé, Gail-Joon Ahn",
                    "abstract": "We investigate the feasibility of targeted privacy attacks using only information available in physical channels of LTE mobile networks and propose three privacy attacks to demonstrate this feasibility: mobile-app fingerprinting attack, history attack, and correlation attack. These attacks can reveal the geolocation of targeted mobile devices, the victim's app usage patterns, and even the relationship between two users within the same LTE network cell. An attacker also may launch these attacks stealthily by capturing radio signals transmitted over the air, using only a passive sniffer as equipment. To ensure the impact of these attacks on mobile users' privacy, we perform evaluations in both laboratory and real-world settings, demonstrating their practicality and dependability. Furthermore, we argue that these attacks can target not only 4G/LTE but also the evolving 5G standards.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "通过在LTE无线电层对移动应用进行指纹识别，实现有针对性的隐私攻击",
                    "abstract_zh": "我们研究了仅使用LTE移动网络的物理信道中可用的信息进行针对性隐私攻击的可行性，并提出了三种隐私攻击来证明这种可行性:移动应用指纹攻击、历史攻击和相关性攻击。这些攻击可以揭示目标移动设备的地理位置、受害者的应用使用模式，甚至同一LTE网络小区内两个用户之间的关系。攻击者也可以只使用被动嗅探器作为设备，通过捕捉空中传输的无线电信号来秘密地发起这些攻击。为了确保这些攻击对移动用户隐私的影响，我们在实验室和现实环境中进行了评估，展示了它们的实用性和可靠性。此外，我们认为这些攻击不仅可以针对4G/LTE，还可以针对正在发展的5G标准。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00036",
                    "title": "Fabricated Flips: Poisoning Federated Learning without Data",
                    "authors": "Jiyue Huang, Zilong Zhao, Lydia Y. Chen, Stefanie Roos",
                    "abstract": "Attacks on Federated Learning (FL) can severely reduce the quality of the generated models and limit the usefulness of this emerging learning paradigm that enables on-premise decentralized learning. However, existing untargeted attacks are not practical for many scenarios as they assume that i) the attacker knows every update of benign clients, or ii) the attacker has a large dataset to locally train updates imitating benign parties. In this paper, we propose a data-free untargeted attack (DFA) that synthesizes malicious data to craft adversarial models without eavesdropping on the transmission of benign clients at all or requiring a large quantity of task-specific training data. We design two variants of DFA, namely DFA-R and DFA-G, which differ in how they trade off stealthiness and effectiveness. Specifically, DFA-R iteratively optimizes a malicious data layer to minimize the prediction confidence of all outputs of the global model, whereas DFA-G interactively trains a malicious data generator network by steering the output of the global model toward a particular class. Experimental results on Fashion-MNIST, Cifar-10, and SVHN show that DFA, despite requiring fewer assumptions than existing attacks, achieves similar or even higher attack success rate than state-of-the-art untargeted attacks against various state-of-the-art defense mechanisms. Concretely, they can evade all considered defense mechanisms in at least 50% of the cases for CIFAR-10 and often reduce the accuracy by more than a factor of 2. Consequently, we design REFD, a defense specifically crafted to protect against data-free attacks. REFD leverages a reference dataset to detect updates that are biased or have a low confidence. It greatly improves upon existing defenses by filtering out the malicious updates and achieves high global model accuracy.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "捏造的翻转:毒害没有数据的联邦学习",
                    "abstract_zh": "对联邦学习(FL)的攻击会严重降低生成模型的质量，并限制这种新兴学习范式的有用性，这种学习范式支持现场分散学习。然而，现有的无目标攻击对于许多场景来说是不实际的，因为它们假设I)攻击者知道良性客户端的每个更新，或者ii)攻击者具有大的数据集来本地训练模仿良性方的更新。在本文中，我们提出了一种无数据的无目标攻击(DFA ),它合成恶意数据来构建敌对模型，而完全不窃听良性客户端的传输，也不需要大量特定任务的训练数据。我们设计了DFA的两种变体，即DFA-R和DFA-G，它们在如何权衡隐蔽性和有效性方面有所不同。具体而言，DFA-R迭代地优化恶意数据层，以最小化全局模型的所有输出的预测置信度，而DFA-G通过将全局模型的输出导向特定类别来交互式地训练恶意数据生成器网络。在时尚MNIST、Cifar-10和SVHN上的实验结果表明，尽管DFA比现有的攻击需要更少的假设，但在各种最新的防御机制下，DFA获得了与最新的无目标攻击相似甚至更高的攻击成功率。具体来说，对于CIFAR-10，它们可以在至少50%的情况下逃避所有考虑的防御机制，并且经常将准确性降低超过2倍。因此，我们设计了REFD，这是一种专门针对无数据攻击的防御手段。REFD利用参考数据集来检测有偏差或可信度低的更新。它通过过滤掉恶意更新极大地改进了现有的防御措施，并实现了高的全局模型准确性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00037",
                    "title": "Fortifying Federated Learning against Membership Inference Attacks via Client-level Input Perturbation",
                    "authors": "Yuchen Yang, Haolin Yuan, Bo Hui, Neil Zhenqiang Gong, Neil Fendley, Philippe Burlina, Yinzhi Cao",
                    "abstract": "Membership inference (MI) attacks are more diverse in a Federated Learning (FL) setting, because an adversary may be either an FL client, a server, or an external attacker. Existing defenses against MI attacks rely on perturbations to either the model's output predictions or the training process. However, output perturbations are ineffective in an FL setting, because a malicious server can access the model without output perturbation while training perturbations struggle to achieve a good utility. This paper proposes a novel defense, called CIP, to fortify FL against MI attacks via a client-level input perturbation during training and inference procedures. The key insight is to shift each client's local data distribution via a personalized perturbation to get a shifted model. CIP achieves a good balance between privacy and utility. Our evaluation shows that CIP causes accuracy to drop at most 0.7% while reducing attacks to random guessing.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "通过客户端级输入扰动增强联邦学习对抗成员推理攻击",
                    "abstract_zh": "成员推理(MI)攻击在联合学习(FL)环境中更加多样化，因为对手可能是FL客户端、服务器或外部攻击者。现有的对MI攻击的防御依赖于对模型输出预测或训练过程的扰动。然而，输出扰动在FL设置中是无效的，因为恶意服务器可以在没有输出扰动的情况下访问模型，而训练扰动努力实现良好的效用。本文提出了一种新的防御方法，称为CIP，通过在训练和推理过程中客户端级的输入扰动来加强FL对MI攻击的防御。关键的洞察力是通过个性化的扰动来改变每个客户的本地数据分布，以获得改变的模型。CIP在私密性和实用性之间取得了很好的平衡。我们的评估表明，CIP导致准确率最多下降0.7%，同时减少了对随机猜测的攻击。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00038",
                    "title": "ReFace: Adversarial Transformation Networks for Real-time Attacks on Face Recognition Systems",
                    "authors": "Shehzeen Hussain, Todd Huster, Chris Mesterharm, Paarth Neekhara, Farinaz Koushanfar",
                    "abstract": "In this work, we propose ReFace, a real-time, highly-transferable attack on face recognition models based on Adversarial Transformation Networks (ATNs). Past attacks on face recognition models require the adversary to solve an input-dependent optimization problem using gradient descent making the attack impractical in real-time. Such adversarial examples are also tightly coupled to the victim model and are not as successful in transferring to different models. We find that the white-box attack success rate of a pure U-Net ATN falls substantially short of gradient-based attacks like PGD on large face recognition datasets. We therefore propose a new architecture for ATNs that closes this gap while maintaining a 10000X speedup over PGD. Furthermore, we find that at a given perturbation magnitude, our ATN adversarial perturbations are more effective in transferring to new face recognition models than PGD. We demonstrate that our attacks transfer effectively to models with different architectures, loss functions, and training procedures. ReFace attacks can successfully deceive commercial face recognition services via transfer attack and reduce face identification accuracy from 82% to 16.4% for AWS SearchFaces API and Azure face verification accuracy from 91% to 50.1%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "ReFace:用于人脸识别系统实时攻击的对抗性变换网络",
                    "abstract_zh": "在这项工作中，我们提出了ReFace，一个实时的，高度可转移的攻击人脸识别模型的基础上的敌对转换网络(ATNs)。过去对人脸识别模型的攻击需要对手使用梯度下降来解决依赖于输入的优化问题，这使得攻击在实时上不切实际。这种对立的例子也与受害者模型紧密相连，在转移到不同的模型时不太成功。我们发现，在大型人脸识别数据集上，纯U-Net ATN的白盒攻击成功率远远低于PGD等基于梯度的攻击。因此，我们为ATNs提出了一种新的架构，可以缩小这个差距，同时保持比PGD快10000倍的速度。此外，我们发现，在给定的扰动幅度下，我们的ATN对抗性扰动比PGD更有效地转移到新的人脸识别模型。我们证明了我们的攻击可以有效地转移到具有不同体系结构、损失函数和训练过程的模型。ReFace攻击可以通过transfer攻击成功欺骗商业人脸识别服务，并将AWS SearchFaces API的人脸识别准确率从82%降至16.4%，Azure人脸验证准确率从91%降至50.1%。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00039",
                    "title": "No Free Lunch: On the Increased Code Reuse Attack Surface of Obfuscated Programs",
                    "authors": "Naiqian Zhang, Daroc Alden, Dongpeng Xu, Shuai Wang, Trent Jaeger, Wheeler Ruml",
                    "abstract": "Obfuscation has been widely employed to protect software from the malicious reverse analysis. However, its security risks have not previously been studied in detail. For example, most obfuscation methods introduce large blocks of opaque code that are black boxes to normal users. In this paper, we show that, indeed, obfuscation can increase the attack risk. Existing gadget search tools, while able to find more gadgets in obfuscated code, do not succeed in assembling them into more exploits. However, these tools use strict pattern matching, greedy searching strategies, and only very simple gadgets. We develop Gadget-Planner, a more flexible approach to building code-reuse attacks that overcomes previous limitations via symbolic execution and automated planning. In a study across both benchmark and real-world programs, this approach finds many more exploit payloads on obfuscated programs, both in terms of number and diversity.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "没有免费的午餐:混淆程序的代码重用攻击面增加",
                    "abstract_zh": "混淆被广泛用于保护软件免受恶意逆向分析。然而，它的安全风险以前没有被详细研究过。例如，大多数混淆方法引入了大量不透明的代码，这些代码对于普通用户来说是黑盒。在本文中，我们表明，的确，混淆可以增加攻击风险。现有的小工具搜索工具虽然能够在混淆的代码中找到更多的小工具，但不能成功地将它们组装成更多的漏洞。然而，这些工具使用严格的模式匹配、贪婪的搜索策略和非常简单的小工具。我们开发了Gadget-Planner，这是一种更灵活的构建代码重用攻击的方法，通过符号执行和自动化规划克服了以前的限制。在一项对基准程序和真实程序的研究中，这种方法在混淆程序上发现了更多的漏洞有效载荷，无论是在数量上还是在多样性上。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00040",
                    "title": "TransAST: A Machine Translation-Based Approach for Obfuscated Malicious JavaScript Detection",
                    "authors": "Yan Qin, Weiping Wang, Zixian Chen, Hong Song, Shigeng Zhang",
                    "abstract": "As an essential part of the website, JavaScript greatly enriches its functions. At the same time, JavaScript has become the most common attack payload on malicious websites. Although researchers are constantly proposing methods to detect malicious JavaScript, the emergence of obfuscation technology makes it difficult for previous approaches to detect disguised malicious JavaScript effectively. To solve this problem, we find that there are fixed templates for generating obfuscated code, which makes the original and obfuscated script have a mapping relationship in their structure. The structure information of the code is critical for malicious detection. Therefore, this paper proposes TransAST, a novel static detection method for obfuscated malicious JavaScript. Our approach's key is restoring the obfuscated JavaScript structure information by training the machine translation model. The experiment shows it can achieve 91.35% accuracy and 94.57% recall in the public dataset, which is 5.5% and 10.94% higher than the existing optimal method.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "TransAST:一种基于机器翻译的混淆恶意JavaScript检测方法",
                    "abstract_zh": "JavaScript作为网站必不可少的一部分，极大地丰富了其功能。与此同时，JavaScript已经成为恶意网站最常见的攻击载荷。尽管研究人员不断提出检测恶意JavaScript的方法，但混淆技术的出现使得以前的方法难以有效检测伪装的恶意JavaScript。针对这个问题，我们发现生成混淆代码有固定的模板，使得原脚本和混淆脚本在结构上有映射关系。代码的结构信息对于恶意检测至关重要。因此，本文提出了一种新的针对混淆恶意JavaScript的静态检测方法TransAST。我们的方法的关键是通过训练机器翻译模型来恢复混淆的JavaScript结构信息。实验表明，该方法在公共数据集上的准确率和召回率分别达到91.35%和94.57%，比现有的优化方法分别提高了5.5%和10.94%。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00041",
                    "title": "JSRevealer: A Robust Malicious JavaScript Detector against Obfuscation",
                    "authors": "Kunlun Ren, Weizhong Qiang, Yueming Wu, Yi Zhou, Deqing Zou, Hai Jin",
                    "abstract": "Due to the convenience and popularity of Web applications, they have become a prime target for attackers. As the main programming language for Web applications, many methods have been proposed for detecting malicious JavaScript, among which static analysis-based methods play an important role because of their high effectiveness and efficiency. However, obfuscation techniques are commonly used in JavaScript, which makes the features extracted by static analysis contain many useless and disguised features, leading to many false positives and false negatives in detection results. In this paper, we propose a novel method to find out the essential features related to the semantics of JavaScript code. Specifically, we develop JS-Revealer, a robust, effective, scalable, and interpretable detector for malicious JavaScript. To test the capabilities of JSRevealer, we conduct comparative experiments with four other state-of-the-art malicious JavaScript detection tools. The experimental results show that JSRevealer has an average F1 of 84.8% on the data obfuscated by different obfuscators, which is 21.6%, 22.3%, 18.7%, and 22.9% higher than the tools CUJO, ZOZZLE, JAST, and JSTAP, respectively. Moreover, the detection results of JSRevealer can be interpreted, which can provide meaningful insights for further security research.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "JSRevealer:一个强大的恶意JavaScript混淆检测器",
                    "abstract_zh": "由于Web应用程序的便利性和流行性，它们已经成为攻击者的主要目标。作为Web应用程序的主要编程语言，人们提出了许多检测恶意JavaScript的方法，其中基于静态分析的方法因其高效性和有效性而发挥了重要作用。但是JavaScript中普遍使用混淆技术，使得静态分析提取的特征包含很多无用的、伪装的特征，导致检测结果出现很多误报和漏报。在本文中，我们提出了一种新的方法来找出与JavaScript代码的语义相关的本质特征。具体来说，我们开发了JS-Revealer，这是一个健壮、有效、可伸缩和可解释的恶意JavaScript检测器。为了测试JSRevealer的功能，我们使用其他四种最先进的恶意JavaScript检测工具进行了对比实验。实验结果表明，JSRevealer对不同混淆器混淆后的数据的平均F1为84.8%，比工具CUJO、ZOZZLE、JAST和JSTAP分别高出21.6%、22.3%、18.7%和22.9%。此外，JSRevealer的检测结果可以被解释，这可以为进一步的安全研究提供有意义的见解。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00042",
                    "title": "Detection of e-Mobility-Based Attacks on the Power Grid",
                    "authors": "Dustin Kern, Christoph Krauß",
                    "abstract": "The increasing use of information and communication technology in power grids and connected e-mobility infrastructures enables cyber attacks. E-mobility infrastructure components such as Charge Points (CPs) or Electric Vehicles (EVs) could be used as attack vector on power grids via False Data Injection (FDI) or Manipulation of demand (Mad) attacks. To detect such attacks, Intrusion Detection Systems (IDSs) which are adapted to the specifics of e-mobility are required. In this paper, we propose a novel hybrid IDS for detecting e-mobility-based attacks on the power grid consisting of a rule-based IDS and an anomaly detection component using regression-based forecasting. The IDS is distributed among different e-mobility-related backend systems, namely Charge Point Operators (CPOs) and grid operators. We implemented our IDS and evaluate it on several data sets while simulating realistic attack scenarios to show the effectiveness of our approach. Our evaluation compares different IDS design choices and regression models. Especially, decision tree regression proved to be an effective base for detection at CPOs. By combining the distributed IDS reports of individual CPOs at the grid operator, the overall detection performance is further improved. The distributed nature of the system allows it to identify large-scale attacks effectively and thus robustly detect realistic threats to power grid operation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "基于电子移动性的电网攻击检测",
                    "abstract_zh": "电网和互联电动交通基础设施中越来越多地使用信息和通信技术，这为网络攻击创造了条件。通过虚假数据注入(FDI)或需求操纵(Mad)攻击，充电站(CP)或电动汽车(ev)等电动移动基础设施组件可能被用作电网上的攻击媒介。为了检测这种攻击，需要适应电子移动性的入侵检测系统(IDSs)。在本文中，我们提出了一种新的混合入侵检测系统，用于检测电网上基于移动性的攻击，该系统由基于规则的入侵检测系统和基于回归预测的异常检测组件组成。IDS分布在不同的与电动交通相关的后端系统中，即充电点运营商(CPO)和电网运营商。我们实现了我们的入侵检测系统，并在几个数据集上进行了评估，同时模拟了真实的攻击场景，以显示我们方法的有效性。我们的评估比较了不同的IDS设计选择和回归模型。特别地，决策树回归被证明是CPOs检测的有效基础。通过在网格运营商处组合各个CPO的分布式IDS报告，整体检测性能被进一步提高。该系统的分布式特性使其能够有效地识别大规模攻击，从而稳健地检测对电网运行的现实威胁。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00043",
                    "title": "SwarmFuzz: Discovering GPS Spoofing Attacks in Drone Swarms",
                    "authors": "Yingao Elaine Yao, Pritam Dash, Karthik Pattabiraman",
                    "abstract": "Swarm robotics, particularly drone swarms, are used in various safety-critical tasks. While a lot of attention has been given to improving swarm control algorithms for improved intelligence, the security implications of various design choices in swarm control algorithms have not been studied. We highlight how an attacker can exploit the vulnerabilities in swarm control algorithms to disrupt drone swarms. Specifically, we show that the attacker can target a swarm member (target drone) through GPS spoofing attacks, and indirectly cause other swarm members (victim drones) to veer from their course, resulting in a collision with an obstacle. We call these Swarm Propagation Vulnerabilities. In this paper, we introduce SwarmFuzz, a fuzzing framework to capture the attacker's ability, and efficiently find such vulnerabilities in swarm control algorithms. SwarmFuzz uses a combination of graph theory and gradient-guided optimization to find the potential attack parameters. Our evaluation on a popular swarm control algorithm shows that SwarmFuzz achieves an average success rate of 48.8% in finding vulnerabilities, and compared to random fuzzing, has a 10x higher success rate, and 3x lower runtime. We also find that swarms of a larger size are more vulnerable to this attack type, for a given spoofing distance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "SwarmFuzz:在无人机群中发现GPS欺骗攻击",
                    "abstract_zh": "群体机器人，尤其是无人机群体，用于各种安全关键任务。虽然为了提高智能而对改进群体控制算法给予了很多关注，但是还没有研究群体控制算法中各种设计选择的安全含义。我们强调了攻击者如何利用群体控制算法中的漏洞来扰乱无人机群。具体来说，我们表明攻击者可以通过GPS欺骗攻击瞄准一个群成员(目标无人机)，并间接导致其他群成员(受害无人机)偏离他们的路线，导致与障碍物发生碰撞。我们称之为群体传播漏洞。在本文中，我们介绍了SwarmFuzz，一个模糊框架来捕捉攻击者的能力，并有效地发现这样的漏洞群控制算法。SwarmFuzz使用图论和梯度导向优化的组合来寻找潜在的攻击参数。我们对一种流行的群控制算法的评估表明，SwarmFuzz在发现漏洞方面的平均成功率为48.8%，与随机fuzzing相比，成功率高10倍，运行时间低3倍。我们还发现，对于给定的欺骗距离，更大规模的群体更容易受到这种攻击类型的攻击。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00044",
                    "title": "DNAttest: Digital-twin-based Non-intrusive Attestation under Transient Uncertainty",
                    "authors": "Wei Lin, Heng Chuan Tan, Binbin Chen, Fan Zhang",
                    "abstract": "Programmable logic controllers (PLCs) are vulnerable to malware, which is a key security risk for Industrial Control Systems (ICSs). Existing attestation solutions are invasive because they require hardware security modules and software upgrades in legacy devices. We propose DNAttest, a Digital-twin-based Noninvasive Attestation solution to attest PLC behaviors in near-real time. DNAttest requires minimal ICS infrastructure changes and does not interfere with normal ICS operations. DNAttest detects PLC deviations by replicating all input messages for a PLC to its digital twin and comparing their output messages. Due to transient uncertainty in the PLC's internal processing state, DNAttest may output an incorrect comparison. To generate all plausible output values for comparison, we instantiate multiple emulated PLCs by replicating input messages with different timing profiles. We demonstrate on a close-to-real-world power grid testbed that DNAttest can provide a timely detection of a wide range of attacks non-invasively and accurately. DNAttest solution is lightweight and scalable. A typical desktop PC can attest more than 20 actual PLCs even if we use 10 emulators to monitor every actual PLC.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "DNAttest:瞬时不确定性下基于数字孪生的非侵入式证明",
                    "abstract_zh": "可编程逻辑控制器(PLC)易受恶意软件攻击，这是工业控制系统(ICSs)的一个主要安全风险。现有的证明解决方案是侵入性的，因为它们需要传统设备中的硬件安全模块和软件升级。我们提出了DNAttest，一种基于Digital-twin的非侵入式证明解决方案，用于近实时证明PLC行为。DNAttest只需对ICS基础架构进行最少的更改，并且不会干扰正常的ICS操作。DNAttest通过将PLC的所有输入消息复制到其数字孪生兄弟并比较它们的输出消息来检测PLC偏差。由于PLC内部处理状态的瞬时不确定性，DNAttest可能会输出不正确的比较结果。为了生成所有似是而非的输出值进行比较，我们通过复制具有不同时序配置文件的输入消息来实例化多个仿真PLC。我们在一个接近真实世界的电网试验床上证明，DNAttest可以非侵入性地、准确地及时检测各种攻击。DNAttest解决方案是轻量级和可伸缩的。即使我们使用10个仿真器来监控每一个实际的PLC，一台典型的台式PC也可以测试20多个实际的PLC。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00045",
                    "title": "IRIS: a Record and Replay Framework to Enable Hardware-assisted Virtualization Fuzzing",
                    "authors": "Carmine Cesarano, Marcello Cinque, Domenico Cotroneo, Luigi De Simone, Giorgio Farina",
                    "abstract": "Nowadays, industries are looking into virtualization as an effective means to build safe applications, thanks to the isolation it can provide among virtual machines (VMs) running on the same hardware. In this context, a fundamental issue is understanding to what extent the isolation is guaranteed, despite possible (or induced) problems in the virtualization mechanisms. Uncovering such isolation issues is still an open challenge, especially for hardware-assisted virtualization, since the search space should include all the possible VM states (and the linked hypervisor state), which is prohibitive. In this paper, we propose IRIS, a framework to record (learn) sequences of inputs (i.e., VM seeds) from the real guest execution (e.g., OS boot), replay them as-is to reach valid and complex VM states, and finally use them as valid seed to be mutated for enabling fuzzing solutions for hardware-assisted hypervisors. We demonstrate the accuracy and efficiency of IRIS in automatically reproducing valid VM behaviors, with no need to execute guest workloads. We also provide a proof-of-concept fuzzer, based on the proposed architecture, showing its potential on the Xen hypervisor.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "IRIS:一个支持硬件辅助虚拟化模糊化的记录和回放框架",
                    "abstract_zh": "如今，由于虚拟化可以在相同硬件上运行的虚拟机(VM)之间提供隔离，各行业正在将虚拟化视为构建安全应用的有效手段。在这种情况下，一个基本问题是了解隔离的保证程度，尽管虚拟化机制中可能存在(或引发)问题。发现这种隔离问题仍然是一个公开的挑战，特别是对于硬件辅助虚拟化，因为搜索空间应该包括所有可能的虚拟机状态(和链接的虚拟机管理程序状态)，这是禁止的。在本文中，我们提出了IRIS，这是一个框架，用于记录(学习)来自真实客户执行(例如，操作系统引导)的输入序列(即，虚拟机种子)，按原样重放它们以达到有效和复杂的虚拟机状态，并最终使用它们作为有效种子进行变异，以实现硬件辅助虚拟机管理程序的模糊化解决方案。我们展示了IRIS在自动重现有效虚拟机行为方面的准确性和效率，无需执行客户工作负载。我们还提供了一个基于所提议的架构的概念验证fuzzer，展示了它在Xen hypervisor上的潜力。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00046",
                    "title": "Rewind & Discard: Improving Software Resilience using Isolated Domains",
                    "authors": "Merve Gülmez, Thomas Nyman, Christoph Baumann, Jan Tobias Mühlberg",
                    "abstract": "Well-known defenses exist to detect and mitigate common faults and memory safety vulnerabilities in software. Yet, many of these mitigations do not address the challenge of software resilience and availability, i.e., whether a system can continue to carry out its function and remain responsive, while being under attack and subjected to malicious inputs. In this paper we propose secure rewind and discard of isolated domains as an efficient and secure method of improving the resilience of software that is targeted by run-time attacks. In difference to established approaches, we rely on compartmentalization instead of replication and checkpointing. We show the practicability of our methodology by realizing a software library for Secure Domain Rewind and Discard (SDRaD) and demonstrate how SDRaD can be applied to real-world software.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "倒带和丢弃:使用隔离域提高软件弹性",
                    "abstract_zh": "存在众所周知的防御措施来检测和减轻软件中的常见故障和内存安全漏洞。然而，这些缓解措施中的许多没有解决软件弹性和可用性的挑战，即，当受到攻击和遭受恶意输入时，系统是否能够继续执行其功能并保持响应。在本文中，我们提出了安全回卷和丢弃孤立域作为一种有效和安全的方法来提高软件的弹性，这是由运行时攻击的目标。与已建立的方法不同，我们依赖于划分，而不是复制和检查点。我们通过实现一个用于安全域倒带和丢弃(SDRaD)的软件库来展示我们的方法的实用性，并演示SDRaD如何应用于现实世界的软件。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00047",
                    "title": "Intrusion Injection for Virtualized Systems: Concepts and Approach",
                    "authors": "Charles F. Gonçalves, Nuno Antunes, Marco Vieira",
                    "abstract": "Virtualization is drawing attention due to countless benefits, leaving Hypervisors with the paramount responsibility for performance, dependability, and security. However, while there are consolidated approaches to assessing the performance and dependability of virtualized systems, solutions to assess security are very limited. Key difficulties are evaluating the system in the presence of unknown attacks and vulnerabilities and comparing the security attributes of different systems and configurations when an intrusion occurs. In this paper, we propose a novel concept and approach of intrusion injection for virtualized environments, which consists of directly driving the system into the erroneous states that mimic the ones resulting from actual intrusions (in the same way errors are injected to mimic the effects of residual faults). We present a prototype capable of injecting erroneous states related to memory-corruption in the Xen Hypervisor to show that the concept and approach proposed here are feasible. The prototype is evaluated using publicly disclosed exploits across three different versions of Xen. Results show that our tool can inject erroneous states equivalent to those resulting from attacks that exploit existing vulnerabilities, even on versions where those vulnerabilities do not exist.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "虚拟化系统的入侵注入:概念和方法",
                    "abstract_zh": "虚拟化因其无数的优势而备受关注，让虚拟机管理程序承担起性能、可靠性和安全性的首要责任。然而，尽管有统一的方法来评估虚拟化系统的性能和可靠性，但评估安全性的解决方案却非常有限。关键的困难是在存在未知攻击和漏洞的情况下评估系统，以及在入侵发生时比较不同系统和配置的安全属性。在本文中，我们提出了一种针对虚拟化环境的入侵注入的新概念和方法，包括直接驱动系统进入模拟实际入侵所导致的错误状态(以相同的方式注入错误以模拟残余故障的影响)。我们展示了一个原型，它能够在Xen Hypervisor中注入与内存损坏相关的错误状态，以表明这里提出的概念和方法是可行的。使用公开披露的跨越三个不同版本Xen的漏洞对原型进行评估。结果表明，我们的工具可以注入与利用现有漏洞的攻击所产生的状态等同的错误状态，即使是在不存在这些漏洞的版本上。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00048",
                    "title": "vWitness: Certifying Web Page Interactions with Computer Vision",
                    "authors": "He Shuang, Lianying Zhao, David Lie",
                    "abstract": "Web servers service client requests, some of which might cause the web server to perform security-sensitive operations (e.g. money transfer, voting). An attacker may thus forge or maliciously manipulate such requests by compromising a web client. Unfortunately, a web server has no way of knowing whether the client from which it receives a request has been compromised or not-current “best practice” defenses such as user authentication or network encryption cannot aid a server as they all assume web client integrity. To address this shortcoming, we propose vWitness, which “witnesses” the interactions of a user with a web page and certifies whether they match a specification provided by the web server, enabling the web server to know that the web request is user-intended. The main challenge that vWitness overcomes is that even benign clients introduce unpredictable variations in the way they render web pages. vWitness differentiates between these benign variations and malicious manipulation using computer vision, allowing it to certify to the web server that 1) the web page user interface is properly displayed 2) observed user interactions are used to construct the web request. Our vWitness prototype achieves compatibility with modern web pages, is resilient to adversarial example attacks and is accurate and performant-vWitness achieves 99.97% accuracy and adds 197ms of overhead to the entire interaction session in the average case.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "vWitness:验证网页与计算机视觉的交互",
                    "abstract_zh": "Web服务器为客户端请求提供服务，其中一些请求可能会导致web服务器执行安全敏感的操作(例如，转账、投票)。因此，攻击者可以通过危害web客户端来伪造或恶意操纵此类请求。不幸的是，web服务器无法知道它从其接收请求的客户机是否已经被破坏——当前的“最佳实践”防御，如用户认证或网络加密，不能帮助服务器，因为它们都假定web客户机是完整的。为了解决这个缺点，我们提出了vWitness，它“见证”用户与网页的交互，并证明它们是否与web服务器提供的规范相匹配，从而使web服务器知道web请求是用户想要的。vWitness克服的主要挑战是，即使是良性客户端也会在呈现网页的方式中引入不可预测的变化。vWitness使用计算机视觉区分这些良性变化和恶意操作，允许它向web服务器证明1)网页用户界面显示正确2)观察到的用户交互用于构建web请求。我们的vWitness原型实现了与现代网页的兼容性，对对抗性示例攻击具有弹性，并且是准确和高性能的-vWitness实现了99.97%的准确性，并且在平均情况下给整个交互会话增加了197毫秒的开销。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00049",
                    "title": "Adaptive Webpage Fingerprinting from TLS Traces",
                    "authors": "Vasilios Mavroudis, Jamie Hayes",
                    "abstract": "In webpage fingerprinting, an on-path adversary infers the specific webpage loaded by a victim user by analysing the patterns in the encrypted TLS traffic exchanged between the user's browser and the website's servers. This work studies modern webpage fingerprinting adversaries against the TLS protocol; aiming to shed light on their capabilities and inform potential defences. Despite the importance of this research area (the majority of global Internet users rely on standard web browsing with TLS) and the potential real-life impact, most past works have focused on attacks specific to anonymity networks (e.g., Tor). We introduce a TLS-specific model that: 1) scales to an unprecedented number of target webpages, 2) can accurately classify thousands of classes it never encountered during training, and 3) has low operational costs even in scenarios of frequent page updates. Based on these findings, we then discuss TLS-specific countermeasures and evaluate the effectiveness of the existing padding capabilities provided by TLS 1.3.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "基于TLS轨迹的自适应网页指纹识别",
                    "abstract_zh": "在网页指纹识别中，路径上的对手通过分析用户浏览器和网站服务器之间交换的加密TLS流量中的模式来推断受害用户加载的特定网页。这项工作研究现代网页指纹对手对TLS协议；旨在了解他们的能力并为潜在的防御提供信息。尽管这一研究领域非常重要(大多数全球互联网用户依赖使用TLS的标准网页浏览)并且具有潜在的现实影响，但大多数过去的工作都集中在针对匿名网络(例如Tor)的攻击上。我们引入了一个特定于TLS的模型，该模型:1)可以扩展到前所未有的目标网页数量，2)可以准确地分类成千上万个在训练中从未遇到过的类别，3)即使在页面频繁更新的情况下也具有较低的运营成本。基于这些发现，我们然后讨论TLS特定的对策，并评估TLS 1.3提供的现有填充功能的有效性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00050",
                    "title": "IDTracker: Discovering Illicit Website Communities via Third-party Service IDs",
                    "authors": "Chenxu Wang, Zhao Li, Jiangyi Yin, Zhenni Liu, Zhongyi Zhang, Qingyun Liu",
                    "abstract": "Illicit websites are restricted by governments and application marketplaces due to their detrimental impact on society. Third-party web services play a crucial role in enabling illicit webmasters to establish websites rapidly and evade detection. In this paper, we discover that third-party services usually assign unique credentials to website developers as their identifications (IDs). Websites using the same services with identical IDs are likely to be hosted on shared infrastructures and have textually similar domain names. This observation sparks the idea of building a community of illicit websites by leveraging third-party service IDs. Therefore, we design IDTracker, a novel system for detecting illicit website communities based on domain name semantic and infrastructure relationship features, which empower classification algorithms to achieve a high F1 score of 0.8968. Furthermore, we deploy IDTracker on an Internet Service Provider's (ISP) environment for three months and identify 6,830 illicit communities containing 165,378 illicit websites. Many of these illicit websites can not be identified by the most sophisticated engines, such as Symantec and Baidu, because of the cloaking tactics. In addition, we conduct a large-scale and long-term measurement on the network infrastructures and third-party services of illicit communities, revealing new phenomena. Our findings can help security communities to thwart illicit websites more effectively.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "IDTracker:通过第三方服务id发现非法网站社区",
                    "abstract_zh": "非法网站因其对社会的有害影响而受到政府和应用市场的限制。第三方网络服务在使非法网站管理员快速建立网站并逃避检测方面起着至关重要的作用。在本文中，我们发现第三方服务通常为网站开发者分配唯一的凭证作为他们的身份标识。使用相同id的相同服务的网站很可能托管在共享的基础设施上，并且具有文本相似的域名。这一观察激发了通过利用第三方服务id来构建非法网站社区的想法。因此，我们设计了IDTracker，这是一种基于域名语义和基础设施关系特征来检测非法网站社区的新系统，它使分类算法能够实现0.8968的高F1分数。此外，我们在一家互联网服务提供商(ISP)的环境中部署了为期三个月的IDTracker，发现了包含165，378个非法网站的6，830个非法社区。由于伪装策略，许多这些非法网站无法被最复杂的引擎识别，如赛门铁克和百度。此外，我们对非法社区的网络基础设施和第三方服务进行了大规模和长期的测量，揭示了新的现象。我们的发现可以帮助安全社区更有效地阻止非法网站。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00051",
                    "title": "Creating a Large-scale Memory Error IoT Botnet Using NS3DockerEmulator",
                    "authors": "Islam Obaidat, Bennett Kahn, Fatemeh Tavakoli, Meera Sridhar",
                    "abstract": "DDoSim, a simulation testbed for mimicking real-world, large-scale botnet DDoS attacks, is presented. DDoSim offers various capabilities, including running user-specified software, testing botnet-recruitment exploits, and measuring the severity of resulting DDoS attacks. DDoSim leverages NS3DockerEmulator's Docker and NS-3 integration to load Docker containers with actual binaries and connect them over a simulated NS-3 network. DDoSim is validated through a comparison with results from real hardware experiments. This paper focuses on the results of an experiment series concerning deploying a memory error botnet on IoT devices. Unlike the Mirai attack, which relies on default credentials, these experiments exploit memory error vulnerabilities to access IoT devices. DDoSim also implements realistic IoT churn, reflecting dynamic network conditions in real-world IoT environments. The results reveal that memory error vulnerabilities enable botnet recruitment, while network conditions, attack size, and duration all have a proportional impact on target servers. DDoSim is publicly available for researchers' use.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "使用NS3DockerEmulator创建大规模内存错误物联网僵尸网络",
                    "abstract_zh": "DDoSim是一个模拟真实世界的大规模僵尸网络DDoS攻击的模拟实验床。DDoSim提供各种功能，包括运行用户指定的软件，测试僵尸网络招募漏洞，以及测量由此导致的DDoS攻击的严重性。DDoSim利用s Docker和NS-3集成来加载Docker容器和实际的二进制文件，并通过模拟的NS-3网络连接它们。通过与真实硬件实验结果的比较，验证了DDoSim的有效性。本文重点介绍了一系列关于在物联网设备上部署内存错误僵尸网络的实验结果。与依赖默认凭据的Mirai未来组合攻击不同，这些实验利用内存错误漏洞来访问物联网设备。DDoSim还实现了真实的物联网搅动，反映了真实世界物联网环境中的动态网络条件。结果显示，内存错误漏洞会导致僵尸网络招募，而网络条件、攻击规模和持续时间都会对目标服务器产生相应的影响。DDoSim可供研究人员公开使用。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00052",
                    "title": "DARPA: Combating Asymmetric Dark UI Patterns on Android with Run-time View Decorator",
                    "authors": "Zhaoxin Cai, Yuhong Nan, Xueqiang Wang, Mengyi Long, Qihua Ou, Min Yang, Zibin Zheng",
                    "abstract": "It has been extensively discussed that online services, such as shopping websites, may exploit dark user interface (UI) patterns to mislead users into performing unwanted and even harmful activities on the UI, e.g., subscribing to recurring purchases unknowingly. Most recently, the growing popularity of mobile platforms has led to an ever-extending reach of dark UI patterns in mobile apps, leading to security and privacy risks to end users. A systematic study of such patterns, including how to detect and mitigate them on mobile platforms, unfortunately, has not been conducted. In this paper, we fill the research gap by investigating the dark UI patterns in mobile apps. Specifically, we show the prevalence of the asymmetric dark UI patterns (AUI) in real-world apps, and reveal their risks by characterizing the AUI (e.g., subjects, hosts, and patterns). Then, through user studies, we demonstrate the demand for effective solutions to mitigate the potential risks of AUI. To meet the needs, we propose DARPA - an end-to-end and generic CV-based solution to identify AUIs at run-time and mitigate the risks by highlighting the AUIs with run-time UI decoration. Our evaluation shows that DARPA is highly accurate and introduces negligible overhead. Additionally, running DARPA does not require any modifications to the apps being analyzed and to the operating system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "DARPA:用运行时视图装饰器对抗Android上不对称的深色UI模式",
                    "abstract_zh": "已经广泛讨论了诸如购物网站之类的在线服务可能利用黑暗用户界面(UI)模式来误导用户在UI上执行不想要的甚至有害的活动，例如在不知情的情况下订阅重复购买。最近，移动平台越来越受欢迎，导致移动应用程序中的黑色UI模式不断扩展，给最终用户带来了安全和隐私风险。不幸的是，还没有对这种模式进行系统的研究，包括如何在移动平台上检测和缓解它们。在本文中，我们通过研究移动应用程序中的暗UI模式来填补研究空白。具体来说，我们展示了现实应用中非对称暗UI模式(AUI)的流行，并通过表征AUI(例如，主题、主机和模式)揭示了它们的风险。然后，通过用户研究，我们展示了对有效解决方案的需求，以减轻AUI的潜在风险。为了满足这种需求，我们提出了DARPA——一种端到端的通用的基于CV的解决方案，用于在运行时识别aui，并通过用运行时UI装饰突出显示aui来降低风险。我们的评估表明DARPA是高度准确的，并且引入的开销可以忽略不计。此外，运行DARPA不需要对正在分析的应用程序和操作系统进行任何修改。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00053",
                    "title": "IoT Anomaly Detection Via Device Interaction Graph",
                    "authors": "Jincheng Wang, Zhuohua Li, Mingshen Sun, Bin Yuan, John C. S. Lui",
                    "abstract": "With diverse functionalities and advanced platform applications, Internet of Things (IoT) devices extensively interact with each other, and these interactions govern the legitimate device state transitions. At the same time, attackers can easily manipulate these devices, and it is difficult to detect covert device control. In this work, we propose the device interaction graph, which uses device interactions to profile normal device behavior. We also formalize two types of device anomalies, and present an anomaly detection system CausalIoT. It can automatically construct the graph and validate runtime device events. For any violation of interaction executions, CausalIoT further checks whether it can trigger unexpected interaction executions and tracks the affected devices.1 Compared with existing methods, CausalIoT achieves the highest detection accuracy for abnormal device state transitions (95.2% precision and 96.8% recall). Moreover, we are the first to detect unexpected interaction executions, and CausalIoT successfully reports 91.9% anomaly chains on real-world testbeds.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "基于设备交互图的物联网异常检测",
                    "abstract_zh": "凭借多样化的功能和先进的平台应用，物联网(IoT)设备广泛地相互交互，这些交互控制着合法的设备状态转换。同时，攻击者可以很容易地操纵这些设备，很难检测到隐蔽的设备控制。在这项工作中，我们提出了设备交互图，它使用设备交互来描述正常的设备行为。我们还形式化了两种类型的设备异常，并提出了一个异常检测系统CausalIoT。它可以自动构建图形并验证运行时设备事件。对于任何违反交互执行的情况，CausalIoT会进一步检查是否会触发意外的交互执行，并跟踪受影响的设备。1与现有方法相比，CausalIoT对异常设备状态转换的检测准确率最高(95.2%的精确度和96.8%的召回率)。此外，我们是第一个检测到意外交互执行的，CausalIoT成功报告了现实世界测试床上91.9%的异常链。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00054",
                    "title": "Time Machine: Generative Real-Time Model for Failure (and Lead Time) Prediction in HPC Systems",
                    "authors": "Khalid Ayedh Alharthi, Arshad Jhumka, Sheng Di, Lin Gui, Franck Cappello, Simon McIntosh-Smith",
                    "abstract": "High Performance Computing (HPC) systems generate a large amount of unstructured/alphanumeric log messages that capture the health state of their components. Due to their design complexity, HPC systems often undergo failures that halt applications (e.g., weather prediction, aerodynamics simulation) execution. However, existing failure prediction methods, which typically seek to extract some information theoretic features, fail to scale both in terms of accuracy and prediction speed, limiting their adoption in real-time production systems. In this paper, differently from existing work and inspired by current transformer-based neural networks which have revolutionized the sequential learning in the natural language processing (NLP) tasks, we propose a novel scalable log-based, self-supervised model (i.e., no need for manual labels), called Time Machine 11A Time Machine allows us to travel into the future to observe the health state of HPC system and report back. Here, we travel into the log extension to report an upcoming failure., that predicts (i) forthcoming log events (ii) the upcoming failure and its location and (iii) the expected lead time to failure. Time Machine is designed by combining two stacks of transformer-decoders, each employing the self-attention mechanism. The first stack addresses the failure location by predicting the sequence of log events and then identifying if a failure event is part of that sequence. The lead time to predicted failure is addressed by the second stack. We evaluate Time Machine on four real-world HPC log datasets and compare it against three state-of-the-art failure prediction approaches. Results show that Time Machine significantly outperforms the related works on Bleu, Rouge, MCC, and F1-score in predicting forthcoming events, failure location, failure lead-time, with higher prediction speed.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "时间机器:HPC系统中故障(和交付时间)预测的生成式实时模型",
                    "abstract_zh": "高性能计算(HPC)系统会生成大量非结构化/字母数字日志消息，这些消息可捕获其组件的运行状况。由于其设计的复杂性，HPC系统经常会出现中断应用程序(例如，天气预测、空气动力学模拟)执行的故障。然而，现有的故障预测方法通常试图提取一些信息理论特征，在准确性和预测速度方面都无法扩展，限制了它们在实时生产系统中的采用。在本文中，与现有的工作不同，并受基于当前变压器的神经网络的启发，该神经网络彻底改变了自然语言处理(NLP)任务中的顺序学习，我们提出了一种新的可扩展的基于日志的自监督模型(即，不需要手动标签)，称为时间机器11A时间机器允许我们旅行到未来，以观察HPC系统的健康状态并报告回来。这里，我们进入日志扩展来报告即将发生的故障。，预测(I)即将发生的日志事件(ii)即将发生的故障及其位置，以及(iii)预计的故障前时间。时间机器是通过组合两个变压器-解码器堆栈来设计的，每个堆栈都采用了自我关注机制。第一个堆栈通过预测日志事件的序列，然后识别故障事件是否是该序列的一部分，来确定故障位置。预测故障的交付时间由第二堆栈解决。我们在四个真实的HPC日志数据集上评估了Time Machine，并将其与三种最先进的故障预测方法进行了比较。结果表明，Time Machine在预测即将发生的事件、故障位置、故障提前期方面明显优于Bleu、Rouge、MCC和F1-score上的相关工作，具有更快的预测速度。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00055",
                    "title": "How Different are the Cloud Workloads? Characterizing Large-Scale Private and Public Cloud Workloads",
                    "authors": "Xiaoting Qin, Minghua Ma, Yuheng Zhao, Jue Zhang, Chao Du, Yudong Liu, Anjaly Parayil, Chetan Bansal, Saravan Rajmohan, Íñigo Goiri, Eli Cortez, Si Qin, Qingwei Lin, Dongmei Zhang",
                    "abstract": "With the rapid development of cloud systems, an increasing number of service workloads are deployed in the private cloud and/or public cloud. Although large cloud providers such as Azure and Google have published workload traces in the past, prior work has not focused on analyzing and characterizing the differences between private and public cloud workloads in detail. Based on our experience working with Azure, one of the most widely used cloud platforms in the world, we find that the workload characteristics are different between the private and public cloud workloads. Specifically, compared with the public cloud workloads, the private cloud workloads tend to be more homogeneous in both deployment sizes and utilization patterns, more static with occasional bursts in deployment characteristics, and more region-agnostic regarding the sensitivity to deployed regions. Our findings gain several insights and implications on cloud management and motivate us to build a centralized workload knowledge base.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "云工作负载的差异有多大？描述大规模私有云和公共云工作负载的特征",
                    "abstract_zh": "随着云系统的快速发展，越来越多的服务工作负载部署在私有云或公共云中。尽管Azure和Google等大型云提供商在过去发布了工作负载跟踪，但之前的工作并没有专注于详细分析和描述私有云和公共云工作负载之间的差异。根据我们使用Azure(世界上使用最广泛的云平台之一)的经验，我们发现私有云和公共云工作负载之间的工作负载特征是不同的。具体而言，与公共云工作负载相比，私有云工作负载在部署规模和利用模式方面更趋于同质，在部署特征方面更具静态性，偶尔会出现突发事件，并且在对部署区域的敏感性方面更不受区域限制。我们的发现获得了关于云管理的一些见解和启示，并激励我们构建一个集中式工作负载知识库。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00056",
                    "title": "On Adversarial Robustness of Point Cloud Semantic Segmentation",
                    "authors": "Jiacen Xu, Zhe Zhou, Boyuan Feng, Yufei Ding, Zhou Li",
                    "abstract": "Recent research efforts on 3D point cloud semantic segmentation (PCSS) have achieved outstanding performance by adopting neural networks. However, the robustness of these complex models have not been systematically analyzed. Given that PCSS has been applied in many safety-critical applications like autonomous driving, it is important to fill this knowledge gap, especially, how these models are affected under adversarial samples. As such, we present a comparative study of PCSS robustness. First, we formally define the attacker's objective under performance degradation and object hiding. Then, we develop new attack by whether to bound the norm. We evaluate different attack options on two datasets and three PCSS models. We found all the models are vulnerable and attacking point color is more effective. With this study, we call the attention of the research community to develop new approaches to harden PCSS models.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "点云语义分割的对抗鲁棒性研究",
                    "abstract_zh": "最近关于三维点云语义分割(PCSS)的研究工作通过采用神经网络取得了突出的性能。然而，这些复杂模型的稳健性还没有得到系统的分析。鉴于PCSS已应用于自动驾驶等许多安全关键应用，填补这一知识空白非常重要，特别是这些模型在敌对样本下如何受到影响。因此，我们提出了PCSS稳健性的比较研究。首先，我们在性能下降和对象隐藏的情况下正式定义攻击者的目标。然后，我们通过是否绑定规范来开发新的攻击。我们在两个数据集和三个PCSS模型上评估了不同的攻击选项。我们发现所有的模型都是脆弱的，攻击点颜色更有效。通过这项研究，我们呼吁研究界注意开发新的方法来强化PCSS模型。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00057",
                    "title": "Cost-Damage Analysis of Attack Trees",
                    "authors": "Milan Lopuhaä-Zwakenberg, Mariëlle Stoelinga",
                    "abstract": "Attack trees (ATs) are a widely deployed modelling technique to categorize potential attacks on a system. An attacker of such a system aims at doing as much damage as possible, but might be limited by a cost budget. The maximum possible damage for a given cost budget is an important security metric of a system. In this paper, we find the maximum damage given a cost budget by modelling this problem with ATs, both in deterministic and probabilistic settings. We show that the general problem is NP-complete, and provide heuristics to solve it. For general ATs these are based on integer linear programming. However when the AT is tree-structured, then one can instead use a faster bottom-up approach. We also extend these methods to other problems related to the cost-damage tradeoff, such as the cost-damage Pareto front.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "攻击树的代价损失分析",
                    "abstract_zh": "攻击树(ATs)是一种广泛部署的建模技术，用于对系统上的潜在攻击进行分类。这种系统的攻击者旨在造成尽可能多的损害，但可能会受到成本预算的限制。给定成本预算的最大可能损害是系统的一个重要安全指标。在本文中，我们通过在确定性和概率性设置中用ATs对该问题建模，找到给定成本预算的最大损害。我们表明，一般问题是NP-完全的，并提供启发式来解决它。对于一般的ATs，这些是基于整数线性规划的。然而，当AT是树形结构时，则可以使用更快的自底向上的方法。我们还将这些方法扩展到与成本-损失权衡相关的其他问题，如成本-损失帕累托前沿。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00058",
                    "title": "PASTA: Pragmatic Automated System-Theoretic Process Analysis",
                    "authors": "Jette Petzold, Jana Kreiß, Reinhard von Hanxleden",
                    "abstract": "System- Theoretic Process Analysis (STPA) is a relatively new hazard analysis technique. Several tools supporting the STPA process already exist. However, they are mostly textual. In this paper we present a Domain Specific Language (DSL) for STPA with an automatic visualization of the STPA components. This combines the advantages of textual and graphical approaches. The DSL is implemented with open source tooling, realized as a Visual Studio Code Extension using Langium for the language server and Sprotty for the visualization. A comparison suggests that the DSL has potential to be a good alternative to other STPA supporting tools.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "PASTA:实用自动化系统理论过程分析",
                    "abstract_zh": "系统理论过程分析(STPA)是一种相对较新的危险分析技术。支持STPA进程的若干工具已经存在。然而，它们大多是文本。在这篇文章中，我们提出了一种用于STPA的领域特定语言(DSL ),它具有STPA组件的自动可视化。这结合了文本和图形方法的优点。DSL是用开源工具实现的，作为一个Visual Studio代码扩展来实现，语言服务器使用Langium，可视化使用Sprotty。比较表明，DSL有潜力成为其他STPA支持工具的良好替代品。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00059",
                    "title": "Practical Asynchronous Distributed Key Generation: Improved Efficiency, Weaker Assumption, and Standard Model",
                    "authors": "Haibin Zhang, Sisi Duan, Chao Liu, Boxin Zhao, Xuanji Meng, Shengli Liu, Yong Yu, Fangguo Zhang, Liehuang Zhu",
                    "abstract": "Distributed key generation (DKG) allows bootstrapping threshold cryptosystems without relying on a trusted party, nowadays enabling fully decentralized applications in blockchains and multiparty computation (MPC). While we have recently seen new advancements for asynchronous DKG (ADKG) protocols, their performance remains the bottleneck for many applications, with only one protocol being implemented (DYX+ ADKG, IEEE S&P 2022). DYX+ ADKG relies on the Decisional Composite Residuosity assumption (being expensive to instantiate) and the Decisional Diffie-Hellman assumption, incurring a high latency (more than 100s with a failure threshold of 16). Moreover, the security of DYX+ ADKG is based on the random oracle model (ROM) which takes hash function as an ideal function; assuming the existence of random oracle is a strong assumption, and up to now, we cannot find any theoretically-sound implementation. Furthermore, the ADKG protocol needs public key infrastructure (PKI) to support the trustworthiness of public keys. The strong models (ROM and PKI) further limit the applicability of DYX+ ADKG, as they would add extra and strong assumptions to underlying threshold cryptosystems. For instance, if the original threshold cryptosystem works in the standard model, then the system using DYX+ ADKG would need to use ROM and PKI. In this paper, we design and implement a modular ADKG protocol that offers improved efficiency and stronger security guarantees. We explore a novel and much more direct reduction from ADKG to the underlying blocks, reducing the computational overhead and communication rounds of ADKG in the normal case. Our protocol works for both the low-threshold and high-threshold scenarios, being secure under the standard assumption (the well-established discrete logarithm assumption only) in the standard model (no trusted setup, ROM, or PKI).",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "实用的异步分布式密钥生成:改进的效率、较弱的假设和标准模型",
                    "abstract_zh": "分布式密钥生成(DKG)允许在不依赖可信方的情况下引导门限密码系统，如今在区块链和多方计算(MPC)中实现了完全分散的应用。虽然我们最近看到了异步DKG (ADKG)协议的新进展，但它们的性能仍然是许多应用的瓶颈，只有一个协议正在实施(DYX+ ADKG，IEEE S&P 2022)。DYX+ ADKG依赖于决策性复合剩余假设(实例化成本很高)和决策性Diffie-Hellman假设，导致高延迟(超过100秒，失败阈值为16)。而且DYX+ ADKG的安全性是基于以哈希函数为理想函数的随机预言模型(ROM)的；假设随机预言的存在是一个强假设，到目前为止，我们找不到任何理论上合理的实现。此外，ADKG协议需要公钥基础设施(PKI)来支持公钥的可信性。强模型(ROM和PKI)进一步限制了DYX+ ADKG的适用性，因为它们会给基础的门限密码系统增加额外的强假设。例如，如果原始的门限密码系统在标准模型中工作，那么使用DYX+ ADKG的系统将需要使用ROM和PKI。在本文中，我们设计并实现了一个模块化的ADKG协议，它提供了更高的效率和更强的安全保证。我们探索了一种从ADKG到底层模块的更直接的新方法，减少了正常情况下ADKG的计算开销和通信次数。我们的协议适用于低阈值和高阈值场景，在标准模型(无可信设置、ROM或PKI)中的标准假设(仅公认的离散对数假设)下是安全的。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00060",
                    "title": "VoiceGuard: An Effective and Practical Approach for Detecting and Blocking Unauthorized Voice Commands to Smart Speakers",
                    "authors": "Xuening Xu, Chenglong Fu, Xiaojiang Du, E. Paul Ratazzi",
                    "abstract": "Smart speakers bring convenience to people's daily lives. However, various attacks can be launched against smart speakers to execute malicious commands, which may cause serious safety or security issues. The existing solutions against sophisticated attacks such as voice replay attacks and voice synthesis attacks require intrusive modifications of the smart speaker hardware and/or software, which are impractical for general users. In this work, we present a novel security scheme- VoiceGuard that can effectively detect and block unauthorized voice commands to smart speakers. VoiceGuard does not require any modification to smart speakers' hardware or software. We implement a prototype of VoiceGuard on two popular smart speakers: Amazon Echo Dot and Google Home Mini, and evaluate the scheme in three real-world testbeds, which include both single-user and multi-user scenarios. The experimental results show that VoiceGuard achieves an accuracy of 97% in blocking malicious voice commands issued by illegitimate sources while having a negligible impact on the user experience.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "VoiceGuard:一种有效实用的方法，用于检测和阻止对智能扬声器的未授权语音命令",
                    "abstract_zh": "智能音箱给人们的日常生活带来了便利。然而，可以针对智能扬声器发起各种攻击来执行恶意命令，这可能会导致严重的安全或安保问题。现有的针对复杂攻击(例如语音重放攻击和语音合成攻击)的解决方案需要对智能扬声器硬件和/或软件进行侵入式修改，这对于普通用户来说是不切实际的。在这篇文章中，我们提出了一个新颖的安全方案——voice guard，它可以有效地检测和阻止对智能扬声器的未授权语音命令。VoiceGuard不需要对智能音箱的硬件或软件进行任何修改。我们在两个流行的智能扬声器上实现了VoiceGuard原型:Amazon Echo Dot和Google Home Mini，并在三个真实世界的测试床上评估了该方案，其中包括单用户和多用户场景。实验结果表明，VoiceGuard在拦截非法来源发出的恶意语音命令方面达到了97%的准确率，同时对用户体验的影响可以忽略不计。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN58367.2023.00061",
                    "title": "Speaker Orientation-Aware Privacy Control to Thwart Misactivation of Voice Assistants",
                    "authors": "Shaohu Zhang, Aafaq Sabir, Anupam Das",
                    "abstract": "Smart home voice assistants (VAs) such as Amazon Echo and Google Home have become popular because of the convenience they provide through voice commands. VAs continuously listen to detect the wake command and send the subsequent audio data to the manufacturer-owned cloud service for processing to identify actionable commands. However, research has shown that VAs are prone to replay attack and accidental activations when the wake words are spoken in the background (either by a human or played through a mechanical speaker). Existing privacy controls are not effective in preventing such misactivations. This raises privacy and security concerns for the users as their conversations can be recorded and relayed to the cloud without their knowledge. Recent studies have shown that the visual gaze plays an important role when interacting with conservation agents such as VAs, and users tend to turn their heads or body toward the VA when invoking it. In this paper, we propose a device-free, non-obtrusive acoustic sensing system called HeadTalk to thwart the misactivation of VAs. The proposed system leverages the user's head direction information and verifies that a human generates the sound to minimize accidental activations. Our extensive evaluation shows that HeadTalk can accurately infer a speaker's head orientation with an average accuracy of 96.14% and distinguish human voice from a mechanical speaker with an equal error rate of 2.58%. We also conduct a user interaction study to assess how users perceive our proposed approach compared to existing privacy controls. Our results suggest that HeadTalk can not only enhance the security and privacy controls for VAs but do so in a usable way without requiring any additional hardware.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "防止语音助手误激活的说话者定向感知隐私控制",
                    "abstract_zh": "亚马逊Echo和谷歌home等智能家居语音助手(VAs)因其通过语音命令提供的便利而变得流行。VAs持续监听以检测唤醒命令，并将随后的音频数据发送到制造商拥有的云服务进行处理，以识别可操作的命令。然而，研究表明，当在背景中说出唤醒词(由人或通过机械扬声器播放)时，VAs易于重放攻击和意外激活。现有的隐私控制不能有效地防止这种误激活。这给用户带来了隐私和安全问题，因为他们的对话可能会被记录下来，并在他们不知情的情况下被转发到云端。最近的研究表明，视觉凝视在与守恒代理(如VAs)交互时起着重要的作用，并且用户在调用它时倾向于将他们的头或身体转向VA。在本文中，我们提出了一种无设备的，非侵入性的声学传感系统，称为HeadTalk，以阻止VAs的误激活。所提出的系统利用用户的头部方向信息，并验证人类产生的声音，以最大限度地减少意外激活。我们的大量评估表明，HeadTalk可以准确地推断出说话人的头部方向，平均准确率为96.14%，区分人类语音和机械扬声器的平均错误率为2.58%。我们还进行了一项用户交互研究，以评估与现有的隐私控制相比，用户如何看待我们提出的方法。我们的结果表明，HeadTalk不仅可以增强VAs的安全性和隐私控制，而且以一种可用的方式做到这一点，而不需要任何额外的硬件。"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/dsn/dsn2023w.html",
            "conf_title": "53rd DSN 2023: Porto, Portugal - Workshops",
            "conf_url": "https://doi.org/10.1109/DSN-W58399.2023",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00022",
                    "title": "Diagnosing applications' I/O behavior through system call observability",
                    "authors": "Tânia Esteves, Ricardo Macedo, Rui Oliveira, João Paulo",
                    "abstract": "We present DIO, a generic tool for observing inefficient and erroneous I/O interactions between applications and in-kernel storage systems that lead to performance, dependability, and correctness issues. DIO facilitates the analysis and enables near real-time visualization of complex I/O patterns for data-intensive applications generating millions of storage requests. This is achieved by non-intrusively intercepting system calls, enriching collected data with relevant context, and providing timely analysis and visualization for traced events. We demonstrate its usefulness by analyzing two production-level applications. Results show that DIO enables diagnosing resource contention in multi-threaded I/O that leads to high tail latency and erroneous file accesses that cause data loss.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "通过系统调用可观察性诊断应用程序的I/O行为",
                    "abstract_zh": "我们介绍了DIO，这是一个通用工具，用于观察应用程序和内核存储系统之间低效和错误的I/O交互，这些交互会导致性能、可靠性和正确性问题。DIO有助于分析，并支持对产生数百万存储请求的数据密集型应用程序的复杂I/O模式进行近乎实时的可视化。这是通过非侵入性地拦截系统调用、用相关上下文丰富收集的数据，以及为跟踪的事件提供及时的分析和可视化来实现的。我们通过分析两个生产级应用程序来展示它的有用性。结果表明，DIO能够诊断多线程I/O中的资源争用，这种争用会导致较高的尾部延迟和导致数据丢失的错误文件访问。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00023",
                    "title": "Predicting Cloud Applications Failures from Infrastructure Level Data",
                    "authors": "Jomar Domingos, Frederico Cerveira, Raul Barbosa, Henrique Madeira",
                    "abstract": "Cloud computing assumes a crucial role in the internet applications and services landscape, serving as the default infrastructure for deploying and delivering web applications. To harness the cloud’s technical and financial benefits, one must address the challenges of the increased consequences of software faults. Online failure prediction has emerged as a solution allowing for actions to be taken before the failures. However, conventionally, each target application requires a specific online failure predictor to be trained from application-specific data, which is impractical. In this paper we explore and assess the possibility to achieve online failure prediction for cloud applications from infrastructure-level data, i.e., data from the hypervisor. For this purpose, we present a method to accomplish this type of failure prediction, through fault injection on the hypervisor and machine learning techniques to create failure prediction models. From our experiments we find that it is possible to predict application failures from low-level infrastructural data, i.e., the infrastructure data presented enough application failure predictive power (with an accuracy of 96%, precision of 95% and a recall of 64%), showing the great potential that infrastructural data has to contribute to this task. Additionally, our study also opens interesting future research directions, such as multilevel failure prediction or generic failure prediction models.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "根据基础架构级别的数据预测云应用程序故障",
                    "abstract_zh": "云计算在互联网应用和服务领域扮演着至关重要的角色，是部署和交付web应用的默认基础设施。为了利用云的技术和财务优势，人们必须应对软件故障后果增加的挑战。在线故障预测作为一种解决方案已经出现，允许在故障之前采取行动。然而，传统上，每个目标应用需要从应用特定的数据中训练特定的在线故障预测器，这是不切实际的。在本文中，我们探索并评估了从基础架构级数据(即来自虚拟机管理程序的数据)实现云应用程序在线故障预测的可能性。为此，我们提出了一种方法来完成这种类型的故障预测，通过在管理程序上的故障注入和机器学习技术来创建故障预测模型。从我们的实验中，我们发现从低级基础设施数据预测应用故障是可能的，即，基础设施数据呈现了足够的应用故障预测能力(具有96%的准确度、95%的精确度和64%的召回率)，显示了基础设施数据对该任务做出贡献的巨大潜力。此外，我们的研究还开辟了有趣的未来研究方向，如多级失效预测或通用失效预测模型。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00024",
                    "title": "Underestimation-Aware Failure Statistical Model Creation for Large Scale Critical Systems",
                    "authors": "Szilárd Bozóki, Imre Kocsis, András Pataricza",
                    "abstract": "The two main dependability design quantitative assessment approaches are data-driven (black box) and model-driven (white box). Generally, the data-driven approach is more viable for complex systems because the model-driven approach is often computationally difficult. Meanwhile, the data-driven approach suffers from data modelling-related problems, such as model accuracy, data quality, and scalable data-processing needs. Owing to complexity, the data-driven approach is more viable for modern, dynamically composed, shared resource - virtualized and containerized - distributed systems. However, the empirical models must deal with model accuracy risks. Estimation inaccuracy risks are often asymmetric for critical systems: overestimations ”only” lead to unnecessary resource usage, but underestimations can lead to compromised extra-functional requirements. Rare failures with high severity are prime culprits of underestimation due to the difficulties of estimating long and heavy-tailed distributions over scarce data. Extreme value analysis is an available toolset for this problem; however, its known methods are not ready for the Big Data of modern distributed systems. Under some statistical restrictions, this paper proposes a novel Big Data capable extreme value analysis based computational model. At its core, the proposed method filters non-extreme values in an automated and scalable way to reduce subsequent data processing needs. We evaluated our approach on real-life container restart time data, but the potential applicability is far broader. In the case study, our method discarded 90 to 95% of the data without losing a single extreme value.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "考虑低估的大规模关键系统故障统计模型的建立",
                    "abstract_zh": "两种主要的可靠性设计定量评估方法是数据驱动(黑盒)和模型驱动(白盒)。通常，数据驱动的方法对于复杂的系统更可行，因为模型驱动的方法通常在计算上很困难。同时，数据驱动的方法受到与数据建模相关的问题的困扰，例如模型准确性、数据质量和可伸缩的数据处理需求。由于复杂性，数据驱动的方法对于现代的、动态组合的、共享资源虚拟化的和容器化的分布式系统更可行。然而，经验模型必须处理模型准确性风险。对于关键系统，估计不准确的风险通常是不对称的:高估“仅仅”会导致不必要的资源使用，但是低估会导致额外功能需求的妥协。严重程度高的罕见故障是低估的罪魁祸首，因为难以估计稀缺数据上的长分布和重尾分布。极值分析是解决这一问题的有效工具；然而，其已知的方法还没有为现代分布式系统的大数据做好准备。在一定的统计约束下，提出了一种新的基于大数据极值分析的计算模型。其核心是，所提出的方法以自动化和可扩展的方式过滤非极值，以减少后续的数据处理需求。我们在真实的集装箱重启时间数据上评估了我们的方法，但是潜在的适用性要广泛得多。在案例研究中，我们的方法丢弃了90%到95%的数据，而没有丢失一个极值。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00025",
                    "title": "IVSign: Interpretable Vulnerability Signature via Code Embedding and Static Analysis",
                    "authors": "Ao Ding, Gaolei Li, Xiaoyu Yi, Yuchen Liu",
                    "abstract": "Software vulnerability detection is evolving from pattern-driven methods to data-driven methods to be more automatic and intelligent due to the emergence of deep learning. However, false positives and coarse-grained detection can not tackle changeable and unknown threats (e.g., Oday vulnerabilities), and also low model interpretability leads to incontinent detection results or maliciously being manipulated. To enhance model confidence and interpretability, in this paper, we propose an Interpretable vulnerability signature (IVSign) scheme to combine pattern-driven and data-driven methods. In IVSign, pattern-driven methods utilize static analysis to provide rich vulnerability trace information extracted from data dependencies and data-driven methods respectively train a transformer-based model to encode these vulnerability traces and a recurrent neural network to generate vulnerability signatures. In the testing stage of IVSign, if a program sample with vulnerabilities is fed into the pipeline, its hit rate in the signature database will be very high. Experiments have shown that when the matching threshold is set appropriately, the evaluation metrics on the testing samples exceed 90.00%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "IVSign:通过代码嵌入和静态分析的可解释漏洞签名",
                    "abstract_zh": "由于深度学习的出现，软件漏洞检测正从模式驱动的方法发展到数据驱动的方法，以更加自动化和智能化。然而，误报和粗粒度检测无法应对多变和未知的威胁(例如，Oday漏洞)，并且低模型可解释性导致检测结果失控或被恶意操纵。为了增强模型的可信度和可解释性，本文提出了一种结合模式驱动和数据驱动方法的可解释漏洞签名(IVSign)方案。在IVSign中，模式驱动方法利用静态分析来提供从数据依赖性中提取的丰富的漏洞踪迹信息，而数据驱动方法分别训练基于转换器的模型来编码这些漏洞踪迹，并训练递归神经网络来生成漏洞签名。在IVSign的测试阶段，如果一个有漏洞的程序样本被馈入管道，它在特征码数据库中的命中率会非常高。实验表明，当匹配阈值设置适当时，测试样本上的评价指标超过90.00%。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00026",
                    "title": "Security Risk Growth Models for Software Vulnerability Assessment",
                    "authors": "Takashi Minohara, Masaya Shimakawa",
                    "abstract": "Information system administrators must pay attention to system vulnerability information and take appropriate measures against security attacks on the systems they manage. However, as the number of security vulnerability reports increases, the time required to implement vulnerability remediation also increases, therefore vulnerability risks must be assessed and prioritized. Especially in the early stages of vulnerability discovery, such as zero-day attacks, the risk assessment must consider changes over time, since it takes time to spread the information among adversaries and defenders.The Common Vulnerability Scoring System (CVSS) is used widely for vulnerability risk assessment, but it cannot be said that it can sufficiently cope with temporal changes of risk of attacks. In this paper, we proposed software vulnerability growth models to assist system administrators in decision making. Experimental results show that these models can provide a visual representation of the risk over time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "软件漏洞评估的安全风险增长模型",
                    "abstract_zh": "信息系统管理员必须关注系统漏洞信息，并采取适当的措施来防范对其管理的系统的安全攻击。但是，随着安全漏洞报告数量的增加，实施漏洞补救所需的时间也会增加，因此必须评估漏洞风险并确定其优先级。尤其是在漏洞发现的早期阶段，如零日攻击，风险评估必须考虑随时间的变化，因为在对手和防御者之间传播信息需要时间。通用漏洞评分系统(CVSS)广泛用于漏洞风险评估，但不能说它能够充分应对攻击风险的时间变化。在本文中，我们提出了软件漏洞增长模型来帮助系统管理员进行决策。实验结果表明，这些模型可以提供风险随时间变化的可视化表示。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00027",
                    "title": "JABBERWOCK: A Tool for WebAssembly Dataset Generation towards Malicious Website Detection",
                    "authors": "Chika Komiya, Naoto Yanai, Kyosuke Yamashita, Shingo Okamura",
                    "abstract": "Machine Learning is often used for malicious site detection, but an approach incorporating WebAssembly (WASM) as a feature has not been explored due to a limited number of samples, to the best of our knowledge. In this paper, we propose JABBERWOCK, a tool to generate WASM datasets in a pseudo fashion via JavaScript. Loosely speaking, JABBERWOCK automatically gathers JavaScript code in the real world, converts them into WASM, and then outputs vectors of the WASM as samples for malicious website detection. We also conduct experimental evaluations of JABBERWOCK in terms of the processing time for dataset generation and comparison of the generated samples with actual WASM samples gathered from the Internet. Regarding the processing time, we show that JABBERWOCK can construct a dataset in 4.5 seconds per sample for any number of samples. Next, comparing 4299 samples output by JABBERWOCK with 348 gathered WASM samples, we believe that the generated samples by JABBERWOCK are similar to those in the real world. We believe that a model trained with the generated datasets by JABBERWOCK can detect malicious websites accurately.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "JABBERWOCK:一个面向恶意网站检测的WebAssembly数据集生成工具",
                    "abstract_zh": "机器学习通常用于恶意网站检测，但据我们所知，由于样本数量有限，尚未探索将WebAssembly (WASM)作为一种功能的方法。在本文中，我们提出了JABBERWOCK，一种通过JavaScript以伪方式生成WASM数据集的工具。不严格地说，JABBERWOCK自动收集现实世界中的JavaScript代码，将其转换为WASM，然后输出WASM的向量作为恶意网站检测的样本。我们还根据数据集生成的处理时间以及生成的样本与从互联网上收集的实际WASM样本的比较，对JABBERWOCK进行了实验评估。关于处理时间，我们表明JABBERWOCK可以在4.5秒内为任意数量的样本构建一个数据集。接下来，将JABBERWOCK输出的4299个样本与收集的348个WASM样本进行比较，我们相信JABBERWOCK生成的样本与真实世界中的样本相似。我们认为，用JABBERWOCK生成的数据集训练的模型可以准确地检测恶意网站。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00028",
                    "title": "EMER-GO: real-time grip enhanced speed advisory for emergency intelligent transportation systems",
                    "authors": "Vincenzo Maria Arricale, Michele Caggiano, Marcello Cinque, Angelo Coppola, Flavio Farroni, Mario Fiorentino, Andrea Garofalo, Andrea Marchetta, Antimo Perfetto, Aleksandr Sakhnevych",
                    "abstract": "Green Light Optimal Speed Advisory (GLOSA) is a service that can be beneficial for emergency vehicles, such as ambulances or firetrucks, as it can help them to cross intersections in a short time. However, a wrong or late advice (e.g., due to bad road conditions or unexpected high load) can be hazardous in terms of safety. In this paper, we propose to integrate GLOSA with the road and tire grip evaluated in real-time. The solution has been implemented in a platform for emergency intelligent transportation systems, named EMER-GO, and tested on the road. Isolation tests have been performed as well, to check the capability of state-of-art containerization solutions to withstand unexpected stress loads on the same onboard unit.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "EMER GO:紧急智能交通系统的实时抓地力增强速度咨询",
                    "abstract_zh": "绿灯最佳速度咨询(GLOSA)是一项对救护车或消防车等紧急车辆有益的服务，因为它可以帮助他们在短时间内穿过十字路口。然而，错误或延迟的建议(例如，由于糟糕的路况或意外的高负载)在安全方面可能是危险的。在本文中，我们建议将GLOSA与道路和轮胎抓地力实时评估相结合。该解决方案已在一个名为EMER-GO的应急智能交通系统平台上实施，并进行了道路测试。还进行了隔离测试，以检查最先进的集装箱化解决方案承受同一船载装置上意外应力负载的能力。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00029",
                    "title": "Multi-Objective Optimization for an Online Re-Planning of Autonomous Vehicles",
                    "authors": "Kilian Le Gall, Laurent Lemarchand, Catherine Dezan",
                    "abstract": "Autonomous vehicles are well-known for automated tasks that are difficult or dangerous to be performed by human. However, the environment in which those Autonomous Vehicle (AV) are evolving is generally hard to predict. Thus, the challenge is to achieve a predefined mission while adapting AVs to their shifting environment in real time as efficiently as possible. The mission often includes path planning problems, where self-adaptation to terrain modifications is required while maintaining contradictory objectives, such as safety, risk assessment, travelling time or distance or consumed energy. We choose to focus on supervision missions (covering area with a lidar, with pictures, searching, etc) with two objectives: travelled distance (that could later be modeled into time or energy consumption) and covered area. We propose a multiobjective optimization (MOO) framework for a self adaptation of autonomous vehicles, with an offline/online approach, in order to solve covering/monitoring missions. The offline process will predict a initial path for the AV and the online process will be useful for the dynamic path re-planning when obstacles are detected. Our results demonstrate the benefits of reusing the offline pre-computed solutions for the online phase and for dynamic path re-planning.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "自主车辆在线重规划的多目标优化",
                    "abstract_zh": "众所周知，自动驾驶汽车可以自动完成由人类完成的困难或危险的任务。然而，这些自动驾驶车辆(AV)发展的环境通常很难预测。因此，面临的挑战是在尽可能有效地实时调整AVs以适应其不断变化的环境的同时实现预定的任务。该任务通常包括路径规划问题，其中需要自适应地形变化，同时保持矛盾的目标，例如安全性、风险评估、行驶时间或距离或消耗的能量。我们选择关注监督任务(用激光雷达覆盖区域、图片、搜索等),有两个目标:行驶距离(稍后可以建模为时间或能耗)和覆盖区域。我们提出了一个多目标优化(MOO)框架，用于自主车辆的自适应，采用离线/在线方法，以解决覆盖/监测任务。离线过程将预测AV的初始路径，而在线过程将在检测到障碍物时用于动态路径重新规划。我们的结果证明了在线阶段和动态路径重新规划中重用离线预计算解决方案的好处。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00030",
                    "title": "An ETSI ITS-enabled Robotic Scale Testbed for Network-Aided Safety-Critical Scenarios",
                    "authors": "José M. Pinheiro, Enio Vasconcelos Filho, Pedro M. Santos, Luís Almeida",
                    "abstract": "Vehicle-to-Everything (V2X) communications allows new and exciting relevant Intelligent Transportation Systems (ITS) applications such as cooperative perception. In some vehicular use-cases, infrastructure can have a crucial role in safeguarding safety, e.g. in an intersection in which inflowing vehicles do not have Line-of-Sight (blind corner) and an emergency braking action is required. Performance evaluation of vehicular communications systems (end-to-end delay, packet loss ratio, etc.) often resorts to static wireless testbeds, but there tends to be little consideration about the other subsystems involved in the time-sensitive goal, namely sensors, processing and decision-making, and vehicle actuators. In this paper we present a laboratorial testbed in which ETSI ITS/IEEE 802.11pbased On-Board and Road-Side Units (OBU/RSU) are deployed on a 1110-scale autonomous robotic vehicle and on the road-side respectively, the latter being part of a road-side infrastructure that includes a camera and an edge processing node. We target a use-case of collision avoidance supported by the network, in which the infrastructure detects an impending collision and issues a DEN message to prevent it. We aim to take a step beyond the traditional end-to-end delay characterization that is limited to the communication subsystem, by proposing a tool that enables realistic characterization of the entire end-to-end (detection-to-action) delay in safety-critical use-cases. Results show that the end-to-end latency of the system (camera-edge processing node-RSU-OBU-vehicle actuators) is under 100ms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "ETSI智能交通系统支持的网络辅助安全关键场景机器人秤试验台",
                    "abstract_zh": "车对物(V2X)通信允许新的和令人兴奋的相关智能交通系统(ITS)应用，例如协同感知。在一些车辆使用案例中，基础设施在保障安全方面起着至关重要的作用，例如在十字路口，流入车辆没有视线(死角)，需要紧急制动。车辆通信系统的性能评估(端到端延迟、丢包率等)。)经常求助于静态无线测试床，但往往很少考虑时间敏感目标中涉及的其他子系统，即传感器、处理和决策以及车辆执行器。在本文中，我们介绍了一个实验室测试平台，其中基于ETSI ITS/IEEE 802.11的车载和路边单元(OBU/RSU)分别部署在1110比例的自主机器人车辆上和路边，后者是路边基础设施的一部分，包括一个摄像头和一个边缘处理节点。我们的目标是网络支持的冲突避免用例，其中基础设施检测到即将发生的冲突，并发出DEN消息以防止它。我们的目标是超越仅限于通信子系统的传统端到端延迟表征，提出一种工具，在安全关键用例中实现整个端到端(检测到行动)延迟的真实表征。结果表明，该系统(摄像机-边缘处理节点-RSU-OBU-车辆执行器)的端到端延迟低于100ms。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00031",
                    "title": "PSP Framework: A novel risk assessment method in compliance with ISO/SAE-21434",
                    "authors": "Franco Oberti, Ernesto Sánchez, Alessandro Savino, Filippo Parisi, Stefano Di Carlo",
                    "abstract": "As more cars connect to the internet and other devices, the automotive market has become a lucrative target for cyberattacks. This has made the industry more vulnerable to security threats. As a result, car manufacturers and governments are working together to reduce risks and prevent cyberattacks in the automotive sector. However, existing attack feasibility models derived from the information technology field may not always provide accurate assessments of the potential risks faced by Vehicle Electronic Control Units in different operating conditions and domains. To address this issue, This paper introduces the PUNCH Softronix and Politecnico di Torino (PSP) framework. This framework is designed to provide accurate assessments compatible with the attack feasibility models defined by the automotive product security standards. The PSP framework utilizes social sentiment analysis to evaluate the real threat risk levels.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "PSP框架:符合ISO/SAE-21434的新型风险评估方法",
                    "abstract_zh": "随着越来越多的汽车连接到互联网和其他设备，汽车市场已经成为网络攻击的有利可图的目标。这使得该行业更容易受到安全威胁。因此，汽车制造商和政府正在共同努力降低风险，防止汽车行业的网络攻击。然而，源自信息技术领域的现有攻击可行性模型可能不总是提供对车辆电子控制单元在不同操作条件和领域中面临的潜在风险的准确评估。为了解决这个问题，本文介绍了PUNCH Softronix和Politecnico di Torino (PSP)框架。该框架旨在提供与汽车产品安全标准定义的攻击可行性模型兼容的准确评估。PSP框架利用社会情绪分析来评估真实的威胁风险级别。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00032",
                    "title": "Edge-Aided V2X Collision Avoidance with Platoons: Towards a Hybrid Evaluation Toolset",
                    "authors": "João Pereira, Harrison Kurunathan, Enio Vasconcelos Filho, Pedro M. Santos",
                    "abstract": "Infrastructure-brokered collision avoidance is an Intelligent Transportation Systems (ITS) application built on top of Vehicle-to-Everything (V2X) links. An edge-hosted ITS service receives information from road-side sensors (or CAM messages in V2X-enabled vehicles) and detects impending collisions where vehicles cannot sense or contact each other directly. If so happens, it issues a warning message through network-to-vehicle links. Another relevant ITS application is platooning, through which vehicles following each other closely can benefit of improved fuel economy, and that can be further enhanced through communication. In case of emergency braking in platoons, the response times of network and edge-hosted services must be minimal to ensure no collision amongst the platoon or any other road user. In this paper we present the implementation of a simulation framework tailored (but not limited) to evaluate the presented use-case. This complex and multi-layered use-case can be handled by a dedicated ITS service that leverages the sensing, radio and computing resources available at infrastructure and vehicles, and requires a realistic evaluation framework prior to deployment. Such framework is mostly based on simulation, albeit, to the extent possible, actual devices or services should be used; the present work is a step towards that hybrid setup.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "边缘辅助的V2X队列避碰:混合评估工具集",
                    "abstract_zh": "基础设施代理的碰撞避免是建立在车辆到一切(V2X)链接之上的智能交通系统(ITS)应用。edge托管的ITS服务接收来自路边传感器的信息(或支持V2X的车辆中的CAM消息)，并在车辆无法直接感知或相互接触的情况下检测即将发生的碰撞。如果发生这种情况，它会通过网络到车辆的链接发出警告信息。另一个相关的智能交通系统应用是队列，通过队列，彼此紧跟的车辆可以受益于改进的燃油经济性，并且可以通过通信进一步增强。在车队紧急制动的情况下，网络和edge托管服务的响应时间必须最短，以确保车队或任何其他道路使用者之间不会发生碰撞。在本文中，我们展示了一个模拟框架的实现，该框架被定制(但不限于)以评估所展示的用例。这种复杂的多层用例可以由专门的ITS服务来处理，该服务利用基础设施和车辆上可用的传感、无线电和计算资源，并且在部署之前需要一个现实的评估框架。这种框架主要基于模拟，尽管在可能的范围内，应该使用实际的设备或服务；目前工作是向混合设置迈出的一步。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00033",
                    "title": "Integration of U-space Safety Assessment Methodologies With Experimentation",
                    "authors": "Omid Asghari, Naghmeh Ivaki, Henrique Madeira",
                    "abstract": "In the coming years, there will be a significant increase in the use of Unmanned Aircraft Vehicles (UAVs), particularly drones, in urban environments, where safety due to the large number of drones operating is the primary concern. Therefore, the UAS traffic management (UTM) and its European implementation, U-space services, are being created to guarantee the safe operations of UAVs in large-scale scenarios. To ensure the target level of safety (TLS) in UAVs operation and U-space services, several safety assessment methodologies (e.g., SORA and MEDUSA) have been created. However, they tend to be predominantly qualitative. Consequently, a significant gap arises between the safety requirements and objectives established using these methods and the actual safety objectives in real-world scenarios. In this work, we argue that this gap can be filled by experimentation and a close articulation between existing analytical approaches and experimental methods.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "U空间安全评估方法与实验的结合",
                    "abstract_zh": "在未来几年，在城市环境中，无人飞行器(UAV)的使用将显著增加，尤其是无人机，在城市环境中，由于大量无人机运行，安全性是首要关注的问题。因此，UAS交通管理(UTM)及其欧洲实施U-space services正在创建，以保证无人机在大规模场景中的安全运行。为了确保无人机操作和U-space服务的目标安全水平(TLS ),已经创建了几种安全评估方法(例如SORA和MEDUSA)。然而，它们往往主要是定性的。因此，在使用这些方法建立的安全要求和目标与真实场景中的实际安全目标之间出现了显著的差距。在这项工作中，我们认为这一差距可以通过实验和现有的分析方法和实验方法之间的密切联系来填补。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00034",
                    "title": "Susceptibility of Autonomous Driving Agents to Learning-Based Action-Space Attacks",
                    "authors": "Yuting Wu, Xin Lou, Pengfei Zhou, Rui Tan, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer",
                    "abstract": "Intelligent vehicles with increasing complexity face cybersecurity threats. This paper studies action-space attacks on autonomous driving agents that make decisions using either a traditional modular processing pipeline or the recently proposed end-to-end driving model obtained via deep reinforcement learning (DRL). Such attacks alter the actuation signal and pose direct risks to the vehicle’s state. We formulate the attack construction as a DRL problem based on the input from either an extra camera or inertial measurement unit deployed. The attacks are designed to lurk until a safety-critical moment arises and cause a side collision upon activation. We analyze the behavioral differences between two driving agents when subjected to action-space attacks and demonstrate the superior resilience of the modular processing pipeline. We further investigate the performance and limitations of two enhancement methods, i.e., adversarial training through fine-tuning and progressive neural networks. The result offers valuable insights into vehicle safety from the viewpoints of both the assailant and the defender and informs the future design of autonomous driving systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "自动驾驶智能体对基于学习的动作空间攻击的敏感性",
                    "abstract_zh": "日益复杂的智能车辆面临网络安全威胁。本文研究了对自动驾驶智能体的动作空间攻击，这些智能体使用传统的模块化处理流水线或最近提出的通过深度强化学习(DRL)获得的端到端驾驶模型进行决策。这种攻击会改变启动信号，并对车辆状态造成直接风险。我们根据部署的额外摄像机或惯性测量单元的输入，将攻击构造公式化为DRL问题。这些攻击旨在潜伏到安全关键时刻，并在激活时引起侧面碰撞。我们分析了两个驱动代理在遭受动作空间攻击时的行为差异，并展示了模块化处理流水线的卓越弹性。我们进一步研究了两种增强方法的性能和局限性，即通过微调和渐进神经网络的对抗性训练。该结果从攻击者和防御者的角度提供了对车辆安全的宝贵见解，并为自动驾驶系统的未来设计提供了信息。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00035",
                    "title": "An Automotive Cybersecurity Maturity Level Assessment Programme",
                    "authors": "Patrick Grümer, Pedro Brandão",
                    "abstract": "Cybersecurity will be key for the new and future vehicles that depend on the exchange of data with the infrastructure. These vehicles will bring countless new features and are potentially capable of autonomous driving. This paper analyses the automotive threats, standards and regulations. An explanation about the automotive future vision and cybersecurity dependency is given. The main presentation is a high-level model of a five-grade rating system responsible for evaluating the cybersecurity quality of the future vehicles, in order to establish a trustable and reliable environment. Based on the standards used for secure software development and security assessment we defined a procedure for the evaluation of security of the technological components of a car.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "汽车网络安全成熟度评估计划",
                    "abstract_zh": "对于依赖于与基础设施进行数据交换的新型和未来车辆来说，网络安全将是关键。这些车辆将带来无数新功能，并有可能实现自动驾驶。本文分析了汽车面临的威胁、标准和法规。给出了关于汽车未来愿景和网络安全依赖性的解释。主要介绍的是五级评级系统的高级模型，负责评估未来车辆的网络安全质量，以建立一个可信和可靠的环境。基于用于安全软件开发和安全评估的标准，我们定义了一个评估汽车技术部件安全性的程序。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00036",
                    "title": "CarFASE: A Carla-based Tool for Evaluating the Effects of Faults and Attacks on Autonomous Driving Stacks",
                    "authors": "Mehdi Maleki, Ashfaq Farooqui, Behrooz Sangchoolie",
                    "abstract": "This paper presents CarFASE, an open-source carla-based fault and attack simulation engine that is used to test and evaluate the behavior of autonomous driving stacks in the presence of faults and attacks. Carla is a highly customizable and adaptable simulator for autonomous driving research. In this paper, we demonstrate the application of CarFASE by running fault injection experiments on OpenPilot, an open-source advanced driver assistance system designed to provide a suite of features such as lane keeping, adaptive cruise control, and forward collision warning to enhance the driving experience. A braking scenario is used to study the behavior of OpenPilot in the presence of brightness and salt&pepper faults. The results demonstrate the usefulness of the tool in evaluating the safety attributes of autonomous driving systems in a safe and controlled environment.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "CarFASE:一个基于Carla的工具，用于评估故障和攻击对自动驾驶堆栈的影响",
                    "abstract_zh": "本文介绍了CarFASE，这是一个基于carla的开源故障和攻击模拟引擎，用于测试和评估自动驾驶堆栈在故障和攻击存在时的行为。Carla是一个高度可定制和适应性强的模拟器，用于自动驾驶研究。在本文中，我们通过在OpenPilot上运行故障注入实验来演示CarFASE的应用，open pilot是一个开源的高级驾驶辅助系统，旨在提供一系列功能，如车道保持、自适应巡航控制和前向碰撞警告，以增强驾驶体验。制动场景用于研究OpenPilot在亮度和椒盐故障情况下的行为。结果证明了该工具在安全和受控环境中评估自动驾驶系统的安全属性的有效性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00037",
                    "title": "BEAT-Traffic: a Blockchain-Enabled infrastructure for Anonymous-yet-Traceable Traffic reporting",
                    "authors": "Marina Dehez-Clementi, Jean-Christophe Deneuville, Emmanuel Lochin, Jérôme Lacan",
                    "abstract": "Intelligent Transportation Systems (ITS) have become increasingly popular in recent years, and are viewed as the future of transportation. These systems rely heavily on open communication networks to ensure road safety and efficiency. However, the rapid and secure sharing of information over large-scale cyber-physical systems such as ITS poses significant challenges, including data lineage, data consistency, access rights management, and privacy preservation. In this paper, we propose a solution to improve the sharing of sensitive data over ITS using blockchains and distributed cryptography. We demonstrate how these technologies can be applied to the reporting of Road Hazard Warnings, creating a blockchain-based data collection system that ensures the dissemination and security of reported messages. Our approach combines blockchains and group signatures to achieve the necessary security properties, including privacy preservation and censorship resistance, while maintaining performance levels comparable to existing literature. We provide a theoretical analysis of the solution’s security properties and expected performance characteristics. Our results demonstrate the potential of blockchain-based solutions for addressing the challenges of secure and efficient information sharing in ITS. We believe that our work will contribute to the development of secure and privacy-preserving ITS systems, and encourage further exploration of blockchain-based solutions in the field of intelligent transportation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "BEAT-Traffic:一个支持区块链的基础设施，用于匿名但可追踪的流量报告",
                    "abstract_zh": "智能交通系统(ITS)近年来越来越受欢迎，被视为交通运输的未来。这些系统严重依赖开放的通信网络来确保道路安全和效率。然而，在诸如ITS这样的大规模网络物理系统上快速和安全地共享信息带来了巨大的挑战，包括数据沿袭、数据一致性、访问权限管理和隐私保护。在这篇文章中，我们提出了一个解决方案，通过使用区块链和分布式加密技术来改善敏感数据的共享。我们展示了如何将这些技术应用于道路危险警告的报告，创建了一个基于区块链的数据收集系统，以确保所报告消息的传播和安全性。我们的方法结合了区块链和群签名来实现必要的安全属性，包括隐私保护和审查抵抗，同时保持与现有文献相当的性能水平。我们对解决方案的安全属性和预期性能特征进行了理论分析。我们的结果证明了基于区块链的解决方案在解决ITS中安全有效的信息共享的挑战方面的潜力。我们相信，我们的工作将有助于发展安全和隐私保护的ITS系统，并鼓励进一步探索智能交通领域的区块链解决方案。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00038",
                    "title": "Safeguarding Cooperative Maneuver Information with Practical Byzantine Fault Tolerance",
                    "authors": "Emanuel Vieira, João Almeida, Joaquim Ferreira, Paulo C. Bartolomeu",
                    "abstract": "Vehicular communications play a critical role in facilitating cooperative behavior among vehicles, leading to improved road safety and traffic efficiency. By sharing information such as speed, position, and trajectory, vehicles can collaborate to execute complex maneuvers like platooning, intersection crossing, and lane merging. In addition to coordinating maneuvers, vehicles can also communicate to identify critical information associated with a maneuver that needs to be saved for future analysis, particularly in case of accidents. To analyze the feasibility of such scenarios using a classical consensus algorithm, we implemented the PBFT protocol using short-range vehicular communications. Vehicles employ this protocol to agree on which maneuver data is critical, then registered securely using distributed ledger-based techniques. PBFT is combined with a maneuver coordination protocol similar to current standardization efforts by ETSI. The proposed system was tested using hardware-in-the-loop simulations using vehicles’ onboard units equipped with ITS-G5 radio communications. Performance results show the feasibility of the proposed system for sufficiently high packet delivery rates.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "用实用拜占庭容错保护协同机动信息",
                    "abstract_zh": "车辆通信在促进车辆之间的合作行为、提高道路安全和交通效率方面发挥着关键作用。通过共享速度、位置和轨迹等信息，车辆可以协作执行复杂的机动动作，如列队、交叉路口和车道合并。除了协调机动动作，车辆还可以进行通信，以识别与机动动作相关的关键信息，这些信息需要保存以供将来分析，尤其是在发生事故的情况下。为了分析使用经典一致性算法的这种情况的可行性，我们使用短程车辆通信实现了PBFT协议。车辆使用该协议来商定哪些机动数据是关键的，然后使用基于分布式分类帐的技术安全地注册。PBFT与机动协调协议相结合，该协议类似于目前ETSI的标准化工作。使用配备ITS-G5无线电通信的车辆车载单元，使用硬件在环仿真对提议的系统进行了测试。性能结果显示了所提出的系统对于足够高的分组递送率的可行性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00039",
                    "title": "Minimal Risk Manoeuvre Strategies for Cooperative and Collaborative Automated Vehicles",
                    "authors": "Victoria Vu, Fredrik Warg, Anders Thorsén, Stig Ursing, Fredrik Sunnerstam, Jimmy Holler, Carl Bergenhem, Irina Cosmin",
                    "abstract": "During the last decade, there has been significant increase in research focused on automated vehicles (AVs) and ensuring safe operation of these vehicles. However, challenges still remain, some involving the cooperation and collaboration of multiple AVs, including when and how to perform a minimal risk manoeuvre (MRM), leading to a minimal risk condition (MRC) when an AV within one of these systems is unable to complete its original goal. As most literature is focused on individual AVs, there is a need to adapt and extend the knowledge and techniques to these new contexts. Based on existing knowledge of individual AVs, this paper explores MRM strategies involving cooperative and collaborative AV systems with different capabilities. Specifically, collaborative systems have the potential to enact local MRCs, allowing continued productivity despite having one (or several) of its constituents encounter a fault. Definitions are provided for local and global MRCs, alongside discussions of their implications for MRMs. Illustrative examples are also presented for each type of system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "合作和协作自动车辆的最小风险机动策略",
                    "abstract_zh": "在过去的十年中，对自动车辆(AVs)和确保这些车辆安全运行的研究显著增加。然而，挑战仍然存在，有些挑战涉及多个反车辆系统的合作和协作，包括何时和如何执行最小风险机动(MRM ),当其中一个系统内的反车辆系统无法完成其最初目标时，会导致最小风险状态(MRC)。由于大多数文献都集中在单个AVs上，因此有必要将知识和技术扩展到这些新的环境中。基于对单个AV的现有知识，本文探讨了涉及具有不同能力的合作和协作AV系统的MRM策略。具体来说，协作系统具有制定本地MRC的潜力，即使有一个(或几个)成员遇到故障，也允许继续生产。提供了本地和全球MRC的定义，并讨论了它们对MRM的影响。还为每种类型的系统提供了说明性的例子。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00040",
                    "title": "Adversarial Patch Detection and Mitigation by Detecting High Entropy Regions",
                    "authors": "Niklas Bunzel, Ashim Siwakoti, Gerrit Klause",
                    "abstract": "Neural networks have achieved remarkable performance in many applications, such as image classification and object detection, but security and robustness concerns have also been raised. Even the most advanced object detectors are vulnerable to localised patch attacks, where an adversary introduces a small adversarial patch into an image to either cause the detectors to miss real objects or to cause the detectors to detect objects that do not exist. Adversarial patches are able to force state-of-the-art object detectors to make false predictions with a high degree of confidence. These attacks can be carried out in the physical world, and defending against them is an open problem. In this paper, we propose a novel detection approach for real-world adversarial patches based on edge detection. The approach takes advantage of the fact that patches are high entropy regions featuring many edges and details. We evaluated our approach on a subset of the APRICOT and MS COCO datasets. In total, we achieve over 88% IoU on samples featuring adversarial patches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "通过检测高熵区域的对抗性斑块检测和缓解",
                    "abstract_zh": "神经网络在许多应用中已经取得了显著的性能，例如图像分类和目标检测，但是安全性和鲁棒性也引起了关注。即使是最先进的对象检测器也容易受到局部补丁攻击，在局部补丁攻击中，对手在图像中引入小的敌对补丁，以使检测器错过真实对象或者使检测器检测到不存在的对象。对抗性补丁能够迫使最先进的物体检测器以很高的置信度做出错误的预测。这些攻击可以在物理世界中进行，防御它们是一个开放的问题。在本文中，我们提出了一种新的基于边缘检测的真实世界敌对补丁检测方法。该方法利用了这样一个事实，即斑块是具有许多边缘和细节的高熵区域。我们在杏和可可数据集的子集上评估了我们的方法。总的来说，我们在具有对抗性补丁的样本上实现了超过88%的IoU。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00041",
                    "title": "IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness",
                    "authors": "Xiaoyun Xu, Guilherme Perin, Stjepan Picek",
                    "abstract": "This paper proposes a novel method, IB-RAR, which uses Information Bottleneck (IB) to strengthen adversarial robustness for both adversarial training and non-adversarial-trained methods. We first use the IB theory to build regularizers as learning objectives in the loss function. Then we filter out unnecessary features of intermediate representation according to their mutual information (MI) with labels, as the network trained with IB provides easily distinguishable MI for its features. Experimental results show that IB-RAR can be naturally combined with adversarial training and provides consistently better accuracy on new adversarial examples. The IB-RAR method improves the accuracy by an average of 2.66% against five adversarial attacks for ResNet-18, wide ResNet-28-10, and VGG-16, trained with three adversarial training benchmarks and the CFAR-10, CFAR-100, and Tiny ImageNet datasets. In addition, IB-RAR also provides good robustness for undefended methods, such as training with cross-entropy loss only. Finally, without adversarial training, the VGG-16 network trained using IB-RAR on the CFAR-10 dataset reaches an accuracy of 35.86% against PGD examples, while using all layers reaches 25.61% accuracy.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "IB-RAR:作为对抗鲁棒性正则化的信息瓶颈",
                    "abstract_zh": "提出了一种新的方法IB-RAR，该方法利用信息瓶颈来增强对抗训练和非对抗训练方法的鲁棒性。我们首先使用IB理论建立正则化子作为损失函数中的学习目标。然后，我们根据它们与标签的互信息(MI)过滤掉中间表示的不必要特征，因为用IB训练的网络为其特征提供了容易区分的MI。实验结果表明，IB-RAR可以自然地与对抗训练相结合，并在新的对抗样本上提供持续更好的准确性。对于用三个对抗性训练基准以及CFAR-10、CFAR-100和Tiny ImageNet数据集训练的ResNet-18、wide ResNet-28-10和VGG-16，IB-RAR方法针对五种对抗性攻击的准确率平均提高了2.66%。此外，IB-RAR还为不设防方法提供了良好的鲁棒性，例如仅使用交叉熵损失进行训练。最后，在没有对抗性训练的情况下，使用IB-RAR在CFAR-10数据集上训练的VGG-16网络相对于PGD示例达到35.86%的准确度，而使用所有层达到25.61%的准确度。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00042",
                    "title": "A Concise Analysis of Pasting Attacks and their Impact on Image Classification",
                    "authors": "Niklas Bunzel, Lukas Graner",
                    "abstract": "Neural networks are used for a variety of tasks in a wide range of applications, including high security applications, such as face recognition systems. These are used for identification, authentication and authorization. However, neural networks have been shown to be vulnerable against a variety of attacks that apply small perturbations to an input image in order to alter the predictions of a target model. In this paper, we present a simple pasting attack, which inserts objects, such as a face of a target into a source image. Since there is no reliance on gradients, it can be applied to any black-box image classifier. During evaluation, an average of 4.6 queries were sufficient to render an attack on a FaceNet model successful, 1.8 queries for an ImageNet classifier and 7.7 for the unknown black-box classifier used in the MLSec Competetion. By taking solely advantage of simple image operations, such as translation, scaling, rotation and change of transparency, the approach is lightweight and can be implemented in few lines of code. We make our code publicly available at: https://github.com/bunni90/FacePastingAttack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "浅析粘贴攻击及其对图像分类的影响",
                    "abstract_zh": "神经网络在广泛的应用中用于各种任务，包括高安全性应用，例如人脸识别系统。这些用于识别、认证和授权。然而，神经网络已被证明易受各种攻击，这些攻击将小扰动应用于输入图像以改变目标模型的预测。在本文中，我们提出了一个简单的粘贴攻击，它将目标的脸等物体插入到源图像中。由于不依赖于梯度，它可以应用于任何黑盒图像分类器。在评估期间，平均4.6次查询足以使对FaceNet模型的攻击成功，1.8次查询用于ImageNet分类器，7.7次查询用于MLSec竞争中使用的未知黑盒分类器。通过仅利用简单的图像操作，例如平移、缩放、旋转和透明度的改变，该方法是轻量级的，并且可以用几行代码实现。我们在https://github.com/bunni90/FacePastingAttack.公开我们的代码"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00043",
                    "title": "FADO: A Federated Learning Attack and Defense Orchestrator",
                    "authors": "Filipe Rodrigues, Rodrigo Simões, Nuno Neves",
                    "abstract": "Federated Learning (FL) is a distributed machine learning approach allowing multiple parties to train a model collaboratively without sharing sensitive data. It has gained widespread popularity recently due to its ability to preserve data privacy. However, FL also poses novel security challenges since training relies on data and computations from many entities that a malicious actor might have compromised, as they are usually geographically dispersed and independently managed. Evaluations of current FL security mechanisms in the literature are often based on simplistic testing environments and demand complex programming to integrate new attacks/defenses. Therefore, this work presents an accessible platform that leverages a realistic environment to facilitate the experimentation and evaluation of new solutions in relevant FL scenarios. Comparison with already proposed approaches is also expedited since FADO provides a few out-of-the-box implementations. To demonstrate the platform’s utility, we develop a use case based on a recently published network attack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "FADO:一个联合学习攻击和防御协调器",
                    "abstract_zh": "联邦学习(FL)是一种分布式机器学习方法，允许多方在不共享敏感数据的情况下协作训练模型。由于其保护数据隐私的能力，它最近获得了广泛的流行。然而，FL也提出了新的安全挑战，因为训练依赖于来自许多实体的数据和计算，恶意行为者可能已经损害了这些数据和计算，因为它们通常在地理上分散并且独立管理。文献中对当前FL安全机制的评估通常基于简单的测试环境，并且需要复杂的编程来集成新的攻击/防御。因此，这项工作提出了一个可访问的平台，利用一个现实的环境，以促进实验和评估新的解决方案在相关的外语场景。因为FADO提供了一些开箱即用的实现，所以与已经提出的方法的比较也加快了。为了展示平台的效用，我们基于最近发布的网络攻击开发了一个用例。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00044",
                    "title": "Enhancing the Reliability of Perception Systems using N-version Programming and Rejuvenation",
                    "authors": "Júlio Mendonça, Fumio Machida, Marcus Völp",
                    "abstract": "Machine Learning (ML) has become indispensable for real-world complex systems, such as perception systems of autonomous systems and vehicles. However, ML-based systems are sensitive to input data, faults, and malicious threats that can degrade output quality and compromise the complete system’s correctness. Ensuring a reliable output of ML-based components is crucial, especially for safety-critical systems. In this paper, we investigate architectures of perception systems using N-version programming for ML to mitigate the dependence on a singular ML component and combine it with a time-based rejuvenation mechanism to maintain a healthy system over extended periods. We propose models and functions to evaluate the reliability of N-version perception systems subject to faults, malicious threats, and rejuvenation. Our numerical experiments show that a rejuvenation mechanism could benefit a multiple-version system, with a reliability improvement superior to 13%. Also, the results indicate that rejuvenation could improve output reliability when ML modules’ accuracy is high.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "使用N版本编程和再生增强感知系统的可靠性",
                    "abstract_zh": "机器学习(ML)对于现实世界的复杂系统已经变得不可或缺，例如自主系统和车辆的感知系统。然而，基于ML的系统对输入数据、故障和恶意威胁很敏感，它们会降低输出质量并危及整个系统的正确性。确保基于ML的组件的可靠输出至关重要，尤其是对于安全关键型系统。在本文中，我们研究了感知系统的体系结构，使用N版本ML编程来减轻对单个ML组件的依赖，并将其与基于时间的再生机制相结合，以长期保持健康的系统。我们提出模型和函数来评估遭受故障、恶意威胁和再生的N版本感知系统的可靠性。我们的数值实验表明，再生机制可以使多版本系统的可靠性提高13%以上。此外，结果表明，当ML模块的精度较高时，再生可以提高输出的可靠性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00045",
                    "title": "Revenue Maximization of a Slice Broker in the Presence of Byzantine Faults",
                    "authors": "Muhidul Islam Khan, Gianfranco Nencioni",
                    "abstract": "Multi-Access Edge Computing (MEC) and network slicing are vital for advancing the Fifth Generation (5G) of cellular systems. MEC provides context awareness and reduces the latency for communication. Network slicing allows the division of a single network into multiple virtual networks so that different services can be provided. A slice broker is a business entity that buys the resources from the infrastructure providers and sells them to the tenants. A tenant sends a request for resources for different slices. In this work, we formulate the slice allocation problem to increase the revenue for the slice broker. We formulate a dynamic demand model based on the set price changes. We consider the profit maximization of a slice broker in the presence of Byzantine faults. Moreover, we propose the Comparative Gradient Elimination (CGE) method in Federated Learning (FL) for revenue maximization of the slice broker. Simulation results show that our proposed method outperforms the reference solution.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "拜占庭故障下切片经纪人的收益最大化",
                    "abstract_zh": "多址边缘计算(MEC)和网络切片对于推进第五代(5G)蜂窝系统至关重要。MEC提供了上下文感知并减少了通信延迟。网络切片允许将单个网络划分为多个虚拟网络，以便提供不同的服务。切片代理是一个商业实体，它从基础设施提供者那里购买资源，然后卖给租户。租户发送对不同片的资源的请求。在这项工作中，我们公式化的切片分配问题，以增加收入的切片经纪人。我们建立了一个基于设定价格变化的动态需求模型。我们考虑了存在拜占庭错误时切片经纪人的利润最大化。此外，我们提出了联邦学习中的比较梯度消除(CGE)方法来实现切片经纪人的收益最大化。仿真结果表明，我们提出的方法优于参考解决方案。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00046",
                    "title": "Cross-Layer Approximations for System-Level Optimizations: Challenges and Opportunities",
                    "authors": "Jorge Castro-Godínez, Muhammad Abdullah Hanif, Muhammad Shafique",
                    "abstract": "Approximate computing is an energy-and power-efficient design paradigm for error-tolerant applications. To enable this paradigm, different techniques have been proposed across the entire computing stack. In isolation, these techniques have demonstrated sufficient savings while promising results at complete System-on-Chip and application level are expected. Since half a decade ago, the notion of cross-layer approximate computing has been around in the scientific community. However, to fully accomplish a synergistic use of approximate computing techniques at different levels, existing challenges need to be overcome. In this paper, we discuss key challenges required to be addressed by the scientific community, to unlock the full potential of cross-layer approximations to achieve the ultimate system-level optimizations for error-tolerant applications. We present a crosslayer methodology for designing approximate systems, in which we consider the joint use of existing approximate techniques and contemplate other required methods, such as, statistical analysis of error propagation across different approximate components, and error compensation through self-healing approximations that would enable high-efficiency gains at the system level without aggregating the error magnitudes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "系统级优化的跨层近似:挑战与机遇",
                    "abstract_zh": "近似计算是一种针对容错应用的节能和省电设计范例。为了支持这种模式，在整个计算体系中提出了不同的技术。单独来看，这些技术已经证明了足够的节约，同时预期在完整的片上系统和应用级别上有希望的结果。自五年前以来，跨层近似计算的概念就一直在科学界流传。然而，为了在不同层次上充分实现近似计算技术的协同使用，需要克服现有的挑战。在本文中，我们讨论了科学界需要解决的关键挑战，以释放跨层近似的全部潜力，实现容错应用的最终系统级优化。我们提出了一种用于设计近似系统的跨层方法，其中我们考虑了现有近似技术的联合使用，并考虑了其他所需的方法，例如，对不同近似组件之间的误差传播进行统计分析，以及通过自愈近似进行误差补偿，这将在系统级实现高效率增益，而不会累计误差幅度。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00047",
                    "title": "Design Space Exploration of Approximate Computing Techniques with a Reinforcement Learning Approach",
                    "authors": "Sepide Saeedi, Alessandro Savino, Stefano Di Calro",
                    "abstract": "Approximate Computing (AxC) techniques have become increasingly popular in trading off accuracy for performance gains in various applications. Selecting the best AxC techniques for a given application is challenging. Among proposed approaches for exploring the design space, Machine Learning approaches such as Reinforcement Learning (RL) show promising results. In this paper, we proposed an RL-based multi-objective Design Space Exploration strategy to find the approximate versions of the application that balance accuracy degradation and power and computation time reduction. Our experimental results show a good trade-off between accuracy degradation and decreased power and computation time for some benchmarks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "用强化学习方法探索近似计算技术的设计空间",
                    "abstract_zh": "在各种应用中，近似计算(AxC)技术在牺牲精度以提高性能方面变得越来越流行。为特定应用选择最佳AxC技术极具挑战性。在提出的探索设计空间的方法中，机器学习方法如强化学习(RL)显示出有希望的结果。在本文中，我们提出了一种基于RL的多目标设计空间探索策略，以找到应用程序的近似版本，平衡精度下降和功耗及计算时间减少。我们的实验结果表明，对于一些基准测试，精度下降与功耗和计算时间降低之间存在良好的平衡。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00048",
                    "title": "Generic Accuracy Configurable Matrix Multiplication-Addition Accelerator using HLS",
                    "authors": "Luis G. León-Vega, Jorge Castro-Godínez",
                    "abstract": "Matrix Multiplication-Addition is one of the most common calculations when implementing Machine Learning (ML) algorithms for inference. Edge devices have limited processing power, due to resource and energy constraints, making the execution of these calculations a challenging task. This paper proposes the design of a generic configurable accelerator architecture for Generic Matrix Multiplication-Additions (GEMMA), implemented in untimed C++ for High-Level Synthesis and adaptable in matrix size, data bit-width, and data type for accuracy configuration, allowing tuning the impact on the overall design resource consumption. The overall analysis utilises existing Processing Elements (PE) from previous work as the execution units to perform the matrix operations. This work analyses the proposed architecture to spot design compromises regarding numerical accuracy. Also, this work points out that the proposed architecture inherits the behaviour of implementing each PE, presenting a trade-off between granularity and design efficiency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "使用HLS的通用精度可配置矩阵乘加加速器",
                    "abstract_zh": "当实现用于推理的机器学习(ML)算法时，矩阵乘法-加法是最常见的计算之一。由于资源和能源的限制，边缘设备的处理能力有限，这使得执行这些计算成为一项具有挑战性的任务。本文提出了一种用于通用矩阵乘法-加法(GEMMA)的通用可配置加速器架构的设计，该架构在无计时C++中实现，用于高级综合，并且在矩阵大小、数据位宽和数据类型方面可适应，用于精确配置，允许调整对整体设计资源消耗的影响。总体分析利用先前工作中的现有处理元素(PE)作为执行单元来执行矩阵运算。这项工作分析了拟议的架构，以找出关于数字精度的设计妥协。此外，这项工作指出，提出的架构继承了实现每个PE的行为，呈现了粒度和设计效率之间的权衡。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00049",
                    "title": "A Parametrizable Template for Approximate Logic Synthesis",
                    "authors": "Morteza Rezaalipour, Marco Biasion, Ilaria Scarabottolo, George A. Constantinides, Laura Pozzi",
                    "abstract": "This paper presents XPAT, a novel algorithm for the generation of approximate circuits which employs an SMT solver to shape the final resulting circuit on a given parametrizable template. The solver outlines which products of which input literals must be included in the final circuit in order to undergo a given error constraint. A miter is created containing the exact circuit description, the template, and a measure of the tolerated error, and by carefully tuning some template key parameters, such as limiting the number of literals per product, this algorithm is able to derive circuits that outperform the state of the art in terms of area. XPAT retrieved circuits with area smaller than those found by state of the art methods in 75% of the cases, and on average obtained 9.85% (up to 60.4% in some cases) improvement in area savings.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "近似逻辑综合的参数化模板",
                    "abstract_zh": "本文介绍了XPAT，一种用于生成近似电路的新算法，它采用SMT求解器在给定的可参数化模板上形成最终的电路。解算器概述了最终电路中必须包括哪些输入文字的哪些乘积，以便经受给定的误差约束。创建一个包含精确电路描述、模板和容许误差度量的斜接，并通过仔细调整一些模板关键参数，例如限制每个产品的文字数，该算法能够导出在面积方面优于现有技术的电路。在75%的情况下，XPAT检索到的电路面积小于通过现有技术方法发现的电路面积，并且平均获得9.85%(在某些情况下高达60.4%)的面积节省改善。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00050",
                    "title": "Input-aware accuracy characterization for approximate circuits",
                    "authors": "Ali Piri, Salvatore Pappalardo, Salvatore Barone, Mario Barbareschi, Bastien Deveautour, Marcello Traiola, Ian O'Connor, Alberto Bosio",
                    "abstract": "It has been a while since Approximate Computing (AxC) is applied systematically at various abstraction levels to increase the efficiency of several applications such as image processing and machine learning. Despite its benefit, AxC is still agnostic concerning the specific workload (i.e., input data to be processed) of a given application. For instance, in signal processing applications (such as a filter), some inputs are constants (filter coefficients). Meaning that a further level of approximation can be introduced by considering the specific input distribution. This approach has been referred to as “input-aware approximation”. In this paper, we explore how the input-aware approximate design approach can become part of a systematic, generic, and automatic design flow by knowing the data distribution. In particular, we show how input distribution can affect the error characteristics of an approximate arithmetic circuit and also the advantage of considering the data distribution by designing an input-aware approximate multiplier specifically intended for a high-pass FIR filter, where the coefficients are constant. Experimental results show that we can significantly reduce power consumption while keeping an error rate lower than state-of-the-art approximate multipliers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "近似电路的输入感知精度表征",
                    "abstract_zh": "自从近似计算(AxC)在各种抽象层次上被系统地应用以提高诸如图像处理和机器学习等若干应用的效率以来，已经有一段时间了。尽管有其优势，AxC仍然不知道给定应用程序的特定工作负载(即，要处理的输入数据)。例如，在信号处理应用中(如滤波器)，一些输入是常数(滤波器系数)。这意味着可以通过考虑特定的输入分布来引入更高级别的近似。这种方法被称为“输入感知近似”。在本文中，我们通过了解数据分布，探索输入感知近似设计方法如何成为系统化、通用化和自动化设计流程的一部分。特别是，我们展示了输入分布如何影响近似运算电路的误差特性，以及通过设计专门用于高通FIR滤波器的输入感知型近似乘法器来考虑数据分布的优势，其中系数为常数。实验结果表明，我们可以显著降低功耗，同时保持错误率低于最先进的近似乘法器。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00051",
                    "title": "AxASRE: A Novel Approach to Approximate Adder Synthesis Results Estimation",
                    "authors": "Pedro Tauã Lopes Pereira, Guilherme Paim, Paulo F. Flores, Eduardo A. C. da Costa, Sergio Bampi",
                    "abstract": "Thanks to the high energy efficiency achieved by approximate circuits, the exploration of approximate solutions for a wide of applications is the focus of academic and industrial research. However, defining the most appropriate approximation considering the power consumption and accuracy trade-off can be exhaustive. This paper proposes a novel approach to estimate the synthesis results for approximate adders (AxA) with different bit-width and approximation levels based on a database and simple mathematical operations to reduce the synthesis process complexity during an approximate circuit development. We implement the proposed approach to estimate the synthesis results for the Copy, Error-Tolerant Adder I (ETA-I), Lower-part-or (LOA), and Truncation (Trunc) AxAs. Comparing our estimation with real synthesis results obtained by an industrial synthesis tool, we prove the approach’s efficiency by presenting an average error on the estimated parameters (area, power and delay) less than 10% in the worst case. In addition, our approach reduces by more than 25 times the number of synthesis runs when estimating the synthesis results for all circuits in the bit width range of 2 to 64 with all possible approximation levels.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "AxASRE:一种新的近似加法器综合结果估计方法",
                    "abstract_zh": "由于近似电路实现的高能效，探索广泛应用的近似解决方案是学术和工业研究的焦点。然而，考虑到功耗和精度的权衡，定义最合适的近似值可能会很麻烦。提出了一种基于数据库和简单的数学运算来估计不同位宽和近似级数的近似加法器综合结果的新方法，以降低近似电路开发过程中综合过程的复杂性。我们实现了所提出的方法来估计复制、容错加法器I (ETA-I)、低部分or (LOA)和截断(Trunc)AXA的合成结果。将我们的估计与通过工业综合工具获得的真实综合结果进行比较，我们通过在最坏情况下给出估计参数(面积、功率和延迟)的小于10%的平均误差来证明该方法的效率。此外，当使用所有可能的近似级别估计位宽范围为2到64的所有电路的合成结果时，我们的方法将合成运行次数减少了25倍以上。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00052",
                    "title": "Exploit Approximation to Support Fault Resiliency in MPI-based Applications",
                    "authors": "Roberto Rocco, Gianluca Palermo",
                    "abstract": "Approximate applications feature scalability and intrinsic fault resilience, making them perfect for execution in the HPC scenario. The latter, in particular, is becoming more and more relevant due to the increasing size of HPC clusters, implying a higher fault frequency. To apply fault resilience properties, however, the communication middleware must be able to handle fault presence and limit their impact on the execution. This requirement is not valid in many cases, with MPI being one of the most remarkable cases of fault support lack. In this work, we leverage the Legio framework to enable fault resilience properties in applications without changes in their code. We focus our analysis on the accuracy losses coming from fault management, and we propose a set of solutions to circumvent them. The experimental campaign shows that it is possible to obtain some results with a transparent integration, but the maximum accuracy is reachable by making the application fault-aware.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "利用近似支持基于MPI的应用中的故障恢复",
                    "abstract_zh": "近似应用程序具有可伸缩性和内在的故障恢复能力，非常适合在HPC场景中执行。尤其是后者，由于HPC集群的规模不断扩大，意味着更高的故障频率，因此变得越来越重要。然而，为了应用故障弹性属性，通信中间件必须能够处理故障的存在，并限制它们对执行的影响。这一要求在许多情况下是不成立的，MPI是缺乏故障支持的最显著的例子之一。在这项工作中，我们利用Legio框架在应用程序中启用故障恢复属性，而无需更改其代码。我们重点分析了故障管理带来的准确性损失，并提出了一套解决方案来规避这些损失。实验活动表明，通过透明集成可以获得一些结果，但是通过使应用程序具有故障感知能力可以达到最大的准确性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00053",
                    "title": "Stochastic Computing as a Defence Against Adversarial Attacks",
                    "authors": "Florian Neugebauer, Vivek Vekariya, Ilia Polian, John P. Hayes",
                    "abstract": "Neural networks (NNs) are increasingly often employed in safety critical systems. It is therefore necessary to ensure that these NNs are robust against malicious interference in the form of adversarial attacks, which cause an NN to misclassify inputs. Many proposed defenses against such attacks incorporate randomness in order to make it harder for an attacker to find small input modifications that result in misclassification. Stochastic computing (SC) is a type of approximate computing based on pseudo-random bit-streams that has been successfully used to implement convolutional neural networks (CNNs). Some results have previously suggested that such stochastic CNNs (SCNNs) are partially robust against adversarial attacks. In this work, we will demonstrate that SCNNs do indeed possess inherent protection against some powerful adversarial attacks. Our results show that the white-box C&W attack is up to 16x less successful compared to an equivalent binary NN, and Boundary Attack even fails to generate adversarial inputs in many cases.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "随机计算作为对抗敌对攻击的防御",
                    "abstract_zh": "神经网络(NNs)越来越多地用于安全关键系统。因此，有必要确保这些神经网络对敌对攻击形式的恶意干扰具有鲁棒性，这种恶意干扰会导致神经网络对输入进行错误分类。许多针对这种攻击提出的防御措施结合了随机性，以使攻击者更难发现导致错误分类的小的输入修改。随机计算(SC)是一种基于伪随机比特流的近似计算，已经成功地用于实现卷积神经网络(CNN)。先前的一些结果表明，这种随机细胞神经网络(SCNNs)对对抗性攻击具有部分鲁棒性。在这项工作中，我们将证明SCNNs确实拥有对一些强大的对抗性攻击的内在保护。我们的结果表明，白盒C&W攻击的成功率比等价的二进制神经网络低16倍，在许多情况下，边界攻击甚至不能产生敌对输入。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00054",
                    "title": "Guardband Optimization for the Preconditioned Conjugate Gradient Algorithm",
                    "authors": "Natalia Lylina, Stefan Holst, Hanieh Jafarzadeh, Alexandra Kourfali, Hans-Joachim Wunderlich",
                    "abstract": "Many applications from Artificial Intelligence (AI) and Scientific Computing rely on efficient algorithms for solving large systems of linear equations. The Preconditioned Conjugate Gradient (PCG) algorithm is a promising option and it is a perfect candidate to be executed on specialized hardware accelerators widely used in AI. Hardware accelerators, like other modern devices, are prone to process variations. A conventional approach to handle the variability is to use pessimistic guardbands for all the devices within the population, which implies that the best and even the average accelerators are slowed down significantly. Since the PCG algorithm is inherently error resilient to some extent, it may also tolerate an error rate increase due to overclocking. On another side, increasing the frequency may increase the total execution time if more arithmetic operations are needed until the convergence. This paper presents a method to ensure efficient computing on each hardware accelerator instance running the PCG algorithm. A cross-layer approach identifies an optimized frequency that minimizes the total time to complete the PCG algorithm. Simple high-level checks ensure the quality of the solution. Experimental results validate the feasibility of the developed approach for large systems of linear equations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "预处理共轭梯度算法的保护带优化",
                    "abstract_zh": "人工智能(AI)和科学计算的许多应用依赖于求解大型线性方程组的有效算法。预处理共轭梯度(PCG)算法是一个有前途的选择，它是在人工智能中广泛使用的专用硬件加速器上执行的完美候选。像其他现代设备一样，硬件加速器容易出现工艺差异。处理可变性的传统方法是对群体中的所有设备使用悲观防护频带，这意味着最好的甚至平均的加速器被显著减慢。由于PCG算法在某种程度上具有固有的错误恢复能力，因此它也可以容忍由于超频而导致的错误率增加。另一方面，如果在收敛之前需要更多的算术运算，增加频率可能会增加总执行时间。本文提出了一种在运行PCG算法的每个硬件加速器实例上确保高效计算的方法。跨层方法确定一个优化的频率，使完成PCG算法的总时间最短。简单的高级检查确保了解决方案的质量。实验结果验证了该方法对于大型线性方程组的可行性。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00055",
                    "title": "Multi-Metric SMT-Based Evaluation of Worst-Case-Error for Approximate Circuits",
                    "authors": "Morteza Rezaalipour, Lorenzo Ferretti, Ilaria Scarabottolo, George A. Constantinides, Laura Pozzi",
                    "abstract": "Approximate computing has become a popular technique for leveraging the error resilience of applications that do not require full accuracy. By allowing for small and controlled errors, it is possible to reduce the area and power consumption of circuits. However, one of the main challenges in approximate computing is validating the design to ensure that it adheres to the error constraints. To address this issue, SMT/SAT solvers have been employed to evaluate errors, as their efficiency enables them to produce valid results, unlike statistical methods like Monte Carlo sampling. In this paper, we introduce a novel SMT-based algorithm for error evaluation that can be utilized for any approximate circuit and for any worst-case error metric. The algorithm leverages the solver’s output to improve error evaluation efficiency and explore the error space monotonically. We demonstrate how this approach outperforms other error-evaluation techniques used in current research.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "基于多度量SMT的近似电路最坏情况误差评估",
                    "abstract_zh": "近似计算已经成为利用不需要完全精确的应用程序的错误恢复能力的流行技术。通过允许小的受控误差，可以减少电路的面积和功耗。然而，近似计算的主要挑战之一是验证设计，以确保它符合误差限制。为了解决这个问题，SMT/SAT求解器已被用于评估误差，因为它们的效率使它们能够产生有效的结果，而不像蒙特卡罗抽样这样的统计方法。在本文中，我们介绍了一种新的基于SMT的误差评估算法，可用于任何近似电路和任何最差情况下的误差度量。该算法利用求解器的输出来提高误差评估效率，并单调地探索误差空间。我们展示了这种方法如何优于当前研究中使用的其他误差评估技术。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00056",
                    "title": "Low Power Streaming of Sensor Data Using Gray Code-Based Approximate Communication",
                    "authors": "Somayeh Sadeghi Kohan, Sybille Hellebrand, Hans-Joachim Wunderlich",
                    "abstract": "The streaming of sensor data has to comply with application specific requirements concerning performance and power dissipation. As it is inherently robust against limited inaccuracies, approximate communication is an ideal solution for optimizing performance and power. While previous approaches have mostly focused on one of the two aspects, the novel scheme presented in this paper targets both performance and power by rigorously exploiting the opportunities of approximation within predefined limits. Starting with base-delta encoding and a given error threshold, the stream of delta values is approximated, such that bus encoding using a Gray code is possible with a minimum number of transitions. The experimental data show that the proposed method maintains the performance gain of a traditional base-delta encoding while further reducing the number of transitions down to a few percent of the original data stream.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "使用基于格雷码的近似通信的传感器数据的低功率流传输",
                    "abstract_zh": "传感器数据流必须符合与性能和功耗相关的应用特定要求。由于近似通信本身对有限的不准确性具有鲁棒性，因此它是优化性能和功耗的理想解决方案。虽然以前的方法主要集中在这两个方面中的一个方面，但本文提出的新方案通过严格利用预定义限制内的近似机会，同时以性能和功率为目标。从基本增量编码和给定的误差阈值开始，增量值的流是近似的，使得使用格雷码的总线编码以最少的转换次数成为可能。实验数据表明，所提出的方法保持了传统base-delta编码的性能增益，同时进一步将转换的数量减少到原始数据流的百分之几。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00057",
                    "title": "NetLoiter: A Tool for Automated Testing of Network Applications using Fault-injection",
                    "authors": "Michal Rozsíval, Ales Smrcka",
                    "abstract": "The reliability of a network is a crucial requirement for applications and systems such as IoT (Internet-of-Things), cloud-based solutions, client-server, or peer-to-peer architectures. Unfortunately, real networks cannot be assumed to be fault-free, especially when considering various hardware problems, performance issues, or even malicious attacks. Testing network applications should include the evaluation of fault-tolerance of a system under various network conditions. The paper introduces a tool, NetLoiter, which helps developers and verification&validation practitioners easily analyse their network application’s behaviour in unexpected network situations. The tool is based on man-in-the-middle attacks and aims at network nodes communicating directly using a single network interface or indirectly via a single network active component (such as a switch or router). NetLoiter implements a fault-injection method; supported faults and attacks are inspired by the real world, including lossy channels, network jitter, data corruption, or disconnections.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "NetLoiter:一个使用故障注入的网络应用程序自动化测试工具",
                    "abstract_zh": "网络的可靠性是物联网(IoT)、基于云的解决方案、客户端-服务器或点对点架构等应用和系统的关键要求。不幸的是，不能假设真实的网络是无故障的，尤其是在考虑各种硬件问题、性能问题甚至恶意攻击时。测试网络应用应包括评估系统在各种网络条件下的容错能力。本文介绍了一个工具，NetLoiter，它可以帮助开发人员和验证和确认从业人员轻松地分析他们的网络应用程序在意外网络情况下的行为。该工具基于中间人攻击，目标是使用单个网络接口直接通信或通过单个网络主动组件(如交换机或路由器)间接通信的网络节点。NetLoiter实现了一种故障注入方法；受支持的故障和攻击受到现实世界的启发，包括有损耗的信道、网络抖动、数据损坏或连接断开。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00058",
                    "title": "RISC-V Timing-Instructions for Open Time-Triggered Architectures",
                    "authors": "Nithin Ravani Nanjundaswamy, Gregor Nitsche, Frank Poppen, Kim Grüttner",
                    "abstract": "Time-triggered architectures (TTAs) were a key enabler for time-predictable software execution and, thus, for cyber-physical and embedded systems with real-time requirements. Controlling software-execution by the means of timer-controlled interrupts and a predetermined schedule, TTAs are a common standard to ensure timing in safety-critical systems. Now, with the emerge of the openly available RISC-V architectures and the use of its instruction-set extension allows to easily provide softcore-processors with an application-specific instruction-set configuration. To support the realtime-capability of such RISC-V based, application-specific instruction-set processors (ASIPs), the presented approach provides timing-instructions as a RISC-V instruction-set extension to measure and control the software execution-time at the hardware-level.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "RISC-V定时.开放时间触发体系结构的指令",
                    "abstract_zh": "时间触发架构(TTA)是时间可预测软件执行的关键使能因素，因此也是具有实时要求的信息物理和嵌入式系统的关键使能因素。通过定时器控制的中断和预定的时间表来控制软件执行，TTA是确保安全关键系统中定时的通用标准。现在，随着公开可用的RISC-V架构的出现及其指令集扩展的使用，可以轻松地为软核处理器提供特定于应用的指令集配置。为了支持这种基于RISC-V的专用指令集处理器(ASIPs)的实时能力，所提出的方法提供定时指令作为RISC-V指令集扩展，以在硬件级测量和控制软件执行时间。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00059",
                    "title": "Evaluating the Safety Impact of Network Disturbances for Remote Driving with Simulation-Based Human-in-the-Loop Testing",
                    "authors": "Shrishti Trivedi, Fredrik Warg",
                    "abstract": "One vital safety aspect of advanced vehicle features is ensuring that the interaction with human users will not cause accidents. For remote driving, the human operator is physically removed from the vehicle, instead controlling it from a remote control station over a wireless network. This work presents a methodology to inject network disturbances into this communication and analyse the effects on vehicle manoeuvrability. A driving simulator, CARLA, was connected to a driving station to allow human-in-the-loop testing. NETEM was used to inject faults to emulate network disturbances. Time-To-Collison (TTC) and Steering Reversal Rate (SRR) were used as the main metrics to assess manoeuvrability. Clear negative effects on the ability to safely control the vehicle were observed on both TTC and SRR for 5% packet loss, and collision analysis shows that 50ms communication delay and 5% packet loss resulted in crashes for our test setup. The presented methodology can be used as part of a safety evaluation or in the design loop of remote driving or remote assistance vehicle features.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "用基于仿真的人在回路试验评估网络干扰对远程驾驶的安全影响",
                    "abstract_zh": "高级车辆功能的一个重要安全方面是确保与人类用户的交互不会导致事故。对于远程驾驶，操作人员实际上远离车辆，而是通过无线网络从远程控制站控制车辆。这项工作提出了一种方法，将网络干扰注入这种通信，并分析对车辆机动性的影响。驾驶模拟器卡拉(CARLA)连接到驾驶站，允许人在回路中测试。NETEM用于注入故障以模拟网络干扰。科利森时间(TTC)和转向反转率(SRR)被用作评估机动性的主要指标。在TTC和SRR，5%的数据包丢失对安全控制车辆的能力产生了明显的负面影响，碰撞分析表明，50毫秒的通信延迟和5%的数据包丢失导致了我们测试设置的崩溃。所提出的方法可以用作安全评估的一部分，或者用于远程驾驶或远程协助车辆特征的设计循环中。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00060",
                    "title": "Using AI to Inject Vulnerabilities in Python Code",
                    "authors": "C. G. Frédéric Bogaerts, Naghmeh Ivaki, Jose Fonseca",
                    "abstract": "Developing software that is free of vulnerabilities is an ongoing challenge for developers, as their impact may not be apparent until they are exploited. Although security tools can help identify vulnerabilities, their effectiveness is questionable. To address this challenge and assist developers in implementing more secure code, we aim to develop AI-based vulnerability injection techniques. In fact, having code with security flaws is fundamental both for the evaluation of security tools and for training. Our research specifically focuses on building AI models that can detect potential locations in the code for vulnerability injection. To train these models, we created a dataset that includes vulnerable and secure (i.e., patched) versions of Python code collected from open-source repositories. Results show that our methodology successfully identifies potential locations where a vulnerability can be injected with high accuracy. We also compared our approach with the deterministic use of Regular Expressions (RegEx) created based on the vulnerability patches. As a result, our AI approach outperformed the RegEx by a large margin. This paper demonstrates the feasibility of using AI models to identify potential vulnerability injection locations in Python code, thereby paving the way for future research on injecting and exploiting these vulnerabilities with AI. Such research can help in evaluating the effectiveness of security tools and training security teams. This work represents the first step towards our roadmap of using AI to inject vulnerabilities in Python code.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "利用AI在Python代码中注入漏洞",
                    "abstract_zh": "开发没有漏洞的软件对开发人员来说是一个持续的挑战，因为它们的影响在被利用之前可能并不明显。虽然安全工具可以帮助识别漏洞，但它们的有效性是值得怀疑的。为了应对这一挑战并帮助开发人员实现更安全的代码，我们旨在开发基于人工智能的漏洞注入技术。事实上，具有安全缺陷的代码对于安全工具的评估和培训都是非常重要的。我们的研究特别专注于构建能够检测代码中潜在漏洞注入位置的人工智能模型。为了训练这些模型，我们创建了一个数据集，其中包括从开源存储库中收集的易受攻击和安全(即打了补丁)版本的Python代码。结果表明，我们的方法成功地确定了潜在的位置，漏洞可以注入高精度。我们还将我们的方法与基于漏洞补丁创建的确定性正则表达式(RegEx)进行了比较。结果，我们的人工智能方法大大超过了正则表达式。本文论证了利用人工智能模型来识别Python代码中潜在漏洞注入位置的可行性，从而为将来利用人工智能注入和利用这些漏洞的研究铺平了道路。此类研究有助于评估安全工具的有效性和培训安全团队。这项工作代表了我们使用人工智能在Python代码中注入漏洞的路线图的第一步。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00061",
                    "title": "Timeseries-aware Uncertainty Wrappers for Uncertainty Quantification of Information-Fusion-Enhanced AI Models based on Machine Learning",
                    "authors": "Janek Groß, Michael Kläs, Lisa Jöckel, Pascal Gerber",
                    "abstract": "As the use of Artificial Intelligence (AI) components in cyber-physical systems is becoming more common, the need for reliable system architectures arises. While data-driven models excel at perception tasks, model outcomes are usually not dependable enough for safety-critical applications. In this work, we present a timeseries-aware uncertainty wrapper for dependable uncertainty estimates on timeseries data. The uncertainty wrapper is applied in combination with information fusion over successive model predictions in time. The application of the uncertainty wrapper is demonstrated with a traffic sign recognition use case. We show that it is possible to increase model accuracy through information fusion and additionally increase the quality of uncertainty estimates through timeseries-aware input quality features.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "基于机器学习的信息融合增强人工智能模型不确定性量化的时序感知不确定性包装器",
                    "abstract_zh": "随着人工智能(AI)组件在信息物理系统中的使用越来越普遍，对可靠系统架构的需求也随之增加。虽然数据驱动模型擅长感知任务，但对于安全关键型应用，模型结果通常不够可靠。在这项工作中，我们提出了一个时间序列感知的不确定性包装器，用于对时间序列数据进行可靠的不确定性估计。不确定性包装器与时间上连续模型预测的信息融合结合使用。通过交通标志识别用例演示了不确定性包装器的应用。我们证明了通过信息融合来提高模型精度，以及通过时间序列感知输入质量特征来提高不确定性估计的质量是可能的。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00062",
                    "title": "Modelling V&V Workflows to Improve Development Processes of Software-intensive Systems",
                    "authors": "Thomas Bauer, Wolfgang Herzner, Bob Hruska, Katia Di Blasio, Zain Shahwar",
                    "abstract": "The rapid increase in the complexity of systems, especially due to the integration of subsystems from different domains into cyber-physical systems, presents unique challenges for efficient verification and validation (V&V) processes to meet all requirements and system properties. To address these challenges and enhance quality assurance processes, it is essential to document and analyze V&V workflows. This paper proposes VVML, a novel approach for easy modeling of V&V activities in different industrial domains with varying constraints, V&V methods, and tool chains. This approach includes a dedicated modeling notation and a supporting modelling tool, enabling the creation of reusable workflows assets, such as V&V activities and artifacts, which can be shared across workflows. The VVML approach has been applied to 10+ industrial use cases. This paper explains the basic principles behind VVML and shows an example of its application to an industrial use case.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "模拟V&V工作流以改进软件密集型系统的开发过程",
                    "abstract_zh": "系统复杂性的快速增加，特别是由于来自不同领域的子系统集成到信息物理系统中，对满足所有要求和系统特性的有效验证和确认(V&V)过程提出了独特的挑战。为了应对这些挑战并增强质量保证流程，记录和分析V&V工作流程至关重要。本文提出了VVML，一种新的方法，在不同的约束，V&V方法和工具链的不同工业领域的V&V活动的简单建模。这种方法包括一个专用的建模符号和一个支持的建模工具，支持创建可重用的工作流资产，例如V&V活动和工件，它们可以在工作流之间共享。VVML方法已经应用于10多个工业用例。本文解释了VVML背后的基本原理，并展示了一个将其应用于工业用例的例子。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00063",
                    "title": "SMT-Based Stability Verification of an Industrial Switched PI Control Systems",
                    "authors": "Stylianos Basagiannis, Ludovico Battista, Anna Becchi, Alessandro Cimatti, Georgios Giantamidis, Sergio Mover, Alberto Tacchella, Stefano Tonetta, Vassilios A. Tsachouridis",
                    "abstract": "The control of complex systems is typically designed describing the physical system with differential equations. The standard approach to their verification employs numerical analysis, which is suitable to prove stability properties, but is susceptible to numerical errors. On the other side, symbolic techniques give precise analysis results but typically do not scale to industrial size problems. In this paper, we consider the control design of an aircraft engine. The engine model is represented by a linear state space model of 18 internal state variables, 4 outputs, and 3 inputs. The control switches between two PI controllers, one for thrust control and another for low-pressure compressor spool speed control, based on the engine state and pilot commands. After reformulating the PI controllers in terms of differential equations, we obtain a hybrid system with 21 state variables and two modes, for which we want to prove with symbolic techniques the robustness of the stable states to perturbation. We achieved the verification with standard methods to synthesize quadratic Lyapunov functions and SMT techniques to synthesize neighborhoods of the stable states for which we have symbolic proof of stability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "基于SMT的工业切换PI控制系统稳定性验证",
                    "abstract_zh": "复杂系统的控制通常被设计成用微分方程描述物理系统。验证它们的标准方法采用数值分析，这种方法适合于证明稳定性，但容易出现数值误差。另一方面，符号技术给出了精确的分析结果，但通常不适合工业规模的问题。在本文中，我们考虑一个飞机发动机的控制设计。发动机模型由18个内部状态变量、4个输出和3个输入的线性状态空间模型表示。基于发动机状态和飞行员命令，控制在两个PI控制器之间切换，一个用于推力控制，另一个用于低压压气机转子速度控制。在将PI控制器转化为微分方程之后，我们得到了一个具有21个状态变量和两个模式的混合系统，我们想用符号技术证明这个混合系统的稳定状态对扰动的鲁棒性。我们用标准方法合成了二次李亚普诺夫函数，用SMT技术合成了稳定状态的邻域，并得到了稳定性的符号证明。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00064",
                    "title": "llhsc: A DeviceTree Syntax and Semantic Checker",
                    "authors": "Vítor Rodrigues, André Mato Pedro",
                    "abstract": "Feature models are a commonly used technique for modeling software variability and representing possible configurations of a system. This paper presents the llhsc tool, which is designed to generate and check device trees for custom hardware based on the constraints specified in a feature model. The form of these constraints is a set of logical formulas, which enables product line validation using off-the-shelf satisfiability solvers. For checking purposes, a new set of constraints is defined, which includes the specffication of both syntax and semantic correctness of a delta-oriented software product line for DeviceTree bindings. This approach provides a more general and flexible solution for configuring static-partitioning hypervisors, but can also be used in systems without virtualization support, enabling the tool to be used in various contexts without sacrificing its generality. Through an empirical running example, we demonstrate the effectiveness of our approach, providing evidence that supports the construction of customized configurations for systems running static-partitioning hypervisors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "llhsc:设备树语法和语义检查器",
                    "abstract_zh": "特征模型是一种常用的技术，用于建模软件可变性和表示系统的可能配置。本文介绍了llhsc工具，该工具旨在基于功能模型中指定的约束来生成和检查定制硬件的设备树。这些约束的形式是一组逻辑公式，它使用现成的可满足性求解器来实现产品线验证。为了检查的目的，定义了一组新的约束，其包括用于设备树绑定的面向增量的软件产品线的语法和语义正确性的规范。这种方法为配置静态分区管理程序提供了一种更通用、更灵活的解决方案，但也可以在没有虚拟化支持的系统中使用，使该工具能够在各种环境中使用，而不会牺牲其通用性。通过一个实际运行的例子，我们证明了我们的方法的有效性，为运行静态分区管理程序的系统提供了支持定制配置的证据。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00065",
                    "title": "Translating Natural Language Requirements to Formal Specifications: A Study on GPT and Symbolic NLP",
                    "authors": "Iat Tou Leong, Raul Barbosa",
                    "abstract": "Software verification is essential to ensure dependability and that a system or component fulfils its specified requirements. Natural language is the most common way of specifying requirements, although many verification techniques such as theorem proving depend upon requirements being written in formal specification languages. Automatically translating requirements into a formal specification language is a relevant and challenging research question, because developers often lack the necessary expertise. In our work we consider the application of natural language processing (NLP) to address that research question. This paper considers two distinct approaches to formalise natural language requirements: a symbolic method and a GPT-based method. The two methods are evaluated with respect to their ability to generate accurate Java Modeling Language (JML) from textual requirements, and the results show good promise for automatic formalisation of requirements.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "将自然语言需求翻译成形式规格说明:GPT和符号自然语言处理研究",
                    "abstract_zh": "软件验证对于确保可靠性以及系统或组件满足其规定要求至关重要。自然语言是指定需求的最常见方式，尽管许多验证技术，如定理证明，都依赖于用正式的规范语言编写的需求。将需求自动转换成正式的规格说明语言是一个相关且具有挑战性的研究问题，因为开发人员通常缺乏必要的专业知识。在我们的工作中，我们考虑应用自然语言处理(NLP)来解决这个研究问题。本文考虑了两种不同的方法来形式化自然语言需求:符号方法和基于GPT的方法。对这两种方法从文本需求中生成精确的Java建模语言(JML)的能力进行了评估，结果显示了需求自动化形式化的良好前景。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00066",
                    "title": "Simplifying Requirements Formalization for Resource-Constrained Mission-Critical Software",
                    "authors": "Carlos Mão de Ferro, Anastasia Mavridou, Michael Dille, Francisco Martins",
                    "abstract": "Developing critical software requires adherence to rigorous software development practices, such as formal requirement specification and verification. Despite their importance, such practices are often considered as complex and challenging tasks that require a strong formal methods background. In this paper, we present our work on simplifying the formal requirements specification experience for resource-constrained mission critical software through the use of structured natural language. To this end, we connect NASA’s FRET, a formal requirement elicitation and authoring tool with the Shelley model checking framework for MicroPython code. We report our experience on using these tools to specify requirements and analyze code from the NASA Ames PHALANX exploration concept.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "简化资源受限的关键任务软件的需求形式化",
                    "abstract_zh": "开发关键软件需要遵循严格的软件开发实践，例如正式的需求规格说明和验证。尽管它们很重要，但是这种实践通常被认为是复杂和具有挑战性的任务，需要强大的正式方法背景。在这篇文章中，我们介绍了通过使用结构化自然语言来简化资源受限的关键任务软件的形式化需求规格说明的工作。为此，我们将NASA的FRET(一个正式的需求获取和创作工具)与用于MicroPython代码的Shelley模型检查框架连接起来。我们报告了使用这些工具来指定需求和分析NASA Ames方阵探索概念的代码的经验。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00067",
                    "title": "Preliminary Risk and Mitigation Assessment in Cyber-Physical Systems",
                    "authors": "András Földvári, Francesco Brancati, András Pataricza",
                    "abstract": "Malicious attacks endanger cyber-physical systems to a drastically increasing extent. Successful attacks intruding on the physical part of the system can cause severe or even catastrophic losses. The paper presents a model-based system engineering (MBSE) solution for the assessment and mitigation strategy design tool tailored to the peculiarities of SMEs with limited human and financial resources. The proper quality of the security assessment is assured by using embedded formal methods.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "信息物理系统中的初步风险和缓解评估",
                    "abstract_zh": "恶意攻击在极大程度上危及网络物理系统。入侵系统物理部分的成功攻击会导致严重甚至灾难性的损失。该文件提出了一个基于模型的系统工程(MBSE)解决方案，用于评估和缓解战略设计工具，适合人力和财力资源有限的中小企业的特点。通过使用嵌入的形式化方法来保证安全评估的适当质量。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00068",
                    "title": "Formal Verification for Safe AI-based Flight Planning for UAVs*",
                    "authors": "R. Bouchekir, M. Guzman, A. Cook, J. Haindl, R. Woolnough",
                    "abstract": "Planning and decision-making, especially the planning of collision-free paths, are an integral part of the operation of Unmanned Aerial Vehicles (UAVs). Formalisms like Temporal Plan Networks (TPN) can be used to provide optimal flight plans for UAVs. However, ensuring that the generated flight plans are safe can be a complex task, depending on the method used to generate the plans. Safe in this context means that the next planned action for the UAV does not violate safety constraints, for example, no-fly zones (NFZ). In this paper, we investigate the application of formal methods to generate metrics that could be used as assurance evidence in the argumentation of the safety of the planning component. In particular, we make use of Satisfiability Modulo Theories (SMT)-based verification to verify low-level requirements, together with Program Verification System (PVS) to check the design requirements of the AI-based planning component.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "无人机基于人工智能的安全飞行规划的形式化验证",
                    "abstract_zh": "规划和决策，尤其是无碰撞路径的规划，是无人机运行的一个组成部分。像时间计划网络(TPN)这样的形式可以用来为无人机提供最佳的飞行计划。然而，确保生成的飞行计划是安全的可能是一项复杂的任务，这取决于用于生成计划的方法。在这种情况下，安全意味着UAV的下一个计划动作不违反安全约束，例如，禁飞区(NFZ)。在本文中，我们研究了形式化方法的应用，以生成可在规划组件的安全性论证中用作保证证据的度量。特别地，我们利用基于可满足性模理论(SMT)的验证来验证底层需求，同时利用程序验证系统(PVS)来检查基于人工智能的规划组件的设计需求。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00069",
                    "title": "Formalizing Model Inference of MicroPython",
                    "authors": "Carlos Mão de Ferro, Tiago Cogumbreiro, Francisco Martins",
                    "abstract": "Model checking has often been used for verifying Cyber-Physical Systems (CPS). A major challenge is how to capture a model that represents the actual behavior of the software. Model extraction can introduce errors that can affect the accuracy of the analysis including loss of precision, inconsistency, non-conformance, and over- and under-approximations.In this paper, we formalize and prove the correctness of extracting a model from a subset of the MicroPython programming language with respect to a trace-based semantics. The extracted models capture the order of method calls and can be model checked using Shelley. We formalize the extraction process from an intermediate representation of MicroPython codes and prove that the behavior of our intermediate representation is a regular language. Our formalization and theoretical results are fully mechanized using the Coq proof assistant.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "形式化MicroPython的模型推理",
                    "abstract_zh": "模型检验经常被用来验证信息物理系统。一个主要的挑战是如何捕获一个代表软件实际行为的模型。模型提取会引入影响分析准确性的误差，包括精度损失、不一致、不一致以及过度和欠近似。在本文中，我们形式化并证明了从MicroPython编程语言的子集提取模型的正确性。提取的模型捕获了方法调用的顺序，并且可以使用Shelley进行模型检查。我们形式化了从MicroPython代码的中间表示中提取的过程，并证明了我们的中间表示的行为是一种正则语言。我们的形式化和理论结果是完全机械化的使用Coq证明助理。"
                },
                {
                    "url": "https://doi.org/10.1109/DSN-W58399.2023.00070",
                    "title": "SIMoT: A Low-fidelity Orchestrator Simulator for Task Allocation in IoT Devices",
                    "authors": "Tiago Fragoso, David Silva, João Pedro Dias, André Restivo, Hugo Sereno Ferreira",
                    "abstract": "Performing experiments with Internet-of-Things edge devices is not always a trivial task, as large physical testbeds or complex simulators are often needed, leading to low reproducibility and several difficulties in crafting complex scenarios and tweaking parameters. Most available simulators try to simulate as close to reality as possible. While we agree that this kind of high-fidelity simulation might be necessary for some scenarios, we argue that a low-fidelity easy-to-change simulator may be a good solution when rapid prototyping orchestration strategies and algorithms. In this work, we introduce SIMoT, a low-fidelity orchestrator simulator created to achieve shorter feedback loops when testing different orchestration strategies for task allocation in edge devices. We then transferred the simulator-validated algorithms to both physical and virtual testbeds, where it was possible to assert that the simulator results correlate strongly with the observations on those testbeds.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "title_zh": "SIMoT:面向物联网设备任务分配的低保真度Orchestrator模拟器",
                    "abstract_zh": "使用物联网边缘设备进行实验并不总是一项简单的任务，因为通常需要大型物理试验台或复杂的模拟器，这导致可重复性低，并且在制作复杂场景和调整参数方面存在一些困难。大多数可用的模拟器都试图尽可能接近现实。虽然我们同意这种高保真模拟对于某些场景可能是必要的，但我们认为在快速原型编排策略和算法时，低保真度易于更改的模拟器可能是一个好的解决方案。在本文中，我们介绍了SIMoT，这是一款低保真度编排仿真器，用于在边缘设备中测试不同的任务分配编排策略时缩短反馈环路。然后，我们将模拟器验证的算法转移到物理和虚拟测试床上，在那里可以断言模拟器结果与这些测试床上的观察结果密切相关。"
                }
            ]
        }
    ]
}