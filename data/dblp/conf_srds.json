{
    "2021": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2021.html",
            "conf_title": "40th SRDS 2021: Shanghai, China",
            "conf_url": "https://doi.org/10.1109/SRDS53918.2021",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00010",
                    "title": "Making Reads in BFT State Machine Replication Fast, Linearizable, and Live",
                    "authors": "Christian Berger, Hans P. Reiser, Alysson Bessani",
                    "abstract": "Practical Byzantine Fault Tolerance (PBFT) is a seminal state machine replication protocol that achieves a performance comparable to non-replicated systems in realistic environments. A reason for such high performance is the set of optimizations introduced in the protocol. One of these optimizations is read-only requests, a particular type of client request which avoids running the three-step agreement protocol and allows replicas to respond directly, thus reducing the latency of reads from five to two communication steps. Given PBFT's broad influence, its design and optimizations influenced many BFT protocols and systems that followed, e.g., BFT-SMaRt. We show, for the first time, that the read-only request optimization introduced in PBFT more than 20 years ago can violate its liveness. Notably, the problem affects not only the optimized read-only operations but also standard, totally-ordered operations. We show this weakness by presenting an attack in which a malicious leader blocks correct clients and present two solutions for patching the protocol, making read-only operations fast and correct. The two solutions were implemented on BFT-SMaRt and evaluated in different scenarios, showing their effectiveness in preventing the identified attack.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2107.11144"
                    },
                    "abstract_zh": "实用拜占庭容错(PBFT)是一个开创性的状态机复制协议，在现实环境中实现了与非复制系统相当的性能。如此高性能的一个原因是协议中引入的一组优化。其中一个优化是只读请求，这是一种特殊类型的客户端请求，它避免运行三步协议协议，并允许副本直接响应，从而将读取延迟从五步减少到两步。鉴于PBFT的广泛影响力，其设计和优化影响了许多BFT协议和系统，如BFT智能。我们第一次表明，20多年前在PBFT引入的只读请求优化会破坏它的活性。值得注意的是，这个问题不仅影响优化的只读操作，还影响标准的全序操作。我们通过提出一种攻击来展示这一弱点，在这种攻击中，恶意领导者阻止正确的客户端，并提出两种修补协议的解决方案，使只读操作快速而正确。这两种解决方案在BFT智能系统上实现，并在不同的场景下进行评估，显示了它们在防止已识别攻击方面的有效性。",
                    "title_zh": "使BFT状态机复制中的读取快速、可线性化且实时"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00011",
                    "title": "Node-level indicators of soft faults in wireless sensor networks",
                    "authors": "Dominik Widhalm, Karl M. Göschka, Wolfgang Kastner",
                    "abstract": "Faults in wireless sensor nodes tend to be the norm rather than the exception. Our paper addresses the following problems: How can we make sure the sensed data has not been distorted by faults? And when we experience anomalies in the sensed data, how can we distinguish between rare but correctly measured events and incorrect data due to faults? The focus of this paper is specifically on soft faults, because (i) they deteriorate the data quality and (ii) are hard to distinguish from irregular but correct events. Many papers on how to detect soft faults have been proposed, but they mostly rely on assumptions on the network's deployment or the nature of the collected data. Therefore, they are insufficient as they can miss faults or misinterpret correct data. In this paper, our key idea is to augment the existing fault-detection approaches with node-level information as additional input. Our contribution is to show the existence of such node-level information that can improve (i) the detection of soft faults and (ii) the distinction between faults and events. This node-level information - called fault indicators - can then be included in existing fault detection schemes. Based on practical experiments, we show that using such fault indicators indeed improves the detection rate and reduces the risk of missing fault-induced variations of sensor data.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "无线传感器节点中的故障往往是常态而不是例外。我们的论文解决了以下问题:我们如何确保感测到的数据没有被断层扭曲？当我们在感应数据中经历异常时，我们如何区分罕见但正确测量的事件和由于故障导致的不正确数据？本文的重点特别放在软故障上，因为(I)它们会降低数据质量，以及(ii)很难与不规则但正确的事件区分开来。已经提出了许多关于如何检测软故障的论文，但是它们大多依赖于对网络部署或所收集数据的性质的假设。因此，它们是不够的，因为它们可能遗漏故障或曲解正确的数据。在本文中，我们的主要思想是用节点级信息作为附加输入来扩充现有的故障检测方法。我们的贡献是展示这种节点级信息的存在，它可以改善(I)软故障的检测和(ii)故障和事件之间的区别。这种节点级信息(称为故障指示器)可以包含在现有的故障检测方案中。基于实际实验，我们表明使用这样的故障指示器确实提高了检测率，并且降低了传感器数据的遗漏故障引起的变化的风险。",
                    "title_zh": "无线传感器网络中节点级软故障指示器"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00012",
                    "title": "The design, architecture and performance of the Tendermint Blockchain Network",
                    "authors": "Daniel Cason, Enrique Fynn, Nenad Milosevic, Zarko Milosevic, Ethan Buchman, Fernando Pedone",
                    "abstract": "Tendermint is the replication engine at the core of Cosmos, a network of proof-of-stake blockchains. In the lifespan of blockchains, Cosmos and Tendermint are mature technologies, currently used by more than a hundred businesses and deployed by hundreds of nodes. The system was designed to provide flexible deployment despite heterogeneous environments, scale performance with the number of nodes, and tolerate misbehaving participants. In this practical experience report, we overview Tendermint's main design goals and architecture, and present a detailed performance evaluation of the system in a realistic environment. We report results from a geographically distributed environment with up to 128 nodes, including failure-free executions and fail-prone scenarios, with both crash and Byzantine failures.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Tendermint是Cosmos核心的复制引擎，Cosmos是一个利益相关区块链网络。在区块链的生命周期中，Cosmos和Tendermint是成熟的技术，目前被一百多家企业使用，并由数百个节点部署。该系统旨在提供异构环境下的灵活部署，随着节点数量扩展性能，并容忍行为不端的参与者。在这份实践经验报告中，我们概述了Tendermint的主要设计目标和架构，并对系统在现实环境中的性能进行了详细评估。我们报告了来自多达128个节点的地理分布式环境的结果，包括无故障执行和易故障场景，包括崩溃和拜占庭故障。",
                    "title_zh": "Tendermint区块链网络的设计、架构和性能"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00013",
                    "title": "Adding Fairness to Order: Preventing Front-Running Attacks in BFT Protocols using TEEs",
                    "authors": "Chrysoula Stathakopoulou, Signe Rüsch, Marcus Brandenburger, Marko Vukolic",
                    "abstract": "This paper presents Fairy: a modular system that augments any Total Order Broadcast (TOB) protocol with fairness properties, namely input (request) causality and sender obfuscation. With these properties, Fairy helps to prevent front-running attacks where an adversary can interfere with the order of requests depending on request payload and sender identity, allowing for substantial application-level consequences. Fairy leverages Trusted Execution Environments (TEEs) to implement fairness on top of a TOB-based ordering service. Fairy collocates TEEs with ordering service nodes effectively making them run as trusted proxies of actual TOB clients. TEEs help Fairy to achieve both input causality and sender obfuscation - previous related systems addressing only input causality. We evaluate Fairy on top of a recent, efficient Byzantine Fault-Tolerant (BFT) TOB protocol and compare it to state-of-the-art BFT TOB with input causality. We show that Fairy improves state-of-the-art throughput by 66% and reduces latency by 50%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了Fairy:一个模块化系统，它用公平属性，即输入(请求)因果关系和发送者混淆，来增强任何全序广播(TOB)协议。利用这些属性，Fairy有助于防止抢先攻击，在抢先攻击中，对手可以根据请求有效负载和发送方身份来干扰请求的顺序，从而导致重大的应用程序级后果。Fairy利用可信执行环境(TEEs)在基于TOB的订购服务之上实现公平性。Fairy将tee与订购服务节点搭配起来，有效地使它们作为实际TOB客户端的可信代理运行。TEEs帮助Fairy实现输入因果关系和发送者混淆——以前的相关系统只解决输入因果关系。我们在最近的高效拜占庭容错(BFT) TOB协议上评估了Fairy，并将其与具有输入因果关系的最先进的BFT TOB进行了比较。我们发现，Fairy将最先进的吞吐量提高了66%，并将延迟降低了50%。",
                    "title_zh": "为秩序增加公平性:利用TEEs防止BFT协议中的抢先攻击"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00014",
                    "title": "Chaos Duck: A Tool for Automatic IoT Software Fault-Tolerance Analysis",
                    "authors": "Igor Zavalyshyn, Thomas Given-Wilson, Axel Legay, Ramin Sadre, Etienne Rivière",
                    "abstract": "Internet of Things (IoT) device software frequently handles sensitive data. This software has to be resistant to faults to prevent leakage and ensure data privacy and security. Source code hardening is a common way to make software fault-tolerant. However, the effectiveness and performance impact of a chosen hardening technique are not always obvious. Moreover, it becomes increasingly difficult to predict potential attack vectors and implement proper countermeasures. To assist in this task, we developed Chaos Duck, an automatic tool for IoT software fault-tolerance analysis. Chaos Duck emulates various fault types and provides statistics on their impact on software security and stability. We present a case study in which we use Chaos Duck to compare five software hardening techniques applied to the PRESENT block cipher implementation. We show that some simple hardening techniques may improve fault-tolerance, while others can instead reduce overall security and introduce new vulnerabilities. Our contributions are twofold: we offer a software fault-tolerance analysis tool to IoT developers seeking to make their software secure and robust, and we shed light on the efficiency of various hardening techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "物联网(IoT)设备软件经常处理敏感数据。该软件必须能够抵御故障，以防止泄漏，并确保数据隐私和安全。源代码强化是使软件容错的一种常用方法。然而，所选强化技术的有效性和性能影响并不总是显而易见的。此外，预测潜在的攻击媒介和实施适当的对策变得越来越困难。为了帮助完成这项任务，我们开发了Chaos Duck，这是一款用于物联网软件容错分析的自动化工具。Chaos Duck模拟各种故障类型，并提供它们对软件安全性和稳定性影响的统计数据。我们提出了一个案例研究，其中我们使用混沌鸭比较五个软件加固技术应用于目前的分组密码实现。我们表明，一些简单的加固技术可能会提高容错能力，而其他技术反而会降低整体安全性并引入新的漏洞。我们的贡献是双重的:我们为物联网开发人员提供软件容错分析工具，以使他们的软件安全可靠，我们还揭示了各种加固技术的效率。",
                    "title_zh": "混沌鸭:自动物联网软件容错分析工具"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00015",
                    "title": "Active replication for latency-sensitive stream processing in Apache Flink",
                    "authors": "Guillaume Rosinosky, Florian Schmidt, Oleh Bodunov, Christof Fetzer, André Martin, Etienne Rivière",
                    "abstract": "Stream processing frameworks allow processing massive amounts of data shortly after it is produced, and enable a fast reaction to events in scenarios such as data center monitoring, smart transportation, or telecommunication networks. Many scenarios depend on the fast and reliable processing of incoming data, requiring low end-to-end latencies from the ingest of a new event to the corresponding output. The occurrence of faults jeopardizes these guarantees: Currently-leading high-availability solutions for stream processing such as Spark Streaming or Apache Flink's implement passive replication through snapshotting, requiring a stop-the-world operation to recover from a failure. Active replication, while incurring higher deployment costs, can overcome these limitations and allow to mask the impact of faults and match stringent end-to-end latency requirements. We present the design, implementation, and evaluation of active replication in the popular Apache Flink platform. Our study explores two alternative designs, a leader-based approach leveraging external services (Kafka and ZooKeeper) and a leaderless implementation leveraging a novel deterministic merging algorithm. Our evaluation using a series of microbenchmarks and a SaaS cloud monitoring scenario on a 37-server cluster show that the actively-replicated Flink can fully mask the impact of faults on end-to-end latency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "流处理框架允许在产生大量数据后立即对其进行处理，并在数据中心监控、智能交通或电信网络等场景中实现对事件的快速反应。许多场景都依赖于对传入数据的快速可靠处理，要求从接收新事件到相应输出的端到端延迟较低。故障的发生会危及这些保证:目前领先的流处理高可用性解决方案，如Spark Streaming或Apache Flink的通过快照实现被动复制，需要停止操作才能从故障中恢复。活动复制虽然会导致更高的部署成本，但可以克服这些限制，并允许掩盖故障的影响，满足严格的端到端延迟要求。我们介绍了在流行的Apache Flink平台中主动复制的设计、实现和评估。我们的研究探索了两种替代设计，一种是利用外部服务的基于领导者的方法(Kafka和ZooKeeper ),另一种是利用新的确定性合并算法的无领导者实现。我们使用一系列微基准测试和37服务器集群上的SaaS云监控场景进行的评估表明，主动复制的Flink可以完全掩盖故障对端到端延迟的影响。",
                    "title_zh": "Apache Flink中延迟敏感流处理的主动复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00016",
                    "title": "Parameterized Distributed Synthesis of Fault-Tolerance Using Counter Abstraction",
                    "authors": "Hadi Moloodi, Fathiyeh Faghih, Borzoo Bonakdarpour",
                    "abstract": "In this paper, we propose an automated technique for synthesizing fault-tolerant distributed protocols from their fault-intolerant version, where the number of processes is parameterized. A fault-tolerant protocol is one that ensures constant satisfaction of safety and liveness specifications even in the presence of faults. Although the parametrized synthesis problem is undecidable in general, we could propose a sound algorithm for this challenging problem. Our synthesis algorithm utilizes counter abstraction to construct a finite representation of the state space. Then, it performs fixpoint calculations to compute and exclude states that violate the safety/liveness specifications in the presence of faults. We demonstrate the effectiveness of our algorithm by synthesizing fault-tolerant distributed protocols for well-known problems, such as reliable broadcast and a simplified version of Byzantine agreement in a matter of seconds.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们提出了一种从容错分布式协议综合容错分布式协议的自动化技术，其中进程的数量是参数化的。容错协议是一种即使在存在故障的情况下也能确保持续满足安全性和活性规范的协议。虽然参数化综合问题通常是不可判定的，但我们可以为这个具有挑战性的问题提出一个合理的算法。我们的合成算法利用计数器抽象来构造状态空间的有限表示。然后，它执行定点计算，以计算和排除出现故障时违反安全性/活性规范的状态。我们通过为众所周知的问题合成容错分布式协议来证明我们的算法的有效性，例如可靠的广播和几秒钟内拜占庭协议的简化版本。",
                    "title_zh": "基于计数器抽象的参数化分布式容错综合"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00017",
                    "title": "Threat Adaptive Byzantine Fault Tolerant State-Machine Replication",
                    "authors": "Douglas Simões Silva, Rafal Graczyk, Jérémie Decouchant, Marcus Völp, Paulo Esteves Veríssimo",
                    "abstract": "Critical infrastructures have to withstand advanced and persistent threats, which can be addressed using Byzantine fault tolerant state-machine replication (BFT-SMR). In practice, unattended cyberdefense systems rely on threat level detectors that synchronously inform them of changing threat levels. However, to have a BFT-SMR protocol operate unattended, the state-of-the-art is still to configure them to withstand the highest possible number of faulty replicas $f$ they might encounter, which limits their performance, or to make the strong assumption that a trusted external reconfiguration service is available, which introduces a single point of failure. In this work, we present ThreatAdaptive the first BFT-SMR protocol that is automatically strengthened or optimized by its replicas in reaction to threat level changes. We first determine under which conditions replicas can safely reconfigure a BFT-SMR system, i.e., adapt the number of replicas $n$ and the fault threshold $f$ so as to outpace an adversary. Since replicas typically communicate with each other using an asynchronous network they cannot rely on consensus to decide how the system should be reconfigured. ThreatAdaptive avoids this pitfall by proactively preparing the reconfiguration that may be triggered by an increasing threat when it optimizes its performance. Our evaluation shows that ThreatAdaptive can meet the latency and throughput of BFT baselines configured statically for a particular level of threat, and adapt 30% faster than previous methods, which make stronger assumptions to provide safety.",
                    "files": {
                        "openAccessPdf": "https://repository.kaust.edu.sa/bitstream/10754/673736/1/paper%20%282%29_removed.pdf"
                    },
                    "abstract_zh": "关键基础设施必须抵御高级和持续的威胁，这可以通过拜占庭容错状态机复制(BFT-SMR)来解决。在实践中，无人值守的网络防御系统依赖于威胁级别检测器，这些检测器会同步通知它们威胁级别的变化。然而，为了使BFT-SMR协议无人值守地运行，最先进的技术仍然是将它们配置成能够承受它们可能遇到的最大可能数量的故障复制品，这限制了它们的性能，或者强烈假设可信的外部重新配置服务是可用的，这引入了单点故障。在这项工作中，我们提出了威胁适应性的第一个BFT-SMR协议，它是自动加强或优化其副本反应威胁水平的变化。我们首先确定在什么条件下复制品可以安全地重新配置BFT-SMR系统，即，调整复制品的数量$n$和故障阈值$f$以便超过对手。由于复制品通常使用异步网络相互通信，所以它们不能依靠共识来决定系统应该如何被重新配置。ThreatAdaptive通过在优化性能时主动准备可能由不断增加的威胁触发的重新配置来避免这一缺陷。我们的评估表明，ThreatAdaptive可以满足针对特定威胁级别静态配置的BFT基线的延迟和吞吐量，并且比以前的方法适应速度快30%，以前的方法做出了更强的假设来提供安全性。",
                    "title_zh": "威胁自适应拜占庭容错状态机复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00018",
                    "title": "Failure Recovery from Persistent Memory in Paxos-Based State Machine Replication",
                    "authors": "Jan Z. Konczak, Pawel T. Wojciechowski",
                    "abstract": "Paxos is one of the most popular protocols for state machine replication (a technique used for making services highly available). We are the first to propose a Paxos-based state machine replication framework which is aimed at persistent (non-volatile) memory, pmem in short-a new class of memory offering direct byte-addressable access to memory (e.g., Optane ™ DC Persistent Memory). In the paper, we describe two variants of the framework, called mPaxosSM and mPaxos, which support efficient recovery of processes after crash with the use of pmem. In the latter variant, a part of Paxos's state, and in the former also the entire state machine's state that should survive crashes, are stored in the persistent memory. This allows to achieve low failure recovery time. We used a key-value map to compare our frameworks equipped with different memory backends (pmem, DRAM, and emulated pmem), with the classical Paxos that recovers state from snapshots and logs stored in stable storage, and with Paxos equipped with EpochSS-a state-of-the-art protocol ensuring state recovery from peer replicas. Our results show the advantages of pmem and our approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Paxos是最流行的状态机复制协议之一(一种用于使服务高度可用的技术)。我们率先提出了一个基于Paxos的状态机复制框架，该框架针对持久性(非易失性)存储器，简称pmem一种新的存储器类别，提供对存储器的直接字节可寻址访问(例如Optane DC持久性存储器)。在本文中，我们描述了该框架的两个变体，称为mPaxosSM和mPaxos，它们使用pmem支持崩溃后进程的有效恢复。在后一种变体中，Paxos状态的一部分，以及前一种变体中应该在崩溃中幸存的整个状态机的状态，都存储在永久存储器中。这允许实现低故障恢复时间。我们使用键值映射来比较我们配备了不同内存后端(pmem、DRAM和仿真pmem)的框架、从稳定存储中存储的快照和日志恢复状态的经典Paxos，以及配备了EpochSS的Pax OS——一种确保从对等副本恢复状态的最先进协议。我们的结果显示了pmem和我们的方法的优势。",
                    "title_zh": "基于Paxos的状态机复制中从永久存储器的故障恢复"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00019",
                    "title": "Enabling Low-Redundancy Proactive Fault Tolerance for Stream Machine Learning via Erasure Coding",
                    "authors": "Zhinan Cheng, Lu Tang, Qun Huang, Patrick P. C. Lee",
                    "abstract": "Machine learning for continuous data streams, or stream machine learning in short, is increasingly adopted in real-time big data applications. Fault tolerance is a critical requirement for stream machine learning applications in large-scale distributed deployment. However, existing reactive fault tolerance mechanisms, which trigger failure recovery upon the detection of failures, inevitably incur high recovery overhead and compromise the low-latency requirement of stream machine learning. We design StreamLEC, a stream machine learning system that leverages erasure coding to provide low-redundancy proactive fault tolerance for immediate failure recovery. StreamLEC supports general stream machine learning applications, and incorporates different techniques to mitigate erasure coding overhead. Evaluation on a local cluster and Amazon EC2 shows that StreamLEC achieves much higher throughput than both reactive fault tolerance and replication-based proactive fault tolerance, with negligible failure recovery overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "针对连续数据流的机器学习，或简称为流机器学习，越来越多地被实时大数据应用所采用。容错是大规模分布式部署中流机器学习应用的关键要求。然而，现有的反应式容错机制在检测到故障时触发故障恢复，不可避免地导致高恢复开销，并损害了流机器学习的低延迟要求。我们设计了StreamLEC，这是一个流机器学习系统，它利用擦除编码来提供低冗余的主动容错，以实现即时故障恢复。StreamLEC支持一般的流机器学习应用，并结合了不同的技术来减轻擦除编码开销。在本地集群和Amazon EC2上的评估表明，StreamLEC实现了比被动容错和基于复制的主动容错高得多的吞吐量，而故障恢复开销可以忽略不计。",
                    "title_zh": "通过擦除编码实现流机器学习的低冗余主动容错"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00020",
                    "title": "Characterizing the Impact of Network Delay on Bitcoin Mining",
                    "authors": "Tong Cao, Jérémie Decouchant, Jiangshan Yu, Paulo Esteves Veríssimo",
                    "abstract": "While previous works have discussed the network delay upper bound that guarantees the consistency of Nakamoto consensus, measuring the actual network latencies and evaluating their impact on miners/pools in Bitcoin remain open questions. This paper fills this gap by: (1) defining metrics that quantify the impact of network latency on the mining network; (2) developing a tool, named miner entanglement (ME), to experimentally evaluate these metrics with a focus on the network latency of the top mining pools; and (3) quantifying the impact of the current network delays on Bitcoin's mining network. For example, we evaluated that Poolin, a Bitcoin mining pool, was able to gain between 0.5% and 1.9% of blocks in addition (i.e., from 36.27 BTC to 137.83 BTC) per week thanks to its low network latency. Moreover, as pools are rational in Bitcoin, we model the strategy a pool would follow to improve its network latency (e.g., by leveraging our ME tool) as a two party game. We show that a Bitcoin mining pool could improve its effective hash rate by up to 4.5%. For a multi-party game, we use a state-of-the-art Bitcoin mining simulator to study the situation where all pools attempt to improve their network latency and show that the largest mining pools would improve their revenue and reach a Nash equilibrium while the smaller mining pools would suffer from a decreased access to the network, and therefore a decreased revenue. These conclusions further incentivize the centralisation of the mining network in Bitcoin, and provide an empirical explanation for the observed tendency of pools to design and rely on low latency private networks.",
                    "files": {
                        "openAccessPdf": "https://repository.kaust.edu.sa/bitstream/10754/673735/1/2021135560.pdf"
                    },
                    "abstract_zh": "虽然以前的工作已经讨论了确保中本聪共识一致性的网络延迟上限，但测量实际网络延迟并评估其对比特币矿工/池的影响仍是悬而未决的问题。本文填补了这一空白:(1)定义量化网络延迟对采矿网络的影响的度量；(2)开发一个名为miner entanglement (ME)的工具，以实验性地评估这些度量，重点是顶级挖掘池的网络延迟；以及(3)量化当前网络延迟对比特币挖矿网络的影响。例如，我们评估了比特币挖矿池Poolin，由于其低网络延迟，每周能够额外获得0.5%至1.9%的块(即从36.27 BTC到137.83 BTC)。此外，由于池在比特币中是理性的，我们将池将遵循的改善其网络延迟的策略(例如，通过利用我们的ME工具)建模为两方游戏。我们表明，比特币矿池可以提高其有效散列率高达4.5%。对于多方游戏，我们使用最先进的比特币挖矿模拟器来研究所有池试图改善其网络延迟的情况，并表明最大的挖矿池将提高其收入并达到纳什均衡，而较小的挖矿池将遭受网络访问减少，因此收入减少。这些结论进一步刺激了比特币中挖掘网络的集中化，并为观察到的池设计和依赖低延迟专用网络的趋势提供了经验解释。",
                    "title_zh": "表征网络延迟对比特币挖掘的影响"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00021",
                    "title": "How to Trust Strangers: Composition of Byzantine Quorum Systems",
                    "authors": "Orestis Alpos, Christian Cachin, Luca Zanolini",
                    "abstract": "Trust is the basis of any distributed, fault-tolerant, or secure system. A trust assumption specifies the failures that a system, such as a blockchain network, can tolerate and determines the conditions under which it operates correctly. In systems subject to Byzantine faults, the trust assumption is usually specified through sets of processes that may fail together. Trust has traditionally been symmetric, such that all processes in the system adhere to the same, global assumption about potential faults. Recently, asymmetric trust models have also been considered, especially in the context of blockchains, where every participant is free to choose who to trust. In both cases, it is an open question how to compose trust assumptions. Consider two or more systems, run by different and possibly disjoint sets of participants, with different assumptions about faults: how can they work together? This work answers this question for the first time and offers composition rules for symmetric and for asymmetric quorum systems. These rules are static and do not require interaction or agreement on the new trust assumption among the participants. Moreover, they ensure that if the original systems allow for running a particular protocol (guaranteeing consistency and availability), then so will the joint system. At the same time, the composed system tolerates as many faults as possible, subject to the underlying consistency and availability properties. Reaching consensus with asymmetric trust in the model of personal Byzantine quorum systems (Losa et al., DISC 2019) was shown to be impossible, if the trust assumptions of the processes diverge from each other. With asymmetric quorum systems, and by applying our composition rule, we show how consensus is actually possible, even with the combination of disjoint sets of processes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "信任是任何分布式、容错或安全系统的基础。信任假设指定了系统(例如区块链网络)可以容忍的故障，并确定了系统正确运行的条件。在易受拜占庭错误影响的系统中，信任假设通常是通过可能一起失败的一组进程来指定的。传统上，信任是对称的，因此系统中的所有过程都遵循关于潜在错误的相同的全局假设。最近，不对称信任模型也被考虑，特别是在区块链的环境中，每个参与者都可以自由选择信任谁。在这两种情况下，如何构建信任假设是一个公开的问题。考虑两个或更多的系统，由不同且可能不相交的参与者运行，对故障有不同的假设:它们如何能一起工作？这项工作首次回答了这个问题，并提供了对称和不对称法定人数系统的组成规则。这些规则是静态的，不需要参与者之间就新的信任假设进行交互或达成一致。此外，它们确保如果原始系统允许运行某个特定的协议(保证一致性和可用性)，那么联合系统也会这样做。同时，组成的系统容忍尽可能多的错误，服从底层的一致性和可用性属性。在个人拜占庭法定人数系统(Losa等人，DISC 2019)的模型中，如果流程的信任假设彼此不同，则达成不对称信任的共识是不可能的。对于不对称的法定人数系统，通过应用我们的组合规则，我们展示了即使是不相交的进程集合的组合，共识实际上也是可能的。",
                    "title_zh": "如何信任陌生人:拜占庭法定人数系统的构成"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00022",
                    "title": "Vassago: Efficient and Authenticated Provenance Query on Multiple Blockchains",
                    "authors": "Rui Han, Jiang Xiao, Xiaohai Dai, Shijie Zhang, Yi Sun, Baochun Li, Hai Jin",
                    "abstract": "Recent successful pilot studies on blockchains showed significant benefits of data provenance towards improved visibility and authenticity, as well as a reduction of administrative costs. Traditionally, all the parties reside in a single blockchain system, which leads to various single-chain provenance query schemes. However, for the sake of convenience, it has been a trend for different parties to deploy their own blockchain systems separately, which requires cross-chain provenance queries. Unfortunately, state-of-the-art blockchain query schemes suffered from inauthentic transactions and low efficiencies when expanding to adversarial cross-chain commercial deals. To be more specific, query results may be inconsistent and incomplete over multiple blockchains due to the lack of global knowledge on cross-chain dependencies. Moreover, these schemes perform cross-chain provenance queries in sequence, leading to high query latencies. In this paper, we present Vassago, the first multi-chain system that empowers efficient and authenticated provenance queries. Vassago incorporates three innovative designs: 1) it explores the dependencies of cross-chain transactions, 2) it validates the authenticity of cross-chain provenance by recording and querying the dependencies on a shared blockchain, and 3) it improves efficiency by parallelizing query processes. Our experimental results show that Vassago can shorten the query latency by 85.9% and reduce the storage consumption by up to 85.7%, with negligible overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近关于区块链的成功试点研究表明，数据来源对提高可见性和真实性以及降低行政费用有显著好处。传统上，所有各方驻留在单个区块链系统中，这导致了各种单链出处查询方案。然而，为了方便起见，不同方分别部署他们自己的区块链系统已经成为一种趋势，这需要跨链的出处查询。不幸的是，当扩展到对抗性跨链商业交易时，最先进的区块链查询方案遭受不真实交易和低效率。更具体地说，由于缺乏跨链依赖性的全局知识，在多个区块链上查询结果可能是不一致和不完整的。此外，这些方案按顺序执行跨链出处查询，导致高查询延迟。在本文中，我们介绍了Vassago，这是第一个支持高效认证出处查询的多链系统。Vassago采用了三种创新设计:1)它探索了跨链事务的依赖性，2)它通过记录和查询共享区块链上的依赖性来验证跨链来源的真实性，3)它通过并行化查询过程来提高效率。我们的实验结果表明，Vassago可以在几乎不增加开销的情况下，将查询延迟缩短85.9%，将存储消耗减少85.7%。",
                    "title_zh": "Vassago:基于多区块链的高效认证出处查询"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00023",
                    "title": "Argus: A Fully Transparent Incentive System for Anti-Piracy Campaigns",
                    "authors": "Xian Zhang, Xiaobing Guo, Zixuan Zeng, Wenyan Liu, Zhongxin Guo, Yang Chen, Shuo Chen, Qiufeng Yin, Mao Yang",
                    "abstract": "Anti-piracy is fundamentally a procedure that relies on collecting data from the open anonymous population, so how to incentivize credible reporting is a question at the center of the problem. Industrial alliances and companies are running anti-piracy incentive campaigns, but their effectiveness is publicly questioned due to the lack of transparency. We believe that full transparency of a campaign is necessary to truly incentivize people. It means that every role, e.g., content owner, licensee of the content, or every person in the open population, can understand the mechanism and be assured about its execution without trusting any single role. We see this as a distributed system problem. In this paper, we present Argus, a fully transparent incentive system for anti-piracy campaigns. The groundwork of Argus is to formulate the objectives for fully transparent incentive mechanisms, which securely and comprehensively consolidate the different interests of all roles. These objectives form the core of the Argus design, highlighted by our innovations about a Sybil-proof incentive function, a commit-and-reveal scheme, and an oblivious transfer scheme. In the implementation, we overcome a set of unavoidable obstacles to ensure security despite full transparency. Moreover, we effectively optimize several cryptographic operations so that the cost for a piracy reporting is reduced to an equivalent cost of sending about 14 ETH-transfer transactions to run on the public Ethereum network, which would otherwise correspond to thousands of transactions. With the security and practicality of Argus, we hope real-world anti-piracy campaigns will be truly effective by shifting to a fully transparent incentive mechanism.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "反盗版从根本上说是一个依赖于从公开的匿名人群中收集数据的过程，因此如何激励可信的报告是问题的核心。产业联盟和公司正在开展反盗版激励活动，但由于缺乏透明度，其有效性受到公众质疑。我们认为，要真正激励人们，竞选活动的完全透明是必要的。这意味着每一个角色，例如内容所有者、内容的被许可者或开放群体中的每一个人，都可以理解该机制并确信其执行，而无需信任任何单个角色。我们认为这是一个分布式系统的问题。在本文中，我们提出Argus，一个完全透明的反盗版运动激励系统。Argus的基础是为完全透明的激励机制制定目标，安全而全面地巩固所有角色的不同利益。这些目标构成了Argus设计的核心，突出表现在我们关于Sybil-proof激励功能、提交和披露方案以及不经意转移方案的创新。在实施过程中，我们克服了一系列不可避免的障碍，以确保安全，尽管完全透明。此外，我们有效地优化了一些加密操作，从而将盗版报告的成本降低到相当于在公共以太网上发送大约14个ETH-transfer交易的成本，否则这将对应于数千个交易。凭借Argus的安全性和实用性，我们希望通过转向完全透明的激励机制，真实世界的反盗版运动将真正有效。",
                    "title_zh": "Argus:一个完全透明的反盗版激励系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00024",
                    "title": "BROFY: Towards Essential Integrity Protection for Microservices",
                    "authors": "Ardhi Putra Pratama Hartono, Christof Fetzer",
                    "abstract": "Trusted computing has emerged as one of the main components in a critical microservice application. A powerful adversary such as the cloud provider could harm its integrity by altering the application's code, behavior, and memory. Numerous attempts to preserve application integrity have been made, especially using Trusted Execution Environments (TEE). However, recent studies show that a CPU bitflip, which both adversary or faulty hardware can trigger, may invalidate its integrity despite being executed inside TEE. In the form of Silent Data Corruption (SDC), this bitflip may come undetected and shamble the trust built in a distributed system. We present BROFY, a toolchain that makes the program reliably perform correct computation inside the Intel SGX enclave that already provides code and memory integrity protection out-of-the-box. BROFY is compatible with multiple programming languages, needs no specific requirements or changes on the codebase, and offers a configurable trade-off between recovery ability and performance. We tested BROFY against actual bitflips by undervolting CPU, and our results show a significant decrease in irrecoverable failure rate from 96.7% to 0.5%, with a 100% detection rate inside an SGX enclave. Our experiment shows that programs armored by BROFY, compared to native execution, have 84% overhead on average based on the computation-intensive Starbench benchmark and only 3% overhead on a multithreaded HTTP server application written in C.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可信计算已经成为关键微服务应用的主要组成部分之一。如云提供商这样的强大对手可能会通过改变应用程序的代码、行为和内存来损害其完整性。已经进行了许多尝试来保持应用程序的完整性，尤其是使用可信执行环境(TEE)。然而，最近的研究表明，对手或有故障的硬件都可能触发的CPU位翻转可能会使其完整性无效，尽管它是在TEE中执行的。以无声数据破坏(SDC)的形式，这种比特翻转可能会不被检测到，并破坏分布式系统中建立的信任。我们展示了BROFY工具链，它使程序能够在英特尔SGX飞地内可靠地执行正确的计算，该飞地已经提供了开箱即用的代码和内存完整性保护。BROFY与多种编程语言兼容，不需要对代码库进行特定的要求或更改，并在恢复能力和性能之间提供可配置的权衡。我们通过低估CPU对BROFY进行了测试，结果显示不可恢复的故障率从96.7%显著下降到0.5%，在SGX飞地内的检测率为100%。我们的实验表明，基于计算密集型的Starbench基准测试，与本机执行相比，BROFY保护的程序平均开销为84%，而在用c编写的多线程HTTP服务器应用程序上，开销仅为3%。",
                    "title_zh": "BROFY:面向微服务的基本完整性保护"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00025",
                    "title": "A Secure Access and Accountability Framework for Provisioning Services in Named Data Networks",
                    "authors": "Nazatul Haque Sultan, Vijay Varadharajan, Chandan Kumar Chaudhary, Seyit Camtepe, Surya Nepal",
                    "abstract": "Named Data Networking (NDN) is an emerging network architecture, which is built by keeping data as its pivotal point. The in-network cache, one of the important characteristics, makes data packets to be available from multiple locations on the Internet. Hence data access control and their enforcement mechanisms become even more critical in the NDNs. In this paper, we propose a novel encryption-based data access control scheme using Role-Based Encryption (RBE). The inheritance property of our scheme provides a natural way to achieve efficient data access control over hierarchical content. This in turn makes our scheme suitable for large scale real world content-centric applications and services such as Netflix. Further, the proposed scheme introduces an anonymous signature-based authentication mechanism to reject bogus data requests nearer to the source, thereby preventing them from entering the network. This in turn helps to mitigate better denial of service attacks. In addition, the signature mechanism supports unlinkability, which is essential to prevent leakages of individual user's access patterns. Another major feature of the proposed scheme is that it provides accountability of the Internet Service Providers (ISPs) using batch signature verification. Moreover, we have developed a transparent and secure dispute resolution and payment mechanism using smart-contract and blockchain technologies. We present a formal security analysis of our scheme to show it is provably secure against Chosen Plaintext Attacks. We also demonstrate that our scheme supports more functionalities than the existing schemes and its performance is better in terms of computation, communication and storage.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "命名数据网络(NDN)是一种新兴的网络体系结构，它是以数据为中心构建的。网络内缓存是一个重要的特征，它使得数据包可以从互联网上的多个位置获得。因此，数据访问控制及其执行机制在NDNs中变得更加重要。在本文中，我们提出了一种新的基于加密的数据访问控制方案，该方案使用基于角色的加密(RBE)。我们的方案的继承属性提供了一种自然的方式来实现对分层内容的有效数据访问控制。这反过来使得我们的方案适合于大规模的真实世界的以内容为中心的应用和服务，例如网飞。此外，所提出的方案引入了基于匿名签名的认证机制，以拒绝更接近源的伪造数据请求，从而防止它们进入网络。这反过来有助于更好地缓解拒绝服务攻击。此外，签名机制支持不可链接性，这对于防止个人用户访问模式的泄露是至关重要的。所提出的方案的另一个主要特征是，它使用批量签名验证来提供因特网服务提供商(ISP)的责任。此外，我们还利用智能合同和区块链技术开发了一个透明、安全的争议解决和支付机制。我们对我们的方案进行了形式化的安全性分析，证明了它在选择明文攻击下是可证明安全的。我们还证明了我们的方案比现有方案支持更多的功能，并且在计算、通信和存储方面具有更好的性能。",
                    "title_zh": "用于在命名数据网络中提供服务的安全访问和责任框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00026",
                    "title": "CODBS: A cascading oblivious search protocol optimized for real-world relational database indexes",
                    "authors": "Rogério Pontes, Bernardo Portela, Manuel Barbosa, Ricardo Vilaça",
                    "abstract": "Encrypted databases systems and searchable encryption schemes still leak critical information (e.g.: access patterns) and require a choice between privacy and efficiency. We show that using ORAM schemes as a black-box is not a panacea and that optimizations are still possible by improving the data structures. We design an ORAM-based secure database that is built from the ground up: we replicate the typical data structure of a database system using different optimized ORAM constructions and derive a new solution for oblivious searches on databases. Our construction has a lower bandwidth overhead than state-of-the-art ORAM constructions by moving client-side computations to a proxy with an intermediate (rigorously defined) level of trust, instantiated as a server-side isolated execution environment. We formally prove the security of our construction and show that its access patterns depend only on public information. We also provide an implementation compatible with SQL databases (PostgresSQL). Our system is 1.2 times to 4 times faster than state-of-the-art ORAM-based solutions.",
                    "files": {
                        "openAccessPdf": "http://repositorio.inesctec.pt/bitstreams/d2fdaf39-782c-41c1-8468-797764e6d79d/download"
                    },
                    "abstract_zh": "加密的数据库系统和可搜索的加密方案仍然会泄漏关键信息(例如:访问模式)，并且需要在隐私和效率之间做出选择。我们证明了使用ORAM方案作为黑盒并不是万能的，通过改进数据结构优化仍然是可能的。我们设计了一个基于ORAM的安全数据库，它是从头开始构建的:我们使用不同的优化ORAM构造复制了数据库系统的典型数据结构，并导出了一个新的对数据库进行遗忘搜索的解决方案。通过将客户端计算转移到具有中间(严格定义的)信任级别的代理，实例化为服务器端隔离的执行环境，我们的构造比最先进的ORAM构造具有更低的带宽开销。我们正式证明了我们的构造的安全性，并表明它的访问模式只依赖于公共信息。我们还提供了与SQL数据库(PostgresSQL)兼容的实现。我们的系统比最先进的基于ORAM的解决方案快1.2到4倍。",
                    "title_zh": "CODBS:为现实世界关系数据库索引优化的级联不经意搜索协议"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00027",
                    "title": "Scrooge Attack: Undervolting ARM Processors for Profit: Practical experience report",
                    "authors": "Christian Göttel, Konstantinos Parasyris, Osman S. Unsal, Pascal Felber, Marcelo Pasin, Valerio Schiavoni",
                    "abstract": "Latest ARM processors are approaching the computational power of x86 architectures while consuming much less energy. Consequently, supply follows demand with Amazon EC2, Equinix Metal and Microsoft Azure offering ARM-based instances, while Oracle Cloud Infrastructure is about to add such support. We expect this trend to continue, with an increasing number of cloud providers offering ARM-based cloud instances. ARM processors are more energy-efficient leading to substantial electricity savings for cloud providers. However, a malicious cloud provider could intentionally reduce the CPU voltage to further lower its costs. Running applications malfunction when the undervolting goes below critical thresholds. By avoiding critical voltage regions, a cloud provider can run undervolted instances in a stealthy manner. This practical experience report describes a novel attack scenario: an attack launched by the cloud provider against its users to aggressively reduce the processor voltage for saving energy to the last penny. We call it the Scrooge Attack and show how it could be executed using ARM-based computing instances. We mimic ARM-based cloud instances by deploying our own ARM-based devices using different generations of Raspberry Pi. Using realistic and synthetic workloads, we demonstrate to which degree of aggressiveness the attack is relevant. The attack is unnoticeable by our detection method up to an offset of −50 mV. We show that the attack may even remain completely stealthy for certain workloads. Finally, we propose a set of client-based detection methods that can identify undervolted instances. We support experimental reproducibility and provide instructions to reproduce our results.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2107.00416"
                    },
                    "abstract_zh": "最新的ARM处理器正在接近x86架构的计算能力，同时消耗更少的能量。因此，Amazon EC2、Equinix Metal和Microsoft Azure提供基于ARM的实例，而Oracle Cloud Infrastructure也将增加这种支持，从而满足需求。随着越来越多的云提供商提供基于ARM的云实例，我们预计这一趋势将会继续。ARM处理器更加节能，为云提供商节省了大量电力。然而，恶意的云提供商可能会故意降低CPU电压，以进一步降低成本。当欠载低于临界阈值时，正在运行的应用程序会出现故障。通过避开临界电压区域，云提供商可以秘密地运行欠电压实例。这份实践经验报告描述了一个新颖的攻击场景:云提供商针对其用户发起的攻击，以大幅降低处理器电压，从而将能源节约到最后一分钱。我们称之为Scrooge攻击，并展示如何使用基于ARM的计算实例来执行它。我们通过使用不同代的Raspberry Pi部署我们自己的基于ARM的设备来模仿基于ARM的云实例。使用真实和合成的工作负载，我们展示了攻击的相关攻击程度。失调高达50 mV时，我们的检测方法察觉不到这种攻击。我们表明，对于某些工作负载，攻击甚至可以保持完全隐蔽。最后，我们提出了一套基于客户端的检测方法，可以识别欠载实例。我们支持实验重现性，并提供重现我们结果的说明。",
                    "title_zh": "吝啬鬼攻击:为了利润而低估ARM处理器:实践经验报告"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00028",
                    "title": "2PPS - Publish/Subscribe with Provable Privacy",
                    "authors": "Sarah Abdelwahab Gaballah, Christoph Coijanovic, Thorsten Strufe, Max Mühlhäuser",
                    "abstract": "Publish/Subscribe systems like Twitter and Reddit let users communicate with many recipients without requiring prior personal connections. The content that participants of these systems publish and subscribe to is typically public, but they may nevertheless wish to remain anonymous. While many existing systems allow users to omit explicit identifiers, they do not address the obvious privacy risks of being associated with content that may contain a wide range of sensitive information. We present 2PPS (Twice-Private Publish-Subscribe), the first pub/sub protocol to deliver strong provable privacy protection for both publishers and subscribers, leveraging Distributed Point Function-based secret sharing for publishing and Private Information Retrieval for subscribing. 2PPS does not require trust in other clients and its privacy guarantees hold as long as even a single honest server participant remains. Furthermore, it is scalable and delivers latency suitable for microblogging applications. A prototype implementation of 2PPS can handle 100,000 concurrent active clients with 5 seconds end-to-end latency and significantly lower bandwidth requirements than comparable systems.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2108.08624"
                    },
                    "abstract_zh": "像Twitter和Reddit这样的发布/订阅系统允许用户与许多接收者交流，而不需要事先的个人联系。这些系统的参与者发布和订阅的内容通常是公开的，但是他们可能仍然希望保持匿名。虽然许多现有系统允许用户省略显式标识符，但是它们没有解决与可能包含各种敏感信息的内容相关联的明显隐私风险。我们提出了2PPS(两次私有发布-订阅),这是第一个为发布者和订阅者提供强有力的可证明隐私保护的发布/订阅协议，利用基于分布式点函数的秘密共享进行发布，利用私有信息检索进行订阅。2PPS不需要信任其他客户机，只要还有一个诚实的服务器参与者，它的隐私保证就成立。此外，它是可扩展的，并提供适合微博应用的延迟。2PPS的原型实现可以处理100，000个并发活动客户端，端到端延迟为5秒，带宽要求比同类系统低得多。",
                    "title_zh": "2PPS -发布/订阅可证明隐私"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00029",
                    "title": "A Comprehensive Measurement-based Investigation of DNS Hijacking",
                    "authors": "Rebekah Houser, Shuai Hao, Zhou Li, Daiping Liu, Chase Cotton, Haining Wang",
                    "abstract": "Attacks against the domain name system (DNS) have long plagued the Internet, requiring continual investigation and vigilance to prevent the abuse of this critical infrastructure. Among these attacks, DNS hijacking has repeatedly asserted itself as one of the most serious threats. In recent years, the severity of DNS hijacking has motivated renewed interest in developing more robust defenses. The size, dynamism, and diversity of the DNS ecosystem present nontrivial challenges to crafting an effective and scalable defense. Further, the relative rarity of documented DNS hijacking attacks makes them difficult to study in-depth. In this paper, we attempt to address the challenges in two thrusts. We first conduct an analysis based on the reports of confirmed DNS hijacking attacks and passive DNS records to characterize known DNS hijacking attacks and identify features for building defense mechanisms. Then we explore the extent to which the characteristic features can be used to build a DNS hijacking detection mechanism and evaluate its effectiveness from the perspective of a network gateway.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对域名系统(DNS)的攻击长期以来一直困扰着互联网，需要持续的调查和警惕，以防止滥用这一关键的基础设施。在这些攻击中，DNS劫持一再声称自己是最严重的威胁之一。近年来，DNS劫持的严重性激发了人们对开发更强大防御的兴趣。DNS生态系统的规模、动态性和多样性给打造有效且可扩展的防御带来了不小的挑战。此外，记录在案的DNS劫持攻击相对罕见，因此很难对其进行深入研究。在本文中，我们试图从两个方面解决这些挑战。我们首先根据已确认的DNS劫持攻击报告和被动DNS记录进行分析，以描述已知的DNS劫持攻击，并确定构建防御机制的特征。然后，我们探讨了在何种程度上可以使用这些特征来建立DNS劫持检测机制，并从网关的角度评估其有效性。",
                    "title_zh": "基于测量的DNS劫持综合调查"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00030",
                    "title": "What Distributed Systems Say: A Study of Seven Spark Application Logs",
                    "authors": "Sina Gholamian, Paul A. S. Ward",
                    "abstract": "Execution logs are a crucial medium as they record runtime information of software systems. Although extensive logs are helpful to provide valuable details to identify the root cause in postmortem analysis in case of a failure, this may also incur performance overhead and storage cost. Therefore, in this research, we present the result of our experimental study on seven Spark benchmarks to illustrate the impact of different logging verbosity levels on the execution time and storage cost of distributed software systems. We also evaluate the log effectiveness and the information gain values, and study the changes in performance and the generated logs for each benchmark with various types of distributed system failures. Our research draws insightful findings for developers and practitioners on how to set up and utilize their distributed systems to benefit from the execution logs.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2108.08395"
                    },
                    "abstract_zh": "执行日志是记录软件系统运行时信息的重要媒介。虽然大量的日志有助于提供有价值的详细信息，以便在失败的情况下在事后分析中识别根本原因，但这也可能导致性能开销和存储成本。因此，在本研究中，我们展示了我们在七个Spark基准上的实验研究结果，以说明不同的日志详细程度对分布式软件系统的执行时间和存储成本的影响。我们还评估了日志有效性和信息增益值，并研究了各种类型的分布式系统故障下每个基准的性能变化和生成的日志。我们的研究为开发人员和实践者提供了关于如何设置和利用他们的分布式系统以从执行日志中获益的深刻发现。",
                    "title_zh": "分布式系统说什么:对七个Spark应用程序日志的研究"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00031",
                    "title": "GeoPaxos+: Practical Geographical State Machine Replication",
                    "authors": "Paulo R. Coelho, Fernando Pedone",
                    "abstract": "In some online services, the geographical location of a client tends to determine the data accessed by the client's requests. Geographical locality holds, for example, in location-based services, tracking systems, and social networking services. State machine replication protocols can use geographical locality to optimize performance by ordering requests efficiently. In order to be effective, though, two requirements must be fulfilled. First, protocols must identify the data accessed by a request before the request is executed. Second, protocols must determine which parts of the service state are accessed where and with what probability. The paper presents a geographical state machine replication protocol that meets both requirements. We illustrate the use of our protocol by developing a geographically replicated B+ Tree service. We fully implemented the B+ Tree service and show experimentally that it outperforms implementations based on classic (i.e., Paxos) and recent (i.e., EPaxos) general-purpose replication protocols by a large margin.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在一些在线服务中，客户端的地理位置往往决定了客户端请求所访问的数据。例如，地理位置适用于基于位置的服务、跟踪系统和社交网络服务。状态机复制协议可以使用地理位置，通过高效地对请求进行排序来优化性能。然而，为了有效，必须满足两个要求。首先，协议必须在执行请求之前识别请求所访问的数据。其次，协议必须确定服务状态的哪些部分在哪里被访问以及以什么概率被访问。本文提出了一个满足这两个要求的地理状态机复制协议。我们通过开发地理上复制的B+树服务来说明我们的协议的使用。我们完全实现了B+ Tree服务，并通过实验表明，它远远优于基于经典(即Paxos)和最新(即EPaxos)通用复制协议的实现。",
                    "title_zh": "GeoPaxos+:实用地理状态机复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00032",
                    "title": "Automated Intelligent Healing in Cloud-Scale Data Centers",
                    "authors": "Rui Li, Zhinan Cheng, Patrick P. C. Lee, Pinghui Wang, Yi Qiang, Lin Lan, Cheng He, Jinlong Lu, Mian Wang, Xinquan Ding",
                    "abstract": "Modern cloud-scale data centers necessitate self-healing (i.e., the automation of detecting and repairing component failures) to support reliable and scalable cloud services in the face of prevalent failures. Traditional policy-based self-healing solutions rely on expert knowledge to define the proper policies for choosing repair actions, and hence are error-prone and non-scalable in practical deployment. We propose AIHS, an automated intelligent healing system that applies machine learning to achieve scalable self-healing in cloud-scale data centers. AIHS is designed as a full-fledged, general pipeline that supports various machine learning models for predicting accurate repair actions based on raw monitoring logs. We conduct extensive trace-driven and production experiments, and show that AIHS achieves higher prediction accuracy than current self-healing solutions and successfully fixes 92.4% of the total of 33.7 million production failures over seven months. AIHS also reduces 51% of unavailable time of each failed server on average compared to policy-based self-healing. AIHS is now deployed in production cloud-scale data centers at Alibaba with a total of 600 K servers. We open-source a Python prototype that reproduces the self-healing pipeline of AIHS for public validation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代云规模的数据中心需要自我修复(即自动检测和修复组件故障)，以在面临普遍故障时支持可靠和可扩展的云服务。传统的基于策略的自我修复解决方案依赖于专家知识来定义选择修复动作的适当策略，因此在实际部署中容易出错且不可扩展。我们提出了AIHS，这是一个自动化的智能修复系统，它应用机器学习来实现云规模数据中心的可扩展自我修复。AIHS被设计为成熟的通用管道，支持各种机器学习模型，用于基于原始监控日志预测准确的修复动作。我们进行了广泛的跟踪驱动和生产实验，并表明AIHS实现了比当前自我修复解决方案更高的预测准确性，并在7个月内成功修复了3370万次生产故障中的92.4%。与基于策略的自我修复相比，AIHS还将每台故障服务器的不可用时间平均减少了51%。AIHS现在部署在阿里巴巴的生产云规模数据中心，共有60万台服务器。我们开源了一个Python原型，它重现了AIHS的自我修复管道，供公众验证。",
                    "title_zh": "云规模数据中心的自动化智能修复"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00033",
                    "title": "MinervaFS: A User-Space File System for Generalised Deduplication: (Practical experience report)",
                    "authors": "Lars Nielsen, Dorian Burihabwa, Valerio Schiavoni, Pascal Felber, Daniel E. Lucani",
                    "abstract": "Deduplication exploits the presence of similar data chunks to reduce storage overhead. Generalised deduplication (GD) uses transformation functions to split data into a basis (common to millions of chunks) and a deviation with respect to the basis. Doing so, it avoids computing additional hashes, comparing or differentiating against previously stored chunks. Minervafs is the first FUSE-based file system for GD. We implement and evaluate it using several real-world datasets, e.g., satellite images and virtual machine images, comparing against classical deduplication approaches (ZFS, SDFS), delta compression (xdelta) or compression (Gzip). Compared to ZFS, Minervafs achieves up to 63.53% (average of 27.38%) saving in storage usage and a speedup of 16% in read-heavy workloads. For VM images, MINERVAFS's data compression is on par with Gzip, while outperforming ZFS by severalfold. In contrast to ZFS’ growing RAM costs when more data is stored, MinervaFS’ RAM usage is independent from the amount of data stored, making it well suited to handle growing storage demands.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "重复数据删除利用相似数据区块的存在来减少存储开销。广义重复数据删除(GD)使用转换函数将数据分为一个基数(数百万个区块共有)和一个相对于基数的偏差。这样做，它避免了计算额外的散列，与先前存储的块进行比较或区分。Minervafs是GD的第一个基于FUSE的文件系统。我们使用几个真实数据集(例如卫星图像和虚拟机图像)实施和评估它，并与传统的重复数据删除方法(SDFS ZFS)、增量压缩(xdelta)或压缩(Gzip)进行比较。与ZFS相比，Minervafs在存储使用方面实现了高达63.53%(平均27.38%)的节省，在读取密集型工作负载方面实现了16%的加速。对于虚拟机映像，MINERVAFS的数据压缩与Gzip不相上下，同时比ZFS高出几倍。与ZFS存储更多数据时不断增加的RAM成本相反，MinervaFS的RAM使用与存储的数据量无关，这使其非常适合处理不断增长的存储需求。",
                    "title_zh": "MinervaFS:用于通用重复数据删除的用户空间文件系统:(实践经验报告)"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00034",
                    "title": "Low-Rate Overuse Flow Tracer (LOFT): An Efficient and Scalable Algorithm for Detecting Overuse Flows",
                    "authors": "Simon Scherrer, Che-Yu Wu, Yu-Hsi Chiang, Benjamin Rothenberger, Daniele Enrico Asoni, Arish Sateesan, Jo Vliegen, Nele Mentens, Hsu-Chun Hsiao, Adrian Perrig",
                    "abstract": "Current probabilistic flow-size monitoring can only detect heavy hitters (e.g., flows utilizing 10 times their permitted bandwidth), but cannot detect smaller overuse (e.g., flows utilizing 50-100 % more than their permitted bandwidth). Thus, these systems lack accuracy in the challenging environment of high-throughput packet processing, where fast-memory resources are scarce. Nevertheless, many applications rely on accurate flow-size estimation, e.g., for network monitoring, anomaly detection and Quality of Service. We design, analyze, implement, and evaluate LOFT, a new approach for efficiently detecting overuse flows that achieves dramatically better properties than prior work. LOFT can detect 1.50x overuse flows in one second, whereas prior approaches can only reliably detect flows that overuse their allocation by at least 3x. We demonstrate LOFT's suitability for high-speed packet processing with implementations in the DPDK framework and on an FPGA.",
                    "files": {
                        "openAccessPdf": "https://lirias.kuleuven.be/bitstream/20.500.12942/699586/2/article-3360.pdf"
                    },
                    "abstract_zh": "当前的概率流大小监控只能检测大流量(例如，利用10倍于其许可带宽的流)，而不能检测较小的过度使用(例如，利用超过其许可带宽50-100 %的流)。因此，这些系统在高吞吐量分组处理的挑战性环境中缺乏准确性，在这种环境中快速存储器资源是稀缺的。然而，许多应用依赖于精确的流大小估计，例如用于网络监控、异常检测和服务质量。我们设计、分析、实现和评估LOFT，这是一种有效检测过度使用流的新方法，它比以前的工作具有更好的特性。LOFT可以在一秒钟内检测到1.50倍的过度使用流，而现有方法只能可靠地检测到过度使用其分配至少3倍的流。我们通过在DPDK框架和FPGA上的实现，展示了LOFT对于高速数据包处理的适用性。",
                    "title_zh": "低速率过度使用流量跟踪器(LOFT):一种有效的可扩展的过度使用流量检测算法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00035",
                    "title": "FIFO and Atomic broadcast algorithms with bounded message size for dynamic systems",
                    "authors": "Colette Johnen, Luciana Arantes, Pierre Sens",
                    "abstract": "FIFO broadcast provides application ordering semantics of messages broadcast by the same sender and have been mostly implemented on top of unreliable static networks. In this article, we propose a round-based FIFO broadcast algorithm with both termination detection and bounded message size for dynamic networks with recurrent connectivity (Class $\\mathcal{TC}^{\\mathcal{R}}$ of Time-varying Graph formalism [1]). Initially, processes only know the number of processes $N$ in the system and their identifier. Due to the dynamics of the network links, messages can be lost. Since no unbounded timestamp is used to identify a message, its size is bounded to $2N+O(log(N))+msgSize$ bits where msgSize is the bound size in bits of the broadcast data. We also present a FIFO atomic broadcast algorithm for dynamic networks with recurrent connectivity that uses the proposed FIFO broadcast and deliver primitives. This algorithm provides causal total order broadcast primitives.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-03332423/file/srds-2021.pdf"
                    },
                    "abstract_zh": "FIFO广播提供由同一发送者广播的消息的应用排序语义，并且主要在不可靠的静态网络上实现。在本文中，我们提出了一种基于循环的FIFO广播算法，该算法具有终止检测和有界消息大小，适用于具有循环连通性的动态网络(时变图形式的类$\\mathcal{tc}^{\\mathcal{r}}$[1])。最初，进程只知道系统中进程$N$的数量和它们的标识符。由于网络链路的动态性，消息可能会丢失。由于没有使用不受限制的时间戳来标识消息，因此其大小被限制为$2N+O(log(N))+msgSize$ bits，其中msgSize是广播数据的限制大小，以位为单位。我们还提出了一种用于具有循环连接的动态网络的FIFO原子广播算法，该算法使用了所提出的FIFO广播和传送原语。该算法提供因果全序广播原语。",
                    "title_zh": "动态系统中消息大小受限的FIFO和原子广播算法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00036",
                    "title": "Sliding Window CRDT Sketches",
                    "authors": "Dolev Adas, Roy Friedman",
                    "abstract": "Sketches maintain compact approximate statistics about streams of data, thereby enabling quickly answering queries regarding the data stream without having to reprocess it. Often, recent data is considered more important than older one, which is captured by the sliding window model. In distributed settings, where parts of the stream are seen by different, potentially geographically distributed components of the system, it makes sense to collect global statistics about the stream, but in a decentralized manner. Further, in order to ensure availability, scalability, and good performance, it is appealing to treat sketches as a CRDT data-type. In this work we introduce the notion of sliding window CRDT sketches. We then present the CRDT All Timestamps (aka CRDT-AT) and CRDT Last Timestamp (aka CRDT-LT) algorithms for implementing such sketches and analyze them. We also study the performance of CRDT-AT and CRDT-LT using real workloads, to establish their viability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "草图保持关于数据流的紧凑的近似统计，从而能够快速回答关于数据流的查询，而不必重新处理它。通常，新数据被认为比旧数据更重要，旧数据由滑动窗口模型捕获。在分布式设置中，系统中不同的、地理上可能分布的组件可以看到流的各个部分，收集关于流的全局统计信息是有意义的，但要以分散的方式进行。此外，为了确保可用性、可伸缩性和良好的性能，将草图视为CRDT数据类型是很有吸引力的。在这项工作中，我们介绍了滑动窗口CRDT草图的概念。然后，我们提出了实现这种草图的CRDT所有时间戳(又名CRDT-AT)和CRDT最后时间戳(又名CRDT-LT)算法，并对它们进行了分析。我们还使用真实工作负载研究了CRDT AT和CRDT LT的性能，以确定它们的可行性。",
                    "title_zh": "滑动窗口CRDT草图"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00037",
                    "title": "Protecting Reward Function of Reinforcement Learning via Minimal and Non-catastrophic Adversarial Trajectory",
                    "authors": "Tong Chen, Yingxiao Xiang, Yike Li, Yunzhe Tian, Endong Tong, Wenjia Niu, Jiqiang Liu, Gang Li, Qi Alfred Chen",
                    "abstract": "Reward functions are critical hyperparameters with commercial values for individual or distributed reinforcement learning (RL), as slightly different reward functions result in significantly different performance. However, existing inverse reinforcement learning (IRL) methods can be utilized to approximate reward functions just based on collected expert trajectories through observing. Thus, in the real RL process, how to generate a polluted trajectory and perform an adversarial attack on IRL for protecting reward functions has become the key issue. Meanwhile, considering the actual RL cost, generated adversarial trajectories should be minimal and non-catastrophic for ensuring normal RL performance. In this work, we propose a novel approach to craft adversarial trajectories disguised as expert ones, for decreasing the IRL performance and realize the anti-IRL ability. Firstly, we design a reward clustering-based metric to integrate both advantages of fine- and coarse-grained IRL assessment, including expected value difference (EVD) and mean reward loss (MRL). Further, based on such metric, we explore an adversarial attack based on agglomerative nesting algorithm (AGNES) clustering and determine targeted states as starting states for reward perturbation. Then we employ the intrinsic fear model to predict the probability of imminent catastrophe, supporting to generate non-catastrophic adversarial trajectories. Extensive experiments of 7 state-of-the-art IRL algorithms are implemented on the Object World benchmark, demonstrating the capability of our proposed approach in (a) decreasing the IRL performance and (b) having minimal and non-catastrophic adversarial trajectories.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "奖励函数是个体或分布式强化学习(RL)中具有商业价值的关键超参数，因为稍微不同的奖励函数会导致显著不同的性能。然而，现有的逆向强化学习(IRL)方法只能基于通过观察收集的专家轨迹来逼近奖励函数。因此，在真实的强化学习过程中，如何生成污染轨迹并对强化学习进行对抗性攻击以保护奖励函数成为关键问题。同时，考虑到实际的RL代价，为了保证正常的RL性能，生成的敌对轨迹应该是最小的和非灾难性的。在本文中，我们提出了一种新的方法来制造伪装成专家轨迹的敌对轨迹，以降低IRL的性能并实现抗IRL的能力。首先，我们设计了一个基于回报聚类的度量来整合细粒度和粗粒度IRL评估的优点，包括期望值差异(EVD)和平均回报损失(MRL)。在此基础上，我们探索了一种基于凝聚嵌套算法(AGNES)聚类的对抗性攻击，并将目标状态确定为奖励扰动的起始状态。然后，我们利用内在恐惧模型来预测即将发生灾难的概率，支持生成非灾难性的敌对轨迹。在Object World benchmark上对7种最先进的IRL算法进行了广泛的实验，证明了我们提出的方法在(a)降低IRL性能和(b)具有最小的和非灾难性的敌对轨迹方面的能力。",
                    "title_zh": "通过最小和非灾难性对抗轨迹保护强化学习的奖励函数"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00038",
                    "title": "WAFFLE: Watermarking in Federated Learning",
                    "authors": "Buse G. A. Tekgul, Yuxi Xia, Samuel Marchal, N. Asokan",
                    "abstract": "Federated learning is a distributed learning technique where machine learning models are trained on client devices in which the local training data resides. The training is coordinated via a central server which is, typically, controlled by the intended owner of the resulting model. By avoiding the need to transport the training data to the central server, federated learning improves privacy and efficiency. But it raises the risk of model theft by clients because the resulting model is available on every client device. Even if the application software used for local training may attempt to prevent direct access to the model, a malicious client may bypass any such restrictions by reverse engineering the application software. Watermarking is a well-known deterrence method against model theft by providing the means for model owners to demonstrate ownership of their models. Several recent deep neural network (DNN) watermarking techniques use backdooring: training the models with additional mislabeled data. Backdooring requires full access to the training data and control of the training process. This is feasible when a single party trains the model in a centralized manner, but not in a federated learning setting where the training process and training data are distributed among several client devices. In this paper, we present WAFFLE, the first approach to watermark DNN models trained using federated learning. It introduces a retraining step at the server after each aggregation of local models into the global model. We show that WAFFLE efficiently embeds a resilient watermark into models incurring only negligible degradation in test accuracy (-0.17%), and does not require access to training data. We also introduce a novel technique to generate the backdoor used as a watermark. It outperforms prior techniques, imposing no communication, and low computational (+3.2%) overhead11The research report version of this paper is also available in https://arxiv.org/abs/2008.07298, and the code for reproducing our work can be found at https://github.com/ssg-research/WAFFLE.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2008.07298"
                    },
                    "abstract_zh": "联合学习是一种分布式学习技术，其中机器学习模型在本地训练数据所在的客户端设备上被训练。训练通过中央服务器来协调，中央服务器通常由最终模型的预期所有者来控制。通过避免将训练数据传输到中央服务器，联合学习提高了隐私和效率。但是这增加了客户窃取模型的风险，因为得到的模型在每个客户设备上都是可用的。即使用于本地训练的应用软件可能试图阻止对模型的直接访问，恶意客户端也可以通过对应用软件进行逆向工程来绕过任何这样的限制。水印是一种众所周知的防止模型盗窃的方法，它为模型所有者提供了证明其模型所有权的手段。几种最近的深度神经网络(DNN)水印技术使用后门:用额外的误标记数据训练模型。走后门要求完全访问培训数据和控制培训过程。当一方以集中的方式训练模型时，这是可行的，但是在训练过程和训练数据分布在几个客户端设备之间的联合学习设置中，这是不可行的。在本文中，我们提出了WAFFLE，第一个使用联邦学习训练的水印DNN模型的方法。它在每次将局部模型聚合到全局模型中之后，在服务器上引入一个再训练步骤。我们表明，WAFFLE有效地将弹性水印嵌入到模型中，仅导致测试精度的可忽略的下降(-0.17%)，并且不需要访问训练数据。我们还介绍了一种新的技术来产生后门用作水印。它优于现有技术，不强加任何通信，且计算开销低(+3.2%)。11本文的研究报告版本也可在https://arxiv.org/abs/2008.07298,获得，复制我们工作的代码可在https://github.com/ssg-research/WAFFLE.找到",
                    "title_zh": "华夫:联邦学习中的水印技术"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00039",
                    "title": "Detecting Malicious Gradients from Asynchronous SGD on Variational Autoencoder",
                    "authors": "Zhipin Gu, Yuexiang Yang, Heyuan Shi",
                    "abstract": "In asynchronous distributed learning, the parameter server updates the global model as soon as a new gradient is received from any device. The asynchronous systems are designed to address the existence of lagging devices which is inevitable due to device heterogeneity and network unreliability. However, the lack of synchrony incurs additional noise and makes detecting and defending against malicious model gradients a challenging task. Unlike existing works that struggle to design robust methods to tolerate untargeted model poisoning gradients, the paper considers detecting and removing targeted model poisoning gradients from the normal asynchronous training process. This paper proposes Asynvae, a robust distributed asynchronous learning framework where the parameter server uses variational autoencoder to detect and exclude malicious gradients. Since the reconstruction error of malicious updates is much larger than that of benign ones, it can be used as an anomaly score. We formulate a threshold of reconstruction error to differentiate malicious updates from normal ones based on this idea. Asynvae is tested with extensive experiments on distributed learning benchmarks, showing a competitive performance over existing distributed learning methods under untargeted model poisoning attack, targeted model poisoning attack and lagging attack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在异步分布式学习中，一旦从任何设备接收到新的梯度，参数服务器就更新全局模型。异步系统旨在解决由于设备异构性和网络不可靠性而不可避免的滞后设备的存在。然而，缺乏同步会导致额外的噪声，并使检测和防御恶意模型梯度成为一项具有挑战性的任务。与现有的努力设计鲁棒的方法来容忍非目标模型中毒梯度的工作不同，本文考虑从正常的异步训练过程中检测和去除目标模型中毒梯度。本文提出了一个健壮的分布式异步学习框架Asynvae，其中参数服务器使用可变自动编码器来检测和排除恶意梯度。由于恶意更新的重构误差远大于良性更新的重构误差，因此可以将其作为异常分值。基于这一思想，我们提出了一个重构误差阈值来区分恶意更新和正常更新。Asynvae通过在分布式学习基准上的大量实验进行测试，在非目标模型中毒攻击、目标模型中毒攻击和滞后攻击下显示了优于现有分布式学习方法的性能。",
                    "title_zh": "基于变分自动编码器的异步SGD恶意梯度检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00040",
                    "title": "DragonFly: Drone-Assisted High-Rise Monitoring for Fire Safety",
                    "authors": "Fangqi Liu, Tzu-Yi Fan, Casey Grant, Cheng-Hsin Hsu, Nalini Venkatasubramanian",
                    "abstract": "In this paper, we propose DragonFly, a drone-based data collection framework to enhance real-time situational awareness in high-rise buildings, focusing specifically on mission-critical high-rise fire scenarios. The goal of our proposed solution is to use multiple drones with visual sensors to collect reliable and timely data for monitoring the exterior of a high-rise building. Drones are especially useful in obtaining data from hard-to-access regions in high-rise fires that are used to monitor fire/smoke that might have propagated to higher floors, detect the presence of humans requiring assistance near windows, and determine window open/close states which can have a significant impact on the speed and direction of fire spread. Given a dynamically evolving set of events and multiple drones, the core challenge addressed is to develop a plan for multiple drones to gather a set of observations that can improve both the coverage (identify more events) and accuracy (obtain fine-grained for improved event detection). We develop a solution for the Multi-drone Waypoint scheduling problem (NP-hard) in two steps: 1) allocation of monitoring tasks (AMT) to individual drones and 2) dynamic waypoint scheduling (DWS) that determines the waypoint sequence for each drone to visit. We evaluate our proposed approach using a simulated high-rise fire scenario with a realistic fire spread model and study the applicability and efficiency of the proposed algorithms compared to baseline techniques. The simulation results demonstrate the superior performance of the proposed AMT-DWS algorithms. DragonFly achieve 33% fewer missing events and up to 39 times gain in accuracy, captured as the minimum weighted AUC (Area Under Curve) as compared to baseline algorithms. DragonFly delivers over 85% missing events and about 1.3 times the minimum weighted AUC in comparison to current approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们提出了DragonFly，一种基于无人机的数据收集框架，用于增强高层建筑中的实时态势感知，特别关注关键任务的高层火灾场景。我们提出的解决方案的目标是使用多架带视觉传感器的无人机收集可靠和及时的数据，以监控高层建筑的外部。无人机在从高层火灾中难以进入的区域获取数据方面特别有用，这些数据用于监控可能已经蔓延到更高楼层的火灾/烟雾，检测窗户附近需要帮助的人的存在，以及确定可能对火势蔓延的速度和方向产生重大影响的窗户打开/关闭状态。给定一组动态发展的事件和多个无人机，所解决的核心挑战是为多个无人机制定一个计划，以收集一组可以提高覆盖率(识别更多事件)和准确性(获得细粒度以改进事件检测)的观察值。我们分两步开发了多无人机航点调度问题(NP-hard)的解决方案:1)将监控任务(AMT)分配给各个无人机，2)动态航点调度(DWS ),确定每个无人机要访问的航点顺序。我们使用模拟的高层火灾场景和真实的火灾蔓延模型来评估我们提出的方法，并研究与基线技术相比所提出的算法的适用性和效率。仿真结果表明了所提出的AMT-DWS算法的优越性能。与基线算法相比，DragonFly实现了33%的遗漏事件减少和高达39倍的准确性提高，以最小加权AUC(曲线下面积)捕获。与当前方法相比，DragonFly提供了超过85%的遗漏事件和大约1.3倍的最小加权AUC。",
                    "title_zh": "DragonFly:用于消防安全的无人机辅助高层监控"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00041",
                    "title": "Sharding Techniques in the Era of Blockchain",
                    "authors": "Chunyu Mao, Wojciech M. Golab",
                    "abstract": "Blockchain is a peer-to-peer ledger that records a growing list of transactions in a tamper-resistant manner using cryptographic hashes. Centralized points of vulnerability are eliminated in blockchain, and so it is considered secure by design under some reasonable assumptions, such as honest majority. But scalability remains a major limitation that can be improved by sharding. Full sharding is one of the approaches in achieving the high performance of blockchain systems. This paper proposes a locality-based full sharding protocol in permissioned blockchains. We introduce a simple and efficient cross-shard transaction handling protocol. A prototype is under development based on Hyperledger Fabric.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "区块链是一个点对点的分类账，它使用加密哈希以防篡改的方式记录越来越多的交易列表。区块链消除了集中的漏洞点，因此在一些合理的假设(如诚实多数)下，它被认为是安全的。但是可伸缩性仍然是一个主要的限制，可以通过分片来改善。完全分片是实现区块链系统高性能的方法之一。本文提出了一个在许可区块链中基于位置的完全分片协议。我们介绍了一个简单有效的跨分片事务处理协议。基于Hyperledger Fabric的原型正在开发中。",
                    "title_zh": "区块链时代的分片技术"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00042",
                    "title": "Adaptive Erasure Coded Data Maintenance for Consensus in Distributed Networks",
                    "authors": "Yulei Jia, Guangping Xu, Chi Wan Sung, Salwa Mostafa",
                    "abstract": "Distributed data services usually rely on consensus protocols, such as Paxos and Raft, to provide fault-tolerance and data consistency across distributed data centers and even edge networks. In consensus protocols, erasure coded replication has appealing storage and network cost savings compared with full copy replication, which help achieve low latency, high fault-tolerance and high throughput. However, the liveness level will inevitably decrease when erasure codes are naively applied in consensus protocols. To keep the original liveness level, an existing protocol, called CRaft, switches from erasure coded replication to full copy replication when the number of failures exceeds a certain threshold. Such a solution, however, degrades system performance sharply. To tackle this problem, this work proposes a novel protocol called HRaft to enable graceful degradation on storage and network efficiency when failures happen. Without using full copy replication, it replenishes some coded blocks in healthy servers to reduce storage and network costs and to keep data consistency. The performance of the proposed protocol will be evaluated by deploving it into practical networks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分布式数据服务通常依赖于一致协议，如Paxos和Raft，以提供跨分布式数据中心甚至边缘网络的容错和数据一致性。在共识协议中，与完整拷贝复制相比，擦除编码复制具有诱人的存储和网络成本节约，这有助于实现低延迟、高容错和高吞吐量。然而，当擦除码被天真地应用于一致性协议时，活性水平将不可避免地降低。为了保持原始的活性水平，当失败次数超过特定阈值时，称为CRaft的现有协议从擦除编码复制切换到完整副本复制。然而，这种解决方案大大降低了系统性能。为了解决这一问题，本文提出了一种称为HRaft的新协议，以在故障发生时实现存储和网络效率的适度下降。在不使用完整拷贝复制的情况下，它会补充健康服务器中的一些编码块，以降低存储和网络成本，并保持数据一致性。该协议的性能将通过部署到实际网络中进行评估。",
                    "title_zh": "分布式网络中一致性的自适应擦除编码数据维护"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00043",
                    "title": "Runtime Verification for Blockchains",
                    "authors": "Ritam Ganguly",
                    "abstract": "Blockchains present a secure and reliable ledger to store transactions, but ensuring that a set of transactions follow a certain policy is difficult. In this paper we present a runtime verification approach to monitor transactions involving multiple blockchains with respect to specifications in metric temporal logic (MTL). In our setting, we consider runtime verification of partially synchronous blockchains where a clock synchronization algorithm guarantees a bound on maximum clock skew among all the blockchains in the system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "区块链提供了一个安全可靠分类帐来存储交易，但是确保一组交易遵循特定的策略是困难的。在本文中，我们提出了一种运行时验证方法来监控涉及多个区块链的事务，这些事务符合度量时态逻辑(MTL)的规范。在我们的设置中，我们考虑部分同步区块链的运行时验证，其中时钟同步算法保证系统中所有区块链之间的最大时钟偏移的界限。",
                    "title_zh": "区块链的运行时验证"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS53918.2021.00044",
                    "title": "Runtime Verification for Distributed Cyber-Physical Systems",
                    "authors": "Anik Momtaz",
                    "abstract": "Cyber-physical systems (CPS) are computer systems with integrated software and physical components that ideally seamlessly interact with the real world and each other. While the use of distributed CPS has rapidly grown over the past decade, so has the need for developing efficient methods to ascertain reliability of these systems by validating their correctness. Since exhaustively validating correctness of a distributed CPS is usually not feasible nor possible, many modern validation methods involve run-time verification of distributed CPS based on safety properties. Our work focuses on developing time and resource efficient assurance techniques that can run in parallel with the execution of these systems to ensure reliability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "信息物理系统(CPS)是集成了软件和物理组件的计算机系统，这些组件可以与现实世界以及彼此之间进行无缝交互。虽然分布式CPS的使用在过去十年中迅速增长，但是也需要开发有效的方法，通过验证它们的正确性来确定这些系统的可靠性。因为彻底验证分布式CPS的正确性通常是不可行的，也是不可能的，所以许多现代验证方法包括基于安全属性的分布式CPS的运行时验证。我们的工作重点是开发时间和资源高效的保证技术，这些技术可以与这些系统的执行并行运行，以确保可靠性。",
                    "title_zh": "分布式信息物理系统的运行时验证"
                }
            ]
        }
    ],
    "2022": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2022.html",
            "conf_title": "41st SRDS 2022: Vienna, Austria",
            "conf_url": "https://doi.org/10.1109/SRDS55811.2022",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00011",
                    "title": "D-Cliques: Compensating for Data Heterogeneity with Topology in Decentralized Federated Learning",
                    "authors": "Aurélien Bellet, Anne-Marie Kermarrec, Erick Lavoie",
                    "abstract": "The convergence speed of machine learning models trained with Federated Learning is significantly affected by heterogeneous data partitions, even more so in a fully decentralized setting without a central server. In this paper, we show that the impact of label distribution skew, an important type of data heterogeneity, can be significantly reduced by carefully designing the underlying communication topology. We present D-Cliques, a novel topology that reduces gradient bias by grouping nodes in sparsely interconnected cliques such that the label distribution in a clique is representative of the global label distribution. We also show how to adapt the updates of decentralized SGD to obtain unbiased gradients and implement an effective momentum with D-Cliques. Our extensive empirical evaluation on MNIST and CIFAR10 validates our design and demonstrates that our approach achieves similar convergence speed as a fully-connected topology, while providing a significant reduction in the number of edges and messages. In a 1000-node topology, D-Cliques require 98% less edges and 96% less total messages, with further possible gains using a small-world topology across cliques.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.07365"
                    },
                    "abstract_zh": "用联合学习训练的机器学习模型的收敛速度受异构数据分区的影响很大，在没有中央服务器的完全分散设置中甚至更大。在本文中，我们证明了标签分布偏差(一种重要的数据异构类型)的影响可以通过仔细设计底层通信拓扑来显著降低。我们提出了D-团，这是一种新的拓扑结构，它通过将稀疏互连的团中的节点分组来减少梯度偏差，使得团中的标签分布代表全局标签分布。我们还展示了如何调整分散SGD的更新，以获得无偏的梯度，并利用D集团实现有效的动量。我们在MNIST和CIFAR10上的大量经验评估验证了我们的设计，并表明我们的方法实现了与全连接拓扑类似的收敛速度，同时显著减少了边和消息的数量。在1000个节点的拓扑中，D-集团需要的边数和总消息数分别减少98%和96%,跨集团使用小世界拓扑还可能获得更多好处。",
                    "title_zh": "D-Cliques:在分散联邦学习中用拓扑补偿数据异构性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00012",
                    "title": "AGIC: Approximate Gradient Inversion Attack on Federated Learning",
                    "authors": "Jin Xu, Chi Hong, Jiyue Huang, Lydia Y. Chen, Jérémie Decouchant",
                    "abstract": "Federated learning is a private-by-design distributed learning paradigm where clients train local models on their own data before a central server aggregates their local updates to compute a global model. Depending on the aggregation method used, the local updates are either the gradients or the weights of local learning models, e.g., FedAvg aggregates model weights. Unfortunately, recent reconstruction attacks apply a gradient inversion optimization on the gradient update of a single mini-batch to reconstruct the private data used by clients during training. As the state-of-the-art reconstruction attacks solely focus on single update, realistic adversarial scenarios are over-looked, such as observation across multiple updates and updates trained from multiple mini-batches. A few studies consider a more challenging adversarial scenario where only model updates based on multiple mini-batches are observable, and resort to computationally expensive simulation to untangle the underlying samples for each local step. In this paper, we propose AGIC, a novel Approximate Gradient Inversion Attack that efficiently and effectively reconstructs images from both model or gradient updates, and across multiple epochs. In a nutshell, AGIC (i) approximates gradient updates of used training samples from model updates to avoid costly simulation procedures, (ii) leverages gradient/model updates collected from multiple epochs, and (iii) assigns increasing weights to layers with respect to the neural network structure for reconstruction quality. We extensively evaluate AGIC on three datasets, namely CIFAR-10, CIFAR-100 and ImageNet. Our results show that AGIC increases the peak signal-to-noise ratio (PSNR) by up to 50% compared to two representative state-of-the-art gradient inversion attacks. Furthermore, AGIC is faster than the state-of-the-art simulation-based attack, e.g., it is 5x faster when attacking FedAvg with 8 local steps in between model updates.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2204.13784"
                    },
                    "abstract_zh": "联合学习是一种私人设计的分布式学习范式，其中客户端在中央服务器聚集它们的本地更新以计算全局模型之前，根据它们自己的数据训练本地模型。取决于所使用的聚集方法，局部更新是局部学习模型的梯度或权重，例如，FedAvg聚集模型权重。不幸的是，最近的重建攻击在单个小批量的梯度更新上应用梯度反演优化来重建客户在训练期间使用的私有数据。由于最新的重建攻击只关注单个更新，因此忽略了现实的对抗场景，例如跨多个更新的观察和从多个小批量训练的更新。少数研究考虑了更具挑战性的对立场景，其中只有基于多个小批量的模型更新是可观察的，并求助于计算昂贵的模拟来解开每个局部步骤的基础样本。在本文中，我们提出了AGIC，一种新的近似梯度反演攻击，有效地从模型或梯度更新重建图像，并跨越多个时期。简而言之，AGIC (i)根据模型更新来近似所使用的训练样本的梯度更新，以避免昂贵的模拟过程，(ii)利用从多个时期收集的梯度/模型更新，以及(iii)相对于神经网络结构为层分配增加的权重，以获得重建质量。我们在三个数据集上广泛评估了AGIC，即CIFAR-10、CIFAR-100和ImageNet。我们的结果表明，与两种代表性的最新梯度反演攻击相比，AGIC将峰值信噪比(PSNR)提高了高达50%。此外，AGIC比最先进的基于模拟的攻击更快，例如，当攻击模型更新之间有8个本地步骤的FedAvg时，它快5倍。",
                    "title_zh": "AGIC:对联邦学习的近似梯度反演攻击"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00013",
                    "title": "DAG-based Task Orchestration for Edge Computing",
                    "authors": "Xiang Li, Mustafa Abdallah, Shikhar Suryavansh, Mung Chiang, Kwang Taik Kim, Saurabh Bagchi",
                    "abstract": "Edge computing promises to exploit underlying computation resources closer to users to help run latency-sensitive applications such as augmented reality and video analytics. However, one key missing piece has been how to incorporate personally owned, unmanaged devices into a usable edge computing system. The primary challenges arise due to the heterogeneity, lack of interference management, and unpredictable availability of such devices. In this paper we propose an orchestration framework IBDASH, which orchestrates application tasks on an edge system that comprises a mix of commercial and personal edge devices. IBDASH targets reducing both end-to-end latency of execution and probability of failure for applications that have dependency among tasks, captured by directed acyclic graphs (DAGs). IBDASH takes memory constraints of each edge device and network bandwidth into consideration. To assess the effectiveness of IBDASH, we run real application tasks on real edge devices with widely varying capabilities. We feed these measurements into a simulator that runs IBDASH at scale. Compared to three state-of-the-art edge orchestration schemes and two intuitive baselines, IBDASH reduces the end-to-end latency and probability of failure, by 14% and 41% on average respectively. The main takeaway from our work is that it is feasible to combine personal and commercial devices into a usable edge computing platform, one that delivers low and predictable latency and high availability.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2301.09278"
                    },
                    "abstract_zh": "边缘计算承诺利用离用户更近的底层计算资源来帮助运行延迟敏感型应用，如增强现实和视频分析。然而，一个关键的缺失是如何将个人拥有的、不受管理的设备整合到可用的边缘计算系统中。主要的挑战来自这些设备的异构性、干扰管理的缺乏和不可预测的可用性。在本文中，我们提出了一个编排框架IBDASH，它在一个混合了商业和个人边缘设备的边缘系统上编排应用任务。IBDASH的目标是减少执行的端到端延迟和任务间有依赖关系的应用程序的失败概率，这是由有向无环图(Dag)捕获的。IBDASH考虑了每个边缘设备的内存限制和网络带宽。为了评估IBDASH的有效性，我们在具有各种功能的真实边缘设备上运行真实的应用程序任务。我们将这些测量结果输入到一个模拟器中，该模拟器大规模运行IBDASH。与三个最先进的边缘协调方案和两个直观的基线相比，IBDASH平均分别降低了14%和41%的端到端延迟和故障概率。我们工作的主要收获是，将个人和商业设备结合到一个可用的边缘计算平台是可行的，该平台提供低且可预测的延迟和高可用性。",
                    "title_zh": "基于DAG的边缘计算任务协调"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00014",
                    "title": "In-Vivo Fuzz Testing for Network Services",
                    "authors": "Wen-Yang Lai, Kun-Che Tsai, Che Chen, Yu-Sung Wu",
                    "abstract": "Fuzz testing is typically carried out by running the target program and the fuzzing engine offline in a lab environment. The environment setup may depend on specialized test harness code to activate the target program and inject the test data. Also, due to the vast program state space, domain knowledge-dependent optimization is often needed in the environment setup to achieve reasonably efficient fuzz testing. We propose In-Vivo Fuzzing to alleviate the burdens by performing online fuzz testing on live programs. In-Vivo Fuzzing hooks I/O library calls in a live program to collect test seeds. Upon request, the In-Vivo Runtime will create a fork of the target program and carry out fuzz testing on the forked process. The runtime states from the live program provide a vantage point to start the fuzzing process, and the test seeds collected from the live workload also facilitate the generation of effective test inputs. We applied In-Vivo Fuzzing to network service programs and implemented a prototype on top of the AFL fuzzer. Experiment results indicate that In-Vivo Fuzzing can reach vulnerabilities in real-world programs much more quickly than the baseline. We also demonstrate the potential application of In-Vivo Fuzzing in detecting unknown attacks, where live attack states are captured and amplified through fuzz testing.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "模糊测试通常通过在实验室环境中离线运行目标程序和模糊引擎来执行。环境设置可能依赖于专门的测试工具代码来激活目标程序并注入测试数据。此外，由于巨大的程序状态空间，在环境设置中经常需要领域知识相关的优化，以实现合理有效的模糊测试。我们提出体内模糊化，通过对实时程序进行在线模糊测试来减轻负担。体内Fuzzing hooks I/O库调用一个实时程序来收集测试种子。根据请求，体内运行时将创建目标程序的分叉，并对分叉的进程执行模糊测试。来自实时程序的运行时状态提供了开始模糊化过程的有利位置，从实时工作负载收集的测试种子也有助于有效测试输入的生成。我们将活体模糊应用于网络服务程序，并在AFL模糊器的基础上实现了一个原型。实验结果表明，体内模糊化可以比基线更快地到达真实世界程序中的漏洞。我们还展示了体内模糊化在检测未知攻击中的潜在应用，其中实时攻击状态通过模糊测试被捕获和放大。",
                    "title_zh": "网络服务的体内模糊测试"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00015",
                    "title": "An Investigation on Data Center Cooling Systems Using FPGA-based Temperature Side Channels",
                    "authors": "Yuan Liang, Xing Gao, Kun Sun, Wenjie Xiong, Haining Wang",
                    "abstract": "As power and cooling cost has become a major factor in the total cost of ownership (TCO) of large-scale data centers, it is important to investigate how data centers run their cooling systems in practice. The data centers of Amazon Web Services (AWS) have been continuously expanding worldwide, and their restrictive security policies keep many management aspects of data centers private. In this paper, we make an attempt to explore the cooling systems of AWS data centers without privileged accesses. We first demonstrate PVT (process, voltage, and temperature) variations in AWS FPGAs (Field Programmable Gate Arrays) using time-digital converters (TDC). We further leverage the DRAM temperature side channel and improve the usage of the TDC to measure the temperature change accurately. We conduct a measurement on the daily temperatures of AWS data centers worldwide and find that temperature changes of some data centers are closely related to local weathers. Thus, we deduce they adopt free cooling techniques. This measurement study motivates us to re-think the vulnerability of data centers to power/thermal attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于电力和冷却成本已成为大规模数据中心总拥有成本(TCO)的主要因素，因此研究数据中心如何在实践中运行其冷却系统非常重要。亚马逊网络服务(AWS)的数据中心一直在全球范围内不断扩张，其限制性的安全政策使数据中心的许多管理方面保持私密。在这篇文章中，我们试图探索没有特权访问的自动气象站数据中心的冷却系统。我们首先使用时间数字转换器(TDC)演示AWS FPGAs(现场可编程门阵列)中的PVT(工艺、电压和温度)变化。我们进一步利用DRAM温度侧通道，并提高TDC的利用率，以精确测量温度变化。我们对全球自动气象站数据中心的每日温度进行了测量，发现一些数据中心的温度变化与当地天气密切相关。因此，我们推断他们采用自由冷却技术。这项测量研究促使我们重新思考数据中心对电源/散热攻击的脆弱性。",
                    "title_zh": "基于FPGA的温度侧通道数据中心冷却系统研究"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00016",
                    "title": "Secure Publish-Process-Subscribe System for Dispersed Computing",
                    "authors": "Weizhao Jin, Bhaskar Krishnamachari, Muhammad Naveed, Srivatsan Ravi, Eduard Sanou, Kwame-Lante Wright",
                    "abstract": "Publish-subscribe protocols enable real-time multi-point-to-multi-point communications for many dispersed computing systems like Internet of Things (IoT) applications. Recent interest has focused on adding processing to such publish-subscribe protocols to enable computation over real-time streams such that the protocols can provide functionalities such as sensor fusion, compression, and other statistical analysis on raw sensor data. However, unlike pure publish-subscribe protocols, which can be easily deployed with end-to-end transport layer encryption, it is challenging to ensure security in such publish-process-subscribe protocols when the processing is carried out on an untrusted third party. In this work, we present $\\mathcal{XYZ}$, a secure publish-process-subscribe system that can preserve the confidentiality of computations and support multi-publisher-multi-subscriber settings. Within $\\mathcal{XYZ}$, we design two distinct schemes: the first using Yao's garbled circuits (the GC-Based Scheme) and the second using homomorphic encryption with proxy re-encryption (the Proxy-HE Scheme). We build implementations of the two schemes as an integrated publish-process-subscribe system. We evaluate our system on several functions and also demonstrate real-world applications. The evaluation shows that the GC-Based Scheme can finish most tasks two orders of magnitude times faster than the Proxy-HE Scheme while Proxy-HE can still securely complete tasks within an acceptable time for most functions but with a different security assumption and a simpler system structure.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "发布-订阅协议为许多分散的计算系统(如物联网(IoT)应用)实现了实时多点对多点通信。最近的兴趣集中在向这种发布-订阅协议添加处理，以实现实时流上的计算，使得协议可以提供诸如传感器融合、压缩和对原始传感器数据的其他统计分析的功能。然而，与纯发布-订阅协议不同，纯发布-订阅协议可以很容易地利用端到端传输层加密来部署，当在不受信任的第三方上执行处理时，在这种发布-处理-订阅协议中确保安全性是具有挑战性的。在这项工作中，我们提出了＄\\ mathcal { XYZ } ＄,一个安全的发布-处理-订阅系统，可以保持计算的机密性，并支持多发布者-多订阅者设置。在$\\mathcal{XYZ}$，我们设计了两个不同的方案:第一个使用姚的乱码电路(基于GC的方案)，第二个使用同态加密和代理重加密(代理-HE方案)。我们将这两个方案的实现构建为一个集成的发布-处理-订阅系统。我们评估了我们的系统的几个功能，并展示了现实世界的应用。评估表明，基于GC的方案完成大多数任务的速度比Proxy-HE方案快两个数量级，而Proxy-HE方案仍然可以在可接受的时间内安全地完成大多数功能的任务，但具有不同的安全假设和更简单的系统结构。",
                    "title_zh": "用于分散计算的安全发布-处理-订阅系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00017",
                    "title": "Never Too Late: Tracing and Mitigating Backdoor Attacks in Federated Learning",
                    "authors": "Hui Zeng, Tongqing Zhou, Xinyi Wu, Zhiping Cai",
                    "abstract": "The privacy-preserving nature of Federated Learning (FL) exposes such a distributed learning paradigm to the planting of backdoors with locally corrupted data. We discover that FL backdoors, under a new on-off multi-shot attack form, are essentially stealthy against existing defenses that are built on model statistics and spectral analysis. First-hand observations of such attacks show that the backdoored models are indistinguishable from normal ones w.r.t. both low-level and high-level representations. We thus emphasize that a critical redemption, if not the only, for the tricky stealthiness is reactive tracing and posterior mitigation. A three-step remedy framework is then proposed by exploring the temporal and inferential correlations of models on a trapped sample from an attack. In particular, we use shift ensemble detection and co-occurrence analysis for adversary identification, and repair the model via malicious ingredients removal under theoretical error guarantee. Extensive experiments on various backdoor settings demonstrate that our framework can achieve accuracy on attack round identification of ∼80% and on attackers of ∼50%, which are ∼28.76% better than existing proactive defenses. Meanwhile, it can successfully eliminate the influence of backdoors with only a 5%∼6% performance drop.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "联邦学习(FL)的隐私保护特性使这种分布式学习范式暴露于植入带有本地损坏数据的后门。我们发现，在一种新的开关多次射击攻击形式下，FL后门对基于模型统计和频谱分析的现有防御基本上是隐形的。对此类攻击的第一手观察表明，无论是低级还是高级表示，后门模型都无法与正常模型区分开来。因此，我们强调，对于狡猾的隐秘，一个关键的救赎，如果不是唯一的，是反应追踪和事后缓解。然后，通过探索来自攻击的捕获样本上的模型的时间和推理相关性，提出了一个三步补救框架。特别地，我们使用移位集成检测和共现分析进行对手识别，并在理论误差保证下通过去除恶意成分来修复模型。在各种后门设置上的大量实验表明，我们的框架可以达到80%的攻击轮识别率和50%的攻击者识别率，比现有的主动防御提高了28.76%。同时，它可以成功消除后门的影响，性能下降幅度仅为5%∞6%。",
                    "title_zh": "永远不晚:追踪和减轻联合学习中的后门攻击"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00018",
                    "title": "Compositional Model Checking of Consensus Protocols via Interaction-Preserving Abstraction",
                    "authors": "Xiaosong Gu, Wei Cao, Yicong Zhu, Xuan Song, Yu Huang, Xiaoxing Ma",
                    "abstract": "Consensus protocols are widely used in building reliable distributed software systems and their correctness is of vital importance. TLA+ is a lightweight formal specification language which enables precise specification of system design and exhaustive checking of the design without any human effort. The features of TLA+ make it widely used in the specification and model checking of consensus protocols, both in academia and in industry. However, the application of TLA+ is limited by the state explosion problem in model checking. Though compositional model checking is essential to tame the state explosion problem, existing compositional checking techniques do not sufficiently consider the characteristics of TLA+. In this work, we propose the Interaction-Preserving Abstraction (IPA) framework, which leverages the features of TLA+ and enables practical and efficient compositional model checking of consensus protocols specified in TLA+. In the IPA framework, system specification is partitioned into multiple modules, and each module is divided into the internal part and the interaction part. The basic idea of the interaction-preserving abstraction is to omit the internal part of each module, such that another module cannot distinguish whether it is interacting with the original module or the coarsened abstract one. We apply the IPA framework to the compositional checking of the TLA+ specifications of two consensus protocols Raft and ParallelRaft. Raft is a consensus protocol which was originally developed in academia and then widely used in industry. ParallelRaft is the replication protocol in PolarFS, the distributed file system for the commercial database Alibaba PolarDB. We demonstrate that the IPA framework is easy to use in realistic scenarios and at the same time significantly reduces the model checking cost.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "一致性协议广泛用于构建可靠的分布式软件系统，其正确性至关重要。TLA+是一种轻量级的形式规格说明语言，它能够精确地说明系统设计，并且不需要任何人力就可以对设计进行详尽的检查。TLA+的特性使其在学术界和工业界广泛应用于一致性协议的规范和模型检验。然而，TLA+的应用受到模型检测中状态爆炸问题的限制。虽然组合模型检验对于驯服状态爆炸问题是必要的，但是现有的组合检验技术没有充分考虑TLA+的特性。在这项工作中，我们提出了交互保持抽象(IPA)框架，该框架利用了TLA+的特性，能够对TLA+中指定的一致性协议进行实用有效的组合模型检查。在IPA框架中，系统规范被划分为多个模块，每个模块又分为内部部分和交互部分。交互保持抽象的基本思想是省略每个模块的内部部分，这样另一个模块就不能区分它是在与原始模块交互还是与粗化的抽象模块交互。我们将IPA框架应用于两个一致性协议Raft和ParallelRaft的TLA+规范的组合检查。Raft是一个共识协议，最初是在学术界开发的，后来广泛应用于工业界。ParallelRaft是PolarFS中的复制协议，polar fs是商业数据库阿里巴巴PolarDB的分布式文件系统。我们证明了IPA框架在现实场景中易于使用，同时显著降低了模型检查成本。",
                    "title_zh": "基于交互保持抽象的一致性协议组合模型检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00019",
                    "title": "Democratizing Machine Learning: Resilient Distributed Learning with Heterogeneous Participants",
                    "authors": "Karim Boubouh, Amine Boussetta, Nirupam Gupta, Alexandre Maurer, Rafaël Pinot",
                    "abstract": "The increasing prevalence of personal devices motivates the design of algorithms that can leverage their computing power, together with the data they generate, in order to build privacy-preserving and effective machine learning models. However, traditional distributed learning algorithms impose a uniform workload on all participating devices, most often discarding the weakest participants. This not only induces a suboptimal use of available computational resources, but also significantly reduces the quality of the learning process, as data held by the slowest devices is discarded from the procedure. This paper proposes HgO, a distributed learning scheme with parameterizable iteration costs that can be adjusted to the computational capabilities of different devices. HgO encourages the participation of slower devices, thereby improving the accuracy of the model when the participants do not share the same dataset. When combined with a robust aggregation rule, HgO can tolerate some level of Byzantine behavior, depending on the hardware profile of the devices (we prove, for the first time, a trade-off between Byzantine tolerance and hardware heterogeneity). We also demonstrate the convergence of HgO, theoretically and empirically, without assuming any specific partitioning of the data over the devices. We present an exhaustive set of experiments, evaluating the performance of HgO on several classification tasks and highlighting the importance of incorporating slow devices when learning in a Byzantine-prone environment with heterogeneous participants.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "个人设备的日益普及推动了算法的设计，这些算法可以利用它们的计算能力以及它们生成的数据，以建立保护隐私和有效的机器学习模型。然而，传统的分布式学习算法在所有参与的设备上施加统一的工作负荷，最常见的是丢弃最弱的参与者。这不仅导致可用计算资源的次优使用，而且显著降低了学习过程的质量，因为由最慢的设备保存的数据从过程中被丢弃。本文提出了HgO，一种具有可参数化迭代成本的分布式学习方案，可以根据不同设备的计算能力进行调整。HgO鼓励较慢设备的参与，从而在参与者不共享同一数据集时提高模型的准确性。当与健壮的聚合规则结合时，HgO可以容忍某种程度的拜占庭行为，这取决于设备的硬件配置文件(我们首次证明了拜占庭容忍和硬件异构之间的权衡)。我们还从理论和经验上证明了HgO的收敛性，而不需要对设备上的数据进行任何特定的划分。我们展示了一组详尽的实验，评估了HgO在几个分类任务上的性能，并强调了当在具有不同参与者的拜占庭倾向的环境中学习时合并慢设备的重要性。",
                    "title_zh": "民主化机器学习:具有不同参与者的弹性分布式学习"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00020",
                    "title": "Byzantine Auditable Atomic Register with Optimal Resilience",
                    "authors": "Antonella Del Pozzo, Alessia Milani, Alexandre Rapetti",
                    "abstract": "An auditable register extends the classical register with an audit operation that returns information on the read operations performed on the register. In this paper, we study Byzantine resilient auditable registers implementations in an asynchronous message-passing system. Existing solutions implement the auditable register on top of at least $4\\mathrm{f}+1$ servers, where at most $f$ can be Byzantine. We show that $4\\mathrm{f}+1$ servers are necessary to implement auditability without communication between servers. Then, we pursue the study by relaxing the constraint on the servers' communication, letting them interact with each other. In this setting, we prove that $3\\mathrm{f}+1$ servers are sufficient. This result establishes that with communication between servers, auditability does not come with an additional cost in terms of the number of servers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "可审计寄存器通过审计操作扩展了传统寄存器，该审计操作返回关于在寄存器上执行的读取操作的信息。本文研究了异步消息传递系统中拜占庭弹性可审计寄存器的实现。现有的解决方案在至少$4\\mathrm{f}+1$服务器上实现可审计的注册，其中最多$f$可以是拜占庭式的。我们证明了$4\\mathrm{f}+1$服务器对于在服务器之间没有通信的情况下实现可审计性是必要的。然后，我们通过放松对服务器通信的限制，让它们彼此交互来进行研究。在这种情况下，我们证明$3\\mathrm{f}+1$服务器就足够了。这一结果表明，通过服务器之间的通信，可审计性不会带来服务器数量方面的额外成本。",
                    "title_zh": "具有最佳弹性的拜占庭式可审计原子寄存器"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00021",
                    "title": "G-SINC: Global Synchronization Infrastructure for Network Clocks",
                    "authors": "Marc Frei, Jonghoon Kwon, Seyedali Tabaeiaghdaei, Marc Wyss, Christoph Lenzen, Adrian Perrig",
                    "abstract": "Many critical computing applications rely on secure and dependable time which is reliably synchronized across large distributed systems. Today's time synchronization architectures are commonly based on global navigation satellite systems at the considerable risk of being exposed to outages, malfunction, or attacks against availability and accuracy. This paper describes a practical instantiation of a new global, Byzantine fault-tolerant clock synchronization approach that does not place trust in any single entity and is able to tolerate a fraction of faulty entities while still maintaining synchronization on a global scale among otherwise sovereign network topologies. Leveraging strong resilience and security properties provided by the path-aware SCION networking architecture, the presented design can be implemented as a backward compatible active standby solution for existing time synchronization deployments. Through extensive evaluation, we demonstrate that over 94 % of time servers reliably minimize the offset of their local clocks to real-time in the presence of up to 20 % malicious nodes, and all time servers remain synchronized with a skew of only 2 ms even after one year of reference clock outage.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2207.06116"
                    },
                    "abstract_zh": "许多关键计算应用依赖于安全可靠的时间，这些时间在大型分布式系统中是可靠同步的。当今的时间同步架构通常基于全球导航卫星系统，面临着遭受中断、故障或可用性和准确性受到攻击的巨大风险。本文描述了一种新的全局拜占庭容错时钟同步方法的实际实例，该方法不信任任何单个实体，并且能够容忍一小部分故障实体，同时仍然在其他独占网络拓扑中保持全局范围内的同步。利用路径感知SCION网络架构提供的强大弹性和安全属性，所呈现的设计可以被实现为用于现有时间同步部署的向后兼容的活动备用解决方案。通过广泛的评估，我们证明了在存在高达20 %的恶意节点的情况下，超过94 %的时间服务器可靠地最小化其本地时钟到实时的偏移，并且所有时间服务器保持同步，即使在参考时钟中断一年之后，偏移也只有2 ms。",
                    "title_zh": "G-SINC:网络时钟的全球同步基础设施"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00022",
                    "title": "Babel: A Framework for Developing Performant and Dependable Distributed Protocols",
                    "authors": "Pedro Fouto, Pedro Ákos Costa, Nuno M. Preguiça, João Leitão",
                    "abstract": "Prototyping and implementing distributed algorithms, particularly those that address challenges related with fault-tolerance and dependability, is a time consuming task. This is, in part, due to the need of addressing low level aspects such as management of communication channels, controlling timeouts or periodic tasks, and dealing with concurrency issues. This has a significant impact for researchers that want to build prototypes for conducting experimental evaluation; practitioners that want to compare different design alternatives/solutions; and even for practical teaching activities on distributed algorithms courses. In this paper we present Babel, a novel framework to develop, implement, and execute distributed protocols and systems. Babel promotes an event driven programming and execution model that simplifies the task of translating typical specifications or descriptions of algorithms into performant prototypes, while allowing the programmer to focus on the relevant challenges of these algorithms by transparently handling time consuming low level aspects. Furthermore, Babel provides, and allows the definition of, networking components that can capture different network capabilities (e.g., P2P, Client/Server, p-accrual Failure Detector), making the code mostly independent from the underlying communication aspects. Babel was built to be generic and can be used to implement a wide variety of different classes of distributed protocols. We conduct our experimental work with two relevant case studies, a Peer-to-Peer application and a State Machine Replication application, that show the generality and ease of use of Babel and present competitive performance when compared with significantly more complex implementations.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2205.02106"
                    },
                    "abstract_zh": "原型化和实现分布式算法，尤其是那些解决与容错和可靠性相关的挑战的算法，是一项耗时的任务。这在一定程度上是因为需要解决底层方面的问题，如管理通信通道、控制超时或周期性任务以及处理并发性问题。这对于想要构建原型进行实验评估的研究人员具有重大影响；希望比较不同设计方案/解决方案的从业者；甚至用于分布式算法课程的实践教学活动。在本文中，我们提出了Babel，一个开发、实现和执行分布式协议和系统的新框架。Babel推出了一个事件驱动的编程和执行模型，该模型简化了将典型规范或算法描述转换为高性能原型的任务，同时允许程序员通过透明地处理耗时的低级方面来关注这些算法的相关挑战。此外，Babel提供并允许定义可以捕获不同网络能力的网络组件(例如，P2P、客户端/服务器、p-accrual故障检测器)，使得代码基本上独立于底层通信方面。Babel是通用的，可用于实现各种不同类别的分布式协议。我们用两个相关的案例研究进行了我们的实验工作，一个对等应用程序和一个状态机复制应用程序，它们显示了Babel的通用性和易用性，并在与明显更复杂的实现相比时呈现出竞争性能。",
                    "title_zh": "Babel:一个开发高性能可靠分布式协议的框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00023",
                    "title": "Silent Anonymous Snap-Stabilizing Termination Detection",
                    "authors": "Lélia Blin, Colette Johnen, Gabriel Le Bouder, Franck Petit",
                    "abstract": "We address the problem of Termination Detection (TD) in asynchronous networks. It is known that TD cannot be achieved in the context of self-stabilization, except in the specific case where the TD algorithm is snap-stabilizing, i.e., it always behaves according to its specification regardless of the initial configuration. In this paper, we propose a generic, deterministic, snap-stabilizing, silent algorithm that detects whether an observed terminating silent self-stabilizing algorithm, A, has converged to a configuration that satisfies an intended predicate. Our algorithm assumes that nodes know (an upper bound on) the network diameter D. However, it requires no underlying structure, nor specific topology (arbitrary network), and works in anonymous networks, i.e., our algorithm uses no kind of assumption allowing distinguishing one or more nodes. Furthermore, it works under the weakest scheduling assumptions a.k.a, the unfair daemon. Built over any asynchronous self-stabilizing underlying unison U, our solution adds only O(log D) bits per node. Since there exists no unison algorithm with better space complexity, the extra space of our solution is negligible w.r.t. the space complexity of the underlying unison algorithm. Our algorithm provides a positive answer in O(max (k, k’, D)) time units, where k and k’ are the stabilization time complexities of A and U, respectively.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了异步网络中的终端检测(TD)问题。众所周知，TD无法在自稳定的情况下实现，除非在特定情况下，TD算法是快速稳定的，即无论初始配置如何，它总是根据其规格运行。在本文中，我们提出了一个通用的、确定性的、snap稳定的、静默算法，该算法检测观察到的终止静默自稳定算法A是否已经收敛到满足预期谓词的配置。我们的算法假设节点知道网络直径d(的上限)。然而，它不需要底层结构，也不需要特定的拓扑(任意网络),并且在匿名网络中工作，即，我们的算法不使用允许区分一个或多个节点的任何种类的假设。此外，它在最弱的调度假设下工作，即不公平守护进程。我们的解决方案构建在任何异步自稳定底层unison U之上，每个节点仅增加O(log D)位。由于不存在具有更好空间复杂度的调和算法，我们的解决方案的额外空间相对于基础调和算法的空间复杂度是可以忽略的。我们的算法在O(max (k，k’，D))时间单位内提供了肯定的答案，其中k和k’分别是A和U的稳定时间复杂度。",
                    "title_zh": "静默匿名快照稳定终止检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00024",
                    "title": "Detection and Incentive: A Tampering Detection Mechanism for Object Detection in Edge Computing",
                    "authors": "Zhihui Zhao, Yicheng Zeng, Jinfa Wang, Hong Li, Hongsong Zhu, Limin Sun",
                    "abstract": "The object detection tasks based on edge computing have received great attention. A common concern hasn't been addressed is that edge may be unreliable and uploads the incorrect data to cloud. Existing works focus on the consistency of the transmitted data by edge. However, in cases when the inputs and the outputs are inherently different, the authenticity of data processing has not been addressed. In this paper, we first simply model the tampering detection. Then, bases on the feature insertion and game theory, the tampering detection and economic incentives mechanism (TDEI) is proposed. In tampering detection, terminal negotiates a set of features with cloud and inserts them into the raw data, after the cloud determines whether the results from edge contain the relevant information. The honesty incentives employs game theory to instill the distrust among different edges, preventing them from colluding and thwarting the tampering detection. Meanwhile, the subjectivity of nodes is also considered. TDEI distributes the tampering detection to all edges and realizes the self-detection of edge results. Experimental results based on the KITTI dataset, show that the accuracy of detection is 95% and 80%, when terminal's additional overhead is smaller than 30% for image and 20% for video, respectively. The interference ratios of TDEI to raw data are about 16% for video and 0% for image, respectively. Finally, we discuss the advantage and scalability of TDEI.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于边缘计算的目标检测任务受到了极大的关注。一个尚未解决的常见问题是，edge可能不可靠，会将不正确的数据上传到云。现有的工作集中在边缘传输数据的一致性。然而，在输入和输出本质上不同的情况下，数据处理的真实性没有得到解决。在本文中，我们首先简单地对篡改检测进行建模。然后，基于特征插入和博弈论，提出了篡改检测和经济激励机制。在篡改检测中，终端与云协商一组特征，并在云确定来自edge的结果是否包含相关信息后将它们插入到原始数据中。诚实激励采用博弈论来灌输不同边缘之间的不信任，防止他们共谋和阻挠篡改检测。同时，还考虑了节点的主观性。TDEI将篡改检测分散到所有边缘，实现边缘结果的自检测。基于KITTI数据集的实验结果表明，当图像和视频的终端附加开销分别小于30%和20%时，检测准确率分别为95%和80%。TDEI对原始数据的干扰率分别为视频约16%和图像约0%。最后，我们讨论了TDEI的优势和可扩展性。",
                    "title_zh": "检测和激励:边缘计算中对象检测的篡改检测机制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00025",
                    "title": "FWC: Fitting Weight Compression Method for Reducing Communication Traffic for Federated Learning",
                    "authors": "Hao Jiang, Kedong Yan, Chanying Huang, Qianmu Li, Shan Xiao",
                    "abstract": "Federated learning enables local nodes to train a global model together by uploading only training updates to the parameter server without exchanging private data. However, as the complexity of the federated learning task increases, the communication volume of the training process becomes extremely large, hence the huge communication traffic becomes a serious bottleneck in current federated learning application. Existing methods reduce communication overhead from two aspects, the number of communications and the traffic per communication. But these methods usually lead to more consumption of computing resources or a decrease in model accuracy. To handle these problems, this paper proposes a data fitting based weight compression algorithm, FWC, which includes four sequential stages: sparsification, polynomial fitting, encoding, reconstruction and two mechanism: warm-up and accumulation. In particular, the warm-up mechanism can well address the problem of slow convergence in early training period. Experimental results on models with different scales show that FWC is able to provide more than 600x traffic compression at the cost of only millisecond-level computational time cost and less than 1% accuracy loss.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "联合学习使本地节点能够通过仅将训练更新上传到参数服务器而不交换私有数据来一起训练全局模型。然而，随着联邦学习任务复杂性的增加，训练过程的通信量变得非常大，因此巨大的通信量成为当前联邦学习应用的一个严重瓶颈。现有的方法从两个方面减少了通信开销，即通信次数和每次通信的通信量。但这些方法通常会导致计算资源的更多消耗或模型精度的降低。为了解决这些问题，本文提出了一种基于数据拟合的加权压缩算法——FWC，该算法包括稀疏化、多项式拟合、编码、重构四个连续阶段和两个机制:预热和累加。特别是热身机制可以很好的解决训练前期收敛慢的问题。在不同规模模型上的实验结果表明，FWC能够以毫秒级的计算时间成本和不到1%的精度损失为代价提供超过600倍的流量压缩。",
                    "title_zh": "FWC:降低联邦学习通信量的拟合权重压缩方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00026",
                    "title": "A Performance Study of Epoch-based Commit Protocols in Distributed OLTP Databases",
                    "authors": "Jack Waudby, Paul D. Ezhilchelvan, Isi Mitrani, Jim Webber",
                    "abstract": "Distributed OLTP systems execute the high-overhead, two-phase commit (2PC) protocol at the end of every distributed transaction. Epoch-based commit proposes that 2PC be executed only once for all transactions processed within a time interval called an epoch. Increasing epoch duration allows more transactions to be processed before the common 2PC. It thus reduces 2PC overhead per transaction, increases throughput but also increases average transaction latency. Therefore, required is the ability to choose the right epoch size that offers the desired trade-off between throughput and latency. To this end, we develop two analytical models to estimate throughput and average latency in terms of epoch size taking into account load and failure conditions. Simulations affirm their accuracy and effectiveness. We then present epoch-based multi-commit which, unlike epoch-based commit, seeks to avoid all transactions being aborted when failures occur, and also performs identically when failures do not occur. Our performance study identifies workload factors that make it more effective in preventing transaction aborts and concludes that the analytical models can be equally useful in predicting its performance as well.",
                    "files": {
                        "openAccessPdf": "https://eprints.ncl.ac.uk/fulltext.aspx?url=286685/2C73DD74-3D05-473C-B3A8-26985F76FBAD.pdf&pub_id=286685"
                    },
                    "abstract_zh": "分布式OLTP系统在每个分布式事务结束时执行高开销的两阶段提交(2PC)协议。基于时期的提交建议，对于在称为时期的时间间隔内处理的所有事务，2PC只执行一次。增加历元持续时间允许在公共2PC之前处理更多的事务。因此，它减少了每个事务2PC的开销，增加了吞吐量，但也增加了平均事务延迟。因此，需要能够选择正确的时段大小，以提供吞吐量和延迟之间的理想折衷。为此，我们开发了两个分析模型来估计吞吐量和平均延迟，根据时段大小考虑负载和故障条件。仿真证实了它们的准确性和有效性。然后，我们提出了基于时期的多提交，与基于时期的提交不同，它试图避免所有事务在失败发生时被中止，并且在失败没有发生时也同样执行。我们的性能研究确定了使其更有效地防止事务中止的工作负载因素，并得出结论，分析模型在预测其性能方面也同样有用。",
                    "title_zh": "分布式OLTP数据库中基于时段的提交协议的性能研究"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00027",
                    "title": "Dynamic Fault Trees with Correlated Failure Times - Modeling and Efficient Analysis -",
                    "authors": "Peter Buchholz, Andreas Blume",
                    "abstract": "Dynamic Fault Trees (DFTs) are a powerful and widely used class of models for reliability analysis of technical systems. They describe the relation between failure times of elementary components and failures of the system modeled by the DFT. Failure times of elementary components are assumed to be independent and often exponentially distributed. Then the underlying stochastic process is a Continuous Time Markov Chain (CTMC) which is often analyzed numerically. In this paper, we use phase type distributions to model failure times of elementary components and extend DFTs by introducing two new types of nodes to express different variants of correlation between failure times which often can be observed in real systems. Since the use of phase type distributions enlarges the state space of the CTMC, compositional techniques allowing a compact representation of the generator matrix and analysis techniques exploiting this compact representation are also introduced. In particular, analysis techniques are presented that exploit the specific structure of the DFT.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "动态故障树(DFT)是一种功能强大且广泛应用于技术系统可靠性分析的模型。它们描述了基本组件的故障时间和由DFT建模的系统故障之间的关系。基本元件的失效时间被认为是独立的，通常呈指数分布。那么潜在的随机过程是一个连续时间的马尔可夫链(CTMC ),它经常被数值分析。在本文中，我们使用相型分布来模拟基本元件的故障时间，并通过引入两种新类型的节点来表示在实际系统中经常可以观察到的故障时间之间相关性的不同变量，从而扩展DFT。由于相位型分布的使用扩大了CTMC的状态空间，还引入了允许生成矩阵的紧凑表示的组合技术和利用这种紧凑表示的分析技术。特别地，提出了利用DFT的特定结构的分析技术。",
                    "title_zh": "具有相关故障时间的动态故障树——建模和有效分析"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00028",
                    "title": "Real-Time Byzantine Resilience for Power Grid Substations",
                    "authors": "Sahiti Bommareddy, Daniel Qian, Christopher A. Bonebrake, Paul M. Skare, Yair Amir",
                    "abstract": "In the world of increasing cyber threats, a compromised protective relay can put power grid resilience at risk by irreparably damaging costly power assets or by causing significant disruptions. We present the first architecture and protocols for the substation that ensure correct protective relay operation in the face of successful relay intrusions and network attacks while meeting the required latency constraint of a quarter power cycle (4.167ms). Our architecture supports other rigid requirements, including continuous availability over a long system lifetime and seamless substation integration. We evaluate our implementation in a range of fault-free and faulty operation conditions, and provide deployment tradeoffs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在网络威胁日益增加的世界中，受损的保护继电器可能会对昂贵的电力资产造成不可挽回的损害，或导致重大中断，从而危及电网的弹性。我们提出了变电站的第一个架构和协议，确保在面对成功的继电器入侵和网络攻击时正确的保护继电器操作，同时满足所需的四分之一功率周期(4.167毫秒)的延迟限制。我们的架构支持其他严格要求，包括长系统寿命内的连续可用性和无缝变电站集成。我们在一系列无故障和故障运行条件下评估我们的实施，并提供部署权衡。",
                    "title_zh": "电网变电站的实时拜占庭弹性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00029",
                    "title": "Soter: Deep Learning Enhanced In-Network Attack Detection Based on Programmable Switches",
                    "authors": "Guorui Xie, Qing Li, Chupeng Cui, Peican Zhu, Dan Zhao, Wanxin Shi, Zhuyun Qi, Yong Jiang, Xi Xiao",
                    "abstract": "Though several deep learning (DL) detectors have been proposed for the network attack detection and achieved high accuracy, they are computationally expensive and struggle to satisfy the real-time detection for high-speed networks. Recently, programmable switches exhibit a remarkable throughput efficiency on production networks, indicating a possible deployment of the timely detector. Therefore, we present Soter, a DL enhanced in-network framework for the accurate real-time detection. Soter consists of two phases. One is filtering packets by a rule-based decision tree running on the Tofino ASIC. The other is executing a well-designed lightweight neural network for the thorough inspection of the suspicious packets on the CPU. Experiments on the commodity switch demonstrate that Soter behaves stably in ten network scenarios of different traffic rates and fulfills per-flow detection in 0.03s. Moreover, Soter naturally adapts to the distributed deployment among multiple switches, guaranteeing a higher total throughput for large data centers and cloud networks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然已经提出了几种用于网络攻击检测的深度学习(DL)检测器，并获得了高精度，但是它们计算量大，难以满足高速网络的实时检测。最近，可编程开关在生产网络中表现出显著的吞吐效率，表明了适时检测器的可能部署。因此，我们提出了Soter，一种DL增强的网内框架，用于精确的实时检测。Soter由两个阶段组成。一种是通过在Tofino ASIC上运行的基于规则的决策树来过滤数据包。另一个是执行一个设计良好的轻量级神经网络，用于彻底检查CPU上的可疑数据包。在商用交换机上的实验表明，Soter在10种不同流量速率的网络场景中运行稳定，在0.03秒内完成每个流的检测。此外，Soter自然适应多个交换机之间的分布式部署，确保大型数据中心和云网络的更高总吞吐量。",
                    "title_zh": "Soter:基于可编程开关的深度学习增强网内攻击检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00030",
                    "title": "SigGuard: Hardening Vulnerable Signal Handling in Commodity Operating Systems",
                    "authors": "Miao Cai, Junru Shen, Tianning Zhang, Hao Huang, Baoliu Ye",
                    "abstract": "Signal is a useful mechanism provided by many commodity operating systems. However, current signal handling has serious security concerns due to vulnerable design in missing integrity protections for signal handling control flow. Security weaknesses caused by vulnerable design are exploited by adversaries to mount dangerous control-flow attacks. To tackle these issues, this paper investigates root causes of signal-related attacks and proposes SigGuard to harden vulnerable signal handling mechanism. To protect unsafe signal handler execution flow, we design a customized signal handler CFI framework which supports low-cost, reentrant, online CFI analysis and enforcement. To secure signal handler return control flow, we propose an efficient, software-based, intra-process memory isolation method to ensure signal frame data integrity. We evaluate SigGuard with both security and performance experiments. In security experiments, SigGuard successfully thwarts four signal-based attacks, including two proof-of-concept exploits and two realistic attacks conducted in Nginx and Apache server programs, respectively. We also evaluate SigGuard key techniques with a series of microbenchmarks and real-world applications. Experimental results suggest that key defense techniques used in SigGuard introduce reasonable performance costs.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "信号是许多商业操作系统提供的一种有用的机制。然而，由于信号处理控制流中缺少完整性保护的脆弱设计，当前的信号处理具有严重的安全性问题。由易受攻击的设计引起的安全弱点被对手利用来发起危险的控制流攻击。为了解决这些问题，本文研究了信号相关攻击的根本原因，并提出SigGuard来强化易受攻击的信号处理机制。为了保护不安全的信号处理程序执行流，我们设计了一个定制的信号处理程序CFI框架，它支持低成本、可重入的在线CFI分析和执行。为了保证信号处理器返回控制流的安全，我们提出了一种有效的、基于软件的进程内内存隔离方法来确保信号帧数据的完整性。我们通过安全性和性能实验对SigGuard进行了评估。在安全实验中，SigGuard成功挫败了四次基于信号的攻击，包括两次概念验证攻击和两次分别在Nginx和Apache服务器程序中进行的实际攻击。我们还通过一系列微基准测试和实际应用来评估SigGuard关键技术。实验结果表明，SigGuard中使用的关键防御技术引入了合理的性能成本。",
                    "title_zh": "SigGuard:强化商用操作系统中易受攻击的信号处理"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00031",
                    "title": "Reliable Password Hardening Service with Opt-Out",
                    "authors": "Chunfu Jia, Shaoqiang Wu, Ding Wang",
                    "abstract": "As the most dominant authentication mechanism, password-based authentication suffers catastrophic offline password guessing attacks once the authentication server is compromised and the password database is leaked. Password hardening (PH) service, an external/third-party crypto service, has been recently proposed to strengthen password storage and reduce the damage of authentication server compromise. However, all existing schemes are unreliable in that they overlook the important restorable property: PH service opt-out. In existing PH schemes, once the authentication server has subscribed to a PH service, it must adopt this service forever, even if it wants to stop the external/third-party PH service and restore its original password storage (or subscribe to another PH service). To fill the gap, we propose a new PH service called PW-Hero that equips its PH service with an option to terminate its use (i.e., opt-out). In PW-Hero, password authentication is strengthened against offline attacks by adding external secret spices to password records. With the opt-out property, authentication servers can proactively request to end the PH service after successful authentications. Then password records can be securely migrated to their traditional salted hash state, ready for subscription to other PH services. Besides, PW-Hero achieves all existing desirable properties, such as comprehensive verifiability, rate limits against online attacks, and user privacy. We define PW-Hero as a suite of protocols that meet desirable properties and build a simple, secure, and efficient instance. Moreover, we develop a prototype implementation and evaluate its performance, establishing the practicality of our PW-Hero service.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为最主要的认证机制，基于口令的认证一旦认证服务器被攻破和口令数据库被泄露，就会遭受灾难性的离线口令猜测攻击。密码加固(PH)服务是一种外部/第三方加密服务，最近被提议用于加强密码存储和减少认证服务器泄露的损害。然而，所有现有的方案都是不可靠的，因为它们忽略了重要的可恢复属性:PH服务选择退出。在现有的PH方案中，一旦认证服务器订阅了PH服务，它必须永远采用该服务，即使它想要停止外部/第三方PH服务并恢复其原始密码存储(或订阅另一个PH服务)。为了填补这一空白，我们提出了一个名为PW-Hero的新PH服务，它为其PH服务提供了一个终止使用的选项(即选择退出)。在PW-Hero中，通过在密码记录中添加外部秘密香料来加强密码认证以抵御离线攻击。通过选择退出属性，认证服务器可以在成功认证后主动请求结束PH服务。然后，密码记录可以安全地迁移到其传统的salted hash状态，以备订阅其他PH服务。此外，PW-Hero实现了所有现有的期望属性，例如全面的可验证性、针对在线攻击的速率限制以及用户隐私。我们将PW-Hero定义为一套协议，这些协议满足期望的属性并构建简单、安全和高效的实例。此外，我们开发了一个原型实现并评估了它的性能，确定了我们的PW-Hero服务的实用性。",
                    "title_zh": "具有退出功能的可靠密码强化服务"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00032",
                    "title": "An In-Depth Correlative Study Between DRAM Errors and Server Failures in Production Data Centers",
                    "authors": "Zhinan Cheng, Shujie Han, Patrick P. C. Lee, Xin Li, Jiongzhou Liu, Zhan Li",
                    "abstract": "Dynamic Random Access Memory (DRAM) errors are prevalent and lead to server failures in production data centers. However, little is known about the correlation between DRAM errors and server failures in state-of-the-art field studies on DRAM error measurement. To fill this void, we present an in-depth data-driven correlative analysis between DRAM errors and server failures, with the primary goal of predicting server failures based on DRAM error characterization and hence enabling proactive reliability maintenance for production data centers. Our analysis is based on an eight-month dataset collected from over three million memory modules in the production data centers at Alibaba. We find that the correctable DRAM errors of most server failures only manifest within a short time before the failures happen, implying that server failure prediction should be conducted regularly at short time intervals for accurate prediction. We also study various impacting factors (including component failures in the memory subsystem, DRAM configurations, types of correctable DRAM errors) on server failures. Furthermore, we design a machine-learning-based server failure prediction workflow and demonstrate the feasibility of server failure prediction based on DRAM error characterization. To this end, we report 14 findings from our measurement and prediction studies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "动态随机存取存储器(DRAM)错误非常普遍，会导致生产数据中心的服务器故障。然而，在关于DRAM错误测量的最新现场研究中，关于DRAM错误和服务器故障之间的相关性知之甚少。为了填补这一空白，我们提出了一种深入的数据驱动的DRAM错误和服务器故障之间的相关性分析，其主要目标是基于DRAM错误特征预测服务器故障，从而实现生产数据中心的主动可靠性维护。我们的分析基于从阿里巴巴生产数据中心的300多万个内存模块中收集的八个月数据集。我们发现，大多数服务器故障的可校正DRAM错误仅在故障发生前的短时间内显现，这意味着服务器故障预测应该以短时间间隔定期进行，以便准确预测。我们还研究了影响服务器故障的各种因素(包括内存子系统中的组件故障、DRAM配置、可纠正的DRAM错误类型)。此外，我们设计了一个基于机器学习的服务器故障预测工作流程，并证明了基于DRAM错误表征的服务器故障预测的可行性。为此，我们报告了我们的测量和预测研究的14个发现。",
                    "title_zh": "生产数据中心DRAM错误与服务器故障的深入关联研究"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00033",
                    "title": "XHR-Code: An Efficient Wide Stripe Erasure Code to Reduce Cross-Rack Overhead in Cloud Storage Systems",
                    "authors": "Guofeng Yang, Huangzhen Xue, Yunfei Gu, Chentao Wu, Jie Li, Minyi Guo, Shiyi Li, Xin Xie, Yuanyuan Dong, Yafei Zhao",
                    "abstract": "Nowadays wide stripe erasure codes (ECs) become popular as they can achieve low monetary cost and provide high reliability for cold data. Generally, wide stripe erasure codes can be generated by extending traditional erasure codes with a large stripe size, or designing new codes. However, although wide stripe erasure codes can decrease the storage cost significantly, the construction of lost data is extraordinary slow, which stems primarily from high cross-rack overhead. It is because a large number of racks participate in the construction of the lost data, which results in high cross-rack traffic. To address the above problems, we propose a novel erasure code called XOR-Hitchhiker-RS (XHR) code, to decrease the cross-rack overhead and still maintain low storage cost. The key idea of XHR is that it utilizes a triple dimensional framework to place more chunks within racks and reduce global repair triggers. To demonstrate the effectiveness of XHR-Code, we provide mathematical analysis and conduct comprehensive experiments. The results show that, compared to the state-of-the-art solutions such as ECWide under various failure conditions, XHR can effectively reduce cross-rack repair traffic and the repair time by up to 36.50%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，宽条带擦除码(ECs)变得流行，因为它们可以实现低货币成本并为冷数据提供高可靠性。一般来说，宽条带纠删码可以通过用大条带尺寸扩展传统纠删码或者设计新的码来生成。然而，尽管宽条带擦除码可以显著降低存储成本，但是丢失数据的构建非常慢，这主要源于高的跨机架开销。是因为大量机架参与了丢失数据的构建，导致跨机架流量高。为了解决上述问题，我们提出了一种新的纠删码——XHR码，以减少跨机架开销并保持较低的存储成本。XHR的关键思想是，它利用三维框架在机架中放置更多的块，并减少全局维修触发。为了证明XHR码的有效性，我们进行了数学分析和综合实验。结果表明，在各种故障条件下，与ECWide等最先进的解决方案相比，XHR可以有效地减少跨机架维修流量和维修时间，最多可减少36.50%。",
                    "title_zh": "XHR码:一种有效降低云存储系统跨机架开销的宽条带擦除码"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS55811.2022.00034",
                    "title": "Achieving Scalability and Load Balance across Blockchain Shards for State Sharding",
                    "authors": "Canlin Li, Huawei Huang, Yetong Zhao, Xiaowen Peng, Ruijie Yang, Zibin Zheng, Song Guo",
                    "abstract": "Sharding technique is viewed as the most promising solution to improving blockchain scalability. However, to implement a sharded blockchain, developers have to address two major challenges. The first challenge is that the ratio of cross-shard transactions (TXs) across blockchain shards is very high. This issue significantly degrades the throughput of a blockchain. The second challenge is that the workloads across blockchain shards are largely imbalanced. If workloads are imbalanced, some shards have to handle an overwhelming number of TXs and become congested very possibly. Facing these two challenges, a dilemma is that it is difficult to guarantee a low cross-shard TX ratio and maintain the workload balance across all shards, simultaneously. We believe that a fine-grained account-allocation strategy can address this dilemma. To this end, we first formulate the tradeoff between such two metrics as a network-partition problem. We then solve this problem using a community-aware account partition algorithm. Furthermore, we also propose a sharding protocol, named Transformers, to apply the proposed algorithm into the sharded blockchain system. Finally, trace-driven evaluation results demonstrate that the proposed protocol outperforms other baselines in terms of throughput, latency, cross-shard TX ratio, and the queue size of transaction pool.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分片技术被认为是提高区块链可扩展性的最有前途的解决方案。然而，要实现分片区块链，开发人员必须解决两个主要挑战。第一个挑战是跨区块链碎片的跨碎片事务(TXs)的比率非常高。这个问题显著降低了区块链的吞吐量。第二个挑战是区块链各部分的工作负载很不均衡。如果工作负载不平衡，一些碎片必须处理大量的事务，很可能会出现拥塞。面对这两个挑战，一个难题是很难同时保证低的跨分片TX比率和保持所有分片的工作负载平衡。我们相信一个细粒度的账户分配策略可以解决这个难题。为此，我们首先将这两个度量之间的权衡公式化为网络划分问题。然后，我们使用社区感知账户划分算法来解决这个问题。此外，我们还提出了一个名为Transformers的分片协议，将提出的算法应用到分片区块链系统中。最后，跟踪驱动的评估结果表明，该协议在吞吐量、延迟、跨片发送比率和事务池队列大小方面优于其他基线。",
                    "title_zh": "为状态分片实现跨区块链分片的可扩展性和负载平衡"
                }
            ]
        }
    ],
    "2020": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2020.html",
            "conf_title": "39th SRDS 2020: Shanghai, China",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/9251916/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00008",
                    "title": "Self-Stabilizing Construction of a Minimal Weakly ST-Reachable Directed Acyclic Graph",
                    "authors": "Junya Nakamura, Masahiro Shibata, Yuichi Sudo, Yonghwan Kim",
                    "abstract": "We propose a self-stabilizing algorithm to construct a minimal weakly ST-reachable directed acyclic graph (DAG), which is suited for routing messages on wireless networks. Given an arbitrary, simple, connected, and undirected graph $G=(V,\\ E)$ and two sets of nodes, senders $S(\\subset V)$ and targets $T(\\subset V)$, a directed subgraph $\\vec{G}$ of G is a weakly ST-reachable DAG on G, if $\\vec{G}$ is a DAG and every sender can reach at least one target, and every target is reachable from at least one sender in $\\vec{G}$. We say that a weakly ST-reachable DAG $\\vec{G}$ on G is minimal if any proper subgraph of $\\vec{G}$ is no longer a weakly ST-reachable DAG. This DAG is a relaxed version of the original (or strongly) ST-reachable DAG, where every target is reachable from every sender. This is because a strongly ST reachable DAG G does not always exist; some graph has no strongly ST-reachable DAG even in the case $|S|=|T|=2$. On the other hand, the proposed algorithm always constructs a weakly ST-reachable DAG for any $|S|$ and $|T|$. Furthermore, the proposed algorithm is self-stabilizing; even if the constructed DAG deviates from the reachability requirement by a breakdown or exhausting the battery of a node having an arc in the DAG, this algorithm automatically reconstructs the DAG to satisfy the requirement again. The convergence time of the algorithm is O(D) asynchronous rounds, where D is the diameter of a given graph. We conduct small simulations to evaluate the performance of the proposed algorithm. The simulation result indicates that its execution time decreases when the number of sender nodes or target nodes is large.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2009.03585"
                    },
                    "abstract_zh": "我们提出了一个自稳定算法来构造一个最小弱ST-可达有向无环图(DAG ),它适用于在无线网络中路由消息。给定一个任意的、简单的、连通的、无向图$G=(V，\\ E)$和两组节点，发送者$ S(\\子集V)$和目标$ T(\\子集V)$ G的有向子图$\\vec{G}$是G上的弱ST-可达DAG，如果$\\vec{G}$是DAG并且每个发送者至少可以到达一个目标，并且每个目标至少可以从$\\vec{G}中的一个发送者到达。我们说G上的弱ST-可达DAG $\\vec{G}$是极小的，如果$\\vec{G}$的任何适当子图不再是弱ST-可达DAG。这个DAG是原始(或强)ST可达DAG的宽松版本，其中每个发送者都可以到达每个目标。这是因为强ST可达DAG并不总是存在；一些图甚至在$|S|=|T|=2$的情况下也没有强ST-可达DAG。另一方面，所提出的算法总是为任何$|S|$和$|T|$构造一个弱ST-可达DAG。此外，所提出的算法是自稳定的；即使构建的DAG由于故障或耗尽DAG中具有弧的节点的电池而偏离可达性要求，该算法也会自动重建DAG以再次满足要求。该算法的收敛时间为O(D)个异步轮次，其中D是给定图的直径。我们进行了小规模的模拟来评估所提出的算法的性能。仿真结果表明，当发送节点或目标节点数量较大时，该算法的执行时间减少。",
                    "title_zh": "最小弱ST-可达有向无环图的自稳定构造"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00009",
                    "title": "Benefits of Stabilization versus Rollback in Self-Stabilizing Graph-Based Applications on Eventually Consistent Key-Value Stores",
                    "authors": "Duong N. Nguyen, Sandeep S. Kulkarni",
                    "abstract": "In this paper, we evaluate and compare the performance of two approaches, namely self-stabilization and rollback, to handling consistency violating faults (cυf) that occur when a self-stabilizing distributed graph-based program is executed on an eventually consistent key-value store. Consistency violating faults are caused by reading wrong values due to weaker level of consistency provided by the key-value store. One way to deal with these faults is to utilize rollback whereas another way is to rely on the property of self-stabilization that is expected to provide recovery from arbitrary states. We evaluate both these approaches in different case studies -planar graph coloring, arbitrary graph coloring, and maximal matching-as well as for different problem dimensions such as input data characteristics, workload partition, and network latency. We also consider the effect of executing non-stabilizing algorithm with rollback with a similar stabilizing algorithm that does not utilize rollback.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们评估和比较了两种方法的性能，即自稳定和回滚，以处理自稳定分布式基于图的程序在最终一致的键值存储上执行时发生的一致性违反故障(cυf)。由于键值存储提供的一致性级别较弱，导致读取错误的值，从而导致违反一致性的错误。处理这些故障的一种方式是利用回滚，而另一种方式是依靠自稳定的属性，该属性被期望提供从任意状态的恢复。我们在不同的案例研究中评估了这两种方法——平面图着色、任意图着色和最大匹配——以及不同的问题维度，如输入数据特征、工作负载划分和网络延迟。我们还考虑了执行带回滚的非稳定算法和不利用回滚的类似稳定算法的效果。",
                    "title_zh": "在基于图的自稳定应用程序中，稳定与回滚在最终一致的键值存储上的优势"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00010",
                    "title": "Consensus Beyond Thresholds: Generalized Byzantine Quorums Made Live",
                    "authors": "Orestis Alpos, Christian Cachin",
                    "abstract": "Existing Byzantine fault-tolerant (BFT) consensus protocols address only threshold failures, where the participating nodes fail independently of each other, each one fails equally likely, and the protocol’s guarantees follow from a simple bound on the number of faulty nodes. With the widespread deployment of Byzantine consensus in blockchains and distributed ledgers today, however, more sophisticated trust assumptions are needed. This paper presents the first implementation of BFT consensus with generalized quorums. It starts from a number of generalized trust structures motivated by practice and explores methods to specify and implement them efficiently. In particular, it expresses the trust assumption by a monotone Boolean formula (MBF) with threshold operators and by a monotone span program (MSP), a linear-algebraic model for computation. An implementation of HotStuff BFT consensus using these quorum systems is described as well and compared to the existing threshold model. Benchmarks with HotStuff running on up to 40 replicas demonstrate that the MBF specification incurs no significant slowdown, whereas the MSP expression affects latency and throughput noticeably due to the involved computations.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2006.04616"
                    },
                    "abstract_zh": "现有的拜占庭容错(BFT)一致性协议仅解决阈值故障，其中参与节点彼此独立地发生故障，每个节点发生故障的可能性相等，并且协议的保证遵循对故障节点数量的简单限制。然而，随着拜占庭共识在区块链的广泛应用和分布式账本的今天，需要更复杂的信任假设。本文介绍了BFT共识在广义法定人数下的首次实现。它从许多由实践激发的广义信任结构出发，探索有效地指定和实现它们的方法。特别地，它通过具有阈值算子的单调布尔公式(MBF)和用于计算的线性代数模型单调跨度程序(MSP)来表达信任假设。还描述了使用这些法定人数系统的HotStuff BFT共识的实现，并与现有的阈值模型进行了比较。在多达40个副本上运行HotStuff的基准测试表明，MBF规范不会导致明显的速度下降，而MSP表达式会因涉及的计算而显著影响延迟和吞吐量。",
                    "title_zh": "超越门槛的共识:广义的拜占庭法定人数"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00011",
                    "title": "TZ4Fabric: Executing Smart Contracts with ARM TrustZone : (Practical Experience Report)",
                    "authors": "Christina Müller, Marcus Brandenburger, Christian Cachin, Pascal Felber, Christian Göttel, Valerio Schiavoni",
                    "abstract": "Blockchain technology promises to revolutionize manufacturing industries. For example, several supply chain use cases may benefit from transparent asset tracking and automated processes using smart contracts. Several real-world deployments exist where the transparency aspect of a blockchain is both an advantage and a disadvantage at the same time. The exposure of assets and business interaction represent critical risks. However, there are typically no confidentiality guarantees to protect the smart contract logic as well as the processed data. Trusted execution environments (TEE) are an emerging technology available in both edge or mobile-grade processors (e.g., ARM TrustZone) and server-grade processors (e.g., Intel SGX). TEEs shield both code and data from malicious attackers. This practical experience report presents TZ4FABRIC, an extension of Hyperledger Fabric to leverage ARM TrustZone for the secure execution of smart contracts. Our design minimizes the trusted computing base executed by avoiding the execution of a whole Hyperledger Fabric node inside the TEE, which continues to run in untrusted environment. Instead, we restrict it to the execution of only the smart contract. The TZ4FABRIC prototype exploits the opensource OP-TEE framework, as it supports deployments on cheap low-end devices (e.g., Raspberry Pis). Our experimental results highlight the performance trade-off due to the additional security guarantees provided by ARM TrustZone. TZ4FABRIC will be released as open source.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2008.11601"
                    },
                    "abstract_zh": "区块链技术有望彻底改变制造业。例如，一些供应链用例可能受益于使用智能合同的透明资产跟踪和自动化流程。在现实世界中，区块链的透明性既是优势也是劣势。资产的暴露和业务互动代表着重大风险。但是，通常没有机密性保证来保护智能合约逻辑和处理的数据。可信执行环境(TEE)是一项新兴技术，可用于边缘或移动级处理器(如ARM TrustZone)和服务器级处理器(如SGX)。TEEs保护代码和数据免受恶意攻击者的攻击。这份实践经验报告介绍了TZ4FABRIC，这是Hyperledger Fabric的一个扩展，用于利用ARM TrustZone安全执行智能合同。我们的设计通过避免在TEE内执行整个Hyperledger结构节点来最小化执行的可信计算基础，TEE继续在不可信环境中运行。相反，我们将其限制为仅执行智能合同。TZ4FABRIC原型利用了开源OP-TEE框架，因为它支持在廉价的低端设备上部署(例如，Raspberry Pis)。我们的实验结果突出了ARM TrustZone提供的额外安全保证所带来的性能权衡。TZ4FABRIC将作为开源发布。",
                    "title_zh": "TZ4Fabric:使用ARM TrustZone执行智能合约:(实践经验报告)"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00012",
                    "title": "NF-Crowd: Nearly-free Blockchain-based Crowdsourcing",
                    "authors": "Chao Li, Balaji Palanisamy, Runhua Xu, Jian Wang, Jiqiang Liu",
                    "abstract": "Advancements in distributed ledger technologies are rapidly driving the rise of decentralized crowdsourcing systems on top of open smart contract platforms like Ethereum. While decentralized blockchain-based crowdsourcing provides numerous benefits compared to centralized solutions, current implementations of decentralized crowdsourcing suffer from fundamental scalability limitations by requiring all participants to pay a small transaction fee every time they interact with the blockchain. This increases the cost of using decentralized crowdsourcing solutions, resulting in a total payment that could be even higher than the price charged by centralized crowdsourcing platforms. This paper proposes a novel suite of protocols called NF-Crowd that resolves the scalability issue by reducing the lower bound of the total cost of a decentralized crowdsourcing project to O(1). NF-Crowd is a highly reliable solution for scaling decentralized crowdsourcing. We prove that as long as participants of a project powered by NF-Crowd are rational, the O(1) lower bound of cost could be reached regardless of the scale of the crowd. We also demonstrate that as long as at least one participant of a project powered by NF-Crowd is honest, the project cannot be aborted and the results are guaranteed to be correct. We design NF-Crowd protocols for a representative type of project named crowdsourcing contest with open community review (CC-OCR). We implement the protocols over the Ethereum official test network. Our results demonstrate that NF-Crowd protocols can reduce the cost of running a CC-OCR project to less than $2 regardless of the scale of the crowd, providing a significant cost benefit in adopting decentralized crowdsourcing solutions.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2009.02561"
                    },
                    "abstract_zh": "分布式账本技术的进步正在快速推动以太坊(Ethereum)等开放智能合约平台之上的去中心化众包系统的崛起。虽然与集中式解决方案相比，基于区块链的分散式众包提供了许多好处，但分散式众包的当前实施受到基本的可扩展性限制，因为要求所有参与者每次与区块链互动时支付少量交易费。这增加了使用分散众包解决方案的成本，导致总支付额可能甚至高于集中众包平台收取的价格。本文提出了一套新的协议，称为NF-Crowd，它通过将分散众包项目的总成本的下限降低到O(1)来解决可扩展性问题。NF-Crowd是一个高度可靠的解决方案，用于扩展分散的众包。我们证明了，只要NF-Crowd项目的参与者是理性的，那么不管人群的规模如何，成本的O(1)下界都可以达到。我们还证明，只要NF-Crowd支持的项目中至少有一个参与者是诚实的，该项目就不能被中止，并且结果保证是正确的。我们为一个具有代表性的项目设计了NF-Crowd协议，该项目名为开放社区评审众包竞赛(CC-OCR)。我们通过以太坊官方测试网络实现协议。我们的结果表明，无论人群的规模如何，NF-Crowd协议都可以将运行CC-OCR项目的成本降低到2美元以下，从而在采用分散式众包解决方案时提供显著的成本效益。",
                    "title_zh": "NF-Crowd:几乎免费的基于区块链的众包"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00013",
                    "title": "An Efficient Query Scheme for Hybrid Storage Blockchains Based on Merkle Semantic Trie",
                    "authors": "Qingqi Pei, Enyuan Zhou, Yang Xiao, Deyu Zhang, Dongxiao Zhao",
                    "abstract": "As a decentralized trusted database, the blockchain is finding applications in a growing number of fields such as finance, supply chain and medicine traceability, where large volumes of valuable data are stored on the blockchain. Currently, the mainstream blockchains employ a hybrid data storage architecture combining on-chain and off-chain storage. Real-time distributed search of mass data stored in this hybrid system is now a major need. However, previous fast retrieval schemes for the blockchain system are aimed only at on-chain data without considering their relevance to off-chain data, and thus fail to meet the requirement. In this paper, we propose an efficient blockchain data query scheme by introducing a novel Merkle Semantic Trie-based indexing technique without modifying the underlying database. A consensus on-chain index structure is constructed using the extracted semantic information of the off-chain data to create a mapping between the on-chain and off-chain data, thus enabling real-time data query both on and off the chain. Our scheme also provides multiple complex analytical query primitives to support semantic query, range query, and even fuzzy query. Experiments on three open data sets show that the proposed scheme has good query performance with shorter query latency for four different search types and offers better retrieval performance and verification efficiency than those available.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "作为一个分散的可信数据库，区块链正在越来越多的领域得到应用，如金融、供应链和药品追溯，其中大量有价值的数据存储在区块链上。目前，主流的区块链采用链上存储和链外存储相结合的混合数据存储体系结构。存储在这个混合系统中的海量数据的实时分布式搜索现在是一个主要需求。然而，以前的区块链系统的快速检索方案只针对链上数据，没有考虑它们与链外数据的相关性，因此不能满足要求。本文通过引入一种新的基于Merkle语义Trie的索引技术，在不修改底层数据库的情况下，提出了一种高效的区块链数据查询方案。使用提取的链外数据的语义信息构建一致的链上索引结构，以创建链上和链下数据之间的映射，从而实现链上和链下的实时数据查询。我们的方案还提供了多种复杂的分析查询原语来支持语义查询、范围查询，甚至模糊查询。在三个开放数据集上的实验表明，该方法对四种不同的搜索类型具有较好的查询性能和较短的查询延迟，并提供了比现有方法更好的检索性能和验证效率。",
                    "title_zh": "基于Merkle语义Trie的混合存储区块链高效查询方案"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00014",
                    "title": "Protect Your Smart Contract Against Unfair Payment",
                    "authors": "Yue Li, Han Liu, Zhiqiang Yang, Bin Wang, Qian Ren, Lei Wang, Bangdao Chen",
                    "abstract": "While smart contracts have enabled a wide range of applications in many public blockchains, e.g., Ethereum, their security issues have been raising an increasing number of threats on the stability of blockchain ecosystem. In practice, many external attacks on smart contracts result from broken payments with digital assets, e.g., cryptocurrencies. While an increasing number of research works have been focusing on such problems, many of them adopted pattern-based heuristics (e.g., reentrancy) to find payment-related attacks thus can incur a considerably large portion of both false positives and negatives. To overcome these limitations and achieve better payment security on blockchain, we introduced a new class of payment attacks in this paper, i.e., unfair payment (UP). Compared to existing heuristics, UP semantically captures a wider range of payment attacks. Furthermore, we highlighted the general framework SAFEPAY to systematically detect UP. The key insight behind is a novel security invariant, i.e., fair value exchange (FVE), which models the fairness for blockchain payments between multiple parties. More specifically, SAFEPAY systematically explores the transaction space of a given smart contract and generates a bounded set of transaction sequences. For each of the sequence, SAFEPAY reports a UP attack once a violation on FVE is confirmed. We have further instantiated SAFEPAY for Ethereum and applied it in real-world smart contracts. In the empirical evaluation, SAFEPAY managed to identify previously unreported UP attacks and effectively avoid false alarms compared to analyzers in the literature as well.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然智能合约在许多公共区块链(如以太坊)中实现了广泛的应用，但其安全问题对区块链生态系统的稳定性构成了越来越多的威胁。在实践中，对智能合约的许多外部攻击都是由数字资产(如加密货币)的中断支付引起的。虽然越来越多的研究工作已经集中在这样的问题上，但是它们中的许多采用基于模式的试探法(例如，可重入性)来发现与支付相关的攻击，因此会导致相当大部分的误报和漏报。为了克服这些局限性，在区块链上实现更好的支付安全性，本文引入了一类新的支付攻击，即不公平支付。与现有的启发式算法相比，UP在语义上捕获了更广泛的支付攻击。此外，我们强调了SAFEPAY的一般框架，以便系统地检测UP。背后的关键见解是一个新的安全不变量，即公平价值交换(FVE)，它为多方之间的区块链支付的公平性建模。更具体地说，SAFEPAY系统地探索给定智能合约的交易空间，并生成一组有界的交易序列。对于每一个序列，一旦确认对FVE的侵犯，SAFEPAY就报告向上攻击。我们进一步实例化了以太坊的SAFEPAY，并将其应用于现实世界的智能合约中。在实证评估中，SAFEPAY成功识别了以前未报告的UP攻击，并且与文献中的分析器相比，有效地避免了错误警报。",
                    "title_zh": "保护您的智能合同免受不公平付款的影响"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00015",
                    "title": "Fast and Robust Distributed Learning in High Dimension",
                    "authors": "El-Mahdi El-Mhamdi, Rachid Guerraoui, Sébastien Rouault",
                    "abstract": "Could a gradient aggregation rule (GAR) for distributed machine learning be both robust and fast? This paper answers by the affirmative through MULTI-BULYAN. Given n workers, f of which are arbitrary malicious (Byzantine) and $m=n-f$ are not, we prove that MULTI-BULYAN can ensure a strong form of Byzantine resilience, as well as an $\\frac{m}{n}$ slowdown, compared to averaging, the fastest (but non Byzantine resilient) rule for distributed machine learning. When $m\\approx n$ (almost all workers are correct), MULTI-BULYAN reaches the speed of averaging. We also prove that MULTI-BULYAN’s cost in local computation is $O(d)$ (like averaging), an important feature for ML where d commonly reaches 109, while robust alternatives have at least quadratic cost in d. Our theoretical findings are complemented with an experimental evaluation which, in addition to supporting the linear O(d) complexity argument, conveys the fact that MULTI-BULYAN’s parallelisability further adds to its efficiency.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1905.04374"
                    },
                    "abstract_zh": "分布式机器学习的梯度聚合规则(GAR)可能既健壮又快速吗？本文通过多方论证作出了肯定的回答。给定n个工人，其中f个是任意恶意的(拜占庭式的),而$m=n-f$不是，我们证明了与分布式机器学习的最快(但非拜占庭式的弹性)规则平均相比，MULTI-BULYAN可以确保强形式的拜占庭式弹性，以及$\\frac{m}{n}$减速。当$m\\approx n$(几乎所有工人都是正确的)时，MULTI-BULYAN达到平均的速度。我们还证明了MULTI-BULYAN在本地计算中的成本是＄O(d)＄(类似于平均),这是ML的一个重要特性，其中d通常达到109，而健壮的替代方案在d中至少具有二次成本。我们的理论发现得到了实验评估的补充，该实验评估除了支持线性O(d)复杂性论点之外，还传达了MULTI-BULYAN的可并行性进一步增加了其效率的事实。",
                    "title_zh": "高维空间中快速鲁棒的分布式学习"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00016",
                    "title": "Double Insurance: Incentivized Federated Learning with Differential Privacy in Mobile Crowdsensing",
                    "authors": "Chenhao Ying, Haiming Jin, Xudong Wang, Yuan Luo",
                    "abstract": "Exploiting the computing capability of mobile devices with specialized engines (e.g., Neural Engine in iPhone), an attractive paradigm of federated learning that combines the mobile crowdsensing (MCS) has been deeply investigated recently (e.g., Google AI and Nvidia), where the training task is offloaded to the mobile crowd. However, this new paradigm still has numerous problems. Since executing the training task is costly for individual workers, the first problem is how to attract more participants. Following the incentive requirement, the second is how to preserve the workers’ bid privacy since the reported costs are usually sensitive. Finally, the third problem is to guarantee the privacy protection on locally training models in the federated learning which involve the private information of local data. In this paper, we propose an incentivized federated learning with differential privacy in MCS system, namely, SHIELD, to solve the three significant problems. In fact, SHIELD satisfies the truthfulness and individual rationality while preserving the differential privacy of workers’ bids and locally training models. Furthermore, for accuracy, the excess empirical risk of SHIELD is proved to be upper bounded by $\\mathcal{O}\\left(\\frac{\\left(\\ln\\left(Kn_{\\min}\\right)\\right)^{\\frac{1}{2}}}{Kn_{\\min}}+\\right. \\left.\\frac{\\ln\\left(Kn_{\\min}\\right)}{K^{2}n_{\\min}^{2}}\\right)$, where a special case for totally distributed scenario leads to a much sharper bound $\\mathcal{O}\\left(\\frac{\\log\\left(n\\right)}{n^{2}}\\right)$ than the latest result $\\mathcal{O}\\left(\\frac{\\ln\\left(mn_{\\min}\\right)}{m^{2}n^{2}}\\right)$. Finally, comparing with the state-of-art approaches, SHIELl illustrates superior performance by numerous experiments in classification and regression tasks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "利用具有专门引擎(例如，iPhone中的神经引擎)的移动设备的计算能力，结合移动众测(MCS)的联合学习的一个有吸引力的范例最近已经被深入研究(例如，Google AI和Nvidia)，其中训练任务被卸载到移动人群。然而，这种新的模式仍然有许多问题。由于执行培训任务对单个工人来说成本很高，所以首要问题是如何吸引更多的参与者。在激励要求之后，第二个问题是如何保护工人的投标隐私，因为报告的成本通常是敏感的。最后，第三个问题是在联邦学习中保证局部训练模型的隐私保护，这涉及到局部数据的隐私信息。本文提出了一种在MCS系统中具有差分隐私的激励联邦学习方法，即SHIELD，来解决这三个重要问题。事实上，SHIELD在保留工人出价和本地训练模型的差分隐私的同时，满足了真实性和个体合理性。此外，为了精确起见，证明了屏蔽的超额经验风险是$\\mathcal{o}\\left(\\frac{\\left(\\ln\\left(kn_{\\min}\\right)\\right)^{\\frac{1}{2}}}{kn_{\\min}}+\\right.的上界\\向左。在\\frac{\\ln\\left(kn_{\\min}\\right)}{k^{2}n_{\\min}^{2}}\\right)$，一个完全分布式场景的特例导致了一个比最新结果$\\mathcal{o}\\left(\\frac{\\ln\\left(mn_{\\min}\\right)}{m^{2}n^{2}}\\right)$.更尖锐的边界$\\mathcal{o}\\left(\\frac{\\log\\left(n\\right)}{n^{2}}\\right)$最后，通过在分类和回归任务中的大量实验，SHIELl与最先进的方法进行了比较，展示了优越的性能。",
                    "title_zh": "双重保险:移动众测中具有差分隐私的激励式联邦学习"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00017",
                    "title": "End-to-End Evaluation of Federated Learning and Split Learning for Internet of Things",
                    "authors": "Yansong Gao, Minki Kim, Sharif Abuadbba, Yeonjae Kim, Chandra Thapa, Kyuyeon Kim, Seyit Ahmet Çamtepe, Hyoungshick Kim, Surya Nepal",
                    "abstract": "Federated learning (FL) and split neural networks (SplitNN) are state-of-art distributed machine learning techniques to enable machine learning without directly accessing raw data on clients or end devices. In theory, such distributed machine learning techniques have great potential in distributed applications, in which data are typically generated and collected at the client-side while the collected data should be processed by the application deployed at the server-side. However, there is still a significant gap in evaluating the performance of those techniques concerning their practicality in the Internet of Things (IoT)-enabled distributed systems constituted by resource-constrained devices. This work is the first attempt to provide empirical comparisons of FL and SplitNN in real-world IoT settings in terms of learning performance and device implementation overhead. We consider a variety of datasets, different model architectures, multiple clients, and various performance metrics. For the learning performance (i.e., model accuracy and convergence time), we empirically evaluate both FL and SplitNN under different types of data distributions such as imbalanced and non-independent and identically distributed (non-IID) data. We show that the learning performance of SplitNN is better than FL under an imbalanced data distribution but worse than FL under an extreme non-IID data distribution. For implementation overhead, we mount both FL and SplitNN on Raspberry Pi devices and comprehensively evaluate their overhead, including training time, communication overhead, power consumption, and memory usage. Our key observations are that under the IoT scenario where the communication traffic is the primary concern, FL appears to perform better over SplitNN because FL has a significantly lower communication overhead compared with SplitNN. However, our experimental results also demonstrate that neither FL or SplitNN can be applied to a heavy model, e.g., with several million parameters, on resource-constrained IoT devices because its training cost would be too expensive for such devices. Source code is released and available: https://github.com/Minki-Kim95/Federated-Learning-and-Split-Learning-with-raspberry-pi.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2003.13376"
                    },
                    "abstract_zh": "联邦学习(FL)和分裂神经网络(SplitNN)是最先进的分布式机器学习技术，能够在不直接访问客户端或终端设备上的原始数据的情况下实现机器学习。理论上，这种分布式机器学习技术在分布式应用中有很大的潜力，其中数据通常在客户端生成和收集，而收集的数据应该由部署在服务器端的应用来处理。然而，在评估这些技术在由资源受限设备构成的支持物联网(IoT)的分布式系统中的实用性方面，仍然存在显著的差距。这项工作首次尝试在现实世界的物联网环境中，从学习性能和设备实施开销方面对FL和SplitNN进行实证比较。我们考虑各种数据集、不同的模型架构、多个客户端和各种性能指标。对于学习性能(即模型精度和收敛时间)，我们在不同类型的数据分布(如不平衡和非独立以及同分布(非IID)数据)下对FL和SplitNN进行了经验评估。我们证明了SplitNN的学习性能在不平衡数据分布下优于FL，但在极端非IID数据分布下差于FL。对于实现开销，我们在Raspberry Pi设备上安装FL和SplitNN，并全面评估它们的开销，包括训练时间、通信开销、功耗和内存使用。我们的主要观察结果是，在通信流量是主要关注点的物联网场景下，FL似乎比SplitNN表现得更好，因为与SplitNN相比，FL的通信开销明显更低。然而，我们的实验结果还表明，FL或SplitNN都不能应用于资源受限的物联网设备上的重型模型，例如，具有几百万个参数，因为其训练成本对于这种设备来说太昂贵了。源代码已经发布并可用:https://github . com/Minki-Kim 95/Federated-Learning-and-Split-Learning-with-raspberry-pi。",
                    "title_zh": "物联网联合学习和分裂学习的端到端评估"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00018",
                    "title": "A Formally Verified Protocol for Log Replication with Byzantine Fault Tolerance",
                    "authors": "Joel Wanner, Laurent Chuat, Adrian Perrig",
                    "abstract": "Byzantine fault tolerant protocols enable state replication in the presence of crashed, malfunctioning, or actively malicious processes. Designing such protocols without the assistance of verification tools, however, is remarkably error-prone. In an adversarial environment, performance and flexibility come at the cost of complexity, making the verification of existing protocols extremely difficult. We take a different approach and propose a formally verified consensus protocol designed for a specific use case: secure logging. Our protocol allows each node to propose entries in a parallel subroutine, and guarantees that correct nodes agree on the set of all proposed entries, without leader election. It is simple yet practical, as it can accommodate the workload of a logging system such as Certificate Transparency. We show that it is optimal in terms of both required rounds and tolerable faults. Using Isabelle/HOL, we provide a fully machine-checked security proof based upon the Heard-Of model, which we extend to support signatures. We also present and evaluate a prototype implementation.",
                    "files": {
                        "openAccessPdf": "https://www.research-collection.ethz.ch/bitstream/20.500.11850/452542/1/logres-paper.pdf"
                    },
                    "abstract_zh": "拜占庭容错协议允许在出现崩溃、故障或恶意进程时进行状态复制。然而，在没有验证工具帮助的情况下设计这样的协议是非常容易出错的。在敌对环境中，性能和灵活性是以复杂性为代价的，使得现有协议的验证极其困难。我们采用不同的方法，提出了一个正式验证的共识协议，它是为一个特定的用例设计的:安全日志。我们的协议允许每个节点在一个并行子例程中提出条目，并保证正确的节点同意所有提出的条目的集合，而无需选举领导者。它简单而实用，因为它可以适应日志系统的工作负载，如证书透明性。我们证明了它在所需的轮数和可容忍的错误方面都是最优的。通过使用伊莎贝尔/HOL，我们提供了一个基于听说过的模型的完全机器检查的安全证明，我们将其扩展到支持签名。我们还提出并评估了一个原型实现。",
                    "title_zh": "一种形式化验证的拜占庭容错日志复制协议"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00019",
                    "title": "Using Model Checking to Formally Verify Rendezvous Algorithms for Robots with Lights in Euclidean Space",
                    "authors": "Xavier Défago, Adam Heriban, Sébastien Tixeuil, Koichi Wada",
                    "abstract": "The paper details the first successful attempt at using model checking techniques to verify the correctness of distributed algorithms for robots evolving in a continuous environment. The study focuses on the problem of rendezvous of two robots with lights.There exist many different rendezvous algorithms that aim at finding the minimal number of colors needed to solve rendezvous in various synchrony models (e.g., FSYNC, SSYNC, ASYNC). While these rendezvous algorithms are typically very simple, their analysis and proof of correctness tend to be extremely complex, tedious, and error-prone as impossibility results are based on subtle interactions between robots activation schedules.The paper presents a generic verification model written for the SPIN model checker. In particular, we explain the subtle design decisions that allow to keep the search space finite and tractable, as well as prove several important theorems that support them. As a sanity check, we use the model to verify several known rendezvous algorithms in six different models of synchrony. In each case, we find that the results obtained from the model checker are consistent with the results known in the literature. The model checker outputs a counter-example execution in every case that is known to fail.In the course of developing and proving the validity of the model, we identified several fundamental theorems, including the ability for a well chosen algorithm and ASYNC scheduler to produce an emerging property of memory in a system of oblivious mobile robots, and why it is not a problem for luminous rendezvous algorithms.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1907.09871"
                    },
                    "abstract_zh": "本文详细介绍了首次成功尝试使用模型检测技术来验证机器人在连续环境中进化的分布式算法的正确性。研究重点是两个带灯机器人的交会问题。存在许多不同的会合算法，旨在找到在各种同步模型(例如，FSYNC、SSYNC、ASYNC)中解决会合所需的最小数量的颜色。虽然这些会合算法通常非常简单，但它们的分析和正确性证明往往非常复杂、乏味且容易出错，因为不可能的结果是基于机器人激活时间表之间的微妙交互。本文提出了一个为自旋模型检验器编写的通用验证模型。特别是，我们解释了微妙的设计决策，允许保持搜索空间有限和易处理，以及证明几个重要的定理支持他们。作为健全性检查，我们使用该模型在六个不同的同步模型中验证了几个已知的会合算法。在每种情况下，我们发现从模型检验器获得的结果与文献中已知的结果一致。模型检查器在每一个已知失败的情况下输出一个反例执行。在开发和证明该模型的有效性的过程中，我们确定了几个基本定理，包括精心选择的算法和异步调度程序在健忘的移动机器人系统中产生记忆的新兴属性的能力，以及为什么这对发光的会合算法来说不是问题。",
                    "title_zh": "利用模型检测形式化验证欧氏空间中带灯机器人的交会算法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00020",
                    "title": "Efficient Two-Layered Monitor for Partially Synchronous Distributed Systems",
                    "authors": "Vidhya Tekken Valapil, Sandeep S. Kulkarni, Eric Torng, Gabe Appleton",
                    "abstract": "Monitoring distributed systems to ensure their correctness is a challenging and expensive but essential problem. It is challenging because while execution of a distributed system creates a partial order among events, the monitor will typically observe only one serialization of that partial order. This means that even if the observed serialization is consistent with the system specifications, the monitor cannot assume that the system is correct because some other unobserved serialization can be inconsistent with the system specifications. Existing solutions that guarantee identification of all such unobserved violations require some combination of lots of time and large clocks, e.g. O(n) sized Vector Clocks.We present a new, efficient two-layered monitoring approach that overcomes both the time and space limitations of earlier monitors. The first layer is imprecise but efficient and the second layer is precise but (relatively) inefficient. We show that the combination of these two layers reduces the cost of monitoring by 85-95%. Furthermore, the two-layered monitor permits the use of O(1) sized Hybrid Logical Clocks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "监控分布式系统以确保其正确性是一个具有挑战性且昂贵的问题，但却是一个基本问题。这是具有挑战性的，因为当分布式系统的执行在事件之间创建一个偏序时，监视器将典型地只观察该偏序的一个串行化。这意味着即使观察到的串行化与系统规范一致，监视器也不能假定系统是正确的，因为一些其他未观察到的串行化可能与系统规范不一致。保证识别所有这种未观察到的违反的现有解决方案需要大量时间和大时钟的某种组合，例如O(n)大小的向量时钟。我们提出了一种新的、有效的两层监控方法，克服了早期监控器的时间和空间限制。第一层不精确但有效，第二层精确但(相对)低效。我们表明，这两层的结合减少了85-95%的监控成本。此外，双层监视器允许使用O(1)大小的混合逻辑时钟。",
                    "title_zh": "部分同步分布式系统的高效双层监控器"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00021",
                    "title": "Parallel State Machine Replication from Generalized Consensus",
                    "authors": "Tarcisio Ceolin Junior, Fernando Luís Dotti, Fernando Pedone",
                    "abstract": "State machine replication (SMR) is a established approach to building fault-tolerant services. In search for high SMR throughput, approaches that exploit semantic information in the ordering and execution of commands have emerged. Generalized consensus and parallel state machine replication are two representative examples, respectively. Although both approaches have been proved effective in isolation, no study in the literature has considered their integration. In this paper, we investigate the integration of generalized consensus and parallel SMR. We derive algorithms to parallelize the execution of commands based on the ordering of commands provided by consensus. As a prototype, we extended Egalitarian Paxos and conducted many experiments varying conflict rates, command computational costs, and number of cores at replicas. Compared to Egalitarian Paxos, the integrated approach (a) results in important throughput gains, as command independency and computational cost increase, and (b) converges to the same performance with high conflict rates or reduced number of cores. Index Terms– State Machine Replication, Generalized Consensus, Distributed Algorithms",
                    "files": {
                        "openAccessPdf": "https://repositorio.pucrs.br/dspace/bitstream/10923/18691/2/Parallel_State_Machine_Replication_from_Generalized_Consensus.pdf"
                    },
                    "abstract_zh": "状态机复制(SMR)是一种建立容错服务的既定方法。在寻找高SMR吞吐量的过程中，出现了在命令的排序和执行中利用语义信息的方法。广义一致性和并行状态机复制分别是两个有代表性的例子。尽管这两种方法在单独使用时都被证明是有效的，但是在文献中还没有研究考虑过它们的整合。本文研究了广义一致性和并行SMR的整合。我们基于共识提供的命令排序，推导出并行化命令执行的算法。作为原型，我们扩展了平等派Paxos，并进行了许多实验，改变了冲突率、命令计算成本和副本中的内核数量。与平均主义Paxos相比，集成方法(a)随着命令独立性和计算成本的增加，导致了重要的吞吐量增益，以及(b)在高冲突率或减少内核数量的情况下，收敛到相同的性能。索引术语——状态机复制、广义共识、分布式算法",
                    "title_zh": "来自广义一致性的并行状态机复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00022",
                    "title": "A Generic Specification Framework for Weakly Consistent Replicated Data Types",
                    "authors": "Xue Jiang, Hengfeng Wei, Yu Huang",
                    "abstract": "Recently Burckhardt et al. proposed a formal specification framework for eventually consistent replicated data types, denoted (vis, ar), based on the notions of visibility and arbitration relations. However, being specific to eventually consistent systems, this framework has two limitations. First, it does not cover non-convergent consistency models since arbitration ar is defined to be a total order over events in a computation. Second, it does not cover the consistency models in which each event is required to be aware of the return values of some or all events that are visible to it.In this paper, we extend the (vis, ar) specification framework into a more generic one called (vis, ar, V) for weakly consistent replicated data types. To specify non-convergent consistency models as well, we simply relax the arbitration relation ar to be a partial order. To overcome the second limitation, we allow to specify for each event e, a subset V(e) of its visible set whose return values cannot be ignored when justifying the return value of e. To make it practically feasible, we provide candidates for the visibility and arbitration relations and the V function. By combining these candidates, we demonstrate how to specify various existing consistency models in the (vis, ar, V) framework. Moreover, it helps to discover new consistency models. As a case study, we prove that the causal consistency protocol of MongoDB database satisfies Causal Memory Convergence, a new causal consistency variant discovered in our framework.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近，Burckhardt等人基于可见性和仲裁关系的概念，提出了最终一致的复制数据类型的正式规范框架，表示为(vis，ar)。然而，由于特定于最终一致的系统，这个框架有两个限制。首先，它不包括非收敛一致性模型，因为仲裁ar被定义为计算中事件的总顺序。其次，它没有涵盖一致性模型，在这种模型中，每个事件都需要知道对它可见的一些或所有事件的返回值。在本文中，我们将(vis，ar)规范框架扩展为一个更通用的框架，称为(vis，ar，V ),用于弱一致性复制数据类型。为了指定非收敛的一致性模型，我们简单地将仲裁关系ar放宽到一个偏序。为了克服第二个限制，我们允许为每个事件e指定其可见集的子集V(e ),当证明e的返回值时，其返回值不能被忽略。为了使其实际可行，我们提供了可见性和仲裁关系以及V函数的候选。通过组合这些候选者，我们演示了如何在(vis，ar，V)框架中指定各种现有的一致性模型。此外，它有助于发现新的一致性模型。作为一个案例研究，我们证明了MongoDB数据库的因果一致性协议满足因果记忆收敛，这是在我们的框架中发现的一种新的因果一致性变体。",
                    "title_zh": "弱一致性复制数据类型的通用规范框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00023",
                    "title": "PnyxDB: a Lightweight Leaderless Democratic Byzantine Fault Tolerant Replicated Datastore",
                    "authors": "Loïck Bonniot, Christoph Neumann, François Taïani",
                    "abstract": "Byzantine-Fault-Tolerant (BFT) systems for closed consortia have recently attracted a growing attention notably in financial and supply-chain applications. Unfortunately, most existing solutions suffer from substantial scalability issues, and lack self-governance mechanisms. In this paper, we observe that many workloads present little concurrency, and propose PnyxDB, an eventually-consistent Byzantine Fault Tolerant replicated data-store that exhibits both high scalability and low latency. Our approach hinges on conditional endorsements that track conflicts between transactions. In addition to its high scalability, PnyxDB supports application-level voting, i.e. individual nodes are able to endorse or reject a transaction according to application-defined policies without compromising consistency. We provide a comparison against BFT-SMART and Tendermint, two competitors with different design aims, and show that our implementation speeds up commit latencies by a factor of 11, remaining below 5 seconds in a worldwide geodistributed deployment of 180 nodes.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1911.03291"
                    },
                    "abstract_zh": "针对封闭联合体的拜占庭容错(BFT)系统最近吸引了越来越多的关注，特别是在金融和供应链应用中。不幸的是，大多数现有的解决方案都存在很大的可扩展性问题，并且缺乏自我管理机制。在本文中，我们观察到许多工作负载几乎没有并发性，并提出PnyxDB，一种最终一致的拜占庭容错复制数据存储，它表现出高可伸缩性和低延迟。我们的方法依赖于跟踪交易间冲突的有条件背书。除了高可伸缩性之外，PnyxDB还支持应用程序级投票，即各个节点能够根据应用程序定义的策略批准或拒绝事务，而不会影响一致性。我们提供了与BFT智能和Tendermint这两个具有不同设计目标的竞争对手的比较，并表明我们的实施将提交延迟加快了11倍，在全球180个节点的地理分布部署中保持在5秒以下。",
                    "title_zh": "PnyxDB:轻量级无领导民主拜占庭容错复制数据存储"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00024",
                    "title": "Self-optimising Application-agnostic Multithreading for Replicated State Machines",
                    "authors": "Gerhard Habiger, Franz J. Hauck, Hans P. Reiser, Johannes Köstler",
                    "abstract": "State-machine replication (SMR) is a well-known approach for fault-tolerant services demanding fast recovery. It is not easy, however, to parallelise SMR in order to exploit modern multicore architectures. Two main approaches have been extensively studied; one focusing on request-level concurrency using prior knowledge, the other utilising application-agnostic and lock-level deterministic scheduling. We show that significant performance improvements for the latter approach require deterministic scheduler configurations to be dynamically adapted to the current application load during runtime. First, we summarise current research on parallel SMR execution. Second, an analysis of obstacles in lock-level deterministic multithreading approaches shows how static scheduler configurations can lead to poor performance when load on the system varies over time. Third, we present a simple yet effective automatic adaptation solution, which provides significantly better overall system behaviour compared to static configurations. This is demonstrated by evaluations using a full system setup.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对于要求快速恢复的容错服务，状态机复制(SMR)是一种众所周知的方法。然而，为了利用现代多核架构，并行化SMR并不容易。已经广泛研究了两种主要方法；一种侧重于使用先验知识的请求级并发，另一种利用应用程序无关性和锁级确定性调度。我们表明，后一种方法的显著性能改进需要确定性调度器配置在运行时动态适应当前的应用程序负载。首先，我们总结了当前关于并行SMR执行的研究。第二，对锁级确定性多线程方法中的障碍的分析表明，当系统上的负载随时间变化时，静态调度器配置如何会导致较差的性能。第三，我们提出了一种简单而有效的自动适应解决方案，与静态配置相比，它提供了明显更好的整体系统行为。使用完整系统设置的评估证明了这一点。",
                    "title_zh": "用于复制状态机的自优化应用无关多线程"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00025",
                    "title": "Secure Embedding of Rooted Spanning Trees for Scalable Routing in Topology-Restricted Networks",
                    "authors": "Martin Byrenheid, Thorsten Strufe, Stefanie Roos",
                    "abstract": "Greedy embeddings on rooted spanning trees are the most promising solution to provide sufficiently scalable routing in dynamic networks with restricted topologies, for instance friend-to-friend overlays such as the Dark Freenet and payment channel networks such as Lightning. Yet, they are not deployed in practice, as electing a root and configuring addresses remains an unsolved problem in adverse environments. Indeed, faulty or malicious nodes might provide incorrect coordinates, prevent the network from stabilizing by simulating dynamics, or not start the assignment of coordinates in their subtree at all. All of the above attacks may result in an inability to route. To mitigate the above attacks, we design a novel embedding algorithm with an adapted distance metric that only relies on interconnections between benign subtrees for successful delivery. In other words, even if roots of (sub-)trees are malicious or faulty, the remaining nodes still receive coordinates and can communicate with nodes in their tree branch as well as other branches reachable via the neighborhood of their benign ancestors. Extensive simulations demonstrate that we thus facilitate efficient routing even when seemingly decisive parts of the network are under adversarial control.",
                    "files": {
                        "openAccessPdf": "https://repository.tudelft.nl/islandora/object/uuid%3A57224685-ce9e-413e-a13f-4445d5882549/datastream/OBJ/download"
                    },
                    "abstract_zh": "有根生成树上的贪婪嵌入是在具有受限拓扑的动态网络中提供足够可扩展的路由的最有前途的解决方案，例如朋友对朋友的覆盖(如黑暗免费网络)和支付通道网络(如闪电)。然而，它们在实践中并没有被部署，因为在不利的环境中选举根和配置地址仍然是一个未解决的问题。事实上，故障或恶意节点可能会提供不正确的坐标，通过模拟动态来阻止网络稳定，或者根本不开始在它们的子树中分配坐标。上述所有攻击都可能导致无法路由。为了减轻上述攻击，我们设计了一种新颖的嵌入算法，该算法具有自适应的距离度量，仅依赖于良性子树之间的互连来成功传递。换句话说，即使(子)树根是恶意的或有缺陷的，剩余的节点仍然接收坐标，并且可以与它们的树分支中的节点以及经由它们良性祖先的邻域可到达的其他分支通信。大量的模拟表明，即使网络中看似决定性的部分处于敌对的控制之下，我们也能促进有效的路由。",
                    "title_zh": "拓扑受限网络中可扩展路由的根生成树安全嵌入"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00026",
                    "title": "On the Detection of Shilling Attacks in Federated Collaborative Filtering",
                    "authors": "Yangfan Jiang, Yipeng Zhou, Di Wu, Chao Li, Yan Wang",
                    "abstract": "Federated collaborative filtering (Fed-CF) is a variant of federated learning (FL) models, which can protect user privacy in recommender systems. In Fed-CF, the recommendation model is collectively trained across multiple decentralized clients by exchanging gradients only. However, the decentralized nature of Fed-CF makes it vulnerable to shilling attacks, which can be realized by inserting fake ratings of target items to distort recommendation results. Unfortunately, previous detection algorithms cannot work well in the FL framework, as all original data samples are not disclosed at all. In this paper, we are the first to systematically study the problem of shilling attacks in the context of federated learning, and propose an effective detection method called Federated Shilling Attack Detector (FSAD) to detect shilling attackers in Fed-CF. We first show the feasibility of shilling attacks in Fed-CF. Next, we dedicatedly design four novel features based on exchanged gradients among clients. By incorporating these gradient-based features, we train a semi-supervised Bayes classifier to identify shilling attackers effectively. Finally, we conduct extensive experiments based on real-world datasets to evaluate the performance of our proposed FSAD method. The experimental results show that FSAD can detect shilling attackers in Fed-CF with high accuracy, with the F1 value as high as 0.90 on the Netflix dataset, which approaches the performance of the optimal detector that utilizes complete private user information for detection.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "联合协同过滤(federated collaborative filtering，Fed-CF)是联合学习(federated learning，FL)模型的一种变体，可以在推荐系统中保护用户隐私。在Fed-CF中，推荐模型仅通过交换梯度跨多个分散的客户端进行集体训练。然而，Fed-CF的去中心化特性使其容易受到先令攻击，这种攻击可以通过插入目标项目的虚假评级来扭曲推荐结果来实现。不幸的是，以前的检测算法在FL框架中不能很好地工作，因为所有的原始数据样本根本没有被公开。在本文中，我们首次系统地研究了联邦学习环境下的先令攻击问题，并提出了一种有效的检测方法，称为联邦先令攻击检测器(FSAD ),用于检测Fed-CF中的先令攻击者。通过结合这些基于梯度的特征，我们训练了一个半监督贝叶斯分类器来有效地识别先令攻击者。最后，我们基于真实数据集进行了大量的实验来评估我们提出的FSAD方法的性能。实验结果表明，FSAD能够以较高的准确率检测出Fed-CF中的先令攻击者，在网飞数据集上的F1值高达0.90，接近利用完全私有用户信息检测的最优检测器的性能。",
                    "title_zh": "联合协同过滤中先令攻击的检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00027",
                    "title": "Anomaly Detection via Mining Numerical Workflow Relations from Logs",
                    "authors": "Bo Zhang, Hongyu Zhang, Pablo Moscato, Aozhong Zhang",
                    "abstract": "Complex software-intensive systems, especially distributed systems, generate logs for troubleshooting. The logs are text messages recording system events, which can help engineers determine the system’s runtime status. This paper proposes a novel approach named ADR (stands for Anomaly Detection by workflow Relations), which employs matrix nullspace to mine numerical relations from log data. The mined relations can be used for both offline and online anomaly detection and facilitate fault diagnosis. We have evaluated ADR on log data collected from two distributed systems. ADR successfully mined 87 and 669 numerical relations from the logs and used them to detect anomalies with high precision and recall. For online anomaly detection, ADR employs PSO (Particle Swarm Optimization) to find the optimal sliding windows’ size and achieves fast anomaly detection. The experimental results confirm that ADR is effective for both offline and online anomaly detection.",
                    "files": {
                        "openAccessPdf": "https://figshare.com/articles/preprint/Anomaly_Detection_via_Mining_Numerical_Workflow_Relations_from_Logs/12570926/2/files/24628187.pdf"
                    },
                    "abstract_zh": "复杂的软件密集型系统，尤其是分布式系统，会生成用于故障排除的日志。日志是记录系统事件的文本消息，可以帮助工程师确定系统的运行状态。本文提出了一种新的方法ADR(工作流关系异常检测),该方法利用矩阵零空间从日志数据中挖掘数值关系。挖掘的关系可用于离线和在线异常检测，并有助于故障诊断。我们对从两个分布式系统收集的日志数据进行了ADR评估。ADR成功地从日志中挖掘出87和669个数值关系，并使用它们以高精度和高召回率检测异常。对于在线异常检测，ADR采用粒子群优化算法寻找最优滑动窗口大小，实现快速异常检测。实验结果表明，ADR对离线和在线异常检测都是有效的。",
                    "title_zh": "从日志中挖掘数值工作流关系的异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00028",
                    "title": "TLP-IDS: A Two-layer Intrusion Detection System for Integrated Electronic Systems",
                    "authors": "Xiaoxia Liu, Daojing He, Yun Gao, Sencun Zhu, Sammy Chan",
                    "abstract": "With the increasing applications of integrated electronic systems (IESs), especially in security critical application scenarios like satellites and aircraft, new vulnerabilities and attacks have emerged recently. To detect the attacks, we propose TLP-IDS, a real-time intrusion detection system (IDS). TLP-IDS includes two layers of detection modules, one based on time and sequence logic and the other based on historical data. For the modules in the first layer, periodic and aperiodic messages are distinguished based on variations of message intervals, and we learnd from the idea of Markov decision process (MDP) in reinforcement learning (RL) to automatically learn the logical relationship between sequences. In the second layer, an online sequence extreme learning machine (OS-ELM) method is deployed to fit the data and further combined with the Weibull distribution function for prediction and detection. To evaluate our system, we implement several attack scenarios on a test bed, and measure the detection performance. Experimental results show that our system can quickly and effectively detect various attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着综合电子系统(IESs)应用的增加，特别是在卫星和飞机等安全关键应用场景中，新的漏洞和攻击不断出现。为了检测这些攻击，我们提出了实时入侵检测系统TLP-IDS。TLP-IDS包括两层检测模块，一层基于时间和顺序逻辑，另一层基于历史数据。在第一层模块中，根据消息间隔的变化来区分周期性和非周期性消息，并借鉴强化学习中MDP的思想来自动学习序列之间的逻辑关系。在第二层中，使用在线序列极限学习机(OS-ELM)方法来拟合数据，并进一步结合威布尔分布函数进行预测和检测。为了评估我们的系统，我们在测试床上实现了几个攻击场景，并测量了检测性能。实验结果表明，该系统能够快速有效地检测各种攻击。",
                    "title_zh": "TLP-IDS:集成电子系统的双层入侵检测系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00029",
                    "title": "Audinet: A Decentralized Auditing System for Cloud Storage",
                    "authors": "Meng Yan, Jiajia Xu, Trent G. Marbach, Haitao Li, Gang Wang, Xiaoguang Liu",
                    "abstract": "In cloud storage, remote data auditing is designed to verify the integrity of cloud data on behalf of cloud users. The audit is performed by a third-party auditor (TPA) according to auditing protocols such as proof of retrievability and provable data possession. However, the TPA-based auditing framework leads to single-point failures, opaque audit processes and undetected mistakes. In this paper, we propose a decentralized auditing system in which the audit is performed by multiple auditors and the audit result is reached in a collaborative and transparent way. Auditors are selected for each audit randomly from the set of cloud users via modified cryptographic sortition; auditing procedures are implemented using a smart contract, and auditing records are published on a blockchain; an incentive mechanism is provided to regulate the behavior of system participants. We implement a prototype system and demonstrate that the proposed system is reliable and technically feasible.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在云存储中，远程数据审计旨在代表云用户验证云数据的完整性。审计由第三方审计员(TPA)根据审计协议执行，如可检索性证明和可证明的数据所有权。然而，基于TPA的审计框架会导致单点故障、不透明的审计流程和未被发现的错误。在本文中，我们提出了一个分散的审计系统，在该系统中，审计由多个审计员执行，审计结果以协作和透明的方式达成。通过修改的加密排序，从云用户集合中随机地为每个审计选择审计者；使用智能合同实施审计程序，并在区块链上公布审计记录；提供激励机制来规范系统参与者的行为。我们实现了一个原型系统，并证明了所提出的系统是可靠的和技术上可行的。",
                    "title_zh": "Audinet:一个分散的云存储审计系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00030",
                    "title": "Device and Placement Aware Framework to optimize Single Failure Recoveries and Reads for Erasure Coded Storage System with Heterogeneous Storage Devices",
                    "authors": "Yingxun Fu, Xun Liu, Jiwu Shu, Zhirong Shen, Shiye Zhang, Jun Wu, Jianyong Duan, Li Ma",
                    "abstract": "Erasure codes are widely used in cloud storage systems, such as in Google File System and Windows Azure. However, most of existing erasure codes focus on homogeneous storage device, but ignore that heterogeneous devices are in majority in cloud storage system. In this paper, we propose a new erasure code framework termed Device Placement Aware Framework (DPAF), to integrate existing erasure codes to generate DPAF-Codes, in order to gain good performance on heterogeneous storage devices. The key insight is to detect the device performance to generate a series of coefficients, and use these coefficients to choose proper devices to construct DPAF-Codes. We utilize simulated annealing algorithm to optimize the selection process, in order to maintain the balance among devices by considering the coefficients. The experiment results show that, our proposed DPAF-Codes gain up to 70.3%, 48.7%, and 48.5% improvements on single failure recovery, normal read, and degraded read speed, compared to RS code and LRC code with different configurations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "纠删码广泛应用于云存储系统中，如Google文件系统和Windows Azure。然而，现有的纠删码大多集中在同构存储设备上，却忽略了云存储系统中异构设备占大多数。本文提出了一种新的纠删码框架，称为设备布局感知框架(DPAF ),用来整合现有的纠删码生成DPAF码，从而在异构存储设备上获得良好的性能。关键在于检测器件性能以产生一系列系数，并使用这些系数选择合适的器件来构造DPAF码。我们利用模拟退火算法来优化选择过程，以便通过考虑系数来保持器件之间的平衡。实验结果表明，与不同配置的RS码和LRC码相比，我们提出的DPAF码在单故障恢复、正常读取和降级读取速度方面分别获得了70.3%、48.7%和48.5%的提高。",
                    "title_zh": "用于优化具有异构存储设备的擦除编码存储系统的单一故障恢复和读取的设备和放置感知框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00031",
                    "title": "AZ-Recovery: An Efficient Crossing-AZ Recovery Scheme for Erasure Coded Cloud Storage Systems",
                    "authors": "Xin Xie, Chentao Wu, Gen Yang, Zongxin Ye, Xubin He, Jie Li, Minyi Guo, Guangtao Xue, Yuanyuan Dong, Yafei Zhao",
                    "abstract": "As massive data in modern cloud storage systems grow dramatically, it is a common method to partition and store data in multiple Availability Zones (AZs). Multiple AZs not only provide high reliability, but also reduce the network latency. Erasure Codes (ECs) are widely used in multiple AZs to provide high reliability at low storage cost. However, the recovery cost of EC is extremely high in multiple AZs’ environment, which is mainly because a normal EC needs to reconstruct the lost data via transferring the data/parities across AZs. Although existing fast recovery approaches can save the I/O cost or network bandwidth in an effective manner, they are not suitable for multiple AZs. The reasons include low flexibility on various complex network scenarios, less consideration on crossing-AZ bandwidth, low capabilities on multiple disk/node failures, etc. To address the above problem, in this paper, we propose a crossing $\\underline{\\mathrm{A}}$vailability Zone Recovery (AZ-Recovery) method to efficiently improve the recovery performance for multiple AZs. AZ-Recovery investigates the complex homogeneous/heterogeneous network topologies, and finds an optimal data transmission path. Using this method, AZ-Recovery can significantly reduce the recovery cost and save the crossing AZ bandwidth in various failure scenarios. To demonstrate the effectiveness of AZ-Recovery, we evaluate various erasure codes via mathematical analysis and simulations in Network Simulator-3. The results show that, compared to the traditional erasure coding methods, AZ-Recovery saves the recovery bandwidth by up to 77.47%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着现代云存储系统中海量数据的急剧增长，将数据划分并存储在多个可用区(AZs)中是一种常见的方法。多个az不仅提供了高可靠性，还减少了网络延迟。擦除码(ECs)广泛用于多个az中，以低存储成本提供高可靠性。然而，在多az环境中，EC的恢复成本非常高，这主要是因为普通的EC需要通过跨az传输数据/奇偶校验来重建丢失的数据。尽管现有的快速恢复方法可以以有效的方式节省I/O成本或网络带宽，但是它们不适用于多个az。原因包括对各种复杂网络场景的低灵活性、对跨AZ带宽的较少考虑、对多个磁盘/节点故障的低能力等。为了解决上述问题，在本文中，我们提出了一种交叉＄\\ underline { \\ mathrm { A } }＄avail ability Zone Recovery(AZ-Recovery)方法来有效地提高多个AZ的恢复性能。AZ-Recovery研究复杂的同构/异构网络拓扑，并找到最佳的数据传输路径。使用这种方法，AZ-Recovery可以显著降低恢复成本，节省各种故障场景下的交叉AZ带宽。为了证明AZ-Recovery的有效性，我们通过数学分析和在Network Simulator-3中的仿真来评估各种擦除码。结果表明，与传统的擦除编码方法相比，AZ-Recovery节省了高达77.47%的恢复带宽。",
                    "title_zh": "AZ-Recovery:一种高效的擦除编码云存储系统跨AZ恢复方案"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00032",
                    "title": "Enabling I/O-Efficient Redundancy Transitioning in Erasure-Coded KV Stores via Elastic Reed-Solomon Codes",
                    "authors": "Si Wu, Zhirong Shen, Patrick P. C. Lee",
                    "abstract": "Modern key-value (KV) stores increasingly adopt erasure coding to reliably store data. To adapt to the changing demands on access performance and reliability requirements, KV stores perform redundancy transitioning by tuning the redundancy schemes with different coding parameters. However, redundancy transitioning incurs extensive I/Os, which impair the performance of KV stores. We propose a new family of erasure codes, called Elastic Reed-Solomon (ERS) codes, whose primary goal is to mitigate I/Os in redundancy transitioning. ERS codes eliminate data block relocation, while limiting I/Os for parity block updates via the new co-design of encoding matrix construction and data placement. We realize ERS codes as a KV store atop Memcached, and show via LAN testbed experiments that ERS codes significantly reduce the latency of redundancy transitioning compared to state-of-the-arts.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代键值(KV)存储越来越多地采用擦除编码来可靠地存储数据。为了适应不断变化的访问性能和可靠性要求，KV商店通过调整具有不同编码参数的冗余方案来执行冗余转换。但是，冗余转换会导致大量的I/o，这会损害KV存储的性能。我们提出了一种新的擦除码，称为弹性里德-所罗门(ERS)码，其主要目标是减少冗余转换中的I/o。ERS代码消除了数据块重新定位，同时通过编码矩阵构造和数据放置的新协同设计，限制了奇偶校验块更新的I/o。我们将ERS代码实现为Memcached上的KV存储，并通过LAN测试床实验表明，与最先进的技术相比，ERS代码显著减少了冗余转换的延迟。",
                    "title_zh": "通过弹性Reed-Solomon码在擦除编码KV存储器中实现I/O高效冗余转换"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00033",
                    "title": "MQT-TZ: Hardening IoT Brokers Using ARM TrustZone : (Practical Experience Report)",
                    "authors": "Carlos Segarra, Ricard Delgado-Gonzalo, Valerio Schiavoni",
                    "abstract": "The publish-subscribe paradigm is an efficient communication scheme with strong decoupling between the nodes, that is especially fit for large-scale deployments. It adapts natively to very dynamic settings and it is used in a diversity of real-world scenarios, including finance, smart cities, medical environments, or IoT sensors. Several of the mentioned application scenarios require increasingly stringent security guarantees due to the sensitive nature of the exchanged messages as well as the privacy demands of the clients/stakeholders/receivers. MQTT is a lightweight topic-based publish-subscribe protocol popular in edge and IoT settings, a de-facto standard widely adopted nowadays by the industry and researchers. However, MQTT brokers must process data in clear, hence exposing a large attack surface. This paper presents MQT-TZ, a secure MQTT broker leveraging ARM TRUSTZONE, a trusted execution environment (TEE) commonly found even on inexpensive devices largely available on the market (such as Raspberry Pi units). We define a mutual TLS-based handshake and a two-layer encryption for end-to-end security using the TEE as a trusted proxy. The experimental evaluation of our fully implemented prototype with micro-, macro-benchmarks, as well as with real-world industrial workloads from a MedTech use-case, highlights several tradeoffs using TRUSTZONE TEE. We report several lessons learned while building and evaluating our system. We release MQT-TZ as open-source.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "发布-订阅模式是一种高效的通信方案，在节点之间具有很强的解耦性，特别适合大规模部署。它天生适应非常动态的设置，并用于各种现实世界的场景，包括金融、智能城市、医疗环境或物联网传感器。由于所交换消息的敏感性以及客户/利益相关者/接收者的隐私要求，上述几种应用场景需要越来越严格的安全保证。MQTT是一种轻量级的基于主题的发布-订阅协议，在edge和IoT环境中很流行，是当今业界和研究人员广泛采用的事实上的标准。然而，MQTT代理必须以明文方式处理数据，因此暴露了很大的攻击面。本文介绍了MQT-TZ，一个利用ARM TRUSTZONE的安全MQTT代理，这是一个受信任的执行环境(TEE ),甚至在市场上大量可用的廉价设备(如Raspberry Pi单元)上也可以找到。我们使用TEE作为可信代理，定义了基于TLS的相互握手和用于端到端安全性的两层加密。我们使用微观、宏观基准以及来自MedTech用例的真实世界工业工作负载对完全实施的原型进行了实验评估，突出了使用TRUSTZONE TEE的几个权衡。我们报告了在构建和评估我们的系统时学到的一些经验教训。我们将MQT-TZ作为开源软件发布。",
                    "title_zh": "MQT-TZ:使用ARM TrustZone强化物联网代理:(实践经验报告)"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00034",
                    "title": "Solving Linear Systems on High Performance Hardware with Resilience to Multiple Hard Faults",
                    "authors": "Daniela Loreti, Marcello Artioli, Anna Ciampolini",
                    "abstract": "As large-scale linear equation systems are pervasive in many scientific fields, great efforts have been done over the last decade in realizing efficient techniques to solve such systems, possibly relying on High Performance Computing (HPC) infrastructures to boost the performance. In this framework, the ever-growing scale of supercomputers inevitably increases the frequency of faults, making it a crucial issue of HPC application development.A previous study [1] investigated the possibility to enhance the Inhibition Method (IMe) –a linear systems solver for dense unstructured matrices-with fault tolerance to single hard errors, i.e. failures causing one computing processor to stop.This article extends [1] by proposing an efficient technique to obtain fault tolerance to multiple hard errors, which may occur concurrently on different processors belonging to the same or different machines. An improved parallel implementation is also proposed, which is particularly suitable for HPC environments and moves towards the direction of a complete decentralization. The theoretical analysis suggests that the technique (which does not require check pointing, nor rollback) is able to provide fault tolerance to multiple faults at the price of a small overhead and a limited number of additional processors to store the checksums. Experimental results on a HPC architecture validate the theoretical study, showing promising performance improvements w.r.t. a popular fault-tolerant solving technique.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于大规模线性方程系统在许多科学领域中普遍存在，在过去十年中，人们在实现解决此类系统的有效技术方面付出了巨大努力，可能依赖于高性能计算(HPC)基础设施来提高性能。在这个框架中，不断增长的超级计算机规模不可避免地增加了故障频率，使其成为HPC应用程序开发的一个关键问题。之前的一项研究[1]调查了增强抑制方法(IMe)的可能性，IMe是一种用于密集非结构化矩阵的线性系统解算器，具有对单个硬错误的容错能力，即导致一个计算处理器停止的故障。本文对[1]进行了扩展，提出了一种有效的技术来获得对多个硬错误的容错，这些硬错误可能同时发生在属于相同或不同机器的不同处理器上。还提出了一种改进的并行实现，特别适合HPC环境，并朝着完全去中心化的方向发展。理论分析表明，该技术(不需要检查点，也不需要回滚)能够以较小的开销和有限数量的附加处理器来存储校验和为代价，提供对多个故障的容错。在一个高性能计算体系结构上的实验结果验证了理论研究，显示了与一种流行的容错解决技术相比有希望的性能改进。",
                    "title_zh": "在高性能硬件上求解线性系统，对多个硬故障具有弹性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00035",
                    "title": "Robust Cache-Aware Quantum Processor Layout",
                    "authors": "Travis LeCompte, Fang Qi, Lu Peng",
                    "abstract": "Quantum computation has taken over as one of the largest current research areas in computer architecture and information theory. With the potential to make a large number of factorization-based encryption methods obsolete, companies and governments around the globe are racing to build the first large-scale quantum computer. Currently, most quantum computers are noisy intermediate-scale quantum (NISQ), using a relatively small collection of unreliable qubits. While error correction methods exist, they require a large number of ancilla qubits to protect the data qubits which is not practical for use on current NISQ machines. However, following the Dowling-Neven Law, available qubits on a superconducting chip are growing at an exponential rate similar to Moore’s Law. Looking toward larger scale quantum machines, we examine a method to increase usable qubit density of quantum machines implementing error correction by using quantum caches that utilize simpler error correction codes. Alternatively, this also allows for the design of reliable systems while meeting the performance and qubit requirements for quantum algorithms. We modify the Qiskit quantum simulation library to work with caches and investigate the effects of region size and topology on the swap characteristics of algorithm execution. We also present our results and discuss recommended topologies for each algorithm. Lastly, we present mix scale-out simulations to examine the impact of cache on future large-scale machines. The default central cache topology gains a maximum performance increase of 2.15 times compared to the worst topology, which creates a robust cache-aware quantum processor layout.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "量子计算已经成为计算机体系结构和信息理论中当前最大的研究领域之一。由于有可能淘汰大量基于因式分解的加密方法，全球各地的公司和政府都在竞相建造第一台大规模量子计算机。目前，大多数量子计算机都是噪音中等规模量子(NISQ)，使用相对较少的不可靠量子位集合。虽然存在纠错方法，但是它们需要大量的辅助量子位来保护数据量子位，这对于在当前的NISQ机器上使用是不实际的。然而，根据道林-内文定律，超导芯片上可用的量子位正以类似摩尔定律的指数速度增长。着眼于更大规模的量子机器，我们研究了一种通过使用利用更简单的纠错码的量子缓存来增加实现纠错的量子机器的可用量子位密度的方法。或者，这也允许设计可靠的系统，同时满足量子算法的性能和量子位要求。我们修改了Qiskit quantum模拟库，使其与缓存一起工作，并研究了区域大小和拓扑对算法执行的交换特征的影响。我们还介绍了我们的结果，并讨论了每种算法推荐的拓扑结构。最后，我们展示了混合横向扩展模拟，以检验缓存对未来大规模机器的影响。与最差的拓扑相比，默认的中央缓存拓扑获得了2.15倍的最大性能提升，从而创建了一个强大的缓存感知量子处理器布局。",
                    "title_zh": "强大的缓存感知量子处理器布局"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00036",
                    "title": "Performance Evaluation of the Impact of NUMA on One-sided RDMA Interactions",
                    "authors": "Jacob Nelson, Roberto Palmieri",
                    "abstract": "Remote direct memory access (RDMA) and non-uniform memory access (NUMA) are critical technologies of modern high-performance computing platforms. RDMA allows nodes to directly access memory on remote machines. Multiprocessor architectures implement NUMA to scale up memory access performance. When paired together, these technologies exhibit performance penalties under certain configurations. This paper is the first study to explore these configurations to provide quantitative findings on the impact of NUMA for RDMA-based systems. One of the consequences of ultra-fast networks is that known implications of NUMA locality now constitute a higher relative impact on the performance of RDMA-enabled distributed systems. Our study quantifies its role and uncovers unexpected behavior. In summary, poor NUMA locality of remotely accessible memory can lead to an automatic 20% performance degradation. Additionally, local workloads operating on remotely accessible memory can lead to 300% performance gap depending on memory locality. Surprisingly, configurations demonstrating this result contradict the presumed impact of NUMA locality. Our findings are validated using two generations of RDMA cards, a synthetic benchmark, and the popular application Memcached ported for RDMA.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "远程直接内存访问(RDMA)和非均匀内存访问(NUMA)是现代高性能计算平台的关键技术。RDMA允许节点直接访问远程机器上的内存。多处理器架构实现了NUMA来提升内存访问性能。当这些技术结合在一起时，在某些配置下会表现出性能损失。本文是第一份探索这些配置的研究，旨在提供NUMA对RDMA系统影响的定量研究结果。超高速网络的后果之一是，NUMA局部性的已知含义现在对支持RDMA的分布式系统的性能构成了更高的相对影响。我们的研究量化了它的作用并揭示了意想不到的行为。总之，远程可访问内存的不良NUMA局部性会导致自动20%的性能下降。此外，在可远程访问的内存上运行的本地工作负载可能会导致300%的性能差距，具体取决于内存位置。令人惊讶的是，显示这一结果的构型与NUMA位置的假定影响相矛盾。我们的发现通过两代RDMA卡、一个合成基准和为RDMA移植的流行应用Memcached得到了验证。",
                    "title_zh": "NUMA对单边RDMA相互作用影响的性能评估"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00037",
                    "title": "Robust P2P Personalized Learning",
                    "authors": "Karim Boubouh, Amine Boussetta, Yahya Benkaouz, Rachid Guerraoui",
                    "abstract": "Decentralized machine learning over peer-to-peer networks is very appealing for it enables to learn personalized models without sharing users data, nor relying on any central server. Peers can improve upon their locally trained model across a network graph of other peers with similar objectives. Whilst they offer an inherently scalable scheme with a very simple cost-efficient learning model, peer-to-peer networks are also fragile. In particular, they can be very easily disrupted by unfairness, free-riding, and adversarial behaviors.In this paper, we present CDPL (Contribution Driven P2P Learning), a novel Byzantine-resilient distributed algorithm to train personalized models across similar peers. We convey theoretically and empirically the effectiveness of CDPL in terms of speed of convergence as well as robustness to Byzantine behavior.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对等网络上的分散式机器学习非常有吸引力，因为它能够在不共享用户数据也不依赖任何中央服务器的情况下学习个性化模型。对等体可以跨越具有相似目标的其他对等体的网络图来改进其本地训练的模型。虽然它们提供了一个具有非常简单的成本效益学习模型的内在可扩展方案，但是对等网络也是脆弱的。特别是，它们很容易被不公平、搭便车和敌对行为破坏。本文提出了CDPL(Contribution Driven P2P Learning ),这是一种新颖的拜占庭弹性分布式算法，用于训练相似节点之间的个性化模型。我们从理论上和经验上传达了CDPL在收敛速度以及对拜占庭行为的鲁棒性方面的有效性。",
                    "title_zh": "鲁棒的P2P个性化学习"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00038",
                    "title": "Towards Efficient, Credible and Privacy-Preserving Service QoS Prediction in Unreliable Mobile Edge Environments",
                    "authors": "Yilei Zhang, Peiyun Zhang, Yonglong Luo, Liya Ji",
                    "abstract": "With the widespread adoption of the fifth-generation (5G) cellular network and Mobile Edge Computing (MEC), numerous Internet of Things (IoT) applications are emerging in many critical areas. IoT applications are typically running on mobile devices to provide real-time interaction with users by connecting with smart IoT devices and remote cloud services. In order to ensure the performance of IoT applications, Quality of Service (QoS) is commonly used as a key metric for the selection and adaptation of high-quality services at runtime. Collaborative QoS prediction methods have been proposed in the literature to predict personalized QoS values, enabling QoS-based selection and adaptation. However, privacy issues in collaborative QoS prediction discourage users from collaborating by sharing data in practice. Furthermore, there are untrusted users in the unreliable MEC environment, which makes the prediction encounter serious reliability issues. As a result, privacy and reliability issues have become key challenges to make QoS prediction approaches feasible. In this paper, we proposed a credible and privacypreserving QoS prediction approach by leveraging federated learning techniques and developing reputation mechanisms to address this critical challenge. We evaluate the method on a large- scale real QoS dataset and the experimental results demonstrate the effectiveness and efficiency of the method.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着第五代(5G)蜂窝网络和移动边缘计算(MEC)的广泛采用，许多物联网(IoT)应用正在许多关键领域涌现。物联网应用通常运行在移动设备上，通过连接智能物联网设备和远程云服务来提供与用户的实时交互。为了保证物联网应用的性能，服务质量(QoS)通常被用作运行时选择和适应高质量服务的关键指标。在文献中已经提出了协作QoS预测方法来预测个性化的QoS值，从而实现基于QoS的选择和适应。然而，协作QoS预测中的隐私问题阻碍了用户在实践中通过共享数据进行协作。此外，在不可靠的MEC环境中存在不可信的用户，这使得预测遇到严重的可靠性问题。因此，隐私和可靠性问题已经成为使QoS预测方法可行的关键挑战。在本文中，我们提出了一个可信的和隐私保护的QoS预测方法，通过利用联合学习技术和开发信誉机制来解决这个关键的挑战。我们在大规模真实QoS数据集上对该方法进行了评估，实验结果表明了该方法的有效性和高效性。",
                    "title_zh": "面向不可靠移动边缘环境中高效、可信和隐私保护的服务QoS预测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00039",
                    "title": "Intrusion-Tolerant and Confidentiality-Preserving Publish/Subscribe Messaging",
                    "authors": "Sisi Duan, Chao Liu, Xin Wang, Yusen Wu, Shuai Xu, Yelena Yesha, Haibin Zhang",
                    "abstract": "We present Chios, an intrusion-tolerant publish/subscribe system which protects against Byzantine failures. Chios is the first publish/subscribe system achieving decentralized confidentiality with fine-grained access control and strong publication order guarantees. This is in contrast to existing publish/subscribe systems achieving much weaker security and reliability properties. Chios is flexible and modular, consisting of four fully-fledged publish/subscribe configurations (each designed to meet different goals). We have deployed and evaluated our system on Amazon EC2. We compare Chios with various publish/subscribe systems. Chios is as efficient as an unreplicated, single-broker publish/subscribe implementation, only marginally slower than Kafka and Kafka with passive replication, and at least an order of magnitude faster than all Hyperledger Fabric modules and publish/subscribe systems using Fabric.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了Chios，一个入侵容忍的发布/订阅系统，它可以防止拜占庭故障。Chios是第一个通过细粒度访问控制和强大的发布顺序保证实现分散机密性的发布/订阅系统。这与现有的发布/订阅系统形成对比，现有的发布/订阅系统实现了弱得多的安全性和可靠性属性。Chios是灵活的、模块化的，由四个完全成熟的发布/订阅配置组成(每个配置都是为满足不同的目标而设计的)。我们已经在Amazon EC2上部署并评估了我们的系统。我们将Chios与各种发布/订阅系统进行了比较。Chios与未复制的、单代理发布/订阅实现一样高效，仅比Kafka和具有被动复制的Kafka稍慢，并且比所有Hyperledger Fabric模块和使用Fabric的发布/订阅系统至少快一个数量级。",
                    "title_zh": "容忍入侵和保密的发布/订阅消息传递"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00040",
                    "title": "Poster: No More Slow Messages: Programmable Packet Handling in Hard IRQ",
                    "authors": "Ko Natori, Takafumi Kikuchi, Kenji Kono",
                    "abstract": "Tail latency in packet handling can easily occur in today’s huge distributed systems. Serious failure can happen if a packet experiences tail latency, especially if that packet is used to manage distributed systems. For example, the delay in heartbeat packets results in unnecessary invocation of recovery procedures, and degrades the overall availability of the system. This poster presents a mechanism that handles critical management packets without any tail latency. It handles critical packets inside hard interrupt request (IRQ) contexts to avoid unexpected delay of packet handling due to resource contention. The code for handling management packets is programmable. To allow the installation of user-defined code, it also provides programmable but safe execution environments. Our experimental results demonstrate our system can reduce 99.9 percentile latency up to 74.7% compared to XDP, a state-of-the-art packet handling system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在当今的大型分布式系统中，数据包处理中的尾部延迟很容易发生。如果数据包经历尾部延迟，特别是如果该数据包用于管理分布式系统，可能会发生严重故障。例如，心跳包的延迟会导致不必要的恢复过程调用，并降低系统的整体可用性。这张海报展示了一种处理关键管理包的机制，没有任何尾部延迟。它处理硬中断请求(IRQ)上下文中的关键数据包，以避免因资源争用而导致数据包处理的意外延迟。用于处理管理包的代码是可编程的。为了允许安装用户定义的代码，它还提供了可编程但安全的执行环境。我们的实验结果表明，与一流的数据包处理系统XDP相比，我们的系统可以将99.9%的延迟降低74.7%。",
                    "title_zh": "海报:不再有慢速消息:硬IRQ中的可编程数据包处理"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00041",
                    "title": "Demo: A Proof-of-Concept Implementation of Guard Secure Routing Protocol",
                    "authors": "Sanaz Taheri Boshrooyeh, Ali Utkan Sahin, Yahya Hassanzadeh-Nazarabadi, Öznur Özkasap",
                    "abstract": "Skip Graphs belong to the family of Distributed Hash Table (DHT) structures that are utilized as routing overlays in various peer-to-peer applications including blockchains, cloud storage, and social networks. In a Skip Graph overlay, any misbehavior of peers during the routing of a query compromises the system functionality. Guard is the first authenticated search mechanism for Skip Graphs, enables reliable search operation in a fully decentralized manner. In this demo paper, we present a proof-of-concept implementation of Guard on Skip Graph nodes as well as a deployment demo scenario.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2007.13212"
                    },
                    "abstract_zh": "跳跃图属于分布式哈希表(DHT)结构家族，在包括区块链、云存储和社交网络的各种对等应用中用作路由覆盖。在Skip Graph overlay中，在查询路由期间，对等体的任何不当行为都会损害系统功能。Guard是第一个用于跳过图的认证搜索机制，能够以完全分散的方式进行可靠的搜索操作。在这篇演示文章中，我们展示了跳过图节点上的Guard的概念验证实现以及一个部署演示场景。",
                    "title_zh": "演示:Guard安全路由协议的概念验证实现"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS51746.2020.00042",
                    "title": "Demo: Skip Graph Middleware Implementation",
                    "authors": "Yahya Hassanzadeh-Nazarabadi, Nazir Nayal, Shadi Sameh Hamdan, Ali Utkan Sahin, Öznur Özkasap, Alptekin Küpçü",
                    "abstract": "Skip Graphs are Distributed Hash Table (DHT)based data structures that are immensely utilized as routing overlays in Peer-to-Peer (P2P) applications. In this demo paper, we present the software architecture of our open-source implementation of Skip Graph middleware in Java. We also present a demo scenario on configuration and constructing an overlay of Skip Graph processes in a fully decentralized manner. Our implementation is capable of hosting data objects at the Skip Graph processes and serving as a P2P data storage platform as well. Our middleware implementation provides an open-source platform to support Skip Graph-based applications on top of it.",
                    "files": {
                        "openAccessPdf": "https://cdm21054.contentdm.oclc.org/digital/api/collection/IR/id/9246/download"
                    },
                    "abstract_zh": "跳跃图是基于分布式哈希表(DHT)的数据结构，在对等(P2P)应用中广泛用作路由覆盖。在这篇演示论文中，我们展示了我们用Java实现的跳过图中间件的开源实现的软件架构。我们还展示了一个配置的演示场景，并以完全分散的方式构建了一个跳过图流程的覆盖图。我们的实现能够在跳图进程中托管数据对象，并且还可以作为P2P数据存储平台。我们的中间件实现提供了一个开源平台来支持基于Skip Graph的应用程序。",
                    "title_zh": "演示:跳过图形中间件实现"
                }
            ]
        }
    ],
    "2019": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2019w.html",
            "conf_title": "38th SRDS 2019: Lyon, France - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8936051/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00008",
                    "title": "On the Impact of log Compaction on Incrementally Checkpointing Stateful Stream-Processing Operators",
                    "authors": "Aris Chronarakis, Antonis Papaioannou, Kostas Magoutis",
                    "abstract": "Incremental checkpointing (IC) is a fault-tolerance technique used in several stateful distributed stream processing systems. It relies on continuously logging state updates to a remote storage service and periodically compacting the update-log via a background process. We highlight a tradeoff between the intensity of compaction of the IC update-log (and the associated resource overhead) and its impact on recovery time in such systems. We also highlight the control parameters that can be used to adjust this tradeoff in the Apache Samza stream processing system, and demonstrate this tradeoff experimentally.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/4637054/files/papaioan_drss19_ic_compactions.pdf"
                    },
                    "abstract_zh": "增量检查点(IC)是一种容错技术，用于多种有状态分布式流处理系统。它依赖于将状态更新连续记录到远程存储服务，并通过后台进程定期压缩更新日志。我们强调IC更新日志的压缩强度(以及相关的资源开销)和它对这种系统中恢复时间的影响之间的权衡。我们还强调了在Apache Samza流处理系统中可以用来调整这种折衷的控制参数，并通过实验演示了这种折衷。",
                    "title_zh": "日志压缩对增量检查点有状态流处理操作符的影响"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00009",
                    "title": "A Case for Dynamically Programmable Storage Background Tasks",
                    "authors": "Ricardo Macedo, Alberto Faria, João Paulo, José Pereira",
                    "abstract": "Modern storage infrastructures feature long and complicated I/O paths composed of several layers, each employing their own optimizations to serve varied applications with fluctuating requirements. However, as these layers do not have global infrastructure visibility, they are unable to optimally tune their behavior to achieve maximum performance. Background storage tasks, in particular, can rapidly overload shared resources, but are executed either periodically or whenever a certain threshold is hit regardless of the overall load on the system. In this paper, we argue that to achieve optimal holistic performance, these tasks should be dynamically programmable and handled by a controller with global visibility. To support this argument, we evaluate the impact on performance of compaction and checkpointing in the context of HBase and PostgreSQL. We find that these tasks can respectively increase 99th percentile latencies by 955.2% and 61.9%. We also identify future research directions to achieve programmable background tasks.",
                    "files": {
                        "openAccessPdf": "http://repositorio.inesctec.pt/bitstreams/0cec7286-3a87-4b9a-a472-d66a49c649cc/download"
                    },
                    "abstract_zh": "现代存储基础架构的特点是由几层组成的长而复杂的I/O路径，每一层都采用自己的优化来满足需求不断变化的各种应用程序。但是，由于这些层不具备全局基础架构可见性，因此它们无法优化其行为以实现最佳性能。特别地，后台存储任务可能会使共享资源迅速过载，但是无论系统的整体负载如何，这些任务都会定期执行，或者在达到某个阈值时执行。在本文中，我们认为，为了实现最佳的整体性能，这些任务应该是动态可编程的，并由具有全局可见性的控制器来处理。为了支持这一论点，我们在HBase和PostgreSQL的上下文中评估了压缩和检查点对性能的影响。我们发现这些任务可以分别增加99%的潜伏期955.2%和61.9%。我们还确定了未来的研究方向，以实现可编程的后台任务。",
                    "title_zh": "动态可编程存储后台任务的案例"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00010",
                    "title": "A Comprehensive Rearranging Priority Based Method To Accelerate the Reconstruction of RAID Arrays",
                    "authors": "Xin Xie, Chentao Wu, Chao Li, Jie Li, Minyi Guo, Fang Xu",
                    "abstract": "With the development of cloud computing, the reliability of disk arrays are increasingly concerned. Data centers usually use erasure codes to provide high reliability. However, most of reconstruction methods on disk arrays focus on single/ multiple disk(s) recovery, which ignores how to efficiently reconstruct the lost data such as Latent Sector Errors (LSEs), etc. In real situations, local stripe errors are much more common than disk failures. It has become an urgent problem that how to improve reconstruction efficiently for stripes. This paper proposes a comprehensive rearranging priority reconstruction(CRPR), which combines temporal locality, spatial locality and coding characteristics together. CRPR divides different blocks into various priorities and recovers them sequentially. To demonstrate the effectiveness of CRPR, we conduct several simulations via disksim. The simulations results show that, the comprehensive rearranging priority reconstruction method keeps up with previous methods and can save up to 63.9% in terms of waiting time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着云计算的发展，磁盘阵列的可靠性越来越受到关注。数据中心通常使用擦除代码来提供高可靠性。然而，大多数磁盘阵列的重建方法都集中在单个/多个磁盘的恢复上，忽略了如何有效地重建潜在扇区错误等丢失数据。在实际情况中，本地条带错误比磁盘故障更常见。如何有效地提高条纹的重建速度已经成为一个亟待解决的问题。该文提出了一种综合重排优先重建(CRPR ),它结合了时间局部性、空间局部性和编码特性。CRPR将不同的块划分为不同的优先级，并按顺序恢复它们。为了证明CRPR的有效性，我们通过disksim进行了几次模拟。仿真结果表明，综合重排优先重建方法与以往方法相比，在等待时间方面可以节省63.9%。",
                    "title_zh": "基于优先级的综合重排方法加速RAID阵列重建"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00011",
                    "title": "Enabling the Efficient, Dependable Cloud-Based Storage of Human Genomes",
                    "authors": "Vinicius Vielmo Cogo, Alysson Bessani",
                    "abstract": "Efficiently storing large data sets of human genomes is a long-term ambition from both the research and clinical life sciences communities. For instance, biobanks stock thousands to millions of biological physical samples and have been under pressure to store also their resulting digitized genomes. However, these and other life sciences institutions lack the infrastructure and expertise to efficiently store this data. Cloud computing is a natural economic alternative to private infrastructures, but it is not as good an alternative in terms of security and privacy. In this work, we present an end-to-end composite pipeline intended to enable the efficient, dependable cloud-based storage of human genomes by integrating three mechanisms we have recently proposed. These mechanisms encompass (1) a privacy-sensitivity detector for human genomes, (2) a similarity-based deduplication and delta-encoding algorithm for sequencing data, and (3) an auditability scheme to verify who has effectively read data in storage systems that use secure information dispersal. By integrating them with appropriate storage configurations, one can obtain reasonable privacy protection, security, and dependability guarantees at modest costs (e.g., less than $1/Genome/Year). Our preliminary analysis indicates that this pipeline costs only 3% more than non-replicated systems, 48% less than fully-replicating all data, and 31% less than secure information dispersal schemes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "有效存储人类基因组的大型数据集是研究和临床生命科学社区的长期目标。例如，生物银行储存了数以千计到数百万计的生物物理样本，并且一直面临着存储由此产生的数字化基因组的压力。然而，这些和其他生命科学机构缺乏有效存储这些数据的基础设施和专业知识。云计算是私有基础设施的自然经济替代方案，但在安全性和隐私性方面，它不是一个好的替代方案。在这项工作中，我们提出了一种端到端的复合管道，旨在通过集成我们最近提出的三种机制来实现人类基因组的高效、可靠的基于云的存储。这些机制包括(1)用于人类基因组的隐私敏感性检测器，(2)用于数据排序的基于相似性的重复数据删除和增量编码算法，以及(3)用于验证谁有效读取了使用安全信息传播的存储系统中的数据的可审核性方案。通过将它们与适当的存储配置集成，可以以适中的成本(例如，低于1美元/基因组/年)获得合理的隐私保护、安全性和可靠性保证。我们的初步分析表明，这种管道的成本仅比非复制系统高3%，比完全复制所有数据低48%，比安全信息传播方案低31%。",
                    "title_zh": "实现高效、可靠的人类基因组云存储"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00012",
                    "title": "TrustFS: An SGX-Enabled Stackable File System Framework",
                    "authors": "Tânia Esteves, Ricardo Macedo, Alberto Faria, Bernardo Portela, João Paulo, José Pereira, Danny Harnik",
                    "abstract": "Data confidentiality in cloud services is commonly ensured by encrypting information before uploading it. However, this approach limits the use of content-aware functionalities, such as deduplication and compression. Although this issue has been addressed individually for some of these functionalities, no unified framework for building secure storage systems exists that can leverage such operations over encrypted data. We present TrustFS, a programmable and modular stackable file system framework for implementing secure content-aware storage functionalities over hardware-assisted trusted execution environments. This framework extends the original SafeFS architecture to provide the isolated execution guarantees of Intel SGX. We demonstrate its usability by implementing an SGX-enabled stackable file system prototype while a preliminary evaluation shows that it incurs reasonable performance overhead when compared to conventional storage systems. Finally, we highlight open research challenges that must be further pursued in order for TrustFS to be fully adequate for building production-ready secure storage solutions.",
                    "files": {
                        "openAccessPdf": "http://repositorio.inesctec.pt/bitstreams/c97a06cb-a5ab-4d26-9f5a-a71bc19afd1c/download"
                    },
                    "abstract_zh": "云服务中的数据机密性通常是通过在上传信息之前对信息进行加密来确保的。但是，这种方法限制了内容感知功能的使用，如重复数据删除和压缩。尽管已经针对这些功能中的一些单独解决了该问题，但是不存在用于构建安全存储系统的统一框架，该框架可以利用对加密数据的这种操作。我们介绍了TrustFS，这是一个可编程和模块化的可堆叠文件系统框架，用于在硬件辅助的可信执行环境中实现安全的内容感知存储功能。该框架扩展了原有的SafeFS架构，以提供SGX的隔离执行保证。我们通过实现支持SGX的可堆叠文件系统原型来展示其可用性，同时初步评估表明，与传统存储系统相比，它会产生合理的性能开销。最后，我们强调了开放的研究挑战，为了使TrustFS完全适用于构建生产就绪的安全存储解决方案，必须进一步应对这些挑战。",
                    "title_zh": "TrustFS:一个支持SGX的可堆叠文件系统框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00013",
                    "title": "A Cost-Effective Cloud Event Archival for SIEMs",
                    "authors": "Adriano Serckumecka, Ibéria Medeiros, Bernardo Ferreira",
                    "abstract": "Security Information and Event Management (SIEM) systems have been adopted by organizations to enable holistic monitoring of malicious activities in their IT infrastructures. SIEMs receive events from diverse devices of the organization's IT infrastructure (e.g., servers, firewalls, IDS), correlate these events, and present reports for security analysts. Given the large number of events collected by SIEMs, it is costly to store such data for long periods. Since organizations store a relatively limited time-frame of events, the forensic analysis capabilities severely become reduced. This concern limits the organizations' ability to store important information about the past cybersecurity-related activity, limiting forensic analysis. A possible solution for this issue is to leverage public cloud storage services, exploiting their low cost and \"infinite\" scalability. We present SLiCER an archival system for long-term storage that makes use of a multi-cloud-based storage system to guarantee data security and ensures cost-effectiveness by grouping events in blocks and using indexing techniques to recover them. The system was evaluated using a real dataset and the results show that it is significantly more cost-efficient than competing alternatives.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "组织已经采用安全信息和事件管理(SIEM)系统来实现对其IT基础架构中的恶意活动的整体监控。SIEMs从组织的IT基础架构的各种设备(例如，服务器、防火墙、IDS)接收事件，关联这些事件，并为安全分析师提供报告。鉴于SIEMs收集了大量事件，长期存储此类数据的成本很高。由于组织存储的事件时间范围相对有限，因此取证分析能力严重下降。这种担心限制了组织存储有关过去网络安全相关活动的重要信息的能力，从而限制了取证分析。这个问题的一个可能的解决方案是利用公共云存储服务，利用它们的低成本和“无限”可扩展性。我们提出了SLiCER，这是一个用于长期存储的存档系统，它利用基于多种云的存储系统来保证数据安全，并通过将事件分组到块中并使用索引技术来恢复它们来确保成本效益。使用真实数据集对该系统进行了评估，结果显示该系统比竞争对手的系统更具成本效益。",
                    "title_zh": "面向SIEMs的经济高效的云事件归档"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00014",
                    "title": "Evaluation and Ranking of Replica Deployments in Geographic State Machine Replication",
                    "authors": "Shota Numakura, Junya Nakamura, Ren Ohmura",
                    "abstract": "Geographic state machine replication (SMR) is a replication method in which replicas of a service are located on multiple continents to improve the fault tolerance of a general service. Nowadays, geographic SMR is easily realized using public cloud services; SMR provides extraordinary resilience against catastrophic disasters. Previous studies have revealed that the geographic distribution of the replicas has a significant influence on the performance of the geographic SMR; however, the optimal way for a system integrator to deploy replicas remains unknown. In this paper, we propose a method to evaluate and rank replica deployments to assist a system integrator in deciding a final replica deployment. In the method, we also propose a novel evaluation function that estimates a latency of SMR protocols with round-trip time (RTT). To demonstrate the effectiveness of the proposed method, we build thousands of geographic SMRs on Amazon Web Services and present experimental results. The results show that the proposed method that estimates a latency based on RTTs can generate consistent rankings with reasonable calculation time.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2110.04615"
                    },
                    "abstract_zh": "地理状态机复制(SMR)是一种复制方法，其中服务的副本位于多个大陆上，以提高一般服务的容错能力。如今，利用公共云服务可以轻松实现地理SMR；SMR提供了应对灾难性灾难的非凡恢复能力。先前的研究表明，副本的地理分布对地理SMR的性能有显著影响；然而，系统集成商部署副本的最佳方式仍然未知。在本文中，我们提出了一种评估和排序副本部署的方法，以帮助系统集成商决定最终的副本部署。在该方法中，我们还提出了一种新的评估函数，该函数估计具有往返时间(RTT)的SMR协议的延迟。为了证明所提出方法的有效性，我们在Amazon Web Services上建立了数千个地理SMR并给出了实验结果。结果表明，所提出的基于RTTs的延迟估计方法能够以合理的计算时间生成一致的排序。",
                    "title_zh": "地理状态机复制中副本部署的评估和排序"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00015",
                    "title": "Pooled Mining is Driving Blockchains Toward Centralized Systems",
                    "authors": "Liuyang Ren, Paul A. S. Ward",
                    "abstract": "The decentralization property of blockchains stems from the fact that each miner accepts or refuses transactions and blocks based on its own verification results. However, pooled mining causes blockchains to evolve into centralized systems because pool participants delegate their decision-making rights to pool managers. In this paper, we established and validated a model for Proof-of-Work mining, introduced the concept of equivalent blocks, and quantitatively derived that pooling effectively lowers the income variance of miners. We also analyzed Bitcoin and Ethereum data to prove that pooled mining has become prevalent in the real world. The percentage of pool-mined blocks increased from 49.91% to 91.12% within four months in Bitcoin and from 76.9% to 92.2% within five months in Ethereum. In July 2018, Bitcoin and Ethereum mining were dominated by only six and five pools respectively.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "区块链的分散化属性源于这样一个事实，即每个矿工根据自己的核查结果接受或拒绝交易和封锁。然而，联营采矿导致区块链演变成集中系统，因为联营参与者将其决策权委托给联营管理者。在本文中，我们建立并验证了一个工作证据挖掘模型，引入了等价区块的概念，并定量推导出联营有效地降低了矿工的收入方差。我们还分析了比特币和以太坊数据，以证明池化挖掘在现实世界中已经普遍存在。在比特币中，四个月内池挖掘块的百分比从49.91%增加到91.12%，在以太坊中，五个月内从76.9%增加到92.2%。2018年7月，比特币和以太坊挖矿分别只有6个和5个池主导。",
                    "title_zh": "联营采矿正推动区块链走向中央集权制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00016",
                    "title": "Forkmon: Monitoring the Networks Supporting Bitcoin Hard Forks",
                    "authors": "Thiago Luiz Gontijo de Almeida, Pierre Francois, Stéphane Frénot",
                    "abstract": "In this article, we shed light on the peer-to-peer networks which support public blockchains stemming from Bitcoin forks. While the Bitcoin network has undergone a lot of attention, little has been discovered on the size, geographical spread, and general dependability of the networks supporting such forks. In this paper, we first discuss the various types of Bitcoin forks. We identify the case of hard forks which essentially consist in independent crypto-currencies that become completely separated from the reference Bitcoin network. We present a set of tools that are used to gather information on the Bitcoin forks networks. Finally, we provide preliminary analysis results regarding the size, IP layer localization, concentration, and overlap of ten Bitcoin forks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们揭示了支持源于比特币分叉的公共区块链的对等网络。虽然比特币网络受到了很多关注，但对支持这种分支的网络的规模、地理分布和总体可靠性却鲜有发现。在本文中，我们首先讨论比特币分叉的各种类型。我们确定了硬分叉的情况，它本质上是独立的加密货币，与参考比特币网络完全分离。我们展示了一套用于收集比特币分叉网络信息的工具。最后，我们提供了关于十个比特币分叉的大小、IP层本地化、集中度和重叠的初步分析结果。",
                    "title_zh": "Forkmon:监控支持比特币硬分叉的网络"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW49218.2019.00017",
                    "title": "Towards A Unified Programming Model for Blockchain Smart Contract dApp Systems",
                    "authors": "Joshua Ellul, Gordon J. Pace",
                    "abstract": "Developing smart contract decentralised application based systems typically involves writing code for various platforms, from the smart contract code residing on the underlying distributed ledger technology implementation to back end oracles and front end websites or mobile apps. In addition to the different technologies used for the different parts, the programmer is also burdened with implementing communication channels between the various parts. In this paper we propose a unified programming model allowing for developers to build such systems through a single code artifact, using a macroprogramming approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "开发基于智能合约分散应用的系统通常涉及为各种平台编写代码，从驻留在底层分布式账本技术实现上的智能合约代码到后端oracles和前端网站或移动应用。除了用于不同部分的不同技术之外，程序员还负担着实现不同部分之间的通信信道。在本文中，我们提出了一个统一的编程模型，允许开发人员使用宏编程方法，通过单个代码工件来构建这样的系统。",
                    "title_zh": "面向区块链智能合约dApp系统的统一编程模型"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2019.html",
            "conf_title": "38th SRDS 2019: Lyon, France",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/9036730/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00011",
                    "title": "P3LS: Plausible Deniability for Practical Privacy-Preserving Live Streaming",
                    "authors": "Jérémie Decouchant, Antoine Boutet, Jiangshan Yu, Paulo Jorge Esteves Veríssimo",
                    "abstract": "Video consumption is one of the most popular Internet activities worldwide. The emergence of sharing videos directly recorded with smartphones raises important privacy concerns. In this paper we propose P3LS, the first practical privacy-preserving peer-to-peer live streaming system. To protect the privacy of its users, P3LS relies on k-anonymity when users subscribe to streams, and on plausible deniability for the dissemination of video streams. Specifically, plausible deniability during the dissemination phase ensures that an adversary is never able to distinguish a user's stream of interest from the fake streams from a statistical analysis (i.e., using an analysis of variance). We exhaustively evaluate P3LS and show that adversaries are not able to identify the real stream of a user with very high confidence. Moreover, P3LS consumes 30% less bandwidth than the standard k-anonymity approach where nodes fully contribute to the dissemination of k streams.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-02421820/file/SRDS_2019_paper_10%283%29.pdf"
                    },
                    "abstract_zh": "视频消费是全球最受欢迎的互联网活动之一。用智能手机直接录制的共享视频的出现引发了重要的隐私问题。在本文中，我们提出了P3LS，第一个实用的隐私保护点对点直播系统。为了保护其用户的隐私，P3LS在用户订阅流时依赖于k-匿名，并在视频流传播时依赖于可信的可否认性。具体而言，在传播阶段的似是而非的可否认性确保了对手永远无法从统计分析(即，使用方差分析)中区分用户的兴趣流和虚假流。我们对P3LS进行了详尽的评估，结果表明对手无法以非常高的置信度识别用户的真实流。此外，P3LS消耗的带宽比标准k-匿名方法少30%，在标准k-匿名方法中，节点完全有助于k个流的传播。",
                    "title_zh": "P3LS:实用隐私保护直播流的似是而非的可否认性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00012",
                    "title": "Fuzzing IPC with Knowledge Inference",
                    "authors": "Kun Yang, Hanqing Zhao, Chao Zhang, Jianwei Zhuge, Haixin Duan",
                    "abstract": "Sandboxing provides a strong security guarantee for applications, by isolating untrusted code into separated compartments. Untrusted code could only use IPC (inter-process communication) to launch sensitive actions, which are implemented in trusted (and maybe privileged) code. IPC-related security bugs in trusted code could facilitate jailbreaks of sandboxing, and thus are becoming high-value targets. However, finding vulnerabilities that could be triggered by IPC is challenging, due to the fact that IPC communication is stateful and format-sensitive. In this paper, we propose a new fuzzing solution to discover IPC bugs in IPC services without source code, by combining static analysis and dynamic analysis. We use static analysis to recognize format checks and help construct IPC messages of valid formats. We then use dynamic analysis to infer the constraints between IPC messages, and model the stateful logic with a probability matrix. Therefore, we are able to generate high-quality IPC messages to test IPC services, and discover deep and complex IPC bugs. Without loss of generality, we implemented a prototype MachFuzzer, for a specific complicated and crucial IPC service, i.e., WindowServer in macOS. This prototype helps us find 12 previously unknown vulnerabilities in WindowServer in 48 hours. Among them, three vulnerabilities are confirmed exploitable, and could be exploited to escape the sandbox and gain root privilege.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "沙盒通过将不受信任的代码隔离到不同的隔离舱中，为应用程序提供了强大的安全保证。不受信任的代码只能使用IPC(进程间通信)来启动敏感的操作，这些操作在受信任的(也可能是有特权的)代码中实现。可信代码中与IPC相关的安全缺陷可能有助于沙盒的越狱，因此成为高价值的目标。然而，由于IPC通信是有状态的和对格式敏感的，因此发现可能由IPC触发的漏洞是具有挑战性的。本文提出了一种新的模糊化解决方案，通过结合静态分析和动态分析，在没有源代码的情况下发现IPC服务中的IPC错误。我们使用静态分析来识别格式检查，并帮助构建有效格式的IPC消息。然后，我们使用动态分析来推断IPC消息之间的约束，并用概率矩阵来建模有状态逻辑。因此，我们能够生成高质量的IPC消息来测试IPC服务，并发现深层和复杂的IPC错误。不失一般性，我们实现了一个原型MachFuzzer，用于一个特定的复杂和关键的IPC服务，即macOS中的WindowServer。这个原型帮助我们在48小时内找到了WindowServer中12个以前未知的漏洞。其中，有三个漏洞已被确认为可被利用，可被利用来逃离沙箱并获得root权限。",
                    "title_zh": "用知识推理模糊IPC"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00013",
                    "title": "Anonymous and Confidential File Sharing over Untrusted Clouds",
                    "authors": "Stefan Contiu, Sébastien Vaucher, Rafael Pires, Marcelo Pasin, Pascal Felber, Laurent Réveillère",
                    "abstract": "Using public cloud services for storing and sharing confidential data requires end users to cryptographically protect both the data and the access to the data. In some cases, the identity of end users needs to remain confidential against the cloud provider and fellow users accessing the data. As such, the underlying cryptographic access control mechanism needs to ensure the anonymity of both data producers and consumers. We introduce A-SKY, a cryptographic access control extension capable of providing confidentiality and anonymity guarantees, all while efficiently scaling to large organizations. A-SKY leverages trusted execution environments (TEEs) to address the impracticality of anonymous broadcast encryption (ANOBE) schemes, achieving faster execution times and shorter ciphertexts. The innovative design of A-SKY limits the usage of the TEE to the narrow set of data producing operations, and thus optimizes the dominant data consumption actions by not requiring a TEE. Furthermore, we propose a scalable implementation for A-SKY leveraging micro-services that preserves strong security guarantees while being able to efficiently manage realistic large user bases. Results highlight that the A-SKY cryptographic scheme is 3 orders of magnitude better than state of the art ANOBE, and an end-to-end system encapsulating A-SKY can elastically scale to support groups of 10000 users while maintaining processing costs below 1 second.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1907.06466"
                    },
                    "abstract_zh": "使用公共云服务存储和共享机密数据要求最终用户对数据和数据访问进行加密保护。在某些情况下，最终用户的身份需要对访问数据的云提供商和其他用户保密。因此，底层加密访问控制机制需要确保数据生产者和消费者的匿名性。我们引入了A-SKY，这是一种加密访问控制扩展，能够提供机密性和匿名性保证，同时能够高效地扩展到大型组织。A-SKY利用可信执行环境(TEEs)来解决匿名广播加密(ANOBE)方案的不可行性，从而实现更快的执行时间和更短的密文。A-SKY的创新设计将TEE的使用限制在狭窄的数据生成操作集，从而通过不需要TEE来优化主要的数据消费操作。此外，我们为A-SKY提出了一个利用微服务的可扩展实现，它保留了强大的安全保证，同时能够有效地管理现实的大型用户群。结果突出表明，A-SKY加密方案比最先进的ANOBE方案好3个数量级，封装A-SKY的端到端系统可以弹性扩展以支持10000个用户的组，同时保持处理成本低于1秒。",
                    "title_zh": "通过不受信任的云共享匿名和机密文件"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00014",
                    "title": "Preacher: Network Policy Checker for Adversarial Environments",
                    "authors": "Kashyap Thimmaraju, Liron Schiff, Stefan Schmid",
                    "abstract": "Private networks are typically assumed to be trusted as security mechanisms are usually deployed on hosts and the data plane is managed in-house. The increasing number of attacks on network devices, and recent reports on backdoors, forces us to revisit existing security assumptions and demands new approaches to detect malicious activity. This paper presents Preacher, a runtime network policy checker, which leverages a secure, redundant and adaptive sample distribution scheme that allows us to provably detect and localize adversarial switches or routers trying to reroute, mirror, drop, inject, or modify packets (i.e., header and/or payload) even under collusion. The analysis performed by Preacher is highly parallelizable. We show that emerging programmable networks provide an ideal vehicle to detect suspicious network activity. Furthermore, we analytically and empirically evaluate the effectiveness of our approach in different adversarial settings, report on a proof-of-concept implementation using ONOS, and provide insights into the resource and performance overheads of Preacher.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "私有网络通常被认为是可信的，因为安全机制通常部署在主机上，并且数据平面由内部管理。越来越多的网络设备攻击和最近的后门报告迫使我们重新审视现有的安全假设，并要求新的方法来检测恶意活动。本文介绍了一种运行时网络策略检查器，它利用一种安全、冗余和自适应的样本分布方案，允许我们可证明地检测和定位试图重新路由、镜像、丢弃、注入或修改分组(即报头和/或有效载荷)的敌对交换机或路由器，即使在共谋的情况下也是如此。由布道者执行的分析是高度并行的。我们表明，新兴的可编程网络提供了一个理想的工具来检测可疑的网络活动。此外，我们通过分析和经验评估了我们的方法在不同对抗环境中的有效性，报告了使用ONOS的概念验证实施，并提供了对传教士的资源和性能开销的见解。",
                    "title_zh": "传教士:敌对环境下的网络策略检查器"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00015",
                    "title": "Architecture and Prototype Implementation for Process-Aware Intrusion Detection in Electrical Grids",
                    "authors": "Robert Flosbach, Justyna Joanna Chromik, Anne Remke",
                    "abstract": "Supervisory Control and Data Acquisition (SCADA) systems monitor and control electric power distribution. Recent history has shown that cyber-attacks pose a tremendous risk for the economy and safety of modern countries. This paper introduces an architecture and a prototype implementation for a process-aware, network-based Intrusion Detection System (IDS) to secure control networks in the domain of power distribution. Based on a recently proposed process model, the system continuously assesses the local physical process and all control commands with regard to consistency and safety of the underlying physical process. Its detection capabilities focus on process-based attacks like manipulated control commands, which appear legitimate to traditional IDS but might nevertheless have devastating effects on the power distribution. The architecture separates the evaluation part from the traffic processing, which ensures extensibility and scalability. The developed implementation has been successfully tested at a Dutch power distribution substation. Its detection performance is characterized by a very low miss rate and high precision.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "监控和数据采集(SCADA)系统监测和控制电力分配。最近的历史表明，网络攻击对现代国家的经济和安全构成了巨大的风险。本文介绍了一个基于网络的过程感知入侵检测系统(IDS)的架构和原型实现，以保护配电领域的控制网络。基于最近提出的过程模型，该系统不断地评估本地物理过程和所有控制命令的一致性和底层物理过程的安全性。它的检测能力侧重于基于过程的攻击，如操纵控制命令，这对于传统的IDS来说似乎是合法的，但却可能对配电产生毁灭性的影响。该架构将评估部分从流量处理中分离出来，确保了可扩展性和可伸缩性。开发的实现已经在荷兰配电变电站成功测试。其检测性能的特点是非常低的漏检率和高精度。",
                    "title_zh": "电网中过程感知入侵检测的体系结构和原型实现"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00016",
                    "title": "Supply Chain Malware Targets SGX: Take Care of what you Sign",
                    "authors": "Andrei Mogage, Rafael Pires, Vlad Cracium, Emanuel Onica, Pascal Felber",
                    "abstract": "Malware attacks represent a significant part of today's security threats. Software guard extensions (SGX) are a set of hardware instructions introduced by Intel in their recent lines of processors that are intended to provide a secure execution environment for user-developed applications. To our knowledge, there was no serious attempt yet to overcome the SGX protection by leveraging the software supply chain infrastructure, such as weaknesses in the development, build or signing servers. While SGX protection does not specifically take into consideration such threats, we show in the current paper that a simple malware attack exploiting a separation between the build and signing processes can have a serious damaging impact, practically nullifying the SGX integrity protection measures. Finally, we also suggest some possible mitigations against the attack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "恶意软件攻击是当今安全威胁的重要组成部分。软件保护扩展(SGX)是英特尔在其最新处理器系列中推出的一组硬件指令，旨在为用户开发的应用提供安全的执行环境。据我们所知，还没有人试图通过利用软件供应链基础设施(如开发、构建或签名服务器中的弱点)来克服SGX保护。虽然SGX保护没有特别考虑这种威胁，但我们在当前的论文中表明，利用构建和签名过程之间的分离的简单恶意软件攻击可以产生严重的破坏性影响，实际上使SGX完整性保护措施无效。最后，我们还提出了一些可能的攻击缓解措施。",
                    "title_zh": "供应链恶意软件瞄准SGX:小心你签的东西"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00017",
                    "title": "d'Artagnan: A Trusted NoSQL Database on Untrusted Clouds",
                    "authors": "Rogério Pontes, Francisco Maia, Ricardo Vilaça, Nuno Machado",
                    "abstract": "Privacy sensitive applications that store confidential information such as personal identifiable data or medical records have strict security concerns. These concerns hinder the adoption of the cloud. With cloud providers under the constant threat of malicious attacks, a single successful breach is sufficient to exploit any valuable information and disclose sensitive data. Existing privacy-aware databases mitigate some of these concerns, but sill leak critical information that can potently compromise the entire system's security. This paper proposes d'Artagnan, the first privacy-aware multi-cloud NoSQL database framework that renders database leaks worthless. The framework stores data as encrypted secrets in multiple clouds such that i) a single data breach cannot break the database's confidentiality and ii) queries are processed on the server-side without leaking any sensitive information. d'Artagnan is evaluated with industry-standard benchmark on market-leading cloud providers.",
                    "files": {
                        "openAccessPdf": "https://repositorium.sdum.uminho.pt/bitstream/1822/66217/1/srds19-rpontes.pdf"
                    },
                    "abstract_zh": "存储个人可识别数据或医疗记录等机密信息的隐私敏感应用程序有严格的安全顾虑。这些顾虑阻碍了云的采用。由于云提供商不断受到恶意攻击的威胁，一次成功的入侵就足以利用任何有价值的信息并泄露敏感数据。现有的隐私感知数据库减轻了这些担忧，但仍然会泄漏关键信息，从而潜在地危及整个系统的安全。本文提出了d'Artagnan，第一个隐私感知的多云NoSQL数据库框架，使数据库泄漏变得毫无价值。该框架将数据作为加密的秘密存储在多个云中，从而I)单个数据泄露不会破坏数据库的机密性，ii)查询在服务器端处理，而不会泄漏任何敏感信息。达达尼昂通过市场领先的云提供商的行业标准基准进行评估。",
                    "title_zh": "达达尼昂:不可信云上的可信NoSQL数据库"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00018",
                    "title": "Gyro: A Modular Scale-Out Layer for Single-Server DBMSs",
                    "authors": "Habib Saissi, Marco Serafini, Neeraj Suri",
                    "abstract": "Scaling out database management systems (DBMSs) requires distributed coordination, which can easily become a bottleneck. Recent work on speeding up distributed transactions has addressed this problem by proposing scale-out techniques that are deeply integrated with the concurrency control mechanism of the DBMS. This paper explores the design of modular coordination layers, which encapsulate all scale-out logic and can be applied to scale out any unmodified single-server DBMS. It proposes Gyro, a modular coordination layer that runs on top of a collection of single-server DBMS instances and interacts with them only through their client interface. Gyro distributes the load by ensuring that as many requests as possible are executed by only one DBMS instance. Our experiments show that modular distributed coordination is practically viable and that it can be much faster than traditional distributed transaction protocols using two-phase commit.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "向外扩展数据库管理系统(DBMSs)需要分布式协调，这很容易成为瓶颈。最近关于加速分布式事务的工作通过提出与DBMS的并发控制机制深度集成的向外扩展技术解决了这个问题。本文探讨了模块化协调层的设计，它封装了所有的横向扩展逻辑，可以应用于任何未经修改的单服务器DBMS的横向扩展。它提出了Gyro，这是一个模块化的协调层，运行在单服务器DBMS实例的集合之上，只通过它们的客户端接口与它们进行交互。Gyro通过确保尽可能多的请求仅由一个DBMS实例执行来分配负载。我们的实验表明，模块化分布式协调实际上是可行的，并且它可以比使用两阶段提交的传统分布式事务协议快得多。",
                    "title_zh": "Gyro:用于单服务器DBMSs的模块化横向扩展层"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00019",
                    "title": "Fulva: Efficient Live Migration for In-Memory Key-Value Stores with Zero Downtime",
                    "authors": "Jiewen Hai, Cheng Wang, Xusheng Chen, Tsz On Li, Heming Cui, Sen Wang",
                    "abstract": "A key-value store live migration approach migrates key-value tuples and their client requests from an overloaded machine (source) to an idle machine (destination), while still serving client requests. Existing migration approaches fall into two categories. First, a source-driven approach (e.g., DrTM-B) executes all client requests on the source and incrementally propagates the updated key-value tuples to the destination. This approach has an inevitable downtime to completely propagate the updated tuples at the end of a migration. Second, a destination-driven approach (e.g., RockSteady) executes all read and write requests on the destination, and pulls tuples from source for read requests on-demand. This approach has zero downtime, but incurs extra network round-trips due to the on-demand pull, greatly increasing request latency. Overall, a live migration approach that has zero downtime and no performance degradation during the migration is highly desirable but missing. The key observation of our Fulva system is that the source and destination can cooperatively drive the migration and serve requests, and we need only to design an efficient protocol to ensure linearizability (i.e., reads see the updates from the latest writes). To this end, when a migration starts, Fulva works by three steps. First, all write requests are redirected to the destination. Second, each client program uses a Fulva's RPC library to track the migration progress. For read requests accessing the already-migrated tuples, Fulva RPC library sends the requests to the destination. Third, for read requests accessing not-yet-migrated tuples, Fulva sends to both machines. The first step avoids downtime because all updated tuples are already on the destination. The second and third steps avoid the on-demand pull and ensure linearizability, making Fulva efficient. We implemented Fulva using DPDK and integrated it with RAMCloud, a popular in-memory key-value store. We compared Fulva with two notable systems, RockSteady (destination-driven approach) and RAMCloud's default source-driven approach. Extensive evaluation shows that Fulva had much higher throughput and lower latency than the two systems, and Fulva's network bandwidth usage is comparable with RockSteady. All Fulva's source code and raw evaluation results are released on github.com/hku-systems/fulva.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "键值存储实时迁移方法将键值元组及其客户端请求从过载的机器(源)迁移到空闲的机器(目的地)，同时仍然服务于客户端请求。现有的迁移方法分为两类。首先，源驱动的方法(例如，DrTM-B)在源上执行所有客户端请求，并递增地将更新的键值元组传播到目的地。在迁移结束时，这种方法不可避免地要停机才能完全传播更新的元组。第二，目的地驱动的方法(例如，RockSteady)在目的地上执行所有读和写请求，并且按需从源拉取读请求的元组。这种方法没有停机时间，但由于按需拉取，会导致额外的网络往返，大大增加了请求延迟。总的来说，在迁移过程中零宕机和无性能下降的实时迁移方法是非常理想的，但却是缺失的。我们的Fulva系统的主要观察结果是，源和目的地可以合作驱动迁移和服务请求，我们只需要设计一个有效的协议来确保线性化(即，读取看到来自最新写入的更新)。为此，当迁移开始时，Fulva通过三个步骤工作。首先，所有写请求都被重定向到目标。其次，每个客户端程序都使用Fulva的RPC库来跟踪迁移进度。对于访问已经迁移的元组的读请求，Fulva RPC库将请求发送到目的地。第三，对于访问尚未迁移的元组的读请求，Fulva发送到两台机器。第一步避免了停机时间，因为所有更新的元组都已经在目的地上。第二步和第三步避免了按需拉动，并确保了线性化，使Fulva高效。我们使用DPDK实现了Fulva，并将其与RAMCloud(一种流行的内存键值存储)集成。我们将Fulva与两个著名的系统进行了比较，RockSteady(目的地驱动方法)和RAMCloud的默认源驱动方法。广泛的评估表明，Fulva比这两个系统具有更高的吞吐量和更低的延迟，Fulva的网络带宽使用率与RockSteady相当。Fulva的所有源代码和原始评估结果都在github.com/hku-systems/fulva.上发布",
                    "title_zh": "Fulva:内存中键值存储的高效实时迁移，零宕机"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00020",
                    "title": "ESCAPe: Elastic Caching For Big Data Systems",
                    "authors": "Thanasis Priovolos, Stathis Maroulis, Vana Kalogeraki",
                    "abstract": "In recent years, in-memory cache systems have been commonly utilized to help maintain low application response times, compared to traditional relational databases, where the data items are stored in disk drives. Although cache memory systems offer improved performance, running everything in memory might not be cost-effective. In this paper, we present ESCAPe, an elastic high throughput and low latency key-value in-memory cache system. Unlike existing schemes, ESCAPe offers an elastic mechanism that proactively adds or removes nodes to scale-down or scale-up to meet fluctuating application demands, and incorporates a dynamic redistribution scheme that prioritizes the distribution of the keys at the nodes, while keeping the overhead cost as low as possible. We have evaluated our approach in a real cluster, using ESCAPe as the memcache system for Web Applications using different workload traces and comparing our approach with state of the art schemes. Our results illustrate that ESCAPe is able to select the most useful items to keep in memory, significantly reducing the end-to-end latency experienced by the applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，与数据项存储在磁盘驱动器中的传统关系数据库相比，内存缓存系统已被普遍用于帮助维持较低的应用程序响应时间。尽管高速缓存系统提供了改进的性能，但是在内存中运行所有的东西可能不划算。在本文中，我们提出了ESCAPe，一个弹性的高吞吐量和低延迟的键值内存缓存系统。与现有的方案不同，ESCAPe提供了一种灵活的机制，可以主动添加或删除节点来缩小或扩大规模，以满足不断变化的应用程序需求，并结合了一种动态重新分配方案，该方案对节点上的密钥分配进行优先排序，同时尽可能降低开销成本。我们在一个真实的集群中评估了我们的方法，使用ESCAPe作为Web应用程序的memcache系统，使用不同的工作负载跟踪，并将我们的方法与最先进的方案进行比较。我们的结果表明，ESCAPe能够选择最有用的项目保存在内存中，从而显著减少应用程序经历的端到端延迟。",
                    "title_zh": "ESCAPe:大数据系统的弹性缓存"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00021",
                    "title": "BISEN: Efficient Boolean Searchable Symmetric Encryption with Verifiability and Minimal Leakage",
                    "authors": "Bernardo Ferreira, Bernardo Portela, Tiago Oliveira, Guilherme Borges, Henrique João L. Domingos, João Leitão",
                    "abstract": "The prevalence and availability of cloud infrastructures has made them the de facto solution for storing and archiving data, both for organizations and individual users. Nonetheless, the cloud's wide spread adoption is still hindered by dependability and security concerns, particularly in applications with large data collections where efficient search and retrieval services are also major requirements. This leads to an increased tension between security, efficiency, and search expressiveness, which current state of the art solutions try to balance through complex cryptographic protocols that tradeoff efficiency and expressiveness for near optimal security. In this paper we tackle this tension by proposing BISEN, a new provably-secure boolean searchable symmetric encryption scheme that improves these three complementary dimensions by exploring the design space of isolation guarantees offered by novel commodity hardware such as Intel SGX, abstracted as Isolated Execution Environments (IEEs). BISEN is the first scheme to enable highly expressive and arbitrarily complex boolean queries, with minimal information leakage regarding performed queries and accessed data, and verifiability regarding fully malicious adversaries. Furthermore, by exploiting trusted hardware and the IEE abstraction, BISEN reduces communication costs between the client and the cloud, boosting query execution performance. Experimental validation and comparison with the state of art shows that BISEN provides better performance with enriched search semantics and security properties.",
                    "files": {
                        "openAccessPdf": "http://repositorio.inesctec.pt/bitstreams/dfe68b7c-b271-4f81-ae15-479ce9b8cc3e/download"
                    },
                    "abstract_zh": "云基础设施的普及和可用性使其成为组织和个人用户存储和归档数据的事实上的解决方案。尽管如此，云的广泛采用仍然受到可靠性和安全性问题的阻碍，特别是在具有大量数据收集的应用程序中，高效的搜索和检索服务也是主要需求。这导致安全性、效率和搜索表达性之间的紧张关系增加，当前技术水平的解决方案试图通过复杂的密码协议来平衡这种紧张关系，所述复杂的密码协议为了接近最优的安全性而折衷效率和表达性。在本文中，我们通过提出一种新的可证明安全的布尔可搜索对称加密方案BISEN来解决这一矛盾，该方案通过探索由新型商用硬件(如SGX)提供的隔离保证的设计空间来改进这三个互补维度，抽象为隔离执行环境(IEEs)。BISEN是第一个支持高度表达和任意复杂布尔查询的方案，具有关于执行的查询和访问的数据的最小信息泄漏，以及关于完全恶意对手的可验证性。此外，通过利用可信硬件和IEE抽象，BISEN降低了客户端和云之间的通信成本，提高了查询执行性能。实验验证和与现有技术的比较表明，BISEN提供了更好的性能，丰富了搜索语义和安全属性。",
                    "title_zh": "BISEN:具有可验证性和最小泄漏的高效布尔可搜索对称加密"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00022",
                    "title": "Fault Tolerant High Performance Solver for Linear Equation Systems",
                    "authors": "Marcello Artioli, Daniela Loreti, Anna Ciampolini",
                    "abstract": "The ever-increasing size of High Performance Computing (HPC) systems inevitably causes an unwanted decrease of Mean Time Between Failures (MTBF). For this reason, over the last decade, much work has been done on the topic of fault tolerance for supercomputers. In particular, as large-scale linear algebra applications permeate many scientific fields, important efforts have been focused on the performance enhancements that could be provided by HPC infrastructures if reliable fault tolerant solutions are adopted. This article explores a popular topic of linear algebra (i.e., linear equation system resolution) and proposes an efficient, error-resilient approach based on an existing technique called Inhibition Method (IMe). Initially conceived to analyse complex electric circuits and later extended to solve linear systems, the original method is here enhanced with a simple, yet effective strategy to provide tolerance to single fail-stop recurring to neither checkpointing, nor rollbacks. Experimental results on a medium-scale HPC architecture show negligible overheads and promising performance improvements when compared with a popular fault-tolerant solving technique.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高性能计算(HPC)系统规模的不断增长不可避免地导致平均无故障时间(MTBF)的减少。由于这个原因，在过去的十年里，人们对超级计算机的容错性做了大量的工作。特别是，随着大规模线性代数应用渗透到许多科学领域，如果采用可靠的容错解决方案，HPC基础架构可以提供的性能增强已经成为重要的研究重点。本文探讨了线性代数的一个热门话题(即线性方程组求解)，并提出了一种基于现有技术(称为抑制方法(IMe ))的高效、容错方法。最初设想用于分析复杂的电路，后来扩展到解决线性系统，原始方法在这里用一个简单而有效的策略进行了增强，以提供对既不是检查点也不是回滚的单一故障停止的容限。在中等规模HPC架构上的实验结果表明，与流行的容错求解技术相比，开销可以忽略不计，性能有望提高。",
                    "title_zh": "线性方程组的容错高性能求解器"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00023",
                    "title": "DBFT: A Byzantine Fault Tolerant Protocol with Graceful Performance Degradation",
                    "authors": "Jingjing Zhang, Yingyao Rong, Jiannong Cao, Chunming Rong, Jing Bian, Weigang Wu",
                    "abstract": "The surging interest in blockchain has revitalized the search for efficient Byzantine fault-tolerant (BFT) protocols, which are used for blockchains to achieve consensus among replicated data blocks. Most existing BFT protocols perform well in fault-free cases, but they usually suffer from serious performance degradation when faults occur. In this paper, we present DBFT, a BFT protocol that realizes graceful performance degradation in normal cases. The major novelty of DBFT lies in the double-response mechanism, which lets replica nodes deterministically respond to clients twice: one is after the speculative execution phase and the other is after the commitment phase. The double-response mechanism can handle inconsistency in speculative execution, so as to alleviate performance degradation caused by faults. Moreover, DBFT does not involve clients in critical consensus operations so as to reduce the load of clients. The correctness properties, i.e., safety and liveness, of DBFT is rigorously proved. The performance of DBFT is evaluated via experiments and the results show that, DBFT outperforms similar BFT protocols obviously in normal cases.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "人们对区块链的兴趣日益高涨，这促使人们重新寻找高效的拜占庭容错(BFT)协议，该协议用于区块链在复制的数据块之间达成共识。现有的大多数BFT协议在无故障情况下性能良好，但当故障发生时，它们的性能通常会严重下降。在本文中，我们提出了DBFT，一个BFT协议，实现了正常情况下优雅的性能下降。DBFT的主要新颖之处在于双重响应机制，它让副本节点确定性地响应客户机两次:一次是在推测执行阶段之后，另一次是在提交阶段之后。双响应机制可以处理推测执行中的不一致性，从而减轻由故障引起的性能下降。此外，DBFT不会让客户参与关键的共识操作，以减轻客户的负担。严格证明了DBFT的正确性性质，即安全性和活性。通过实验对DBFT的性能进行了评估，结果表明，在正常情况下，DBFT明显优于同类BFT协议。",
                    "title_zh": "DBFT:一种性能适度下降的拜占庭容错协议"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00024",
                    "title": "Making Speculative BFT Resilient with Trusted Monotonic Counters",
                    "authors": "Lachlan J. Gunn, Jian Liu, Bruno Vavala, N. Asokan",
                    "abstract": "Consensus mechanisms used by popular distributed ledgers are highly scalable but notoriously inefficient. Byzantine fault tolerance (BFT) protocols are efficient but far less scalable. Speculative BFT protocols such as Zyzzyva and Zyzzyva5 are efficient and scalable but require a trade-off: Zyzzyva requires only 3f + 1 replicas to tolerate f faults, but even a single slow replica will make Zyzzyva fall back to more expensive non-speculative operation. Zyzzyva5 does not require a non-speculative fallback, but requires 5f + 1 replicas in order to tolerate f faults. BFT variants using hardware-assisted trusted components can tolerate a greater proportion of faults, but require that every replica have this hardware. We present SACZyzzyva, addressing these concerns: resilience to slow replicas and requiring only 3f + 1 replicas, with only one replica needing an active monotonic counter at any given time. We experimentally evaluate our protocols, demonstrating low latency and high scalability. We prove that SACZyzzyva is optimally robust and that trusted components cannot increase fault tolerance unless they are present in at least two-thirds of replicas.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1905.10255"
                    },
                    "abstract_zh": "流行的分布式分类帐使用的共识机制具有很高的可伸缩性，但效率极低。拜占庭容错(BFT)协议是高效的，但是可扩展性差得多。诸如Zyzzyva和Zyzzyva5之类的推测性BFT协议是高效的和可扩展的，但是需要一种折衷:Zyzzyva只需要3f + 1个副本来容忍f个错误，但是即使单个缓慢的副本也会使Zyzzyva退回到更昂贵的非推测性操作。Zyzzyva5不需要非推测性回退，但需要5f + 1个副本以容忍f个故障。使用硬件辅助可信组件的BFT变体可以容忍更大比例的故障，但是要求每个复制品都具有该硬件。我们提出了SACZyzzyva，解决了这些问题:对慢速副本的弹性，并且只需要3f + 1个副本，在任何给定时间只有一个副本需要活动的单调计数器。我们实验性地评估了我们的协议，证明了低延迟和高可扩展性。我们证明SACZyzzyva是最优健壮的，并且可信组件不能增加容错性，除非它们存在于至少三分之二的副本中。",
                    "title_zh": "利用可信单调计数器使推测BFT具有弹性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00025",
                    "title": "Multilevel Checkpoint/Restart for Large Computational Jobs on Distributed Computing Resources",
                    "authors": "Masoud Gholami Estahbanati, Florian Schintke",
                    "abstract": "New generations of high-performance computing applications depend on an increasing number of components to satisfy their growing demand for computation. On such large systems, the execution of long-running jobs is more likely affected by component failures. Failure classes vary from frequent transient memory faults to rather rare correlated node errors. Multilevel checkpoint/restart has been introduced to proactively cope with failures at different levels. Writing checkpoints on slower stable devices, which survive fatal failures, causes more overhead than writing them on fast devices (main memory or local SSD), which, however, only protect against light faults. Given a graph of the components of a particular storage hierarchy mapping their fault-domains and their expected mean time to failure (MTTF), we optimize the checkpoint frequencies for each level of the storage hierarchy (multilevel checkpointing) to minimize the overhead and runtime of a given job. We reduce the checkpoint/restart overhead of large data-intensive jobs compared to state-of-the-art solutions on multilevel checkpointing by up to 10 percent in the investigated cases. The improvement increases further with growing checkpoint sizes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "新一代高性能计算应用程序依赖于越来越多的组件来满足其不断增长的计算需求。在这样的大型系统中，长时间运行的作业的执行更容易受到组件故障的影响。故障类别从频繁的瞬时存储器故障到相当罕见的相关节点错误不等。引入了多级检查点/重启来主动应对不同级别的故障。在较慢的稳定设备上写入检查点(在致命故障中幸存)比在快速设备(主内存或本地SSD)上写入检查点会导致更多开销，然而，快速设备只能防止轻微故障。给定特定存储层次结构的组件图，映射它们的容错域和它们的预期平均无故障时间(MTTF)，我们优化存储层次结构的每一级的检查点频率(多级检查点)，以最小化给定作业的开销和运行时间。在所调查的案例中，与先进的多级检查点解决方案相比，我们将大型数据密集型作业的检查点/重启开销减少了10%。随着检查点大小的增加，性能会进一步提高。",
                    "title_zh": "分布式计算资源上大型计算任务的多级检查点/重启"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00026",
                    "title": "Deterministic Fuzzy Checkpoints",
                    "authors": "Michael Eischer, Markus Büttner, Tobias Distler",
                    "abstract": "Replicated systems tolerating arbitrary (Byzantine) faults require periodic and deterministic application-state checkpoints to perform essential tasks such as initializing new replicas, enabling faulty replicas to recover, and garbage-collecting old agreement-protocol messages. Existing techniques to create checkpoints in these systems make it necessary to temporarily suspend request execution in order to capture a consistent checkpoint, causing significant service disruptions for applications with large states. Unfortunately, state-of-the-art approaches from the domain of crash-tolerant systems also are not directly applicable, because the checkpoints they produce are not comparable across replicas and therefore cannot be validated in an environment in which replicas may fail arbitrarily and do not trust each other. In this paper, we address these problems by proposing deterministic fuzzy checkpoints (DFC), a novel technique that enables all correct replicas in a system to create consistent and matching checkpoints in parallel to processing requests. As a consequence, DFC increases service availability while still allowing replicas to verify the correctness of a checkpoint before applying it to their local states. In addition to our general approach, we present different alternatives to implement DFC within a replication library and furthermore discuss support for the creation of differential checkpoints. Experiments with a key-value store show that DFC is able to snapshot states of 3 GB while sustaining high performance throughout the entire checkpointing process.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "容忍任意(拜占庭)错误的复制系统需要周期性的和确定性的应用程序状态检查点来执行基本任务，例如初始化新的副本，使有错误的副本能够恢复，以及对旧的协议消息进行垃圾收集。在这些系统中创建检查点的现有技术使得有必要暂时挂起请求执行，以便捕获一致的检查点，这导致具有大状态的应用程序的服务严重中断。不幸的是，来自容错系统领域的最先进的方法也不能直接应用，因为它们产生的检查点在副本之间是不可比较的，因此不能在副本可能任意失败并且彼此不信任的环境中得到验证。在本文中，我们通过提出确定性模糊检查点(DFC)来解决这些问题，这是一种新的技术，它使系统中所有正确的副本能够在处理请求的同时创建一致和匹配的检查点。因此，DFC提高了服务可用性，同时仍然允许副本在将检查点应用于其本地状态之前验证检查点的正确性。除了我们的一般方法，我们还介绍了在复制库中实现DFC的不同方法，并进一步讨论了对创建差异检查点的支持。键值存储的实验表明，DFC能够快照3 GB的状态，同时在整个检查点过程中保持高性能。",
                    "title_zh": "确定性模糊检查点"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00027",
                    "title": "A More Consistent Understanding of Consistency",
                    "authors": "Subhajit Sidhanta, Ricardo J. Dias, Rodrigo Rodrigues",
                    "abstract": "Recent storage systems trade strong consistency for performance, availability, and scalability. However, this makes it hard to understand the semantics that the storage system provides, and also makes the design and implementation of the storage system itself more error-prone. This paper proposes a comprehensive solution to these problems. In particular, we propose a specification language named ConSpec, which enables the formalization of different consistency semantics that a storage system may provide, using a uniform syntax that is independent of the design and implementation of the target storage system. We use ConSpec to revisit several existing models in light of a common way to define and compare them. Furthermore, we generalize the CAP theorem, whose original formulation only considered linearizability, to precisely define the class of consistency definitions that can and cannot be implemented in a highly-available, partition-tolerant way. Finally, we present the design and implementation of a new consistency checker that takes a trace from a storage system (e.g., the output of a test suite) and validates whether it meets any consistency semantics defined using ConSpec. The evaluation of our consistency checker shows that it is able to verify the correctness of long traces in a reasonable time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近的存储系统用强大的一致性换取了性能、可用性和可扩展性。然而，这使得很难理解存储系统提供的语义，并且也使得存储系统本身的设计和实现更容易出错。本文提出了解决这些问题的综合方案。特别地，我们提出了一种命名为ConSpec的规范语言，它使用独立于目标存储系统的设计和实现的统一语法，使得存储系统可以提供的不同一致性语义能够形式化。我们使用ConSpec根据定义和比较它们的通用方法重新访问几个现有的模型。此外，我们推广了CAP定理，其原始公式仅考虑了线性化，以精确地定义可以和不可以以高可用、分区容忍的方式实现的一致性定义类。最后，我们介绍了一种新的一致性检查器的设计和实现，它从存储系统(例如，测试套件的输出)中获取跟踪，并验证它是否满足使用ConSpec定义的任何一致性语义。对我们的一致性检查器的评估表明，它能够在合理的时间内验证长跟踪的正确性。",
                    "title_zh": "对一致性更一致的理解"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00028",
                    "title": "Improved Fast Rerouting Using Postprocessing",
                    "authors": "Klaus-Tycho Foerster, Andrzej Kamisinski, Yvonne-Anne Pignolet, Stefan Schmid, Gilles Trédan",
                    "abstract": "To provide fast traffic recovery upon failures, most modern networks support static Fast Rerouting (FRR) mechanisms for mission critical services. However, configuring FRR mechanisms to tolerate multiple failures poses challenging algorithmic problems. While state-of-the-art solutions leveraging arc-disjoint arborescence-based network decompositions ensure that failover routes always reach their destinations eventually, even under multiple concurrent failures, these routes may be long and introduce unnecessary loads; moreover, they are tailored to worst-case failure scenarios. This paper presents an algorithmic framework for improving a given FRR network decomposition, using postprocessing. In particular, our framework is based on iterative arc swapping strategies and supports a number of use cases, from strengthening the resilience (e.g., in the presence of shared risk link groups) to improving the quality of the resulting routes (e.g., reducing route lengths and induced loads). Our simulations show that postprocessing is indeed beneficial in various scenarios, and can therefore enhance today's approaches.",
                    "files": {
                        "openAccessPdf": "https://hal.laas.fr/hal-03048830/file/srds2019-journal.pdf"
                    },
                    "abstract_zh": "为了在出现故障时提供快速流量恢复，大多数现代网络都支持针对关键任务服务的静态快速重路由(FRR)机制。然而，配置FRR机制以容忍多个故障提出了具有挑战性的算法问题。虽然利用基于弧不相交树状结构的网络分解的最新解决方案确保了故障转移路由总是最终到达它们的目的地，即使在多个并发故障的情况下，这些路由也可能很长并引入不必要的负载；此外，它们是为最糟糕的故障情况量身定制的。本文提出了一个算法框架，以改善给定的FRR网络分解，使用后处理。具体而言，我们的框架基于迭代弧交换策略，并支持许多用例，从增强弹性(例如，在存在共享风险链路组的情况下)到提高所得路线的质量(例如，减少路线长度和诱发负载)。我们的模拟表明，后处理在各种情况下确实是有益的，因此可以增强今天的方法。",
                    "title_zh": "使用后处理改进快速重新路由"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00029",
                    "title": "Resilient Wide-Area Byzantine Consensus Using Adaptive Weighted Replication",
                    "authors": "Christian Berger, Hans P. Reiser, João Sousa, Alysson Bessani",
                    "abstract": "In geo-replicated systems, the heterogeneous latencies of connections between replicas limit the system's ability to achieve consensus fast. State machine replication (SMR) protocols can be refined for their deployment in wide-area networks by using a weighting scheme for active replication that employs additional replicas and assigns higher voting power to faster replicas. Utilizing more variability in quorum formation allows replicas to swiftly proceed to subsequent protocol stages, thus decreasing consensus latency. However, if network conditions vary during the system's lifespan or faults occur, the system needs a solution to autonomously adjust to new conditions. We incorporate the idea of self-optimization into geographically distributed, weighted replication by introducing AWARE, an automated and dynamic voting weight tuning and leader positioning scheme. AWARE measures replica-to-replica latencies and uses a prediction model, thriving to minimize the system's consensus latency. In experiments using different Amazon EC2 regions, AWARE dynamically optimizes consensus latency by self-reliantly finding a fast weight configuration yielding latency gains observed by clients located across the globe.",
                    "files": {
                        "openAccessPdf": "https://opus4.kobv.de/opus4-uni-passau/files/753/srds19_AWARE.pdf"
                    },
                    "abstract_zh": "在地理复制系统中，副本之间连接的异构延迟限制了系统快速达成一致的能力。通过使用用于主动复制的加权方案，可以改进状态机复制(SMR)协议，以用于在广域网中的部署，该加权方案采用额外的副本，并为更快的副本分配更高的投票权。在群体形成中利用更多的可变性允许复制品迅速进行到随后的协议阶段，从而减少共识延迟。但是，如果网络条件在系统生命周期内发生变化或出现故障，系统需要一种解决方案来自动适应新的条件。我们通过引入AWARE，一种自动化和动态的投票权重调整和领导者定位方案，将自我优化的思想融入到地理分布的加权复制中。AWARE测量副本到副本的延迟，并使用预测模型，最大限度地减少系统的一致延迟。在使用不同亚马逊EC2区域的实验中，AWARE通过独立地找到快速权重配置来动态优化共识延迟，从而产生全球各地的客户端所观察到的延迟增益。",
                    "title_zh": "使用自适应加权复制的弹性广域拜占庭一致性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00030",
                    "title": "Emergent Overlays for Adaptive MANET Broadcast",
                    "authors": "Raziel Carvajal-Gomez, Yehia Elkhatib, Laurent Réveillère, Etienne Rivière, Yérom-David Bromberg",
                    "abstract": "Mobile Ad-Hoc Networks (MANETs) allow distributed applications where no fixed network infrastructure is available. MANETs use wireless communication subject to faults and uncertainty, and must support efficient broadcast. Controlled flooding is suitable for highly-dynamic networks, while overlay-based broadcast is suitable for dense and more static ones. Density and mobility vary significantly over a MANET deployment area. We present the design and implementation of emergent overlays for efficient and reliable broadcast in heterogeneous MANETs. This adaptation technique allows nodes to automatically switch from controlled flooding to the use of an overlay. Interoperability protocols support the integration of both protocols in a single heterogeneous system. Coordinated adaptation policies allow regions of nodes to autonomously and collectively emerge and dissolve overlays. Our simulation of the full network stack of 600 mobile nodes shows that emergent overlays reduce energy consumption, and improve reliability and coverage compared to single protocols and to two previously-proposed adaptation techniques.",
                    "files": {
                        "openAccessPdf": "https://eprints.lancs.ac.uk/id/eprint/136473/1/srds.pdf"
                    },
                    "abstract_zh": "移动自组织网络(MANETs)允许在没有固定网络基础设施的地方进行分布式应用。MANETs使用易受故障和不确定性影响的无线通信，并且必须支持有效的广播。受控泛洪适用于高度动态的网络，而基于覆盖的广播适用于密集和更加静态的网络。密度和移动性在MANET部署区域内变化很大。我们提出了紧急覆盖的设计和实现，用于异构MANETs中高效和可靠的广播。这种自适应技术允许节点自动从受控泛洪切换到使用覆盖。互操作性协议支持在单个异构系统中集成这两种协议。协调的适应策略允许节点区域自主地和集体地出现和消除覆盖。我们对600个移动节点的全网络堆栈的模拟表明，与单个协议和两种先前提出的自适应技术相比，紧急覆盖降低了能耗，提高了可靠性和覆盖范围。",
                    "title_zh": "用于自适应MANET广播的紧急覆盖"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00031",
                    "title": "A Dual Digraph Approach for Leaderless Atomic Broadcast",
                    "authors": "Marius Poke, Colin W. Glass",
                    "abstract": "Many distributed systems work on a common shared state; in such systems, distributed agreement is necessary for consistency. With an increasing number of servers, these systems become more susceptible to single-server failures, increasing the relevance of fault-tolerance. Atomic broadcast enables fault-tolerant distributed agreement, yet it is costly to solve. Most practical algorithms entail linear work per broadcast message. AllConcur – a leaderless approach – reduces the work, by connecting the servers via a sparse resilient overlay network; yet, this resiliency entails redundancy, limiting the reduction of work. In this paper, we propose AllConcur+, an atomic broadcast algorithm that lifts this limitation: During intervals with no failures, it achieves minimal work by using a redundancy-free overlay network. When failures do occur, it automatically recovers by switching to a resilient overlay network. In our performance evaluation of non-failure scenarios, AllConcur+ achieves comparable throughput to AllGather – a non-fault-tolerant distributed agreement algorithm – and outperforms AllConcur, LCR and Libpaxos both in terms of throughput and latency. Furthermore, our evaluation of failure scenarios shows that AllConcur+'s expected performance is robust with regard to occasional failures. Thus, for realistic use cases, leveraging redundancy-free distributed agreement during intervals with no failures improves performance significantly.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "许多分布式系统在一个公共的共享状态下工作；在这样的系统中，分布式协议对于一致性是必要的。随着服务器数量的增加，这些系统变得更容易受到单服务器故障的影响，增加了容错的相关性。原子广播实现了容错分布式协议，但解决起来成本很高。大多数实用算法都需要对每个广播消息进行线性运算。all concur——一种无领导的方法——通过稀疏的弹性覆盖网络连接服务器，减少了工作；然而，这种弹性需要冗余，限制了工作量的减少。在本文中，我们提出了AllConcur+，这是一种原子广播算法，它消除了这种限制:在无故障间隔期间，它通过使用无冗余的覆盖网络来实现最小的工作。当故障确实发生时，它通过切换到弹性覆盖网络来自动恢复。在我们对无故障场景的性能评估中，AllConcur+实现了与AllGather(一种非容错分布式协议算法)相当的吞吐量，并且在吞吐量和延迟方面都优于AllConcur、LCR和Libpaxos。此外，我们对故障场景的评估表明，AllConcur+的预期性能在偶然故障方面非常稳健。因此，对于实际的用例，在无故障间隔期间利用无冗余分布式协议可以显著提高性能。",
                    "title_zh": "无领导原子广播的对偶有向图方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00032",
                    "title": "Merkle Search Trees: Efficient State-Based CRDTs in Open Networks",
                    "authors": "Alex Auvolat, François Taïani",
                    "abstract": "Most recent CRDT techniques rely on a causal broadcast primitive to provide guarantees on the delivery of operation deltas. Such a primitive is unfortunately hard to implement efficiently in large open networks, whose membership is often difficult to track. As an alternative, we argue in this paper that pure state-based CRDTs can be efficiently implemented by encoding states as specialized Merkle trees, and that this approach is well suited to open networks where many nodes may join and leave. At the core of our contribution lies a new kind of Merkle tree, called Merkle Search Tree (MST), that implements a balanced search tree while maintaining key ordering. This latter property makes it particularly efficient in the case of updates on sets of sequential keys, a common occurrence in many applications. We use this new data structure to implement a distributed event store, and show its efficiency in very large systems with low rates of updates. In particular, we show that in some scenarios our approach is able to achieve both a 66% reduction of bandwidth cost over a vector-clock approach, as well as a 34% improvement in consistency level. We finally suggest other uses of our construction for distributed databases in open networks.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/3935655/files/article.pdf"
                    },
                    "abstract_zh": "大多数最新的CRDT技术依赖于因果广播原语来保证操作增量的传递。不幸的是，这种原语很难在大型开放网络中有效实现，因为其成员关系通常很难跟踪。作为一种选择，我们在本文中认为，纯基于状态的CRDTs可以通过将状态编码为专门的Merkle树来有效地实现，并且这种方法非常适合于许多节点可能加入和离开的开放网络。我们贡献的核心是一种新的Merkle树，称为Merkle搜索树(MST ),它实现了一种平衡的搜索树，同时保持了键的排序。后一个属性使得它在更新连续键集的情况下特别有效，这在许多应用程序中很常见。我们使用这种新的数据结构实现了一个分布式事件存储，并展示了它在更新率较低的大型系统中的效率。特别是，我们表明，在某些情况下，我们的方法能够实现比矢量时钟方法减少66%的带宽成本，以及提高34%的一致性水平。最后，我们提出了开放网络中分布式数据库结构的其他用途。",
                    "title_zh": "Merkle搜索树:开放网络中有效的基于状态的CRDTs"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00033",
                    "title": "Revisiting Broadcast Algorithms for Wireless Edge Networks",
                    "authors": "André Rosa, Pedro Ákos Costa, João Leitão",
                    "abstract": "With the advent of Edge Computing, suitable, practical, and novel abstractions are required for applications to leverage the existing computational power at the edge. In particular, applications in the domains of smart cities and the Internet of Things (IoT) can rely on devices in the vicinity of data consumers and producers for their operation. While these devices are expected to be equipped with wireless radios, network infrastructure might be unavailable in many scenarios. In those cases, devices must rely on wireless ad hoc networks for coordination and cooperation. In this context, one of the most important primitives is the broadcast of messages, that can be leveraged as a building block to devise more complex distributed services and applications. The literature on wireless ad hoc broadcast algorithms is quite vast, with many different algorithms being proposed which explore or combine different techniques or features in their operation. While such protocols are becoming increasingly relevant, understanding how they relate among them is complicated. To address this challenge, in this paper, we introduce a novel framework that allows to abstract the operation of wireless ad hoc broadcast protocols. Leveraging on our framework, we explore a particularly interesting class of these protocols: neighbor-aware ad hoc broadcast protocols; of which we propose 4 novel protocols. Finally, we rely on a materialization of our framework to implement prototypes of these protocols and experimentally study their performance in a testbed composed of 21 Raspberry Pi 3 - model B.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着边缘计算的出现，应用程序需要合适、实用和新颖的抽象来利用边缘的现有计算能力。特别是，智慧城市和物联网(IoT)领域的应用可以依赖数据消费者和生产者附近的设备进行操作。虽然这些设备有望配备无线电，但在许多情况下网络基础设施可能不可用。在这些情况下，设备必须依靠无线特设网络进行协调和合作。在这种情况下，最重要的原语之一是消息广播，它可以作为构建块来设计更复杂的分布式服务和应用程序。关于无线自组织广播算法的文献相当广泛，提出了许多不同的算法，这些算法在其操作中探索或组合了不同的技术或特征。虽然这些协议变得越来越相关，但是理解它们之间的关系是复杂的。为了应对这一挑战，在本文中，我们介绍了一个新的框架，允许抽象的无线自组织广播协议的运作。利用我们的框架，我们探索了一类特别有趣的协议:邻居感知的ad hoc广播协议；其中我们提出了4个新的协议。最后，我们依靠我们的框架实现了这些协议的原型，并在由21个Raspberry Pi 3 - model B组成的测试床上实验性地研究了它们的性能。",
                    "title_zh": "重新审视无线边缘网络的广播算法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00034",
                    "title": "THUNDERSTORM: A Tool to Evaluate Dynamic Network Topologies on Distributed Systems",
                    "authors": "Luca Liechti, Paulo Gouveia, João Neves, Peter G. Kropf, Miguel Matos, Valerio Schiavoni",
                    "abstract": "Network dynamics, such as sudden changes in latency or available bandwidth, have a significant impact on the performance of distributed systems. While such dynamics are common, especially in WAN deployments, existing tools lack the capabilities to systematically evaluate the impact of such changes in real systems. We present THUNDERSTORM, a tool to evaluate the impact of dynamic network topologies on the performance of large-scale distributed systems. THUNDERSTORM is a fully functional tool that integrates with Kubernetes and can be used to evaluate off-the-shelf applications. THUNDERSTORM defines an easy-to-use language to describe arbitrarily complex network topologies and dynamic events used to enrich the default container composition descriptors. Our evaluation, using micro-and macro-benchmarks, as well as off-the-shelf unmodified systems (e.g., Apache Cassandra, MariaDB) shows that THUNDERSTORM is easy to use, accurate in reproducing dynamic behaviours and that it can help researchers uncover unexpected behaviours otherwise very costly to reproduce in real deployments typically captured only during malfunctioning periods.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "网络动态，如延迟或可用带宽的突然变化，对分布式系统的性能有很大的影响。虽然这种动态是常见的，尤其是在WAN部署中，但是现有的工具缺乏系统地评估这种变化在实际系统中的影响的能力。我们提出了雷暴，一个工具来评估的影响，动态网络拓扑对大规模分布式系统的性能。雷暴是一个与Kubernetes集成的全功能工具，可用于评估现成的应用程序。雷暴定义了一种易于使用的语言来描述任意复杂的网络拓扑和动态事件，用来丰富默认的容器组成描述符。我们使用微观和宏观基准以及现成的未经修改的系统(例如Apache Cassandra、MariaDB)进行的评估表明，雷暴易于使用，能够准确地再现动态行为，并且可以帮助研究人员发现意外行为，否则在实际部署中再现这些行为的成本会非常高，通常只能在故障期间捕获。",
                    "title_zh": "雷暴:一个评估分布式系统动态网络拓扑的工具"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00035",
                    "title": "Attack-Resistant Spanning Tree Construction in Route-Restricted Overlay Networks",
                    "authors": "Martin Byrenheid, Stefanie Roos, Thorsten Strufe",
                    "abstract": "Nodes in route-restricted overlays have an immutable set of neighbors, explicitly specified by their users. Popular examples include payment networks such as the Lightning network as well as social overlays such as the Dark Freenet. Routing algorithms are central to such overlays as they enable communication between nodes that are not directly connected. Recent results show that algorithms based on spanning trees are the most promising provably efficient choice. However, all suggested solutions fail to address how distributed spanning tree algorithms can deal with active denial of service attacks by malicious nodes. In this work, we design a novel self-stabilizing spanning tree construction algorithm that utilizes cryptographic signatures and prove that it reduces the set of nodes affected by active attacks. Our simulations substantiate this theoretical result with concrete values based on real-world data sets. In particular, our results indicate that our algorithm reduces the number of affected nodes by up to 74% compared to state-of-the-art attack-resistant spanning tree constructions.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1901.02729"
                    },
                    "abstract_zh": "路由受限覆盖中的节点有一组不可变的邻居，由它们的用户明确指定。常见的例子包括支付网络，如闪电网络，以及社会覆盖，如黑暗免费网络。路由算法是这种覆盖的核心，因为它们使得不直接连接的节点之间能够通信。最近的结果表明，基于生成树的算法是最有前途的有效选择。然而，所有建议的解决方案都未能解决分布式生成树算法如何处理恶意节点的主动拒绝服务攻击。在这项工作中，我们设计了一个新的自稳定生成树构造算法，利用加密签名，并证明它减少了受主动攻击影响的节点集。我们的模拟用基于真实世界数据集的具体值证实了这一理论结果。特别地，我们的结果表明，与最先进的抗攻击生成树构造相比，我们的算法将受影响节点的数量减少了74%。",
                    "title_zh": "路由受限覆盖网络中抗攻击生成树的构建"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00036",
                    "title": "Challenges and Opportunities for Efficient Serverless Computing at the Edge",
                    "authors": "Phani Kishore Gadepalli, Gregor Peach, Ludmila Cherkasova, Rob Aitken, Gabriel Parmer",
                    "abstract": "Serverless computing frameworks allow users to execute a small application (dedicated to a specific task) without handling operational issues such as server provisioning, resource management, and resource scaling for the increased load. Serverless computing originally emerged as a Cloud computing framework, but might be a perfect match for IoT data processing at the Edge. However, the existing serverless solutions, based on VMs and containers, are too heavy-weight (large memory footprint and high function invocation time) for operating efficiency and elastic scaling at the Edge. Moreover, many novel IoT applications require low-latency data processing and near real-time responses, which makes the current cloud-based serverless solutions unsuitable. Recently, WebAssembly (Wasm) has been proposed as an alternative method for running serverless applications at near-native speeds, while having a small memory footprint and optimized invocation time. In this paper, we discuss some existing serverless solutions, their design details, and unresolved performance challenges for an efficient serverless management at the Edge. We outline our serverless framework, called aWsm, based on the WebAssembly approach, and discuss the opportunities enabled by the aWsm design, including function profiling and SLO-driven performance management of users' functions. Finally, we present an initial assessment of aWsm performance featuring average startup time (12µs to 30µs) and an economical memory footprint (ranging from 10s to 100s of kB) for a subset of MiBench microbenchmarks used as functions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "无服务器计算框架允许用户执行小型应用程序(专用于特定任务),而无需处理操作问题，例如服务器供应、资源管理和针对增加的负载的资源缩放。无服务器计算最初是作为云计算框架出现的，但可能是边缘物联网数据处理的完美匹配。然而，现有的基于虚拟机和容器的无服务器解决方案对于运行效率和边缘的弹性扩展来说过于笨重(大内存占用和高函数调用时间)。此外，许多新颖的物联网应用需要低延迟的数据处理和接近实时的响应，这使得当前基于云的无服务器解决方案不合适。最近，WebAssembly (Wasm)被提议作为以接近本地速度运行无服务器应用程序的替代方法，同时具有较小的内存占用和优化的调用时间。在本文中，我们讨论了一些现有的无服务器解决方案，它们的设计细节，以及在边缘实现高效无服务器管理的未解决的性能挑战。我们概述了基于WebAssembly方法的无服务器框架aWsm，并讨论了aWsm设计带来的机遇，包括功能分析和SLO驱动的用户功能性能管理。最后，我们对aWsm性能进行了初步评估，对用作函数的MiBench微基准测试子集，评估了平均启动时间(12秒到30秒)和经济的内存占用(从10秒到100 kB不等)。",
                    "title_zh": "边缘高效无服务器计算的挑战和机遇"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00037",
                    "title": "Scalability and Resilience in Practice: Current Trends and Opportunities",
                    "authors": "Julien Ponge, Mark C. Little",
                    "abstract": "In this presentation we report on the current trends for implementing distributed services that are both scalable and resilient based on our experiences across the Red Hat Middleware portfolio. We tackle the topics of reactive event-driven services and distributed consensus at cloud scale.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本演示中，我们将根据我们在Red Hat中间件产品组合中的经验，报告实现可伸缩且有弹性的分布式服务的当前趋势。我们解决了反应式事件驱动服务和云级分布式共识的主题。",
                    "title_zh": "实践中的可伸缩性和弹性:当前趋势和机遇"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00038",
                    "title": "Toward an in-Kernel High Performance Key-Value Store Implementation",
                    "authors": "Kahina Lazri, Antoine Blin, Julien Sopena, Gilles Muller",
                    "abstract": "This work proposes to leverage the programming capabilities offered by eBPF with the high-performance of the XDP hook to execute KVS applications as kernel modules. With this design, the application is executed as a cache module in the kernel space. Our preliminary evaluation results show improvements of up to 30% of the number of processed get requests with UDP protocol. Moreover, this work discusses the eBPF limitations that prevent from full implementation of in-kernel KVS cache application.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "这项工作旨在利用eBPF提供的编程能力和XDP钩子的高性能来执行作为内核模块的KVS应用程序。通过这种设计，应用程序作为内核空间中的缓存模块执行。我们的初步评估结果显示，使用UDP协议处理的get请求数量提高了30%。此外，本文还讨论了eBPF的局限性，这些局限性阻碍了内核KVS缓存应用的全面实现。",
                    "title_zh": "面向内核高性能键值存储实现"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00039",
                    "title": "Combining Learning and Model-Based Reasoning to Reduce Uncertainties in Cloud Security and Compliance Auditing",
                    "authors": "Uttam Thakore, Rohit Ranchal, Yi-Hsiu Wei, HariGovind V. Ramasamy",
                    "abstract": "Security and compliance auditing is expensive, time-consuming, and error-prone for cloud service providers operating in multiple domains. Existing approaches predominantly use formal logic and domain-specific languages to facilitate collection and validation of evidence needed for compliance certification. Such approaches do not sufficiently account for the uncertainties and challenges caused by human involvement, which are a major contributor to inefficiencies and mistakes in the audit process. We propose that hybrid approaches, in which formal, model-based approaches are combined with machine learning techniques to reason about evidence and historical audit data, are necessary to address such uncertainties. Such approaches can help both auditors and service providers better deal with uncertainties, and reduce costs, errors, and the manual effort required to identify evidence needed for compliance certification. We present a taxonomic framework for understanding the causes of and potential solutions to uncertainty in the audit process. We identify areas within evidence collection and validation in which machine learning can augment model-based techniques to reduce uncertainties. We provide some examples of hybrid approaches that we are exploring and discuss the need for more work in this area.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对于在多个域中运营的云服务提供商来说，安全性和合规性审计既昂贵又耗时，而且容易出错。现有的方法主要使用形式逻辑和特定领域语言来帮助收集和验证符合性认证所需的证据。这种方法没有充分考虑到由人的参与所引起的不确定性和挑战，而这些不确定性和挑战是审计过程中低效率和错误的主要原因。我们提出混合方法，其中正式的，基于模型的方法与机器学习技术相结合，对证据和历史审计数据进行推理，是解决这种不确定性所必需的。这种方法可以帮助审计员和服务提供商更好地处理不确定性，并减少成本、错误和识别合规性认证所需的证据所需的人工努力。我们提出了一个分类框架来理解审计过程中不确定性的原因和潜在的解决方案。我们确定了证据收集和验证中机器学习可以增强基于模型的技术以减少不确定性的领域。我们提供了一些我们正在探索的混合方法的例子，并讨论了在这一领域进行更多工作的必要性。",
                    "title_zh": "结合学习和基于模型的推理来减少云安全和合规性审计中的不确定性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00040",
                    "title": "A Generic Construction for All Parameters in Minimum Storage Regenerating Codes",
                    "authors": "Liuqing Ye, Dan Feng, Yuchong Hu, Xueliang Wei",
                    "abstract": "Minimum-Storage Regenerating (MSR) codes have become superior alternatives to traditional erasure codes as they can provide optimal repair bandwidth while the reliability and the storage overhead are still optimal. So far, the state-of-the-art MSR codes mainly focus on connecting to all the remaining nodes to repair a single failure. Since the recovery latency may be bottlenecked by the time taken to retrieve the slowest or straggling block, it is however impractical to have the highest connectivity in MSR codes. In this paper, we introduce a generic construction for all parameters in MSR codes, which allows for bandwidth-efficient repair of a single data node failure with an arbitrary (but fixed) number of accessed nodes d. Our method provides explicit and generic encoding and repairing processes, and such codes were not previously known to exist. When d = n - 1, we show that our codes are not inferior to the other MSR codes and retain the same recovery optimality. Furthermore, the arbitrary number of d allows our codes to adapt to the late binding strategy to avoid stragglers (overloaded sites) for efficient recovery performance. As a result, our codes outperform both traditional erasure codes and the state-of-the-art MSR codes on the aspect of the response time when the system is subjected to an imbalanced load.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最小存储再生(MSR)码已经成为传统纠删码的优秀替代方案，因为它们可以提供最佳的修复带宽，同时可靠性和存储开销仍然是最佳的。到目前为止，最先进的MSR代码主要集中在连接到所有剩余节点来修复单个故障。由于恢复等待时间可能受到检索最慢或分散的块所花费的时间的限制，因此在MSR码中具有最高的连通性是不切实际的。在本文中，我们介绍了MSR码中所有参数的通用结构，它允许利用任意(但固定)数量的访问节点d对单个数据节点故障进行带宽有效的修复。我们的方法提供了显式和通用的编码和修复过程，这种码以前是不存在的。当d = n - 1时，我们证明了我们的码不劣于其他MSR码，并保持相同的恢复最优性。此外，任意数量的d允许我们的代码适应后期绑定策略，以避免掉队者(过载站点),从而实现高效的恢复性能。结果表明，在系统负载不均衡的情况下，我们的码在响应时间方面优于传统的纠删码和最新的MSR码。",
                    "title_zh": "最小存储再生码中所有参数的一般构造"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00041",
                    "title": "Exploring Declustered Software RAID for Enhanced Reliability and Recovery Performance in HPC Storage Systems",
                    "authors": "Zhi Qiao, Shuwen Liang, Hsing-Bung Chen, Song Fu, Bradley W. Settlemyer",
                    "abstract": "Redundant array of independent disks (RAID) has been widely used to address the reliability and performance issues of storage systems. As the scale of modern storage systems continues growing, disk failure becomes the norm. With the ever-increasing disk capacity, RAID recovery based on disk rebuild becomes more and more costly, which causes significant performance degradation and even unavailability of storage systems. Declustered data layout enables parallel RAID reconstruction by shuffling data and parity blocks among all drives (including spares) in a RAID group. However, the reliability and performance of declustered RAID in real-world storage environments have not been thoroughly studied. With the popularity of ZFS file system and software RAID used in production data centers, in this paper, we extensively evaluate declustered RAID with regard to the RAID recovery time and I/O performance on a high-performance storage platform at Los Alamos National Laboratory. Our empirical study reveals the advantages and disadvantages of declustered RAID technology. We qualitatively characterize the recovery performance of declustered RAID and compare with that of ZFS RAIDZ under various I/O workloads and access patterns. The experimental results show that the speedup of declustered RAID over traditional RAID is sub-linear to the parallelism of recovery I/O. Furthermore, we formally model and analyze the reliability of declustered RAID in terms of the mean-time-to-data-loss (MTTDL) and discover that the improved recovery performance leads to higher storage reliability compared with the traditional RAID.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "独立磁盘冗余阵列(RAID)已被广泛用于解决存储系统的可靠性和性能问题。随着现代存储系统规模的持续增长，磁盘故障成为常态。随着磁盘容量的不断增加，基于磁盘重建的RAID恢复变得越来越昂贵，这导致存储系统的性能显著下降，甚至不可用。分散数据布局通过在RAID组中的所有驱动器(包括备盘)之间转移数据和奇偶校验块来实现并行RAID重建。然而，现实存储环境中去集群化RAID的可靠性和性能还没有得到彻底的研究。随着ZFS文件系统和软件RAID在生产数据中心的普及，在本文中，我们在洛斯阿拉莫斯国家实验室的高性能存储平台上，针对RAID恢复时间和I/O性能对去集群RAID进行了广泛的评估。我们的实证研究揭示了分散RAID技术的优势和劣势。我们定性地描述了去集群RAID的恢复性能，并与ZFS RAIDZ在各种I/O工作负载和访问模式下的恢复性能进行了比较。实验结果表明，去集群化RAID相对于传统RAID的加速比与恢复I/O并行度呈亚线性关系。此外，我们从平均数据丢失时间(MTTDL)的角度对去集群化RAID的可靠性进行了形式化建模和分析，发现与传统RAID相比，恢复性能的提高带来了更高的存储可靠性。",
                    "title_zh": "探索去集群软件RAID以增强HPC存储系统的可靠性和恢复性能"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00042",
                    "title": "Lightweight Dynamic Redundancy Control for Server-Based Storage",
                    "authors": "Takayuki Fukatani, Hieu Hanh Le, Haruo Yokota",
                    "abstract": "The recent performance improvements in commodity hardware have made commodity server-based storage a practical alternative to dedicated-storage appliances. Because of the low reliability of commodity servers, data redundancy across multiple servers is required for high availability of a server-based storage system. However, the extra storage capacity required to enable this redundancy increases the system cost significantly. Although erasure coding (EC) is a promising approach to reducing the amount of redundant data, it is only available in systems using distributed storage. There remains the need to reduce the performance overhead of using distributed storage, which involves much network traffic and metadata processing. In this paper, we propose a lightweight redundancy-control method called \"dynamic redundancy control\" for server-based storage systems. Our method adds additional file metadata for EC to the local filesystem, enabling the system to take advantage of EC with reduced network traffic and metadata processing. In addition, our method dynamically controls the data redundancy in user data between replication and EC to improve the capacity efficiency while mitigating performance degradation. Our experiments show that our method achieves up to 76% less processing time for a metadata-intensive workload, up to 150% higher read performance, and up to 147% better online-transaction-processing performance than CephFS, a widely used alternative system. In addition, our method successfully improves capacity efficiency while mitigating performance degradation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "商用硬件最近的性能改进使基于服务器的商用存储成为专用存储设备的实用替代方案。由于商用服务器的低可靠性，基于服务器的存储系统的高可用性需要跨多个服务器的数据冗余。然而，实现这种冗余所需的额外存储容量显著增加了系统成本。尽管擦除编码(EC)是减少冗余数据量的一种有前途的方法，但它仅在使用分布式存储的系统中可用。仍然需要降低使用分布式存储的性能开销，这涉及大量网络流量和元数据处理。本文提出了一种轻量级的冗余控制方法，称为“动态冗余控制”，用于基于服务器的存储系统。我们的方法将EC的附加文件元数据添加到本地文件系统，使系统能够利用EC，同时减少网络流量和元数据处理。此外，我们的方法动态控制复制和EC之间的用户数据中的数据冗余，以提高容量效率，同时减轻性能下降。我们的实验表明，与CephFS(一种广泛使用的替代系统)相比，我们的方法在元数据密集型工作负载方面的处理时间减少了76%，读取性能提高了150%，在线事务处理性能提高了147%。此外，我们的方法成功地提高了容量效率，同时减轻了性能下降。",
                    "title_zh": "基于服务器的存储的轻量级动态冗余控制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00043",
                    "title": "Bloxy: Providing Transparent and Generic BFT-Based Ordering Services for Blockchains",
                    "authors": "Signe Rüsch, Kai Bleeke, Rüdiger Kapitza",
                    "abstract": "With the wide-spread use of blockchain technology, Byzantine fault-tolerant (BFT) protocols are explored as a means to achieve consensus on which transactions should be processed next. BFT protocols are not a one-size-fits-all solution: they should be chosen according to the blockchain's use case, which can range from supply chain management to decentralised storage, requiring specialisation e.g. regarding throughput, latency, or level of decentralisation. Previously, consensus protocols were usually hardcoded into the blockchain infrastructure and could not be exchanged, therefore inhibiting flexible use of an otherwise generic blockchain infrastructure. Hyperledger Fabric claims to provide modular consensus and support for crash-fault and Byzantine fault tolerant protocols. However, integrating a BFT protocol has shown that Fabric's architecture is currently not well-suited for this fault model as it requires substantial changes and thereby breaks Fabric's modularity. This also has to be repeated for each integrated BFT protocol. In this paper, we present Bloxy, a blockchain-aware trusted proxy running on the replica that encapsulates all BFT client functionality. Bloxy enables transparent access to generic BFT frameworks and preserves Fabric's modularity even for the Byzantine fault model. It runs inside a trusted execution environment based on Intel's Software Guard Extensions. Bloxy offers blockchain-specific communication mechanisms as well as short-term block storage to handle crashes or disconnects to ensure that all nodes receive block updates. We implemented two Bloxy-based ordering services based on PBFT and the hybrid BFT protocol Hybster. Our evaluation shows that our approach increases throughput by up to 71% compared to directly integrated BFT protocols.",
                    "files": {
                        "openAccessPdf": "https://leopard.tu-braunschweig.de/servlets/MCRFileNodeServlet/dbbs_derivate_00046812/ruesch-bloxy-srds19.pdf"
                    },
                    "abstract_zh": "随着区块链技术的广泛使用，拜占庭容错(BFT)协议被探索作为一种手段，以达成关于接下来应该处理哪些事务的共识。BFT协议不是一个放之四海而皆准的解决方案:应根据区块链的使用案例进行选择，从供应链管理到分散存储，需要在吞吐量、延迟或分散化水平等方面进行专业化。以前，共识协议通常被硬编码到区块链基础设施中，并且不能被交换，因此抑制了其他通用区块链基础设施的灵活使用。Hyperledger Fabric声称为崩溃故障和拜占庭容错协议提供模块化共识和支持。然而，集成BFT协议表明，Fabric的体系结构目前不太适合这种故障模型，因为它需要大量的更改，从而破坏了Fabric的模块化。对于每一项综合性的《BFT议定书》,也必须重复这一步骤。在本文中，我们介绍了Bloxy，它是一个区块链感知的可信代理，运行在封装了所有BFT客户端功能的副本上。Bloxy支持对通用BFT框架的透明访问，即使对于拜占庭故障模型也能保持Fabric的模块化。它运行在基于英特尔软件保护扩展的可信执行环境中。Bloxy提供了特定于区块链的通信机制以及短期块存储来处理崩溃或断开连接，以确保所有节点都能收到块更新。我们基于PBFT和混合BFT协议Hybster实现了两个基于Bloxy的订购服务。我们的评估表明，与直接集成的BFT协议相比，我们的方法将吞吐量提高了71%。",
                    "title_zh": "Bloxy:为区块链提供透明和通用的BFT订购服务"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00044",
                    "title": "Blockchain-Based Metadata Protection for Archival Systems",
                    "authors": "Arnaud L'Hutereau, Dorian Burihabwa, Pascal Felber, Hugues Mercier, Valerio Schiavoni",
                    "abstract": "Long-term archival storage systems must protect data from powerful attackers that might try to corrupt or censor (part of) the documents. They must also protect the corresponding metadata information, which is essential to maintain and rebuild the stored data. In this practical experience report, we present metablock, a metadata protection system leveraging the Ethereum distributed ledger. We combine metablock with an existing secure long-term data archival system to provide a scalable design that allows external auditing, data validation and efficient data repair. We reflect on our experiences in using a blockchain for metadata protection, with the goal of providing valuable insights and lessons for developers of such secure systems, by highlighting the potential and limitations of the approach. Our prototype is available at https://github.com/ArnaudLhutereau/mb.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "长期档案存储系统必须保护数据免受可能试图破坏或审查(部分)文档的强大攻击者的攻击。他们还必须保护相应的元数据信息，这对于维护和重建存储的数据至关重要。在这份实践经验报告中，我们展示了metablock，一个利用以太坊分布式账本的元数据保护系统。我们将metablock与现有的安全长期数据归档系统相结合，以提供可扩展的设计，允许外部审计、数据验证和高效的数据修复。我们反思了使用区块链进行元数据保护的经验，目的是通过强调该方法的潜力和局限性，为这种安全系统的开发人员提供有价值的见解和经验。我们的原型在https://github.com/ArnaudLhutereau/mb.有售",
                    "title_zh": "基于区块链的档案系统元数据保护"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00045",
                    "title": "Trusted Computing Meets Blockchain: Rollback Attacks and a Solution for Hyperledger Fabric",
                    "authors": "Marcus Brandenburger, Christian Cachin, Rüdiger Kapitza, Alessandro Sorniotti",
                    "abstract": "A smart contract on a blockchain cannot keep a secret because its data is replicated on all nodes in a network. To remedy this problem, it has been suggested combining blockchains with trusted execution environments (TEEs), such as Intel SGX, for executing applications that demand confidentiality. As a consequence, untrusted blockchain nodes cannot get access to the data and computations inside the TEE. This paper first explores issues that arise from the combination of TEEs with blockchains: Smart contracts executed inside TEEs are susceptible to rollback attacks, which should be prevented to maintain confidentiality for the application. However, in blockchains with non-final consensus protocols, such as the proof-of-work in Ethereum and others, the contract execution must handle rollbacks by design. This implies that TEEs for securing smart-contract execution cannot be directly used for such blockchains; this approach works only when the consensus decisions are final. Second, this work introduces an architecture and a prototype for smart-contract execution within Intel SGX for Hyperledger Fabric, a prominent enterprise blockchain platform. Our system resolves additional difficulties posed by the specific execute-order-validate architecture of Fabric, prevents rollback attacks on TEE-based execution as far as possible, and minimizes the trusted computing base. For increasing security, our design encapsulates each application on the blockchain within its own enclave that shields it from the host system. An evaluation shows that the overhead of moving the execution into SGX is within 10%–20% for a sealed-bid auction application.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "区块链上的智能合约不能保密，因为它的数据在网络中的所有节点上都被复制。为了解决这个问题，有人建议将区块链与可信执行环境(tee)相结合，例如英特尔SGX，用于执行要求保密性的应用。因此，不受信任的区块链节点无法访问TEE内部的数据和计算。本文首先探讨了由tee和区块链的结合而产生的问题:在tee内部执行的智能契约容易受到回滚攻击，应该防止回滚攻击以维护应用程序的机密性。然而，在具有非最终共识协议的区块链中，例如以太坊中的工作证明和其他协议，契约执行必须通过设计来处理回滚。这意味着用于确保智能合同执行的tee不能直接用于此类区块链；这种方法只有在协商一致的决定是最终决定时才有效。其次，这项工作介绍了英特尔SGX Hyperledger Fabric智能合约执行的架构和原型，Hyperledger Fabric是一个著名的企业区块链平台。我们的系统解决了Fabric特定的执行-顺序-验证体系结构带来的额外困难，尽可能地防止对基于TEE的执行的回滚攻击，并最小化可信计算基础。为了提高安全性，我们的设计将区块链上的每个应用程序封装在自己的飞地中，使其免受主机系统的影响。一项评估显示，对于密封投标拍卖应用程序，将执行转移到SGX的开销在10%-20%以内。",
                    "title_zh": "可信计算遇到区块链:回滚攻击和Hyperledger结构的解决方案"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00046",
                    "title": "The Notion of Universality in Crash-Prone Asynchronous Message-Passing Systems: A Tutorial",
                    "authors": "Michel Raynal",
                    "abstract": "The notion of a universal construction is central in computing science and technology: general solutions make life easier and the wheel has not to be reinvented each time a new problem appears. In the context of message-passing asynchronous distributed systems made up of n processes, where some of them may commit crash failures, a universal construction is an algorithm that is able to build any object defined by a sequential specification despite the adversary effect resulting from the combination of asynchrony and process crashes. The aim of this tutorial is to introduce the reader to the notion of a distributed universal construction (and universal objects these constructions rely on), and more precisely, explain what can be done, what cannot be done, and which assumptions on the environment are necessary in order objects with provably reliability properties can be built. Its aim is be a guided tour providing the reader with the basic knowledge needed to understand and master asynchronous message-passing fault-tolerant computing. Its spirit is not to be a catalog of constructions proposed so far, but an as simple as possible presentation of concepts and mechanisms that constitute the basis these universal constructions rely on.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通用结构的概念是计算科学和技术的核心:通用解决方案使生活更容易，不必每次出现新问题都重新发明轮子。在由n个进程组成的消息传递异步分布式系统的上下文中，其中一些进程可能会发生崩溃故障，通用构造是一种算法，它能够构建由顺序规范定义的任何对象，尽管异步和进程崩溃的组合会产生对抗效应。本教程的目的是向读者介绍分布式通用构造(以及这些构造所依赖的通用对象)的概念，更准确地说，解释什么可以做，什么不可以做，以及为了构建具有可证明的可靠性属性的对象，对环境的哪些假设是必要的。它的目的是为读者提供理解和掌握异步消息传递容错计算所需的基础知识。它的精神不是列出迄今为止提出的结构，而是尽可能简单地介绍构成这些普遍结构所依赖的基础的概念和机制。",
                    "title_zh": "易崩溃异步消息传递系统中的普遍性概念:教程"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00047",
                    "title": "Edge Applications: Just Right Consistency",
                    "authors": "Anshul Ahuja, Geetesh Gupta, Subhajit Sidhanta",
                    "abstract": "CRDTs are distributed data types that make eventual consistency of a distributed object possible and non ad-hoc. Geo-distributed systems are spread across multiple data centers at different geographic locations to ensure availability and performance despite network partitions. These systems must accept updates at any replica and propagate these updates asynchronously to every other replica. Conflict-Free Replicated Data Types (CRDTs) ensures eventual consistency in the replicas despite asynchronous delivery of updates. Extending this idea to fog computing servers where connection reliability is low, eventual consistency amongst the servers is required. We configure Kubernetes, an open-source container orchestration system used for automating deployment, scaling, and management of containerized applications, and use it for cluster deployment of CRDT based low resource intensive AntidoteDB can be used for deployment on fog servers to ensure eventual consistency amongst these servers. We have developed an automated benchmarking tool for benchmarking edge computing applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "CRDTs是分布式数据类型，它使得分布式对象的最终一致性成为可能，并且是非特定的。地理分布式系统分布在不同地理位置的多个数据中心，以确保可用性和性能，而不受网络分区的影响。这些系统必须接受任何副本上的更新，并将这些更新异步传播到每个其他副本。无冲突复制数据类型(CRDTs)确保了副本的最终一致性，尽管更新是异步交付的。将这种想法扩展到连接可靠性低的雾计算服务器，最终需要服务器之间的一致性。我们配置了Kubernetes，这是一个开源的容器编排系统，用于自动化部署、扩展和管理容器化的应用程序，并将其用于基于CRDT的低资源密集型AntidoteDB的集群部署。AntidoteDB可用于在fog服务器上部署，以确保这些服务器之间的最终一致性。我们开发了一个自动化基准测试工具，用于对边缘计算应用进行基准测试。",
                    "title_zh": "边缘应用:恰到好处的一致性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00048",
                    "title": "Self-Stabilizing Manoeuvre Negotiation: The Case of Virtual Traffic Lights",
                    "authors": "António Casimiro, Emelie Ekenstedt, Elad Michael Schiller",
                    "abstract": "The vision of automated driving promises to have safer and more cost-efficient transport systems. Automated driving systems have to demonstrate high levels of dependability and affordability. Recent advances of new communication technologies, e.g., 5G, allow significant cost reduction of timely shared sensory information. However, the design of fault-tolerant automated driving systems remains an open challenge. This work considers the design of automated driving systems through the lenses of self-stabilization—a very strong notion of fault-tolerance. Our self-stabilizing algorithms guarantee, within a bounded period, recovery from a broad fault model and arbitrary state corruption. After this recovery period, our algorithms provide safe maneuver execution despite the presence of failures, such as unbounded periods of packet loss and timing failures as well as inaccurate sensory information and malicious behavior. We evaluate the proposed algorithms through a rigorous correctness proof and a worst-case analysis as well as a prototype that focuses on an intersection crossing protocol. We validate our prototype via computer simulations and a testbed implementation. Our preliminary results show a reduction in the number of vehicle collisions and dangerous situations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动驾驶的愿景承诺拥有更安全、更具成本效益的运输系统。自动驾驶系统必须表现出高度的可靠性和可负担性。新通信技术(例如5G)的最新进展使得及时共享感觉信息的成本显著降低。然而，容错自动驾驶系统的设计仍然是一个开放的挑战。这项工作从自我稳定的角度考虑自动驾驶系统的设计，这是一个非常强的容错概念。我们的自稳定算法保证在有限的时间内，从广泛的故障模型和任意状态损坏中恢复。在这个恢复周期之后，尽管存在故障，例如无限期的分组丢失和定时故障以及不准确的传感信息和恶意行为，我们的算法仍提供安全的机动执行。我们通过严格的正确性证明和最坏情况分析以及一个针对交叉口通行协议的原型来评估所提出的算法。我们通过计算机模拟和测试床实现来验证我们的原型。我们的初步结果显示，车辆碰撞和危险情况的数量有所减少。",
                    "title_zh": "自稳定机动谈判:虚拟交通灯的情况"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00049",
                    "title": "SmartMonit: Real-Time Big Data Monitoring System",
                    "authors": "Umit Demirbaga, Ayman Noor, Zhenyu Wen, Philip James, Karan Mitra, Rajiv Ranjan",
                    "abstract": "Modern big data processing systems are becoming very complex in terms of large-scale, high-concurrency and multiple talents. Thus, many failures and performance reductions only happen at run-time and are very difficult to capture. Moreover, some issues may only be triggered when some components are executed. To analyze the root cause of these types of issues, we have to capture the dependencies of each component in real-time. In this paper, we propose SmartMonit, a real-time big data monitoring system, which collects infrastructure information such as the process status of each task. At the same time, we develop a real-time stream processing framework to analyze the coordination among the tasks and the infrastructures. This coordination information is essential for troubleshooting the reasons for failures and performance reduction, especially the ones propagated from other causes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代大数据处理系统在大规模、高并发和多人才方面变得非常复杂。因此，许多故障和性能降低只发生在运行时，很难捕捉到。此外，一些问题可能仅在一些组件被执行时才被触发。为了分析这类问题的根本原因，我们必须实时捕获每个组件的依赖关系。在本文中，我们提出了实时大数据监控系统SmartMonit，它收集每个任务的进程状态等基础设施信息。同时，我们开发了一个实时流处理框架来分析任务和基础设施之间的协调。这种协调信息对于排除故障和性能下降的原因，尤其是从其他原因传播的原因是必不可少的。",
                    "title_zh": "SmartMonit:实时大数据监控系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00050",
                    "title": "Building Ad-Hoc Clouds with CloudAgora",
                    "authors": "Tasos Bakogiannis, Ioannis Mytilinis, Katerina Doka, Georgios I. Goumas",
                    "abstract": "The public Cloud market has become a monopoly, where a handful of providers - which are by default considered as trusted entities - define the prices, accumulate knowledge from users' data and computations and strengthen their already privileged position. As a remedy we propose CloudAgora, a platform that democratizes the Cloud market by allowing individuals and companies alike to compete on equal terms as potential resource providers, while enabling users to access low-cost storage and computation without having to blindly trust any central authority. During the demo, the attendees will be able to interact with CloudAgora through an easy-to-use UI, which will allow them to act both as users and as providers. As users, the attendees will have the chance to request storage or compute resources, upload data and outsource task processing over remote infrastructures. As providers, they will be able to participate in auctions, serve requests and offer validity proofs upon request. Moreover, the audience will experience first hand how the underlying blockchain technology is used to record commitment policies, publicly verify off-chain services and trigger automatic micropayments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "公共云市场已经成为垄断市场，少数提供商(默认情况下被视为可信实体)定义价格，从用户的数据和计算中积累知识，并加强他们已经享有的特权地位。作为一种补救措施，我们提出了CloudAgora，这是一个通过允许个人和公司作为潜在的资源提供商在平等的条件下竞争来民主化云市场的平台，同时使用户能够访问低成本的存储和计算，而不必盲目信任任何中央权威。在演示期间，与会者将能够通过一个易于使用的UI与CloudAgora进行交互，这将允许他们既作为用户又作为提供商。作为用户，与会者将有机会通过远程基础架构请求存储或计算资源、上传数据和外包任务处理。作为供应商，他们将能够参与拍卖，服务请求，并根据请求提供有效性证明。此外，观众将直接体验基础区块链技术如何用于记录承诺政策，公开验证链外服务和触发自动小额支付。",
                    "title_zh": "使用CloudAgora构建临时云"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00051",
                    "title": "A Framework for Managing an Elastic Redis Cache",
                    "authors": "Thanasis Priovolos, Stathis Maroulis, Vana Kalogeraki",
                    "abstract": "In this demonstration we present ESCAPe, a framework for automatically monitoring and managing an elastic Redis cache. System administrators can configure ESCAPe in concert with their Redis cluster, to meet application real-time objectives while minimizing the cost associated with scaling the applications. ESCAPe comprises Agents that are deployed at each node in the Redis cluster in order to implement the scaling decisions and apply the proposed eviction policy, and a ESCAPe Manager that communicates with all other nodes and makes the scaling decisions in response to the monitored response times and costs. Finally ESCAPe's Web User Interface visualizes realtime statistics related to response time and the distribution of object types in the cluster nodes as well as historical statistics. The system administrators can further fine-tune the cluster parameters and monitor the impact of their decisions on the application performance and cost.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本次演示中，我们将展示ESCAPe，这是一个自动监控和管理弹性Redis缓存的框架。系统管理员可以配置ESCAPe与他们的Redis集群协同工作，以满足应用程序的实时目标，同时最大限度地降低与扩展应用程序相关的成本。ESCAPe包括部署在Redis集群中的每个节点处的代理，以便实现缩放决定并应用所提出的驱逐策略，以及与所有其他节点通信并响应于所监控的响应时间和成本来做出缩放决定的ESCAPe管理器。最后，ESCAPe的Web用户界面可视化了与响应时间和集群节点中对象类型分布相关的实时统计数据以及历史统计数据。系统管理员可以进一步微调集群参数，并监控他们的决策对应用程序性能和成本的影响。",
                    "title_zh": "管理弹性Redis缓存的框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00052",
                    "title": "HyperPubSub: Blockchain Based Publish/Subscribe",
                    "authors": "Gewu Bu, Thanh Son Lam Nguyen, Maria Potop-Butucaru, Kim Loan Thai",
                    "abstract": "In this paper we describe the architecture and the implementation of a broker based publish/subscribe system where the broker role is played by a private blockchain, Hyperledger Fabric. We show the effectiveness of our architecture by implementing and deploying a photo trading platform. Interestingly, our architecture is generic enough to be adapted to any digital asset trading.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1907.03627"
                    },
                    "abstract_zh": "在本文中，我们描述了基于代理的发布/订阅系统的架构和实现，其中代理角色由私有区块链Hyperledger结构扮演。我们通过实现和部署照片交易平台来展示我们的架构的有效性。有趣的是，我们的架构足够通用，可以适用于任何数字资产交易。",
                    "title_zh": "超级订阅:基于区块链的发布/订阅"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00053",
                    "title": "ARTEMIS: An Intrusion Detection System for MQTT Attacks in Internet of Things",
                    "authors": "Ege Ciklabakkal, Ataberk Donmez, Mert Erdemir, Emre Süren, Mert Kaan Yilmaz, Pelin Angin",
                    "abstract": "The Internet of Things (IoT) is now being used increasingly in transportation, healthcare, agriculture, smart home and city systems. IoT devices, the number of which is expected to reach 25 billion all over the world by 2021, are required to be deployed very fast, taking into account commercial pressures. This results in a very important layer, i.e. security, being either completely neglected or having significant shortcomings. Since IoT has a heterogeneous structure, there is a need for intrusion detection systems (IDSs) that take into account the specifics of an IoT system architecture, including the computing power limitations, variety of protocols and prevalence of zero-day attacks. In this paper, we describe ARTEMIS, an IDS for IoT, which processes data from IoT devices using machine learning to detect deviations from the normal behavior of the system and generates alerts in case of anomalies. We have implemented a prototype of the system using IoT devices subscribed to topics at an MQTT broker and provide experimental evaluation of the system under MQTT-related attacks.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "物联网(IoT)现在越来越多地用于交通、医疗保健、农业、智能家居和城市系统。考虑到商业压力，预计到2021年全球物联网设备的数量将达到250亿，因此要求部署速度非常快。这导致非常重要的一层，即安全性，要么被完全忽略，要么有重大缺陷。由于物联网具有异构结构，因此需要入侵检测系统(IDSs)考虑物联网系统架构的具体情况，包括计算能力限制、各种协议和零日攻击的流行程度。在本文中，我们描述了ARTEMIS，这是一种用于物联网的IDS，它使用机器学习来处理来自物联网设备的数据，以检测系统正常行为的偏差，并在出现异常时生成警报。我们使用在MQTT代理订阅主题的物联网设备实现了该系统的原型，并在MQTT相关攻击下提供了该系统的实验评估。",
                    "title_zh": "ARTEMIS:一种针对物联网MQTT攻击的入侵检测系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00054",
                    "title": "Atomic Swapping Bitcoins and Ethers",
                    "authors": "Léonard Lys, Arthur Micoulet, Maria Potop-Butucaru",
                    "abstract": "Blockchains interoperability is one of the hardest problems to be solved in the nowadays blockchain ecosystem that contains thousands of different blockchains. This paper focuses on swapping assets from a blockchain to another without a trusted third party. One recent scheme for atomically swapping assets, Atomic Cross Chain Swap (ACCS), has been formally analyzed in [2]. This paper proposes an implementation of an ACCS between the two most valued crypto-currencies today: Bitcoin and Ether.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-02353945/file/conference_041818.pdf"
                    },
                    "abstract_zh": "区块链互操作性是当今包含成千上万不同区块链的区块链生态系统中最难解决的问题之一。本文关注的是在没有可信第三方的情况下，将资产从一个区块链交换到另一个。最近一个原子交换资产的方案，原子交叉链交换(ACCS)，已经在[2]中进行了正式分析。本文提出了在当今最有价值的两种加密货币:比特币和以太网之间实现一个ACCS。",
                    "title_zh": "原子交换比特币和以太"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00055",
                    "title": "A Testbed for Data Routing in Low-Power WSNs using DV-Hop Based Trajectory Encoding Algorithm",
                    "authors": "Xiaofei Cao, Sanjay Madria",
                    "abstract": "Trajectory-based routing is a common data forwarding protocol while collecting sensor data during a disaster or in a battlefield for situation-awareness. However, wireless sensor networks (WSNs) have limitations in available bandwidth and energy. The trajectory-based routing protocols could reduce redundant broadcasting to save energy and bandwidth significantly. In this demo, we will demonstrate the working of a DV-Hop (Distance Vector Hop) based trajectory encoding algorithm using virtual coordinates rather than using GPS data. Using the proposed trajectory based routing protocol, we achieve energy savings, reduced latency, reliability, better coverage, while routing data from a source node to a mobile sink.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于轨迹的路由是一种常见的数据转发协议，在灾难或战场中收集传感器数据以了解情况。然而，无线传感器网络在可用带宽和能量方面存在限制。基于轨迹的路由协议可以减少冗余广播，从而显著节省能量和带宽。在这个演示中，我们将演示一个基于DV-Hop(距离向量跳跃)的轨迹编码算法的工作原理，它使用虚拟坐标而不是GPS数据。使用所提出的基于轨迹的路由协议，我们在将数据从源节点路由到移动汇聚节点的同时，实现了节能、减少延迟、可靠性、更好的覆盖。",
                    "title_zh": "基于DV-Hop轨迹编码算法的低功耗无线传感器网络数据路由实验平台"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00056",
                    "title": "ABEONA: An Architecture for Energy-Aware Task Migrations from the Edge to the Cloud",
                    "authors": "Isabelly Rocha, Gabriel Vinha, Andrey Brito, Pascal Felber, Marcelo Pasin, Valerio Schiavoni",
                    "abstract": "This paper presents our preliminary results with ABEONA, an edge-to-cloud architecture that allows migrating tasks from low-energy, resource-constrained devices on the edge up to the cloud. Our preliminary results on artificial and real-world datasets show that it is possible to execute workloads in a more efficient manner energy-wise by scaling horizontally at the edge, without negatively affecting the execution runtime.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1910.03445"
                    },
                    "abstract_zh": "本文展示了我们使用ABEONA的初步结果，Abe ona是一种边缘到云的架构，允许将任务从边缘上的低能耗、资源受限的设备迁移到云。我们在人工和真实数据集上的初步结果表明，通过在边缘水平扩展，可以以更高效的方式执行工作负载，而不会对执行运行时产生负面影响。",
                    "title_zh": "ABEONA:从边缘到云的节能任务迁移架构"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00057",
                    "title": "Low-Cost Serverless SIEM in the Cloud",
                    "authors": "Adriano Serckumecka, Ibéria Medeiros, Alysson Bessani",
                    "abstract": "Security systems such as the Security Information and Event Management (SIEMs) have been used to monitor logs and correlate data to quickly detect and respond to incidents. Despite their advantages, SIEMs are expensive to deploy and maintain, requiring extra budget and specialized staff. Another concern is the event retention period, which events are stored for a short period of time, missing important information about how threats may have affected the company infrastructure in the past. This thesis aims to improve these issues by using low-cost cloud services to correlate and store security events. We will investigate techniques to index, compress and store events in the cloud in a cost-efficient and safe way for a long time. We will create a cloud correlation engine using a serverless platform, such as Amazon Lambda. This approach can minimize the complexity of managing SIEMs in place, charging the customer only for the time actually spent processing events. Finally, we will integrate the storage and correlation engine into a cloud SIEM, providing also a monitoring tool, building a complete and innovative low-cost cloud-based security monitoring solution.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "安全信息和事件管理(SIEMs)等安全系统已用于监控日志和关联数据，以快速检测和响应事件。尽管有这些优势，SIEMs的部署和维护成本很高，需要额外的预算和专业人员。另一个问题是事件保留期，即事件只存储很短的一段时间，遗漏了有关威胁在过去如何影响公司基础架构的重要信息。本文旨在通过使用低成本的云服务来关联和存储安全事件，从而改善这些问题。我们将长期研究在云中以经济有效和安全的方式索引、压缩和存储事件的技术。我们将使用无服务器平台创建一个云关联引擎，比如Amazon Lambda。这种方法可以最大限度地降低就地管理SIEMs的复杂性，只对客户处理事件实际花费的时间收费。最后，我们将把存储和关联引擎集成到一个云SIEM中，同时提供一个监控工具，构建一个完整的、创新的低成本、基于云的安全监控解决方案。",
                    "title_zh": "云中的低成本无服务器SIEM"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS47363.2019.00058",
                    "title": "Making Federated Networks More Distributed",
                    "authors": "Alex Auvolat",
                    "abstract": "Federated networks such as Mastodon or Matrix have seen rising usage thanks to their ability to provide users with good privacy and independence from large service providers, while retaining the familiar model of server-backed websites or mobile apps with its advantages of speed, availability and ease of use. However such systems are fragile since each individual server of the federation is a single point of failure for its users. We argue that new secure distributed algorithms could be conceived and applied without changing the server-backed nature of the system, and that such a configuration would provide systemic resilience and better independence of end users from their service providers, without sacrificing privacy, availability, efficiency or ease of use.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Mastodon或Matrix等联合网络的使用量不断上升，这是因为它们能够为用户提供良好的隐私和独立于大型服务提供商的能力，同时保留了服务器支持的网站或移动应用程序的熟悉模式，具有速度、可用性和易用性的优势。然而，这样的系统是脆弱的，因为联盟的每个单独的服务器对于其用户来说是单点故障。我们认为，可以在不改变系统的服务器支持性质的情况下构思和应用新的安全分布式算法，并且这种配置将提供系统弹性和最终用户与其服务提供商的更好独立性，而不会牺牲隐私、可用性、效率或易用性。",
                    "title_zh": "使联合网络更加分散"
                }
            ]
        }
    ],
    "2017": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2017.html",
            "conf_title": "36. SRDS 2017: Hong Kong",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8067712/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.9",
                    "title": "Fine-Grained Consistency Upgrades for Online Services",
                    "authors": "Filipe Freitas, João Leitão, Nuno M. Preguiça, Rodrigo Rodrigues",
                    "abstract": "Online services such as Facebook or Twitter have public APIs to enable an easy integration of these services with third party applications. However, the developers who design these applications have no information about the consistency provided by these services, which exacerbates the complexity of reasoning about the semantics of the applications they are developing. In this paper, we show that is possible to deploy a transparent middleware between the application and the service, which enables a fine-grained control over the session guarantees that comprise the consistency semantics provided by these APIs, without having to gain access to the implementation of the underlying services. We evaluated our middleware using the Facebook public API and the Redis datastore, and our results show that we are able to provide fine-grained control of the consistency semantics incurring in a small local storage and modest latency overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "脸书或Twitter等在线服务拥有公共API，可以轻松地将这些服务与第三方应用集成在一起。然而，设计这些应用程序的开发人员没有关于这些服务提供的一致性的信息，这加剧了对他们正在开发的应用程序的语义进行推理的复杂性。在本文中，我们展示了在应用程序和服务之间部署一个透明的中间件是可能的，它可以对包含这些API提供的一致性语义的会话保证进行细粒度控制，而不必访问底层服务的实现。我们使用脸书公共API和Redis datastore评估了我们的中间件，我们的结果表明，我们能够以较小的本地存储和适度的延迟开销提供对一致性语义的细粒度控制。",
                    "title_zh": "在线服务的细粒度一致性升级"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.10",
                    "title": "A Practical Framework for Privacy-Preserving NoSQL Databases",
                    "authors": "Ricardo Macedo, João Paulo, Rogerio Pontes, Bernardo Portela, Tiago Oliveira, Miguel Matos, Rui Oliveira",
                    "abstract": "Cloud infrastructures provide database services as cost-efficient and scalable solutions for storing and processing large amounts of data. To maximize performance, these services require users to trust sensitive information to the cloud provider, which raises privacy and legal concerns. This represents a major obstacle to the adoption of the cloud computing paradigm. Recent work addressed this issue by extending databases to compute over encrypted data. However, these approaches usually support a single and strict combination of cryptographic techniques invariably making them application specific. To assess and broaden the applicability of cryptographic techniques in secure cloud storage and processing, these techniques need to be thoroughly evaluated in a modular and configurable database environment. This is even more noticeable for NoSQL data stores where data privacy is still mostly overlooked. In this paper, we present a generic NoSQL framework and a set of libraries supporting data processing cryptographic techniques that can be used with existing NoSQL engines and composed to meet the privacy and performance requirements of different applications. This is achieved through a modular and extensible design that enables data processing over multiple cryptographic techniques applied on the same database. For each technique, we provide an overview of its security model, along with an extensive set of experiments. The framework is evaluated with the YCSB benchmark, where we assess the practicality and performance tradeoffs for different combinations of cryptographic techniques. The results for a set of macro experiments show that the average overhead in NoSQL operations performance is below 15%, when comparing our system with a baseline database without privacy guarantees.",
                    "files": {
                        "openAccessPdf": "http://repositorio.inesctec.pt/bitstreams/2a0d697f-cbe4-4584-97cb-10918e443abc/download"
                    },
                    "abstract_zh": "云基础设施提供数据库服务，作为存储和处理大量数据的经济高效且可扩展的解决方案。为了最大限度地提高性能，这些服务要求用户将敏感信息托付给云提供商，这引发了隐私和法律问题。这是采用云计算模式的一个主要障碍。最近的工作通过将数据库扩展到基于加密数据的计算来解决这个问题。然而，这些方法通常支持加密技术的单一和严格的组合，总是使它们特定于应用。为了评估和扩大加密技术在安全云存储和处理中的适用性，需要在模块化和可配置的数据库环境中彻底评估这些技术。这对于NoSQL的数据商店来说更加明显，在那里数据隐私仍然是最容易被忽视的。在本文中，我们提出了一个通用的NoSQL框架和一组支持数据处理加密技术的库，它们可以与现有的NoSQL引擎一起使用，并被组合以满足不同应用的隐私和性能要求。这是通过模块化和可扩展的设计实现的，该设计允许在同一数据库上应用多种加密技术进行数据处理。对于每种技术，我们都提供了其安全模型的概述，以及一组广泛的实验。该框架通过YCSB基准进行评估，我们评估了不同加密技术组合的实用性和性能权衡。一组宏实验的结果表明，当我们的系统与没有隐私保证的基线数据库比较时，NoSQL操作性能的平均开销低于15%。",
                    "title_zh": "保护隐私的NoSQL数据库实用框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.11",
                    "title": "Parameterized and Runtime-Tunable Snapshot Isolation in Distributed Transactional Key-Value Stores",
                    "authors": "Hengfeng Wei, Yu Huang, Jian Lu",
                    "abstract": "Several relaxed variants of Snapshot Isolation (SI) have been proposed for improved performance in distributed transactional key-value stores. These relaxed variants, however, provide no specification or control of the severity of the anomalies with respect to SI. They have also been designed to be used statically throughout the whole system life cycle. To overcome these drawbacks, we propose the idea of parameterized and runtime-tunable snapshot isolation. We first define a new transactional consistency model called Relaxed Version Snapshot Isolation (RVSI), which can formally and quantitatively specify the anomalies it may produce with respect to SI. To this end, we decompose SI into three \"view properties\", for each of which we introduce a parameter to quantify one of three kinds of possible anomalies: k1-BV (k1-version bounded backward view), k2-FV (k2-version bounded forward view), and k3-SV (k3-version bounded snapshot view). We then implement a prototype partitioned replicated distributed transactional key-value store called Chameleon across multiple data centers. While achieving RVSI, Chameleon allows each transaction to dynamically tune its consistency level at runtime. The experiments show that RVSI helps to reduce the transaction abort rates when applications are willing to tolerate certain anomalies. We also evaluate the individual impacts of k1-BV, k2-FV, and k3-SV on reducing the transaction abort rates in various scenarios. We find that it depends on the issue delays between clients and replicas which of k1 and k2 plays a major role in reducing transaction abort rates.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了提高分布式事务性键值存储的性能，已经提出了几种宽松的快照隔离(SI)变体。然而，这些宽松的变体没有提供关于SI异常严重性的规范或控制。它们也被设计成在整个系统生命周期中静态使用。为了克服这些缺点，我们提出了参数化和运行时可调的快照隔离的思想。我们首先定义了一个新的事务一致性模型，称为宽松版本快照隔离(RVSI ),它可以正式地和定量地指定它可能产生的关于SI的异常。为此，我们将SI分解为三个“视图属性”，对于每个属性，我们引入一个参数来量化三种可能的异常之一:k1-BV(k1-版本有界后向视图)、k2-FV(k2-版本有界前向视图)和k3-SV(k3-版本有界快照视图)。然后，我们跨多个数据中心实现了一个名为Chameleon的原型分区复制分布式事务键值存储。在实现RVSI的同时，Chameleon允许每个事务在运行时动态调整其一致性级别。实验表明，当应用程序愿意容忍某些异常时，RVSI有助于降低事务中止率。我们还评估了k1-BV、k2-FV和k3-SV在不同场景下对降低事务中止率的影响。我们发现它取决于客户端和副本之间的发布延迟，k1和k2中的哪一个在降低事务中止率中起主要作用。",
                    "title_zh": "分布式事务键值存储中参数化和运行时可调的快照隔离"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.12",
                    "title": "Robust Multi-Resource Allocation with Demand Uncertainties in Cloud Scheduler",
                    "authors": "Jianguo Yao, Qiumin Lu, Hans-Arno Jacobsen, Haibing Guan",
                    "abstract": "Cloud scheduler manages multi-resources (e.g., CPU, GPU, memory, storage etc.) in cloud platform to improve resource utilization and achieve cost-efficiency for cloud providers. The optimal allocation for multi-resources has become a key technique in cloud computing and attracted more and more researchers' attentions. The existing multi-resource allocation methods are developed based on a condition that the job has constant demands for multi-resources. However, these methods may not apply in a real cloud scheduler due to the dynamic resource demands in jobs' execution. In this paper, we study a robust multi-resource allocation problem with uncertainties brought by varying resource demands. To this end, the cost function is chosen as either of two multi-resource efficiency-fairness metrics called Fairness on Dominant Shares and Generalized Fairness on Jobs, and we model the resource demand uncertainties through three typical models, i.e., scenario demand uncertainty, box demand uncertainty and ellipsoidal demand uncertainty. By solving an optimization problem we get the solution for robust multi-resource allocation with uncertainties for cloud scheduler. The extensive simulations show that the proposed approach can handle the resource demand uncertainties and the cloud scheduler runs in an optimized and robust manner.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云调度程序管理多种资源(例如，CPU、GPU、内存、存储等)。)来提高资源利用率，实现云提供商的成本效益。多资源的优化分配已经成为云计算的一项关键技术，受到越来越多研究者的关注。现有的多资源分配方法都是基于作业对多资源有恒定需求的情况下发展起来的。然而，由于作业执行过程中的动态资源需求，这些方法可能不适用于真正的云调度器。在本文中，我们研究了一个鲁棒的多资源分配问题，该问题具有由变化的资源需求带来的不确定性。为此，成本函数被选择为两个多资源效率-公平性度量标准，即主导份额公平性和工作广义公平性，我们通过三种典型模型，即情景需求不确定性、箱式需求不确定性和椭球需求不确定性，对资源需求不确定性进行建模。通过求解一个优化问题，我们得到了具有不确定性的云调度器鲁棒多资源分配的解。大量的仿真实验表明，该方法能够处理资源需求的不确定性，云调度器能够以一种优化和鲁棒的方式运行。",
                    "title_zh": "云调度器中需求不确定的鲁棒多资源分配"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.13",
                    "title": "Stateless Reliable Geocasting",
                    "authors": "Jordan Adamek, Mikhail Nesterenko, James Scott Robinson, Sébastien Tixeuil",
                    "abstract": "We present two geometric routing algorithms that reliably deliver messages to all devices in a geocast region. One algorithm is based on flooding, the other on concurrent geometric routing. They are the fist known stateless geocasting algorithms. We formally prove the algorithms correct, evaluate their performance through abstract and concrete simulation and estimate their message complexity.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了两种几何路由算法，可靠地将消息传递到地理广播区域中的所有设备。一种算法基于洪泛，另一种基于并发几何路由。它们是第一个已知的无状态地理预测算法。我们形式化地证明了算法的正确性，通过抽象和具体的仿真评估了算法的性能，并估计了算法的消息复杂度。",
                    "title_zh": "无状态可靠地理预测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.14",
                    "title": "Controlling Cascading Failures in Interdependent Networks under Incomplete Knowledge",
                    "authors": "Diman Zad Tootaghaj, Novella Bartolini, Hana Khamfroush, Thomas La Porta",
                    "abstract": "Vulnerability due to inter-connectivity of multiple networks has been observed in many complex networks. Previous works mainly focused on robust network design and on recovery strategies after sporadic or massive failures in the case of complete knowledge of failure location. We focus on cascading failures involving the power grid and its communication network with consequent imprecision in damage assessment. We tackle the problem of mitigating the ongoing cascading failure and providing a recovery strategy. We propose a failure mitigation strategy in two steps: 1) Once a cascading failure is detected, we limit further propagation by re-distributing the generator and load's power. 2) We formulate a recovery plan to maximize the total amount of power delivered to the demand loads during the recovery intervention. Our approach to cope with insufficient knowledge of damage locations is based on the use of a new algorithm to determine consistent failure sets (CFS). We show that, given knowledge of the system state before the disruption, the CFS algorithm can find all consistent sets of unknown failures in polynomial time provided that, each connected component of the disrupted graph has at least one line whose failure status is known to the controller.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在许多复杂网络中已经观察到由于多个网络的互连性而导致的脆弱性。以前的工作主要集中在鲁棒的网络设计和在完全知道故障位置的情况下在偶发或大规模故障后的恢复策略上。我们关注涉及电网及其通信网络的连锁故障，以及随之而来的损失评估的不精确性。我们解决了减轻持续级联故障并提供恢复策略的问题。我们提出分两步的故障缓解策略:1)一旦检测到级联故障，我们通过重新分配发电机和负载的功率来限制进一步的传播。2)我们制定恢复计划，以在恢复干预期间最大化输送给需求负载的总电量。我们处理损伤位置知识不足的方法是基于使用一种新的算法来确定一致失效集(CFS)。我们证明，给定中断前系统状态的知识，CFS算法可以在多项式时间内找到所有未知故障的一致集合，只要中断图的每个连通分量至少有一条线的故障状态为控制器所知。",
                    "title_zh": "不完全知识下控制相互依赖网络中的级联失效"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.15",
                    "title": "On Availability for Blockchain-Based Systems",
                    "authors": "Ingo Weber, Vincent Gramoli, Alexander Ponomarev, Mark Staples, Ralph Holz, An Binh Tran, Paul Rimba",
                    "abstract": "Blockchain has recently gained momentum. Startups, enterprises, banks, and government agencies around the world are exploring the use of blockchain for broad applications including public registries, supply chains, health records, and voting. Dependability properties, like availability, are critical for many of these applications, but the guarantees offered by the blockchain technology remain unclear, especially from an application perspective. In this paper, we identify the availability limitations of two mainstream blockchains, Ethereum and Bitcoin. We demonstrate that while read availability of blockchains is typically high, write availability - for transaction management - is actually low. For Ethereum, we collected 6 million transactions over a period of 97 days. First, we measured the time for transactions to commit as required by the applications. Second, we observed that some transactions never commit, due to the inherent blockchain design. Third and perhaps even more dramatically, we identify the consequences of the lack of built-in options for explicit abort or retry that can maintain the application in an uncertain state, where transactions remain pending (neither aborted nor committed) for an unknown duration. Finally we propose techniques to mitigate the availability limitations of existing blockchains, and experimentally test the efficacy of these techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "区块链最近势头强劲。世界各地的初创公司、企业、银行和政府机构都在探索将区块链用于广泛的应用，包括公共注册、供应链、医疗记录和投票。可靠性属性，如可用性，对于许多这些应用来说是至关重要的，但区块链技术提供的保证仍然不清楚，特别是从应用的角度来看。在本文中，我们确定了以太坊和比特币这两种主流区块链的可用性限制。我们证明，虽然区块链的读可用性通常很高，但对于事务管理来说，写可用性实际上很低。对于以太坊，我们在97天内收集了600万笔交易。首先，我们测量了应用程序所需的事务提交时间。其次，我们观察到，由于固有的区块链设计，一些事务永远不会提交。第三，也许更引人注目的是，我们确定了缺乏显式中止或重试的内置选项的后果，这些选项可以将应用程序保持在不确定的状态，在这种状态下，事务在未知的持续时间内保持挂起(既不是中止也不是提交)。最后，我们提出了减轻现有区块链可用性限制的技术，并通过实验测试了这些技术的有效性。",
                    "title_zh": "基于区块链的系统的可用性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.16",
                    "title": "A Horizontally Scalable and Reliable Architecture for Location-Based Publish-Subscribe",
                    "authors": "Bertil Chapuis, Benoît Garbinato, Lucas Mourot",
                    "abstract": "With billions of connected users and objects, location-based services face a massive scalability challenge. We propose a horizontally-scalable and reliable location-based publish/subscribe architecture that can be deployed on a cluster made of commodity hardware. As many modern location-based publish/subscribe systems, our architecture supports moving publishers, as well as moving subscribers. When a publication moves in the range of a subscription, the owner of this subscription is instantly notified via a server-initiated event, usually in the form of a push notification. To achieve this, most existing solutions rely on classic indexing data structures, such as R-trees, and they struggle at scaling beyond the scope of a single computing unit. Our architecture introduces a multi-step routing mechanism that, to achieve horizontal scalability, efficiently combines range partitioning, consistent hashing and a min-wise hashing agreement. In case of node failure, an active replication strategy ensures a reliable delivery of publication throughout the multistep routing mechanism. From an algorithmic perspective, we show that the number of messages required to compute a match is optimal in the execution model we consider and that the number of routing steps is constant. Using experimental results, we show that our method achieves high throughput, low latency and scales horizontally. For example, with a cluster made of 200~nodes, our architecture can process up to 190'000 location updates per second for a fleet of nearly 1'900'000 moving entities, producing more than 130'000 matches per second.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着数十亿连接的用户和对象，基于位置的服务面临着巨大的可扩展性挑战。我们提出了一个可水平扩展的可靠的基于位置的发布/订阅架构，它可以部署在由商用硬件组成的集群上。正如许多现代的基于位置的发布/订阅系统一样，我们的体系结构支持移动发布者和移动订阅者。当发布在订阅范围内移动时，该订阅的所有者会通过服务器启动的事件立即得到通知，通常采用推送通知的形式。为了实现这一点，大多数现有的解决方案依赖于经典的索引数据结构，如R树，并且它们难以扩展到单个计算单元的范围之外。我们的架构引入了一种多步路由机制，该机制有效地结合了范围划分、一致散列和最小散列协议，以实现水平可扩展性。在节点出现故障的情况下，主动复制策略可以确保通过多步路由机制可靠地传递发布内容。从算法的角度来看，我们表明，在我们考虑的执行模型中，计算匹配所需的消息数量是最优的，并且路由步骤的数量是恒定的。使用实验结果，我们表明我们的方法实现了高吞吐量，低延迟和水平扩展。例如，对于一个由200个节点组成的集群，我们的体系结构每秒可以处理多达190，000个位置更新，从而产生超过130，000个匹配。",
                    "title_zh": "一种可水平扩展的可靠的基于位置的发布-订阅体系结构"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.21",
                    "title": "On the Robustness of a Neural Network",
                    "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Sébastien Rouault",
                    "abstract": "With the development of neural networks based machine learning and their usage in mission critical applications, voices are rising against the black box aspect of neural networks as it becomes crucial to understand their limits and capabilities. With the rise of neuromorphic hardware, it is even more critical to understand how a neural network, as a distributed system, tolerates the failures of its computing nodes, neurons, and its communication channels, synapses. Experimentally assessing the robustness of neural networks involves the quixotic venture of testing all the possible failures, on all the possible inputs, which ultimately hits a combinatorial explosion for the first, and the impossibility to gather all the possible inputs for the second.In this paper, we prove an upper bound on the expected error of the output when a subset of neurons crashes. This bound involves dependencies on the network parameters that can be seen as being too pessimistic in the average case. It involves a polynomial dependency on the Lipschitz coefficient of the neurons' activation function, and an exponential dependency on the depth of the layer where a failure occurs. We back up our theoretical results with experiments illustrating the extent to which our prediction matches the dependencies between the network parameters and robustness. Our results show that the robustness of neural networks to the average crash can be estimated without the need to neither test the network on all failure configurations, nor access the training set used to train the network, both of which are practically impossible requirements.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1707.08167"
                    },
                    "abstract_zh": "随着基于机器学习的神经网络的发展及其在任务关键型应用中的使用，反对神经网络黑盒方面的声音正在兴起，因为了解它们的限制和能力变得至关重要。随着神经形态硬件的兴起，理解作为分布式系统的神经网络如何容忍其计算节点、神经元及其通信通道突触的故障变得更加关键。用实验方法评估神经网络的稳健性涉及对所有可能的输入测试所有可能的失败的不切实际的冒险，对于第一种情况，最终会遇到组合爆炸，对于第二种情况，不可能收集所有可能的输入。在本文中，我们证明了当神经元子集崩溃时输出的期望误差的一个上界。这个界限包括对网络参数的依赖性，在一般情况下，这些参数被认为是过于悲观的。它包括对神经元激活函数的Lipschitz系数的多项式依赖性，以及对发生故障的层的深度的指数依赖性。我们用实验来支持我们的理论结果，这些实验说明了我们的预测与网络参数和鲁棒性之间的依赖性相匹配的程度。我们的结果表明，可以估计神经网络对平均碰撞的鲁棒性，而不需要在所有故障配置上测试网络，也不需要访问用于训练网络的训练集，这两者实际上都是不可能的要求。",
                    "title_zh": "关于神经网络的鲁棒性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.22",
                    "title": "Automated Fine Tuning of Probabilistic Self-Stabilizing Algorithms",
                    "authors": "Saba Aflaki, Matthias Volk, Borzoo Bonakdarpour, Joost-Pieter Katoen, Arne Storjohann",
                    "abstract": "Although randomized algorithms have widely been used in distributed computing as a means to tackle impossibility results, it is currently unclear what type of randomization leads to the best performance in such algorithms. This paper proposes three automated techniques to find the probability distribution that achieves minimum average recovery time for an input randomized distributed self-stabilizing protocol without changing the behavior of the algorithm. Our first technique is based on solving symbolic linear algebraic equations in order to identify fastest state reachability in parametric discrete-time Markov chains. The second approach applies parameter synthesis techniques from probabilistic model checking to compute the rational function describing the average recovery time and then uses dedicated solvers to find the optimal parameter valuation. The third approach computes over- and under-approximations of the result for a given parameter region and iteratively refines the regions with minimal recovery time up to the desired precision. The latter approach finds sub-optimal solutions with negligible errors, but it is significantly more scalable in orders of magnitude as compared to the other approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "尽管随机化算法作为一种解决不可能性结果的方法已经广泛应用于分布式计算中，但是目前还不清楚哪种类型的随机化在这种算法中产生最佳性能。本文提出了三种自动技术来寻找概率分布，该概率分布在不改变算法行为的情况下实现输入随机化分布自稳定协议的最小平均恢复时间。我们的第一种技术是基于求解符号线性代数方程，以便识别参数离散时间马尔可夫链中的最快状态可达性。第二种方法应用来自概率模型检查的参数合成技术来计算描述平均恢复时间的有理函数，然后使用专用的解算器来寻找最佳的参数估值。第三种方法计算给定参数区域的结果的过逼近和欠逼近，并以最小的恢复时间迭代地细化区域，直到期望的精度。后一种方法找到了误差可以忽略的次优解，但与其他方法相比，它在数量级上更具可扩展性。",
                    "title_zh": "概率自稳定算法的自动微调"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.23",
                    "title": "Reconfiguring Parallel State Machine Replication",
                    "authors": "Eduardo Alchieri, Fernando Luís Dotti, Odorico Machado Mendizabal, Fernando Pedone",
                    "abstract": "State Machine Replication (SMR) is a well-known technique to implement fault-tolerant systems. In SMR, servers are replicated and client requests are deterministically executed in the same order by all replicas. To improve performance in multi-processor systems, some approaches have proposed to parallelize the execution of non-conflicting requests. Such approaches perform remarkably well in workloads dominated by non-conflicting requests. Conflicting requests introduce expensive synchronization and result in considerable performance loss. Current approaches to parallel SMR define the degree of parallelism statically. However, it is often difficult to predict the best degree of parallelism for a workload and workloads experience variations that change their best degree of parallelism. This paper proposes a protocol to reconfigure the degree of parallelism in parallel SMR on-the-fly. Experiments show the gains due to reconfiguration and shed some light on the behavior of parallel and reconfigurable SMR.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "状态机复制(SMR)是实现容错系统的一种众所周知的技术。在SMR中，服务器被复制，客户端请求由所有副本以相同的顺序确定地执行。为了提高多处理器系统的性能，已经提出了一些方法来并行化非冲突请求的执行。这种方法在以非冲突请求为主的工作负载中表现得非常好。冲突的请求会引入昂贵的同步，并导致相当大的性能损失。当前的并行SMR方法静态地定义了并行度。然而，通常很难预测工作负载的最佳并行度，并且工作负载会经历改变其最佳并行度的变化。提出了一种在并行SMR中动态重新配置并行度的协议。实验显示了由于重新配置而获得的收益，并揭示了并行和可重新配置SMR的行为。",
                    "title_zh": "重新配置并行状态机复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.24",
                    "title": "A Statistical Framework on Software Aging Modeling with Continuous-Time Hidden Markov Model",
                    "authors": "Hiroyuki Okamura, Junjun Zheng, Tadashi Dohi",
                    "abstract": "This paper considers the statistical approach to model software degradation process from time series data of system attributes. We first develop the continuous-time Markov chain (CTMC) model to represent the degradation level of system. By combining the CTMC with system attributes distributions, a continuous-time hidden Markov model (CT-HMM) is proposed as the basic model to represent the degradation level of system. To estimate model parameters, we develop the EM algorithm for CT-HMM. The advantage of this modeling is that the estimated model is directly applied to existing CTMC-based software aging and rejuvenation models. In numerical experiments, we exhibit the performance of our method by simulated data and also demonstrate estimating the software degradation process with experimental data in MySQL database system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文考虑用统计方法从系统属性的时间序列数据中模拟软件退化过程。我们首先建立连续时间马尔可夫链(CTMC)模型来描述系统的退化程度。将CTMC与系统属性分布相结合，提出了连续时间隐马尔可夫模型(CT-HMM)作为表征系统退化程度的基本模型。为了估计模型参数，我们发展了CT-HMM的EM算法。这种建模的优点是估计的模型直接应用于现有的基于CTMC的软件老化和再生模型。在数值实验中，我们通过模拟数据展示了我们的方法的性能，并通过MySQL数据库系统中的实验数据展示了对软件退化过程的估计。",
                    "title_zh": "基于连续时间隐马尔可夫模型的软件老化建模统计框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.17",
                    "title": "Hybrid-RC: Flexible Erasure Codes with Optimized Recovery Performance and Low Storage Overhead",
                    "authors": "Liuqing Ye, Dan Feng, Yuchong Hu, Qing Liu",
                    "abstract": "Erasure codes are widely used in practical storage systems to prevent disk failure and data loss. However, these codes require excessive disk I/Os and network traffic for recovering unavailable data. As a result, the recovery performance of erasure codes is suboptimal. Among all erasure codes, Minimum Storage Regenerating (MSR) codes can achieve optimal repair bandwidth under the minimum storage during recovery, but some open issues remain to be addressed before applying them in real systems. In this paper, we present Hybrid Regenerating Codes (Hybrid-RC), a new set of erasure codes with optimized recovery performance and low storage overhead. The codes utilize the superiority of MSR codes to compute a subset of data blocks while some other parity blocks are used for reliability maintenance. As a result, our design is near-optimal with respect to storage and network traffic. We show that Hybrid-RC reduces the reconstruction cost by up to 21% compared to the Local Reconstruction Codes (LRC) with the same storage overhead. Most importantly, in Hybrid-RC, each block contributes only half the amount of data when processing a single block failure. Therefore, the number of I/Os consumed per block is reduced by 50%, which is of great help to balance the network load and reduce the latency.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "纠删码广泛应用于实际存储系统中，以防止磁盘故障和数据丢失。但是，这些代码需要过多的磁盘I/o和网络流量来恢复不可用的数据。因此，纠删码的恢复性能是次优的。在所有的纠删码中，最小存储再生(MSR)码可以在恢复过程中以最小的存储获得最佳的修复带宽，但在应用于实际系统之前仍有一些问题需要解决。本文提出了混合再生码(Hybrid-RC ),这是一种具有优化恢复性能和低存储开销的新型纠删码。这些码利用MSR码的优越性来计算数据块的子集，而其他一些奇偶校验块用于可靠性维护。因此，我们的设计在存储和网络流量方面接近最优。我们表明，与具有相同存储开销的本地重建码(LRC)相比，混合RC减少了高达21%的重建成本。最重要的是，在Hybrid-RC中，当处理单个块故障时，每个块只贡献一半的数据量。因此，每个块消耗的I/o数量减少了50%，这对平衡网络负载和降低延迟有很大的帮助。",
                    "title_zh": "混合RC:具有优化恢复性能和低存储开销的灵活擦除码"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.18",
                    "title": "Correlation-Aware Stripe Organization for Efficient Writes in Erasure-Coded Storage Systems",
                    "authors": "Zhirong Shen, Patrick P. C. Lee, Jiwu Shu, Wenzhong Guo",
                    "abstract": "Erasure coding has been extensively employed for data availability protection in production storage systems by maintaining a low degree of data redundancy. However, how to mitigate the parity update overhead of partial stripe writes in erasure-coded storage systems is still a critical concern. In this paper, we reconsider this problem from two new perspectives: data correlation and stripe organization, and propose CASO, a correlation-aware stripe organization algorithm. CASO captures data correlation of a data access stream. It packs correlated data into a small number of stripes to reduce the incurred I/Os in partial stripe writes, and further organizes uncorrelated data into stripes to leverage the spatial locality in later accesses. By differentiating correlated and uncorrelated data in stripe organization, we show via extensive trace-driven evaluation that CASO reduces up to 25.1% of parity updates and accelerates the write speed by up to 28.4%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过维持低程度的数据冗余，擦除编码已被广泛用于生产存储系统中的数据可用性保护。然而，如何减轻擦除编码存储系统中部分条带写入的奇偶校验更新开销仍然是一个关键问题。本文从数据相关性和条带组织两个新的角度重新考虑这个问题，并提出了相关性感知的条带组织算法CASO。CASO捕获数据访问流的数据相关性。它将相关数据打包到少量条带中，以减少部分条带写入中发生的I/o，并进一步将不相关的数据组织到条带中，以便在以后的访问中利用空间局部性。通过区分条带组织中的相关和不相关数据，我们通过广泛的跟踪驱动评估显示，CASO减少了高达25.1%的奇偶校验更新，并将写入速度提高了高达28.4%。",
                    "title_zh": "擦除编码存储系统中高效写入的相关感知条带组织"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.19",
                    "title": "A Simulation Analysis of Reliability in Erasure-Coded Data Centers",
                    "authors": "Mi Zhang, Shujie Han, Patrick P. C. Lee",
                    "abstract": "Erasure coding has been widely adopted to protect data storage against failures in production data centers. Given the hierarchical nature of data centers, characterizing the effects of erasure coding and redundancy placement on the reliability of erasure-coded data centers is critical yet largely unexplored. This paper presents a comprehensive simulation analysis of reliability on erasure-coded data centers. We conduct the analysis by building a discrete-event simulator called SIMEDC, which reports reliability metrics of an erasure-coded data center based on the configurable inputs of the data center topology, erasure codes, redundancy placement, and failure/repair patterns of different subsystems obtained from statistical models or production traces. Our simulation results show that placing erasure-coded data in fewer racks generally improves reliability by reducing cross-rack repair traffic, even though it sacrifices rack-level fault tolerance in the face of correlated failures.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "擦除编码已被广泛用于保护数据存储免受生产数据中心故障的影响。考虑到数据中心的分层性质，描述擦除编码和冗余放置对擦除编码数据中心可靠性的影响是至关重要的，但在很大程度上还未被探索。本文对擦除编码数据中心的可靠性进行了全面的仿真分析。我们通过构建一个名为SIMEDC的离散事件模拟器来进行分析，该模拟器根据从统计模型或生产跟踪中获得的数据中心拓扑结构、擦除代码、冗余放置和不同子系统的故障/修复模式的可配置输入来报告擦除编码数据中心的可靠性指标。我们的模拟结果表明，将擦除编码数据放置在更少的机架中通常会通过减少跨机架修复流量来提高可靠性，尽管在面对相关故障时会牺牲机架级容错能力。",
                    "title_zh": "擦除编码数据中心可靠性的仿真分析"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.20",
                    "title": "Optimal Storage under Unsynchronized Mobile Byzantine Faults",
                    "authors": "Silvia Bonomi, Antonella Del Pozzo, Maria Potop-Butucaru, Sébastien Tixeuil",
                    "abstract": "In this paper we prove lower and matching upper bounds for the number of servers required to implement a regular shared register that tolerates unsynchronized Mobile Byzantine failures. We consider the strongest model of Mobile Byzantine failures to date: agents are moved arbitrarily by an omniscient adversary from a server to another in order to deviate their computation in an unforeseen manner. When a server is infected by an Byzantine agent, it behaves arbitrarily until the adversary decides to move the agent to another server. Previous approaches considered asynchronous servers with synchronous mobile Byzantine agents (yielding impossibility results), and synchronous servers with synchronous mobile Byzantine agents (yielding optimal solutions for regular register implementation, even in the case where servers and agents periods are decoupled). We consider the remaining open case of synchronous servers with unsynchronized agents, that can move at their own pace, and change their pace during the execution of the protocol. Most of our findings relate to lower bounds, and characterizing the model parameters that make the problem solvable. It turns out that unsynchronized mobile Byzantine agent movements requires completely new proof arguments, that can be of independent interest when studying other problems in this model. Additionally, we propose a generic server-based algorithm that emulates a regular register in this model, that is tight with respect to the number of mobile Byzantine agents that can be tolerated. Our emulation spans two awareness models: servers with and without self-diagnose mechanisms. In the first case servers are aware that the mobile Byzantine agent has left and hence they can stop running the protocol until they recover a correct state while in the second case, servers are not aware of their faulty state and continue to run the protocol using an incorrect local state.",
                    "files": {
                        "openAccessPdf": "https://iris.uniroma1.it/bitstream/11573/1022950/2/Bonomi_Postprint_Optimal-Storage_2017.pdf"
                    },
                    "abstract_zh": "在本文中，我们证明了实现容许非同步移动拜占庭故障的常规共享寄存器所需的服务器数量的下限和匹配上限。我们考虑迄今为止最强的移动拜占庭失败模型:代理被一个无所不知的对手任意地从一个服务器移动到另一个服务器，以便以一种不可预见的方式偏离它们的计算。当一台服务器被拜占庭代理感染时，它会任意行为，直到对手决定将代理移动到另一台服务器。以前的方法考虑了具有同步移动拜占庭代理的异步服务器(产生不可能的结果)，以及具有同步移动拜占庭代理的同步服务器(产生常规寄存器实现的最佳解决方案，即使在服务器和代理周期分离的情况下)。我们考虑具有非同步代理的同步服务器的剩余开放情况，它们可以按照自己的速度移动，并且在协议执行期间改变它们的速度。我们的大部分发现都与下界有关，并描述了使问题可解的模型参数。事实证明，不同步的移动拜占庭代理运动需要全新的证明论点，这在研究该模型中的其他问题时可能是独立的兴趣。此外，我们提出了一个通用的基于服务器的算法，该算法在这个模型中模拟一个常规的寄存器，它在可容忍的移动拜占庭代理的数量方面是严格的。我们的仿真跨越了两种感知模型:带和不带自诊断机制的服务器。在第一种情况下，服务器知道移动拜占庭代理已经离开，因此它们可以停止运行协议，直到它们恢复正确的状态，而在第二种情况下，服务器不知道它们的故障状态，并且使用不正确的本地状态继续运行协议。",
                    "title_zh": "非同步移动拜占庭故障下的最优存储"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.25",
                    "title": "PULP: Achieving Privacy and Utility Trade-Off in User Mobility Data",
                    "authors": "Sophie Cerf, Vincent Primault, Antoine Boutet, Sonia Ben Mokhtar, Robert Birke, Sara Bouchenak, Lydia Y. Chen, Nicolas Marchand, Bogdan Robu",
                    "abstract": "Leveraging location information in location-based services leads to improving service utility through geocontextualization. However, this raises privacy concerns as new knowledge can be inferred from location records, such as user's home and work places, or personal habits. Although Location Privacy Protection Mechanisms (LPPMs) provide a means to tackle this problem, they often require manual configuration posing significant challenges to service providers and users. Moreover, their impact on data privacy and utility is seldom assessed. In this paper, we present PULP, a model-driven system which automatically provides user-specific privacy protection and contributes to service utility via choosing adequate LPPM and configuring it. At the heart of PULP is nonlinear models that can capture the complex dependency of data privacy and utility for each individual user under given LPPM considered, i.e., Geo-Indistinguishability and Promesse. According to users' preferences on privacy and utility, PULP efficiently recommends suitable LPPM and corresponding configuration. We evaluate the accuracy of PULP's models and its effectiveness to achieve the privacy-utility trade-off per user, using four real-world mobility traces of 770 users in total. Our extensive experimentation shows that PULP ensures the contribution to location service while adhering to privacy constraints for a great percentage of users, and is orders of magnitude faster than non-model based alternatives.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01578635/file/PID4910579.pdf"
                    },
                    "abstract_zh": "在基于位置的服务中利用位置信息可以通过地理情境化提高服务效用。然而，这引起了隐私问题，因为可以从位置记录中推断出新的知识，例如用户的家庭和工作场所，或者个人习惯。尽管位置隐私保护机制(LPPMs)提供了解决这个问题的手段，但是它们通常需要手动配置，这给服务提供商和用户带来了巨大的挑战。此外，它们对数据隐私和效用的影响很少得到评估。在本文中，我们介绍了一个模型驱动的系统PULP，它通过选择和配置适当的LPPM，自动提供用户特定的隐私保护，并有助于服务效用。PULP的核心是非线性模型，该模型可以在给定的LPPM下捕捉每个个人用户的数据隐私和效用的复杂依赖性，即地理不可区分性和Promesse。根据用户对隐私和实用性的偏好，PULP高效地推荐合适的LPPM和相应的配置。我们使用总共770个用户的四个真实世界移动性痕迹，评估了PULP模型的准确性及其实现每个用户的隐私-效用权衡的有效性。我们的大量实验表明，PULP确保了对位置服务的贡献，同时遵守了大部分用户的隐私约束，并且比基于非模型的替代方案快几个数量级。",
                    "title_zh": "纸浆:在用户移动数据中实现隐私和效用的权衡"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.26",
                    "title": "Incremental Elasticity for NoSQL Data Stores",
                    "authors": "Antonis Papaioannou, Kostas Magoutis",
                    "abstract": "Elasticity actions in NoSQL data stores move large amounts of data over the network to take advantage of new resources. Here we propose incremental elasticity, a new mechanism for scheduling data transfers to a joining server, leading to smoother elasticity actions with a reduced performance impact.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "NoSQL数据存储中的弹性操作通过网络移动大量数据，以利用新资源。在这里，我们提出了增量弹性，这是一种调度数据传输到加入服务器的新机制，可以在降低性能影响的情况下实现更平滑的弹性操作。",
                    "title_zh": "NoSQL数据存储的增量弹性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.27",
                    "title": "CausalSpartan: Causal Consistency for Distributed Data Stores Using Hybrid Logical Clocks",
                    "authors": "Mohammad Roohitavaf, Murat Demirbas, Sandeep S. Kulkarni",
                    "abstract": "Causal consistency is an intermediate consistency model that can be achieved together with high availability and high-performance requirements even in presence of network partitions. In the context of partitioned data stores, it has been shown that implicit dependency tracking using clocks is more efficient than explicit dependency tracking by sending dependency check messages. Existing clock-based solutions depend on monotonic psychical clocks that are closely synchronized. These requirements make current protocols vulnerable to clock anomalies. In this paper, we propose a new clock-based algorithm, CausalSpartan, that instead of physical clocks, utilizes Hybrid Logical Clocks (HLCs). We show that using HLCs, without any overhead, we make the system robust on physical clock anomalies. This improvement is more significant in the context of query amplification, where a single query results in multiple GET/PUT operations. We also show that CausalSpartan decreases the visibility latency for a given data item comparing to existing clock-based approaches. In turn, this reduces the completion time of collaborative applications where two clients accessing two different replicas edit same items of the data store. Like previous protocols, CausalSpartan assumes that a given client does not access more than one replica. We show that in presence of network partitions, this assumption (made in several other works) is essential if one were to provide causal consistency as well as immediate availability to local updates.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "因果一致性是一种中间一致性模型，即使在存在网络分区的情况下，也可以与高可用性和高性能需求一起实现。在分区数据存储的上下文中，已经表明使用时钟的隐式相关性跟踪比通过发送相关性检查消息的显式相关性跟踪更有效。现有的基于时钟的解决方案依赖于紧密同步的单调心理时钟。这些要求使得当前的协议容易受到时钟异常的影响。在本文中，我们提出了一种新的基于时钟的算法，CausalSpartan，它利用混合逻辑时钟代替物理时钟。我们表明，使用HLCs，没有任何开销，我们使系统对物理时钟异常健壮。这种改进在查询放大的上下文中更为显著，在这种情况下，单个查询会导致多个GET/PUT操作。我们还表明，与现有的基于时钟的方法相比，CausalSpartan降低了给定数据项的可见性延迟。反过来，这减少了协作应用的完成时间，在协作应用中，访问两个不同副本的两个客户机编辑数据存储的相同项目。像以前的协议一样，CausalSpartan假设给定的客户端不会访问多个副本。我们表明，在存在网络分区的情况下，如果要提供因果一致性以及本地更新的即时可用性，这一假设(在其他几篇文章中提出)是必不可少的。",
                    "title_zh": "CausalSpartan:使用混合逻辑时钟的分布式数据存储的因果一致性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.28",
                    "title": "DottedDB: Anti-Entropy without Merkle Trees, Deletes without Tombstones",
                    "authors": "Ricardo Jorge Tome Goncalves, Paulo Sérgio Almeida, Carlos Baquero, Victor Fonte",
                    "abstract": "To achieve high availability in the face of network partitions, many distributed databases adopt eventual consistency, allow temporary conflicts due to concurrent writes, and use some form of per-key logical clock to detect and resolve such conflicts. Furthermore, nodes synchronize periodically to ensure replica convergence in a process called anti-entropy, normally using Merkle Trees. We present the design of DottedDB, a Dynamo-like key-value store, which uses a novel node-wide logical clock framework, overcoming three fundamental limitations of the state of the art: (1) minimize the metadata per key necessary to track causality, avoiding its growth even in the face of node churn; (2) correctly and durably delete keys, with no need for tombstones; (3) offer a lightweight anti-entropy mechanism to converge replicated data, avoiding the need for Merkle Trees. We evaluate DottedDB against MerkleDB, an otherwise identical database, but using per-key logical clocks and Merkle Trees for anti-entropy, to precisely measure the impact of the novel approach. Results show that: causality metadata per object always converges rapidly to only one id-counter pair; distributed deletes are correctly achieved without global coordination and with constant metadata; divergent nodes are synchronized faster, with less memory-footprint and with less communication overhead than using Merkle Trees.",
                    "files": {
                        "openAccessPdf": "https://repositorium.sdum.uminho.pt/bitstream/1822/51489/1/DottedDB-SRDS2017.pdf"
                    },
                    "abstract_zh": "为了在面对网络分区时实现高可用性，许多分布式数据库采用最终一致性，允许由于并发写入而产生临时冲突，并使用某种形式的每键逻辑时钟来检测和解决这种冲突。此外，节点定期同步，以确保副本在一个称为反熵的过程中收敛，通常使用Merkle树。我们提出了DottedDB的设计，它是一个类似发电机的键值存储，使用了一个新颖的节点范围的逻辑时钟框架，克服了现有技术的三个基本限制:(1)最小化跟踪因果关系所需的每个键的元数据，即使在面临节点变动时也能避免其增长；(2)正确持久地删除密钥，不需要墓碑；(3)提供轻量级反熵机制来聚合复制的数据，避免对Merkle树的需要。我们针对MerkleDB评估DottedDB，MerkleDB是一个完全相同的数据库，但使用了每个键的逻辑时钟和Merkle树来进行反熵，以精确测量新方法的影响。结果表明:每个对象的因果关系元数据总是快速收敛到仅一个id-counter对；分布式删除在没有全局协调和具有恒定元数据的情况下被正确地实现；与使用Merkle树相比，不同的节点同步速度更快，内存占用更少，通信开销也更少。",
                    "title_zh": "DottedDB:没有Merkle树的反熵，没有墓碑的删除"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.29",
                    "title": "Optimal Cyber-Defense Strategies for Advanced Persistent Threats: A Game Theoretical Analysis",
                    "authors": "Jeffrey Acquaviva, Mark Mahon, Bruce Einfalt, Tom LaPorta",
                    "abstract": "We introduce a novel mathematical model that treats network security as a game between cyber attackers and network administrators. The model takes the form of a zero-sum repeated game where each sub-game corresponds to a possible state of the attacker. Our formulation views state as the set of compromised edges in a graph opposed to the more traditional node-based view. This provides a more expressive model since it allows the defender to anticipate the direction of attack. Both players move independently and in continuous time allowing for the possibility of one player moving several times before the other does. This model shows that defense-in-depth is not always a rational strategy for budget constrained network administrators. Furthermore, a defender can dissuade a rational attacker from attempting to attack a network if the defense budget is sufficiently high. This means that a network administrator does not need to make their system completely free of vulnerabilities, they only to ensure the penalties for being caught outweigh the potential rewards gained.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们引入了一个新颖的数学模型，将网络安全视为网络攻击者和网络管理员之间的博弈。该模型采用零和重复博弈的形式，其中每个子博弈对应于攻击者的一种可能状态。与更传统的基于节点的视图相反，我们的公式视图将状态视为图中折衷边的集合。这提供了一个更具表现力的模型，因为它允许防御者预测攻击的方向。两个玩家独立移动，并在连续的时间内允许一个玩家在另一个之前移动几次。该模型表明，对于预算有限的网络管理员来说，深度防御并不总是一种合理的策略。此外，如果防御预算足够高，防御者可以阻止理性攻击者试图攻击网络。这意味着网络管理员不需要使他们的系统完全没有漏洞，他们只需要确保被抓住的惩罚超过获得的潜在回报。",
                    "title_zh": "高级持续威胁的最优网络防御策略:博弈分析"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.30",
                    "title": "AutoFlowLeaker: Circumventing Web Censorship through Automation Services",
                    "authors": "Shengtuo Hu, Xiaobo Ma, Muhui Jiang, Xiapu Luo, Man Ho Au",
                    "abstract": "By hiding messages inside existing network protocols, anti-censorship tools could empower censored users to visit blocked websites. However, existing solutions generally suffer from two limitations. First, they usually need the support of ISP or the deployment of many customized hosts to conceal the communication between censored users and blocked websites. Second, their manipulations of normal network traffic may result in detectable features, which could be captured by the censorship system. In this paper, to tackle these limitations, we propose a novel framework that exploits the publicly available automation services and the plenty of web services and contents to circumvent web censorship, and realize it in a practical tool named AutoFlowLeaker. Moreover, we conduct extensive experiments to evaluate AutoFlowLeaker, and the results show that it has promising performance and can effectively evade realworld web censorship.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过将信息隐藏在现有的网络协议中，反审查工具可以让被审查的用户访问被屏蔽的网站。然而，现有的解决方案通常受到两个限制。首先，他们通常需要ISP的支持或部署许多定制的主机来隐藏审查用户和被屏蔽网站之间的通信。其次，他们对正常网络流量的操作可能会产生可检测的特征，这些特征可能会被审查系统捕获。在本文中，为了解决这些限制，我们提出了一个新颖的框架，利用公开可用的自动化服务和大量的web服务和内容来绕过web审查，并在一个名为AutoFlowLeaker的实用工具中实现。此外，我们进行了大量的实验来评估AutoFlowLeaker，结果表明它具有良好的性能，可以有效地规避现实世界的网络审查。",
                    "title_zh": "AutoFlowLeaker:通过自动化服务规避网络审查"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.31",
                    "title": "An Unsupervised Multi-Detector Approach for Identifying Malicious Lateral Movement",
                    "authors": "Atul Bohara, Mohammad A. Noureddine, Ahmed M. Fawaz, William H. Sanders",
                    "abstract": "Lateral movement-based attacks are increasingly leading to compromises in large private and government networks, often resulting in information exfiltration or service disruption. Such attacks are often slow and stealthy and usually evade existing security products. To enable effective detection of such attacks, we present a new approach based on graph-based modeling of the security state of the target system and correlation of diverse indicators of anomalous host behavior. We believe that irrespective of the specific attack vectors used, attackers typically establish a command and control channel to operate, and move in the target system to escalate their privileges and reach sensitive areas. Accordingly, we identify important features of command and control and lateral movement activities and extract them from internal and external communication traffic. Driven by the analysis of the features, we propose the use of multiple anomaly detection techniques to identify compromised hosts. These methods include Principal Component Analysis, k-means clustering, and Median Absolute Deviation-based outlier detection. We evaluate the accuracy of identifying compromised hosts by using injected attack traffic in a real enterprise network dataset, for various attack communication models. Our results show that the proposed approach can detect infected hosts with high accuracy and a low false positive rate.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于横向移动的攻击越来越多地导致大型私人和政府网络受损，经常导致信息泄露或服务中断。这种攻击通常是缓慢而隐秘的，并且通常避开现有的安全产品。为了能够有效地检测这种攻击，我们提出了一种新的方法，该方法基于目标系统的安全状态的基于图的建模以及异常主机行为的各种指标的相关性。我们认为，无论使用何种特定的攻击媒介，攻击者通常都会建立一个指挥和控制通道来进行操作，并在目标系统中移动以提升其权限并到达敏感区域。相应地，我们识别指挥控制和横向移动活动的重要特征，并从内部和外部通信流量中提取它们。在特征分析的推动下，我们建议使用多种异常检测技术来识别受损主机。这些方法包括主成分分析、k均值聚类和基于中值绝对偏差的异常值检测。对于各种攻击通信模型，我们通过在真实的企业网络数据集中使用注入的攻击流量来评估识别受损主机的准确性。实验结果表明，该方法能够以较高的准确率和较低的误报率检测出被感染的主机。",
                    "title_zh": "一种用于识别恶意横向移动的无监督多检测器方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.32",
                    "title": "Optimal Network Reconfiguration for Software Defined Networks Using Shuffle-Based Online MTD",
                    "authors": "Jin Bum Hong, Seunghyun Yoon, Hyuk Lim, Dong Seong Kim",
                    "abstract": "A Software Defined Network (SDN) provides functionalities for modifying network configurations. To enhance security, Moving Target Defense (MTD) techniques are deployed in the networks to continuously change the attack surface. In this paper, we realize an MTD system by exploiting the SDN functionality to optimally reconfigure the network topology. We introduce a novel problem Shuffle Assignment Problem (SAP), the reconfiguration of a network topology for enhanced security, and we show how to compute the optimal solution for small-sized networks and the near-optimal solution for large-sized networks using a heuristic method. In addition, we propose a shuffle-based online MTD mechanism, which periodically reconfigures the network topology to continuously change the attack surface. This mechanism also selects an optimal countermeasure using our proposed topological distance metric in real-time when an attack is detected. We demonstrate the feasibility and the effectiveness of our proposed solutions through experimental analysis on an SDN testbed and simulations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件定义网络(SDN)提供修改网络配置的功能。为了增强安全性，移动目标防御(MTD)技术被部署在网络中以不断改变攻击面。在本文中，我们实现了一个MTD系统，通过利用SDN功能来优化重新配置网络拓扑。我们介绍了一个新的问题混洗分配问题(SAP)，一个网络拓扑结构的重新配置以增强安全性，我们展示了如何使用启发式方法计算小型网络的最优解和大型网络的近似最优解。此外，我们提出了一种基于洗牌的在线MTD机制，该机制周期性地重新配置网络拓扑以不断改变攻击面。当检测到攻击时，该机制还使用我们提出的拓扑距离度量实时选择最佳对策。我们通过在SDN测试平台上的实验分析和仿真验证了我们提出的解决方案的可行性和有效性。",
                    "title_zh": "使用基于混洗的在线MTD的软件定义网络的最优网络重构"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.33",
                    "title": "A Greedy-Based Method for Modified Condition/Decision Coverage Testing Criterion",
                    "authors": "Bo-His Li, Chin-Yu Huang",
                    "abstract": "During software regression testing, the code coverage of target program is a crucial factor while we perform test case reduction and prioritization. Modified Condition/ Decision Coverage (MC/DC) is one of the most strict and high-accuracy criterion in code coverage and it is usually considered necessary for adequate testing of critical software. In the past, Hayhurst et al proposed a method to implement the MC/DC criterion that complies with regulatory guidance for DO-178B level A software. Hayhurst's MC/DC approach was to find some test cases which are satisfied by MC/DC criterion for each operator (and, or, not, or xor) in the Boolean expression. However, there could be some problems when using Hayhurst's MC/DC approach to select test cases. In this paper, we discuss how to improve and/or enhance Hayhurst's MC/DC approach by using a greedy-based method. Some experiments are performed based on real programs to evaluate as well as compare the performance of our proposed and Hayhurst's approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在软件回归测试中，目标程序的代码覆盖率是我们进行测试用例缩减和优先级排序的一个关键因素。修正条件/决策覆盖(MC/DC)是代码覆盖中最严格和高精度的准则之一，通常被认为是对关键软件进行充分测试所必需的。过去，Hayhurst等人提出了一种实现MC/DC标准的方法，该标准符合DO-178 b A级软件的管理指南。海赫斯特的MC/DC方法是为布尔表达式中的每个运算符(and、or、not或xor)找到一些满足MC/DC准则的测试用例。然而，当使用海赫斯特的MC/DC方法来选择测试用例时，可能会有一些问题。在本文中，我们讨论了如何通过使用基于贪婪的方法来改进和/或增强海赫斯特的MC/DC方法。基于真实程序进行了一些实验，以评估和比较我们提出的方法和Hayhurst的方法的性能。",
                    "title_zh": "一种基于贪婪的修正条件/决策覆盖测试准则方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.34",
                    "title": "A Resilient Auction Framework for Deadline-Aware Jobs in Cloud Spot Market",
                    "authors": "Abadhan Saumya Sabyasachi, Hussain Mohammed Dipu Kabir, Ahmed Mohamed Abdelmoniem, Subrota Kumar Mondal",
                    "abstract": "Public cloud providers, such as Amazon EC2, offer idle computing resources known as spot instances at a much cheaper rate compared to On-Demand instances. Spot instance prices are set dynamically according to market demand. Cloud users request spot instances by submitting their bid, and if user's bid price exceeds current spot price then a spot instance is assigned to that user. The problem however is that while spot instances are executing their jobs, they can be revoked whenever the spot price rises above the current bid of the user. In such scenarios and to complete jobs reliably, we propose a set of improvements for the cloud spot market which benefits both the provider and users. Typically, the new framework allows users to bid different prices depending on their perceived urgency and nature of the running job. Hence, it practically allow them to negotiate the current bid price in a way that guarantees the timely completion of their jobs. To complement our intuition, we have conducted an empirical study using real cloud spot price traces to evaluate our framework strategies which aim to achieve a resilient deadline-aware auction framework.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "公共云提供商，如Amazon EC2，以比按需实例低得多的价格提供称为spot实例的闲置计算资源。现货实例价格是根据市场需求动态设定的。云用户通过提交他们的投标请求spot实例，如果用户的投标价格超过当前spot价格，那么spot实例被分配给该用户。然而问题是，当spot实例正在执行它们的作业时，只要spot价格高于用户的当前出价，它们就可以被撤销。在这种情况下，为了可靠地完成工作，我们提出了一套对云现货市场的改进，这对提供商和用户都有好处。通常，新框架允许用户根据他们认为的紧急程度和正在运行的作业的性质来出价不同的价格。因此，它实际上允许他们以保证及时完成工作的方式来协商当前的投标价格。为了补充我们的直觉，我们进行了一项实证研究，使用真实的云现货价格跟踪来评估我们的框架策略，旨在实现一个有弹性的截止日期感知拍卖框架。",
                    "title_zh": "云现货市场中截止期敏感作业的弹性拍卖框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.35",
                    "title": "Automated Resource Sharing for Virtualized GPU with Self-Configuration",
                    "authors": "Jianguo Yao, Qiumin Lu, Zhengwei Qi",
                    "abstract": "In this paper, we propose Auto-vGPU, a framework of automated resource sharing for virtualized GPU with self-configuration, to reduce manual intervention in system management while ensuring Service Level Agreement (SLA) targets. Auto-vGPU automatically collects the measurements of system metrics and learns a linear model for each application with dimension reduction. In order to fulfill the automated configuration of controller parameters, we propose a self-control-configuration method featuring the theory of automatic tuning of proportional-integral (PI) regulators. The experimental results of cloud gaming implementation demonstrate that Auto-vGPU is able to automatically build the low-dimension model and configure the control parameters without any manual interventions and the derived controller can adaptively allocate virtualized GPU resource to ensure the high performance of cloud applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们提出了Auto-vGPU，这是一个用于虚拟化GPU的自动资源共享框架，具有自配置功能，可以减少系统管理中的人工干预，同时确保服务级别协议(SLA)目标。Auto-vGPU自动收集系统指标的测量值，并通过降维学习每个应用的线性模型。为了实现控制器参数的自动配置，我们提出了一种基于比例积分(PI)调节器自动整定理论的自控配置方法。云游戏实现的实验结果表明，Auto-vGPU能够自动建立低维模型和配置控制参数，无需任何人工干预，并且派生的控制器能够自适应地分配虚拟化GPU资源，保证云应用的高性能。",
                    "title_zh": "具有自我配置的虚拟化GPU的自动化资源共享"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.36",
                    "title": "Performance Modeling of PBFT Consensus Process for Permissioned Blockchain Network (Hyperledger Fabric)",
                    "authors": "Harish Sukhwani, José M. Martínez, Xiaolin Chang, Kishor S. Trivedi, Andy J. Rindos",
                    "abstract": "While Blockchain network brings tremendous benefits, there are concerns whether their performance would match up with the mainstream IT systems. This paper aims to investigate whether the consensus process using Practical Byzantine Fault Tolerance (PBFT) could be a performance bottleneck for networks with a large number of peers. We model the PBFT consensus process using Stochastic Reward Nets (SRN) to compute the mean time to complete consensus for networks up to 100 peers. We create a blockchain network using IBM Bluemix service, running a production-grade IoT application and use the data to parameterize and validate our models. We also conduct sensitivity analysis over a variety of system parameters and examine the performance of larger networks",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然区块链网络带来了巨大的好处，但人们担心它们的性能是否能与主流IT系统相匹配。本文旨在研究使用实用拜占庭容错(PBFT)的一致性过程是否会成为具有大量对等点的网络的性能瓶颈。我们使用随机奖励网(SRN)对PBFT共识过程进行建模，以计算多达100个对等点的网络完成共识的平均时间。我们使用IBM Bluemix服务创建了一个区块链网络，运行一个生产级物联网应用程序，并使用这些数据来参数化和验证我们的模型。我们还对各种系统参数进行敏感性分析，并检查大型网络的性能",
                    "title_zh": "许可区块链网络PBFT共识过程的性能建模"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.37",
                    "title": "Detecting TCP-Based DDoS Attacks in Baidu Cloud Computing Data Centers",
                    "authors": "Jiahui Jiao, Benjun Ye, Yue Zhao, Rebecca J. Stones, Gang Wang, Xiaoguang Liu, Shaoyan Wang, Guangjun Xie",
                    "abstract": "Cloud computing data centers have become one of the most important infrastructures in the big-data era. When considering the security of data centers, distributed denial of service (DDoS) attacks are one of the most serious problems. Here we consider DDoS attacks leveraging TCP traffic, which are increasingly rampant but are difficult to detect. To detect DDoS attacks, we identify two attack modes: fixed source IP attacks (FSIA) and random source IP attacks (RSIA), based on the source IP address used by attackers. We also propose a real-time TCP-based DDoS detection approach, which extracts effective features of TCP traffic and distinguishes malicious traffic from normal traffic by two decision tree classifiers. We evaluate the proposed approach using a simulated dataset and real datasets, including the ISCX IDS dataset, the CAIDA DDoS Attack 2007 dataset, and a Baidu Cloud Computing Platform dataset. Experimental results show that the proposed approach can achieve attack detection rate higher than 99% with a false alarm rate less than 1%. This approach will be deployed to the victim-end DDoS defense system in Baidu cloud computing data center.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云计算数据中心已经成为大数据时代最重要的基础设施之一。在考虑数据中心的安全性时，分布式拒绝服务(DDoS)攻击是最严重的问题之一。这里我们考虑利用TCP流量的DDoS攻击，这种攻击越来越猖獗，但很难检测。为了检测DDoS攻击，我们根据攻击者使用的源IP地址来识别两种攻击模式:固定源IP攻击(FSIA)和随机源IP攻击(RSIA)。我们还提出了一种基于TCP的实时DDoS检测方法，该方法提取TCP流量的有效特征，并通过两个决策树分类器区分恶意流量和正常流量。我们使用模拟数据集和真实数据集来评估所提出的方法，包括ISCX IDS数据集、CAIDA DDoS Attack 2007数据集和百度云计算平台数据集。实验结果表明，该方法的攻击检测率高于99%，误报率低于1%。该方法将被部署到百度云计算数据中心的受害端DDoS防御系统中。",
                    "title_zh": "百度云计算数据中心基于TCP的DDoS攻击检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.38",
                    "title": "PITR: An Efficient Single-Failure Recovery Scheme for PIT-Coded Cloud Storage Systems",
                    "authors": "Peng Li, Jiaxiang Dong, Xueda Liu, Gang Wang, Zhongwei Li, Xiaoguang Liu",
                    "abstract": "In cloud storage systems, the use of erasure coding results in high read latency and long recovery time when drive or node failure happens. In this paper, we design a parity independent array codes (PIT), a variation of STAR code, which is triple fault tolerant and nearly space-optimal, and also propose an efficient single-failure recovery scheme (PITR) for them to mitigate the problem. In addition, we present a \"shortened\" version of PIT (SPIT) to further reduce the recovery cost. In this way, less disk I/O and network resources are used, thereby reducing the recovery time and achieving a high system reliability and availability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在云存储系统中，当驱动器或节点发生故障时，使用擦除编码会导致高读取延迟和长恢复时间。本文设计了一种奇偶独立阵列码(PIT ),它是STAR码的一种变体，具有三重容错和接近空间最优的特性，并提出了一种有效的单故障恢复方案(PITR)。此外，我们提出了一个“缩短”版本的PIT (SPIT ),以进一步降低恢复成本。这样，使用的磁盘I/O和网络资源更少，从而减少了恢复时间，实现了高系统可靠性和可用性。",
                    "title_zh": "PITR:一种适用于PIT编码云存储系统的高效单故障恢复方案"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.39",
                    "title": "Runtime Measurement Architecture for Bytecode Integrity in JVM-Based Cloud",
                    "authors": "Haihe Ba, Huaizhe Zhou, Jiangchun Ren, Zhiying Wang",
                    "abstract": "While Java Virtual Machine can provide applications with safety property to avoid memory corruption bugs, it continues to encounter some security flaws. Real world exploits show that the current sandbox model can be bypassed. In this paper, we focus our work on bytecode integrity measurement in clouds to identify malicious execution and propose J-IMA architecture to provide runtime measurement and remote attestation for bytecode integrity. To the best of our knowledge, our work is the first measurement approach for dynamically-generated bytecode integrity. Moreover, J-IMA has no need for any modification to host systems and any access to source code.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虽然Java虚拟机可以为应用程序提供安全属性以避免内存损坏错误，但它仍然会遇到一些安全缺陷。现实世界的利用表明，当前的沙盒模型可以被绕过。在本文中，我们将工作集中在云中的字节码完整性度量以识别恶意执行，并提出J-IMA架构来提供字节码完整性的运行时度量和远程证明。据我们所知，我们的工作是动态生成的字节码完整性的第一个测量方法。此外，J-IMA不需要对主机系统进行任何修改，也不需要访问源代码。",
                    "title_zh": "基于JVM的云中字节码完整性的运行时度量体系结构"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.41",
                    "title": "An End-To-End Log Management Framework for Distributed Systems",
                    "authors": "Pinjia He",
                    "abstract": "Logs have been widely employed to ensure the reliability of distributed systems, because logs are often the only data available that records system runtime information. Compared with logs generated by traditional standalone systems, distributed system logs are often large-scale and of great complexity, invalidating many existing log management methods. To address this problem, the paper describes and envisions an end-to-end log management framework for distributed systems. Specifically, this framework includes strategic logging placement, log collection, log parsing, interleaved logs mining, anomaly detection, and problem identification.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "日志已被广泛用于确保分布式系统的可靠性，因为日志通常是记录系统运行时信息的唯一可用数据。与传统的独立系统生成的日志相比，分布式系统日志通常规模大、复杂度高，使得许多现有的日志管理方法失效。为了解决这个问题，本文描述并设想了一个分布式系统的端到端日志管理框架。具体来说，这个框架包括策略日志放置、日志收集、日志解析、交叉日志挖掘、异常检测和问题识别。",
                    "title_zh": "分布式系统的端到端日志管理框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2017.42",
                    "title": "Fault-Tolerant Pattern Formation by Multiple Robots: A Learning Approach",
                    "authors": "Jia Wang, Jiannong Cao, Shan Jiang",
                    "abstract": "In the field of multi-robot system, the problem of pattern formation has attracted considerable attention. However, the faulty sensor input of each robot is crucial for such system to act reliably in practice. Existing works focus on assuming certain noise model and reducing the noise impact. In this work, we propose to use a learning-based method to overcome this kind of barrier. By interacting with the environment, each robot learns to adapt its behavior to eliminate the malfunctions in the sensors and the actuators. Moreover, we plan to evaluate the proposed algorithms by deploying it into the multi-robot platform developed in our research lab",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在多机器人系统领域，模式形成问题引起了广泛关注。然而，每个机器人的错误传感器输入对于这样的系统在实践中可靠地动作是至关重要的。现有的工作集中在假设一定的噪声模型和减少噪声影响。在这项工作中，我们建议使用基于学习的方法来克服这种障碍。通过与环境互动，每个机器人学会调整自己的行为，以消除传感器和执行器中的故障。此外，我们计划通过将所提出的算法部署到我们的研究实验室开发的多机器人平台上来对其进行评估",
                    "title_zh": "多机器人容错模式形成:一种学习方法"
                }
            ]
        }
    ],
    "2018": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2018.html",
            "conf_title": "37th SRDS 2018: Salvador, Brazil",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/8613699/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00011",
                    "title": "Abusing CDNs for Fun and Profit: Security Issues in CDNs' Origin Validation",
                    "authors": "Run Guo, Jianjun Chen, Baojun Liu, Jia Zhang, Chao Zhang, Hai-Xin Duan, Tao Wan, Jian Jiang, Shuang Hao, Yaoqi Jia",
                    "abstract": "Content Delivery Networks (CDNs) are critical Internet infrastructure. Besides high availability and high performance, CDNs also provide security services such as anti-DoS and Web Application Firewalls to CDN-powered websites. However, the massive resources of CDNs may also be leveraged by attackers exploiting their architectural, implementation, or operational weaknesses. In this paper, we show that today's CDN operation is overly loose in customer-controlled forwarding policy and the lack of origin validation leads to a wide range of abuse cases such as DoS attack and stealthy port scan. We systematically study these abuse cases and demonstrate their feasibility in popular CDNs. Further, we evaluate the impact of these abuses by discovering that there are millions of CDN edge servers, and a substantial fraction of them can be abused. Lastly, we propose mitigation solutions against such abuses and discuss their feasibility.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "内容分发网络(cdn)是关键的互联网基础设施。除了高可用性和高性能，CDN还为CDN支持的网站提供安全服务，如防拒绝服务和Web应用防火墙。然而，cdn的大量资源也可能被攻击者利用，利用他们的架构、实现或操作弱点。在本文中，我们指出，当今的CDN运营在客户控制的转发策略方面过于宽松，缺乏来源验证导致了广泛的滥用情况，如DoS攻击和秘密端口扫描。我们系统地研究了这些滥用案例，并证明了它们在流行的cdn中的可行性。此外，我们评估了这些滥用的影响，发现有数百万个CDN边缘服务器，其中很大一部分可能被滥用。最后，我们提出缓解这种滥用的解决方案，并讨论其可行性。",
                    "title_zh": "为了娱乐和利益滥用cdn:cdn来源验证中的安全问题"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00012",
                    "title": "Impact of Man-In-The-Middle Attacks on Ethereum",
                    "authors": "Parinya Ekparinya, Vincent Gramoli, Guillaume Jourjon",
                    "abstract": "Recent theoretical attacks conjectured the vulnerabilities of mainstream blockchains through simulations or assumption violations. Unfortunately, previous results typically omit both the nature of the network under which the blockchain code runs and whether blockchains are private, consortium or public. In this paper, we study the public Ethereum blockchain as well as a consortium and private blockchains and quantify the feasibility of man-in-the-middle and double spending attacks against them. To this end, we list important properties of the Ethereum public blockchain topology, we deploy VMs with constrained CPU quantum to mimic the top-10 mining pools of Ethereum and we attack them, by first partitioning the network through BGP hijacking or ARP spoofing before issuing a Balance Attack to steal coins. Our results demonstrate that attacking Ethereum is remarkably devastating in a consortium or private context as the adversary can multiply her digital assets by 200,000 × in 10 hours through BGP hijacking whereas it would be almost impossible in a public context.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近的理论攻击通过模拟或假设违反来推测主流区块链的脆弱性。不幸的是，以前的结果通常忽略了区块链代码运行的网络的性质，以及区块链是私有的、财团的还是公共的。本文研究了公共以太坊区块链以及一个财团和私人区块链，量化了针对他们的中间人攻击和双重支出攻击的可行性。为此，我们列出了以太坊公共区块链拓扑的重要属性，我们部署了具有受限CPU量子的虚拟机来模拟以太坊的前10个矿池，并对它们进行攻击，首先通过BGP劫持或ARP欺骗对网络进行分区，然后发出平衡攻击来窃取硬币。我们的结果表明，攻击以太坊在财团或私人环境中具有显著的破坏性，因为对手可以通过BGP劫持在10小时内将她的数字资产增加200，000倍，而在公共环境中几乎不可能。",
                    "title_zh": "中间人攻击对以太坊的影响"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00013",
                    "title": "US-AID: Unattended Scalable Attestation of IoT Devices",
                    "authors": "Ahmad Ibrahim, Ahmad-Reza Sadeghi, Gene Tsudik",
                    "abstract": "Embedded devices, personal gadgets and networks thereof are becoming increasingly pervasive, mainly due the advent of, and hype surrounding, the so-called Internet of Things (IoT). Such devices often perform critical actuation tasks, as well as collect, store and process sensitive data. Therefore, as confirmed by recent examples (such as the Mirai botnet), they also represent very attractive attack targets. To mitigate attacks, remote attestation (RA) has emerged as a distinct security service that aims at detecting malware presence on an embedded device. Most prior RA schemes focus on attesting a single devices and do not scale. In recent years, schemes for collective (group or swarm) RA have been designed. However, none is applicable to autonomous and dynamic network settings. This paper presents US-AID – the first collective attestation schemes for large autonomous dynamic networks of embedded devices. AID verifies overall network integrity by combining continuous in-network attestation with a key exchange mechanism and Proofs-of-non-Absence. Using device absence detection US-AID defends against physical attacks that require disconnecting attacked devices form the network for a non-negligible time. We demonstrate feasibility of US-AID with proof-of-concept implementation on state-of-the-art security architectures for low-end embedded devices and on an autonomous testbed formed of six drones. We also assess its scalability and practicality via extensive simulations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "嵌入式设备、个人小工具及其网络正变得越来越普及，这主要是由于所谓的物联网(IoT)的出现和围绕物联网的大肆宣传。这种设备通常执行关键的驱动任务，以及收集、存储和处理敏感数据。因此，正如最近的例子(如Mirai未来组合僵尸网络)所证实的，它们也是非常有吸引力的攻击目标。为了减少攻击，远程证明(RA)已经成为一种独特的安全服务，旨在检测嵌入式设备上恶意软件的存在。大多数现有的RA方案集中于证明单个设备，并且不可扩展。近年来，已经设计了用于集体(组或群)RA的方案。然而，没有一个适用于自治和动态网络设置。本文介绍了US-AID——第一个用于大型自主动态嵌入式设备网络的集体认证方案。AID通过将连续网络内证明与密钥交换机制和不存在证明相结合来验证整体网络完整性。使用设备缺失检测US-AID可以防御物理攻击，这种攻击需要将受攻击的设备与网络断开一段不可忽略的时间。我们展示了US-AID在低端嵌入式设备的最新安全架构和由六架无人机组成的自主测试平台上的概念验证实施的可行性。我们还通过大量的模拟来评估它的可扩展性和实用性。",
                    "title_zh": "US-AID:物联网设备的无人值守可扩展认证"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00014",
                    "title": "A Scalable and Efficient Correlation Engine to Detect Multi-Step Attacks in Distributed Systems",
                    "authors": "David Lanoë, Michel Hurfin, Eric Totel",
                    "abstract": "In distributed systems and in particular in industrial SCADA environments, alert correlation systems are necessary to identify complex multi-step attacks within the huge amount of alerts and events. In this paper we describe an automata-based correlation engine developed in the context of a European project where the main stakeholder was an energy distribution company. The behavior of the engine is extended to fit new requirements. In the proposed solution, a fully automated process generates thousands of correlation rules. Despite this major scalability challenge, the designed correlation engine exhibits good performances. Expected rates of incoming low level alerts approaching several hundreds of elements per second are tolerated. Moreover, the used data structures allow to quickly handle dynamic changes of the set of correlation rules. As some attack steps are not observed, the correlation engine can be tuned to raise an alert when all the attack steps except k of them have been detected. To be able to react to an ongoing attack by taking countermeasures, alerts must also be raised as soon as a significant prefix of an attack scenario is recognized. Fulfilling these additional requirements leads to increase the memory consumption. Therefore purge mechanisms are also proposed and analyzed. An evaluation of the tool is conducted in the context of a SCADA environment.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01949183/file/Hal-SRDS-2018.pdf"
                    },
                    "abstract_zh": "在分布式系统中，尤其是在工业SCADA环境中，警报关联系统对于在大量警报和事件中识别复杂的多步骤攻击是必要的。在本文中，我们描述了一个基于自动机的关联引擎，该引擎是在一个欧洲项目的背景下开发的，该项目的主要利益相关者是一家能源分销公司。引擎的行为被扩展以适应新的需求。在建议的解决方案中，一个完全自动化的过程会生成数千条关联规则。尽管存在这个主要的可扩展性挑战，但所设计的关联引擎表现出良好的性能。每秒接近数百个元素的预期低级别警报传入率是可以接受的。此外，所使用的数据结构允许快速处理关联规则集的动态变化。由于没有观察到一些攻击步骤，可以调整关联引擎，以便在检测到除k个攻击步骤之外的所有攻击步骤时发出警报。为了能够通过采取对策对正在进行的攻击做出反应，还必须在识别到攻击场景的重要前缀时发出警报。满足这些额外要求会导致内存消耗增加。因此，净化机制也被提出和分析。在SCADA环境中对该工具进行了评估。",
                    "title_zh": "分布式系统中检测多步攻击的可扩展高效关联引擎"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00015",
                    "title": "Practical Continuous Aggregation in Wireless Edge Environments",
                    "authors": "Pedro Ákos Costa, João Leitão",
                    "abstract": "The edge computing paradigm brings the promise of overcoming the practical scalability limitations of cloud computing, that are a result of the high volume of data produced by Internet of Things (IoT) and other large-scale applications. The principle of edge computing is to move computations beyond the data center, closer to end-user devices where data is generated and consumed. This new paradigm creates the opportunity for edge-enabled systems and applications, that have components executing directly and cooperatively on edge devices. Having systems' components, actively and directly, collaborating in the edge, requires some form of distributed monitoring as to adapt to variable operational conditions. Monitoring requires efficient ways to aggregate information collected from multiple devices. In particular, and considering some IoT applications, monitoring will happen among devices that communicate primarily via wireless channels. In this paper we study the practical performance of several distributed continuous aggregation protocols in the wireless ad hoc setting, and propose a novel protocol that is more precise and robust than competing alternative.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "边缘计算范式有望克服云计算的实际可扩展性限制，这是物联网(IoT)和其他大规模应用程序产生的大量数据的结果。边缘计算的原理是将计算移出数据中心，更靠近生成和使用数据的最终用户设备。这种新模式为支持边缘的系统和应用创造了机会，这些系统和应用具有在边缘设备上直接协作执行的组件。让系统的组件主动地、直接地在边缘协作，需要某种形式的分布式监控，以适应变化的操作条件。监控需要有效的方法来汇总从多个设备收集的信息。特别是，考虑到一些物联网应用，监控将发生在主要通过无线信道通信的设备之间。本文研究了几种分布式连续聚合协议在无线ad hoc环境中的实际性能，并提出了一种新的协议，它比竞争对手的协议更加精确和健壮。",
                    "title_zh": "无线边缘环境中的实用连续聚合"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00016",
                    "title": "Breaking the Scalability Barrier of Causal Broadcast for Large and Dynamic Systems",
                    "authors": "Brice Nédelec, Pascal Molli, Achour Mostéfaoui",
                    "abstract": "Many distributed protocols and applications rely on causal broadcast to ensure consistency criteria. However, none of causality tracking state-of-the-art approaches scale in large and dynamic systems. This paper presents a new non-blocking causal broadcast protocol suited for such systems. The proposed protocol outperforms state-of-the-art in size of messages, execution time complexity, and local space complexity. Most importantly, messages piggyback control information the size of which is constant. We prove that for both static and dynamic systems. Consequently, large and dynamic systems can finally afford causal broadcast.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1805.05201"
                    },
                    "abstract_zh": "许多分布式协议和应用依赖因果广播来确保一致性标准。然而，没有一种因果关系跟踪的最新方法能够在大型动态系统中扩展。本文提出了一种新的适用于这类系统的无阻塞因果广播协议。所提出的协议在消息大小、执行时间复杂度和本地空间复杂度方面都优于现有技术。最重要的是，消息附带了大小不变的控制信息。我们证明了对于静态和动态系统。因此，大型动态系统最终能够承受因果广播。",
                    "title_zh": "突破大型动态系统因果广播的可扩展性障碍"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00017",
                    "title": "Policy-Based Adaptation of a Byzantine Fault Tolerant Distributed Graph Database",
                    "authors": "Manuel Bravo, Luís E. T. Rodrigues, Ray Neiheiser, Luciana Rech",
                    "abstract": "Modern fault-tolerant distributed architectures can be configured to tolerate a wide-range of faults. For instance, Fireplug is a distributed BFT graph database, based on n-version programming, that can be configured to tolerate crash or Byzantine faults, uncorrelated faults in individual machines, correlated faults that affect all replicas running a given software version, or correlated faults that affect an entire datacenter. Interestingly, in such a system, fault handling heavily depends on the type of faults the system is configured to tolerate. To hardwire all possible behaviours in the fault-handling code is inflexible and may even be impractical. In this paper, we explore a different alternative that consists in specifying not only the system configuration, but also the fault-handling behaviour, and how the system adapts to changes in the workload, in a policy language, that is processed externally to the managed system. We show that, using this approach, a single simplified codebase of the managed system can be used effectively to address a wide range of dependability constraints.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "现代容错分布式体系结构可以被配置为容忍各种各样的故障。例如，Fireplug是一个基于n版本编程的分布式BFT图数据库，它可以被配置为容忍崩溃或拜占庭故障、单个机器中的不相关故障、影响运行给定软件版本的所有副本的相关故障或影响整个数据中心的相关故障。有趣的是，在这样的系统中，故障处理严重依赖于系统被配置为容许的故障类型。在故障处理代码中硬连接所有可能的行为是不灵活的，甚至可能是不切实际的。在本文中，我们探索了一种不同的替代方案，该方案不仅规定了系统配置，还规定了故障处理行为，以及系统如何以策略语言适应工作负载的变化，该策略语言在受管系统的外部进行处理。我们表明，使用这种方法，管理系统的单个简化代码库可以有效地用于解决各种各样的可靠性约束。",
                    "title_zh": "拜占庭容错分布式图形数据库的基于策略的适应"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00018",
                    "title": "Mobile Cloud-of-Clouds Storage Made Efficient: A Network Coding Based Approach",
                    "authors": "Jiajie Shen, Yi Li, Yangfan Zhou, Xin Wang",
                    "abstract": "Cloud-of-clouds storage is a viable means to ensure security and reliability of distributed data storage, where data are encrypted, encoded, and stored in multiple clouds. However, it is a great challenge to adopt such a paradigm in mobile devices (e.g., smartphone). Mobile devices are generally incapable to perform the heavy-weight operations (i.e., data encryption, encoding, and transmission) required in such a paradigm, given the limited resources in such devices. This paper focuses on addressing this challenge, i.e., improving data storage performance in mobile cloud-of-clouds storage systems. The key of our proposal is to allow the low-capability mobile devices to offload the computational and transmission overhead to the clouds. In other words, we propose a Network Coding based Cloud-of-clouds Storage (NCCS) scheme, where the clouds can encode and exchange data collaboratively. We consider two state-of-the-art cloud-of-clouds storage approaches, i.e., AONT-RS and CAONT-RS, as example cases to deploy our scheme. Accordingly, we propose their network coding-based enhancements, namely NAONT-RS and NCAONT-RS. We implement a prototype cloud-of-clouds system to verify the efficiency of our proposal. We deploy the prototype on Microsoft Azure and conduct extensive experiments with real-world traces. The experimental results show that NAONT-RS and NCAONT-RS can reduce the time of data storage process by up to 50% and improve the throughput by up to 110% compared with their original versions, i.e., AONT-RS and CAONT-RS.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云云存储是一种确保分布式数据存储安全性和可靠性的可行方法，其中数据被加密、编码并存储在多个云中。然而，在移动设备(例如，智能手机)中采用这样的范例是一个巨大的挑战。给定移动设备中的有限资源，移动设备通常不能执行这种范例中所需的繁重操作(即，数据加密、编码和传输)。本文致力于解决这一挑战，即提高移动云计算存储系统的数据存储性能。我们提议的关键是允许低性能移动设备将计算和传输开销卸载到云上。换句话说，我们提出了一种基于网络编码的云云存储(NCCS)方案，其中云可以协作编码和交换数据。我们考虑了两种最新的云云存储方法，即AONT-RS和CAONT-RS，作为部署我们方案的实例。因此，我们提出了他们的基于网络编码的增强，即NAONT-RS和NCAONT-RS。我们实现了一个原型云云系统来验证我们的建议的效率。我们在Microsoft Azure上部署了原型，并用真实世界的痕迹进行了广泛的实验。实验结果表明，NAONT-RS和NCAONT-RS与AONT-RS和CAONT-RS相比，数据存储时间减少了50%，吞吐量提高了110%。",
                    "title_zh": "移动云计算存储变得高效:基于网络编码的方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00019",
                    "title": "Adversarially-Resistant On-Demand Topic Channels for Wireless Sensor Networks",
                    "authors": "Hans Walter Behrens, Kasim Selçuk Candan",
                    "abstract": "Wireless sensor networks and other power-efficient devices fill increasingly important roles in modern society. At the same time, they also face increasing internal and external threats, such as node capture or protocol disruption by adversarial agents. Providing reliable and secure service in the face of these challenges remains an ongoing problem, and one that is only exacerbated by the computational and power constraints imposed on these devices. In this paper, we first introduce the concept of on-demand topic channels in the context of ephemeral wireless sensor networks. Then, building on this concept, we introduce three novel messaging protocols to provide secure, authenticated communication between a sensor network and an authorized user while also providing resilience from accidental or adversarial disruption. These protocols leverage homomorphic hashing in innovative ways to trade secrecy against network and computational costs in on-demand topic channel authentication. Finally, we compare and contrast the costs of these protocols, and show that hash-based protocols provide significant implementation-independent improvements to network resilience.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "无线传感器网络和其他节能设备在现代社会中扮演着越来越重要的角色。与此同时，它们还面临着越来越多的内部和外部威胁，如敌对代理的节点捕获或协议破坏。面对这些挑战，提供可靠和安全的服务仍然是一个持续的问题，并且这个问题由于强加在这些设备上的计算和功率限制而变得更加严重。在本文中，我们首先介绍了短暂无线传感器网络环境下的点播主题信道的概念。然后，在这个概念的基础上，我们引入了三种新的消息协议，以在传感器网络和授权用户之间提供安全的认证通信，同时还提供从意外或敌对中断中恢复的能力。这些协议以创新的方式利用同态散列，在按需主题信道认证中用保密性来换取网络和计算成本。最后，我们比较了这些协议的成本，并表明基于哈希的协议为网络弹性提供了显著的独立于实现的改进。",
                    "title_zh": "无线传感器网络中抗对抗的点播主题信道"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00020",
                    "title": "Secure Information Forwarding through Fragmentation in Delay-Tolerant Networks",
                    "authors": "Shudip Datta, Sanjay Madria, James R. Milligan, Mark Linderman",
                    "abstract": "In application environments like international military coalitions or multi-party relief work in a disaster zone, passing secure messages using Delay Tolerant Networks (DTNs) is challenging because existing public-private key cryptographic approaches may not be always accessible across different groups due to the unavailability of Public Key Infrastructure (PKI). In addition, connectivity may be intermittent so finding the reliable route is also difficult. Thus, instead of sending the complete message in a single packet, fragmenting the messages and sending them via multiple nodes can help achieve better security and reliability when multiple groups are involved. Therefore, encrypting messages before fragmentation and then sending both the data fragments and the key fragments (needed for decryption) provide much higher security. Keys are also fragmented as sending the key in a single packet can hamper security if it is forwarded to some corrupted nodes who may try to tamper or drop it. Hence, in this paper, we develop a scheme to provide improved security by generating multiple key-shares and data fragments and disseminating them via some intermediate nodes. In this fragmentation process, we also create a few redundant blocks to guarantee higher data arrival rate at the destination when message drop rate is higher like in the DTN environment. Our performance evaluation when compared to the most closely related scheme like Multiparty Encryption shows the improvement on minimizing the number of compromised messages as well as reduced bandwidth consumption in the network.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在像国际军事联盟或灾区多方救援工作这样的应用环境中，使用延迟容忍网络(DTN)传递安全消息是具有挑战性的，因为由于公钥基础设施(PKI)的不可用性，现有的公钥-私钥加密方法在不同的组之间可能不总是可访问的。此外，连接可能是间歇性的，因此找到可靠的路由也很困难。因此，当涉及多个组时，将消息分段并通过多个节点发送有助于实现更好的安全性和可靠性，而不是在单个数据包中发送完整的消息。因此，在分段之前对消息进行加密，然后发送数据片段和密钥片段(解密所需的)可以提供更高的安全性。密钥也是分段的，因为在单个分组中发送密钥会妨碍安全性，如果它被转发到一些可能试图篡改或丢弃它的被破坏的节点。因此，在本文中，我们开发了一个方案，通过生成多个密钥份额和数据片段并通过一些中间节点传播它们来提供改进的安全性。在这个分段过程中，我们还创建了几个冗余块，以便在消息丢失率较高时(如在DTN环境中),保证较高的数据到达率。与最密切相关的方案(如多方加密)相比，我们的性能评估显示了在最大限度地减少受损消息数量以及降低网络带宽消耗方面的改进。",
                    "title_zh": "延迟容忍网络中通过分段的安全信息转发"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00021",
                    "title": "RATCHETA: Memory-Bounded Hybrid Byzantine Consensus for Cooperative Embedded Systems",
                    "authors": "Wenbo Xu, Rüdiger Kapitza",
                    "abstract": "Cooperative autonomous systems gain increasing popularity nowadays. Most of these systems demand for high fault-resilience, otherwise a single faulty node could render the whole system useless. This essentially calls for a Byzantine fault-tolerant consensus. However, in such algorithms typically only (n-1)/3 faulty nodes can be tolerated in a group of n nodes and the message complexity is high. Even worse, systems with only 3 nodes are too small to even tolerate a single Byzantine node. In this work we present a novel consensus algorithm, RATCHETA. On the one hand it increases the maximum tolerable faulty nodes to (n-1)/2 and lowers the message complexity. This is achieved by assuming a hybrid fault model, which features the use of a small trusted subsystem that hosts a pair of monotonic counters for message authentication to prevent equivocation. Moreover, it can ensure an upper bound of the memory usage and message size, which is not addressed by most other hybrid consensus algorithms. On the other hand RATCHETA is tailored for wireless embedded systems. It uses multicast to reduce the communication overhead, and it does not rely on any packet loss detection or retransmission mechanisms. We implemented RATCHETA with its trusted subsystem built on top of ARM TrustZone. Our experimental results show that RATCHETA can tolerate both Byzantine faults and a certain amount of omission faults. With 20% message omissions, a 10- node group needs less than 1 second on average to reach a consensus. If 4 nodes out of 10 become Byzantine, the consensus latency is only about 1-3.6 seconds even under rough network conditions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，合作自治系统越来越受欢迎。这些系统大多要求高容错能力，否则单个故障节点就可能导致整个系统瘫痪。这本质上需要拜占庭式的容错共识。然而，在这种算法中，通常在一组n个节点中只能容忍(n-1)/3个故障节点，并且消息复杂度很高。更糟糕的是，只有3个节点的系统太小了，甚至无法容纳一个拜占庭式的节点。在这项工作中，我们提出了一个新的共识算法，棘轮。一方面，它将最大容许故障节点数提高到(n-1)/2，降低了消息复杂度。这是通过假设一个混合故障模型来实现的，该模型的特点是使用一个小型可信子系统，该子系统托管一对用于消息身份验证的单调计数器，以防止模棱两可。此外，它可以确保内存使用和消息大小的上限，这是大多数其他混合一致性算法无法解决的。另一方面，RATCHETA是为无线嵌入式系统定制的。它使用多播来减少通信开销，并且不依赖于任何丢包检测或重传机制。我们实现了RATCHETA，其可信子系统构建在ARM TrustZone之上。实验结果表明，RATCHETA能够容忍拜占庭错误和一定数量的遗漏错误。由于20%的消息遗漏，一个10节点的组平均需要不到1秒的时间来达成共识。如果10个节点中有4个变成拜占庭式，即使在恶劣的网络条件下，一致的延迟也只有大约1-3.6秒。",
                    "title_zh": "RATCHETA:协作嵌入式系统的内存受限混合拜占庭一致性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00022",
                    "title": "MaskAl: Privacy Preserving Masked Reads Alignment using Intel SGX",
                    "authors": "Christoph Lambert, Maria Fernandes, Jeremie Decouchant, Paulo Jorge Esteves Veríssimo",
                    "abstract": "The recent introduction of new DNA sequencing techniques caused the amount of processed and stored biological data to skyrocket. In order to process these vast amounts of data, bio-centers have been tempted to use low-cost public clouds. However, genomes are privacy sensitive, since they store personal information about their donors, such as their identity, disease risks, heredity and ethnic origin. The first critical DNA processing step that can be executed in a cloud, i.e., read alignment, consists in finding the location of the DNA sequences produced by a sequencing machine in the human genome. While recent developments aim at increasing performance, only few approaches address the need for fast and privacy preserving read alignment methods. This paper introduces MaskAl, a novel approach for read alignment. MaskAl combines a fast preprocessing step on raw genomic data - filtering and masking - with established algorithms to align sanitized reads, from which sensitive parts have been masked out, and refines the alignment score using the masked out information with Intel's software guard extensions (SGX). MaskAl is a highly competitive privacy-preserving read alignment software that can be massively parallelized with public clouds and emerging enclave clouds. Finally, MaskAl is nearly as accurate as plain-text approaches (more than 96% of aligned reads with MaskAl compared to 98% with BWA) and can process alignment workloads 87% faster than current privacy-preserving approaches while using less memory and network bandwidth.",
                    "files": {
                        "openAccessPdf": "https://orbilu.uni.lu/bitstream/10993/36279/1/maskal_camera_ready.pdf"
                    },
                    "abstract_zh": "最近新的DNA测序技术的引入导致处理和存储的生物数据量激增。为了处理这些海量的数据，生物中心已经尝试使用低成本的公共云。然而，基因组是隐私敏感的，因为它们存储了捐赠者的个人信息，如他们的身份，疾病风险，遗传和种族血统。可以在云中执行的第一个关键DNA处理步骤，即读取比对，在于找到测序机器产生的DNA序列在人类基因组中的位置。虽然最近的发展旨在提高性能，但只有少数方法解决了对快速和隐私保护读取对齐方法的需求。本文介绍了MaskAl，一种新的阅读比对方法。MaskAl将原始基因组数据的快速预处理步骤(过滤和屏蔽)与已建立的算法相结合，以比对净化后的读数，其中敏感部分已被屏蔽，并使用英特尔软件保护扩展(SGX)的屏蔽信息来改进比对分数。MaskAl是一款极具竞争力的隐私保护读取对齐软件，可以与公共云和新兴飞地云实现大规模并行化。最后，MaskAl几乎与纯文本方法一样准确(MaskAl的对齐读取率超过96%，而BWA为98%)，并且处理对齐工作负载的速度比当前的隐私保护方法快87%，同时使用的内存和网络带宽更少。",
                    "title_zh": "MaskAl:使用SGX保护隐私屏蔽读取对齐"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00023",
                    "title": "PubSub-SGX: Exploiting Trusted Execution Environments for Privacy-Preserving Publish/Subscribe Systems",
                    "authors": "Sergei Arnautov, Andrey Brito, Pascal Felber, Christof Fetzer, Franz Gregor, Robert Krahn, Wojciech Ozga, André Martin, Valerio Schiavoni, Fábio Silva, Marcus Tenorio, Nikolaus Thummel",
                    "abstract": "This paper presents PUBSUB-SGX, a content-based publish-subscribe system that exploits trusted execution environments (TEEs), such as Intel SGX, to guarantee confidentiality and integrity of data as well as anonymity and privacy of publishers and subscribers. We describe the technical details of our Python implementation, as well as the required system support introduced to deploy our system in a container-based runtime. Our evaluation results show that our approach is sound, while at the same time highlighting the performance and scalability trade-offs. In particular, by supporting just-in-time compilation inside of TEEs, Python programs inside of TEEs are in general faster than when executed natively using standard CPython.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1902.09848"
                    },
                    "abstract_zh": "本文介绍了SGX发布子系统，这是一个基于内容的发布-订阅系统，它利用英特尔SGX等可信执行环境(TEEs)来保证数据的机密性和完整性，以及发布者和订阅者的匿名性和隐私性。我们描述了Python实现的技术细节，以及在基于容器的运行时中部署我们的系统所需的系统支持。我们的评估结果表明，我们的方法是合理的，同时强调了性能和可伸缩性的权衡。特别是，通过支持TEEs内部的即时编译，TEEs内部的Python程序通常比使用标准CPython本地执行时更快。",
                    "title_zh": "SGX发布分支:为保护隐私的发布/订阅系统开发可信执行环境"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00024",
                    "title": "Security, Performance and Energy Trade-Offs of Hardware-Assisted Memory Protection Mechanisms",
                    "authors": "Christian Göttel, Rafael Pires, Isabelly Rocha, Sébastien Vaucher, Pascal Felber, Marcelo Pasin, Valerio Schiavoni",
                    "abstract": "The deployment of large-scale distributed systems, e.g., publish-subscribe platforms, that operate over sensitive data using the infrastructure of public cloud providers, is nowadays heavily hindered by the surging lack of trust toward the cloud operators. Although purely software-based solutions exist to protect the confidentiality of data and the processing itself, such as homomorphic encryption schemes, their performance is far from being practical under real-world workloads. The performance trade-offs of two novel hardware-assisted memory protection mechanisms, namely AMD SEV and Intel SGX - currently available on the market to tackle this problem, are ADD described in this practical experience. Specifically, we implement and evaluate a publish/subscribe use-case and evaluate the impact of the memory protection mechanisms and the resulting performance. This paper reports on the experience gained while building this system, in particular when having to cope with the technical limitations imposed by SEV and SGX. Several tradeoffs that provide valuable insights in terms of latency, throughput, processing time and energy requirements are exhibited by means of micro-and macro-benchmarks.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1903.04203"
                    },
                    "abstract_zh": "如今，使用公共云提供商的基础设施对敏感数据进行操作的大规模分布式系统(例如发布-订阅平台)的部署受到了对云运营商日益缺乏信任的严重阻碍。尽管存在纯基于软件的解决方案来保护数据和处理本身的机密性，例如同态加密方案，但是它们的性能在真实世界的工作负载下远远不实用。这两个新的硬件辅助内存保护机制的性能权衡，即AMD SEV和英特尔SGX -目前市场上可用于解决这个问题，是在这个实际经验中添加描述。具体来说，我们实现并评估了一个发布/订阅用例，并评估了内存保护机制的影响以及由此产生的性能。本文报告了建立这一系统时所获得的经验，特别是在不得不应付SEV和SGX所施加的技术限制时。通过微观和宏观基准，展示了在延迟、吞吐量、处理时间和能源需求方面提供有价值见解的几种权衡。",
                    "title_zh": "硬件辅助存储器保护机制的安全性、性能和能量权衡"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00025",
                    "title": "Mind the Gap: Autonomous Detection of Partitioned MANET Systems using Opportunistic Aggregation",
                    "authors": "Simon Bouget, Yérom-David Bromberg, Hugues Mercier, Etienne Rivière, François Taïani",
                    "abstract": "Mobile Ad-hoc Networks (MANETs) use limited-range wireless communications and are thus exposed to partitions when nodes fail or move out of reach of each other. Detecting partitions in MANETs is unfortunately a nontrivial task due to their inherently decentralized design and limited resources such as power or bandwidth. In this paper, we propose a novel and fully decentralized approach to detect partitions (and other large membership changes) in MANETs that is both accurate and resource efficient. We monitor the current composition of a MANET using the lightweight aggregation of compact membership-encoding filters. Changes in these filters allow us to infer the likelihood of a partition with a quantifiable level of confidence. We first present an analysis of our approach, and show that it can detect close to 100% of partitions under realistic settings, while at the same time being robust to false positives due to churn or dropped packets. We perform a series of simulations that compare against alternative approaches and confirm our theoretical results, including above 90% accurate detection even under a 40% message loss rate.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01900360/file/Mind-theGap-SRDS-camera-ready.pdf"
                    },
                    "abstract_zh": "移动自组织网络(MANETs)使用有限范围的无线通信，因此当节点发生故障或移动到彼此无法到达时，会暴露于分区。不幸的是，由于MANETss固有的分散设计和有限的资源，如功率或带宽，检测MANET中的分区不是一项简单的任务。在本文中，我们提出了一种新颖的完全分散的方法来检测MANETs中的分区(和其他大的成员变化),该方法既准确又节省资源。我们使用紧凑成员编码过滤器的轻量级集合来监控MANET的当前组成。这些过滤器中的变化允许我们以可量化的置信度推断分区的可能性。我们首先对我们的方法进行了分析，并表明它可以在真实的设置下检测到接近100%的分区，同时对由于变动或丢包引起的误报具有鲁棒性。我们进行了一系列模拟，与其他方法进行比较，并确认了我们的理论结果，包括即使在40%的消息丢失率下也有90%以上的准确检测。",
                    "title_zh": "小心缝隙:使用机会聚合的分块MANET系统的自主检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00026",
                    "title": "DMap: A Fault-Tolerant and Scalable Distributed Data Structure",
                    "authors": "Samuel Benz, Fernando Pedone",
                    "abstract": "Major efforts have been spent in recent years to improve the performance, scalability and reliability of distributed systems. In order to hide the complexity of designing distributed applications, many proposals provide efficient high-level communication abstractions (e.g., atomic multicast). These abstractions, however, are often unfamiliar to average application designers and, as a result, implementing distributed applications that tolerate failures and scale performance without sacrificing consistency remains a challenging task. In this paper, we introduce DMap, a reliable and scalable distributed ordered map. DMap fully implements the generic Java SortedMap interface and can be easily used to scale existing Java applications. To substantiate our claim, we have used DMap to turn H2, a centralized database, into a scalable and reliable data management system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，在提高分布式系统的性能、可扩展性和可靠性方面已经付出了很大的努力。为了隐藏设计分布式应用的复杂性，许多提议提供了高效的高级通信抽象(例如，原子多播)。然而，这些抽象对于一般的应用程序设计人员来说往往是陌生的，因此，实现容忍故障和扩展性能而不牺牲一致性的分布式应用程序仍然是一项具有挑战性的任务。本文介绍了DMap，一种可靠的、可扩展的分布式有序映射。DMap完全实现了通用的Java SortedMap接口，可以很容易地用于扩展现有的Java应用程序。为了证实我们的说法，我们已经使用DMap将H2这个集中式数据库转变为一个可扩展的、可靠的数据管理系统。",
                    "title_zh": "DMap:一种容错和可扩展的分布式数据结构"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00027",
                    "title": "Enabling State Estimation for Fault Identification in Water Distribution Systems Under Large Disasters",
                    "authors": "Qing Han, Ronald T. Eguchi, Sharad Mehrotra, Nalini Venkatasubramanian",
                    "abstract": "We present a graphical model based approach for on-line state estimation of water distribution system failures during large-scale disasters. Water distribution systems often exhibit extreme fragilities during large-scale disasters (e.g., earthquakes) resulting in massive pipe breaks, water contamination, and disruption of service. To monitor and identify potential problems, hidden state information must be extracted from limited and noisy data environments. This requires estimating the operating states of the water system quickly and accurately. We model the water system as a factor graph, characterizing the non-linearity of fluid flow in a network that is dynamically altered by leaks, breaks and operations designed to minimize water loss. The approach considers a structured probabilistic framework which models complex interdependencies within a high-level network topology. The proposed two-phase approach, which begins with a network decomposition using articulation points followed by the distributed Gauss-Newton Belief Propagation (GN-BP) based inference, can deliver optimal estimates of the system state in near real-time. The approach is evaluated in canonical and real-world water systems under different levels of physical and cyber disruptions, using the Water Network Tool for Resilience (WNTR) recently developed by Sandia National Lab and Environmental Protection Agency (EPA). Our results demonstrate that the proposed GN-BP approach can yield an accurate estimation of system states (mean square error 0.02) in a relatively fast manner (within 1s). The two-phase mechanism enables the scalability of state estimation and provides a robust assessment of performance of large-scale water systems in terms of computational complexity and accuracy. A case study on the identification of \"faulty zones\" shows that 80% broken pipelines and 99% loss-of-service to end-users can be localized.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出了一种基于图形模型的方法，用于大规模灾害期间供水系统故障的在线状态估计。在大规模灾害(例如地震)期间，水分配系统通常表现出极端的脆弱性，导致大规模的管道破裂、水污染和服务中断。为了监控和识别潜在的问题，必须从有限和嘈杂的数据环境中提取隐藏状态信息。这就要求快速准确地估计水系统的运行状态。我们将水系统建模为一个因子图，描述了网络中流体流动的非线性，该网络因泄漏、破裂和旨在最小化水损失的操作而动态改变。该方法考虑了一个结构化的概率框架，该框架对高级网络拓扑中复杂的相互依赖关系进行建模。所提出的两阶段方法从使用关节点的网络分解开始，随后是基于分布式高斯-牛顿置信传播(GN-BP)的推理，可以近实时地提供系统状态的最优估计。使用桑迪亚国家实验室和环境保护局(EPA)最近开发的水网络弹性工具(WNTR ),在不同程度的物理和网络中断下，在规范和真实世界的水系统中评估该方法。我们的结果表明，提出的GN-BP方法可以以相对快速的方式(在1s内)产生系统状态的精确估计(均方误差0.02)。两阶段机制实现了状态估计的可扩展性，并在计算复杂性和准确性方面提供了对大规模水系统性能的稳健评估。一项关于识别“故障区域”的案例研究表明，80%的破裂管道和99%的最终用户服务损失可以被定位。",
                    "title_zh": "大灾害下供水系统故障识别的状态估计"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00028",
                    "title": "Improving Reliability of Deduplication-Based Storage Systems with Per-File Parity",
                    "authors": "Suzhen Wu, Huagao Luan, Bo Mao, Hong Jiang, Gen Niu, Hui Rao, Fang Yu, Jindong Zhou",
                    "abstract": "The reliability issue in deduplication-based storage systems has not received adequate attention. Existing approaches introduce data redundancy after files have been deduplicated, either by replication on critical data chunks, i.e., chunks with high reference count, or RAID schemes on unique data chunks, which means that these schemes are based on individual unique data chunks rather than individual files. This can leave individual files vulnerable to losses, particularly in the presence of transient and unrecoverable data chunk errors such as latent sector errors. To address this file reliability issue, this paper proposes a Per-File Parity (short for PFP) scheme to improve the reliability of deduplication-based storage systems. PFP computes the XOR parity within parity groups of data chunks of each file after the chunking process but before the data chunks are deduplicated. Therefore, PFP can provide parity redundancy protection for all files by intra-file recovery and a higher-level protection for data chunks with high reference counts by inter-file recovery. Our reliability analysis and extensive data-driven, failure-injection based experiments conducted on a prototype implementation of PFP show that PFP significantly outperforms the existing redundancy solutions, DTR and RCR, in system reliability, tolerating multiple data chunk failures and guaranteeing file availability upon multiple data chunk failures. Moreover, a performance evaluation shows that PFP only incurs an average of 5.7% performance degradation to the deduplication-based storage system.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于重复数据删除的存储系统中的可靠性问题还没有得到足够的重视。现有方法在文件已经被去重复之后引入数据冗余，或者通过在关键数据块(即，具有高引用计数的块)上的复制，或者在唯一数据块上的RAID方案，这意味着这些方案基于单独的唯一数据块而不是单独的文件。这可能会使单个文件容易丢失，特别是在出现瞬时和不可恢复的数据块错误(如潜在的扇区错误)时。为了解决这个文件可靠性问题，本文提出了一种基于文件的奇偶校验(PFP)方案来提高基于重复数据删除的存储系统的可靠性。在分块过程之后、数据区块消除重复数据之前，PFP会在每个文件的数据区块的奇偶校验组内计算XOR奇偶校验。因此，PFP可以通过文件内恢复为所有文件提供奇偶校验冗余保护，并通过文件间恢复为具有高引用计数的数据区块提供更高级别的保护。我们的可靠性分析和在PFP原型实施上进行的大量数据驱动的基于故障注入的实验表明，PFP在系统可靠性方面明显优于现有的冗余解决方案，即DTR和RCR，能够容忍多个数据块故障，并在多个数据块故障时保证文件可用性。此外，性能评估显示，PFP只会给基于重复数据消除的存储系统带来平均5.7%的性能下降。",
                    "title_zh": "通过逐文件奇偶校验提高基于重复数据消除的存储系统的可靠性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00029",
                    "title": "MuSE: Multimodal Searchable Encryption for Cloud Applications",
                    "authors": "Bernardo Ferreira, João Leitão, Henrique João L. Domingos",
                    "abstract": "In this paper we tackle the practical challenges of searching encrypted multimodal data (i.e., data containing multiple media formats simultaneously), stored in public cloud servers, with reduced information leakage. To this end we propose MuSE, a Multimodal Searchable Encryption scheme that, by combining only standard cryptographic primitives and symmetric-key block ciphers, allows cloud-backed applications to dynamically store, update, and search multimodal datasets with privacy and efficiency guarantees. As searching encrypted data requires a tradeoff between privacy and efficiency, we also propose a variant of MuSE that resorts to partially homomorphic encryption to further reduce information leakage, but at the cost of additional computational overhead. Both schemes are formally proven secure and experimentally evaluated regarding performance and search precision. Experiments with realistic datasets show that our contributions achieve interesting levels of efficiency and privacy, making MuSE particularly suitable for practical application scenarios.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们解决了在减少信息泄漏的情况下搜索存储在公共云服务器中的加密多模态数据(即同时包含多种媒体格式的数据)的实际挑战。为此，我们提出了MuSE，一种多模态可搜索加密方案，通过仅结合标准密码原语和对称密钥分组密码，允许云支持的应用程序动态存储、更新和搜索多模态数据集，同时保证隐私和效率。由于搜索加密数据需要在隐私和效率之间进行权衡，我们还提出了一种MuSE的变体，它采用部分同态加密来进一步减少信息泄漏，但代价是额外的计算开销。这两种方案都被正式证明是安全的，并在性能和搜索精度方面进行了实验评估。真实数据集的实验表明，我们的贡献实现了有趣的效率和隐私水平，使MuSE特别适合实际应用场景。",
                    "title_zh": "MuSE:面向云应用的多模态可搜索加密"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00030",
                    "title": "Héron: Taming Tail Latencies in Key-Value Stores Under Heterogeneous Workloads",
                    "authors": "Vikas Jaiman, Sonia Ben Mokhtar, Vivien Quéma, Lydia Y. Chen, Etienne Rivière",
                    "abstract": "Avoiding latency variability in distributed storage systems is challenging. Even in well-provisioned systems, factors such as the contention on shared resources or the unbalanced load between servers affect the latencies of requests and in particular the tail (95th and 99th percentile) of their distribution. One effective counter measure for reducing tail latency in key-value stores is to provide efficient replica selection algorithms. However, existing solutions are based on the assumption that all requests have almost the same execution time. This is not true for real workloads. This mismatch leads to increased latencies for requests with short execution time that get scheduled behind requests with large execution times. We propose Héron, a replica selection algorithm that supports workloads with heterogeneous request execution times. We evaluate Héron in a cluster of machines using a synthetic dataset inspired from the Facebook dataset as well as two real datasets from Flickr and WikiMedia. Our results show that Héron outperforms state-of-the-art algorithms by reducing both median and tail latency by up to 41%.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01896686/file/HeronSRDS18.pdf"
                    },
                    "abstract_zh": "避免分布式存储系统中的延迟可变性是一项挑战。即使在配置良好的系统中，共享资源的争用或服务器之间的负载不平衡等因素也会影响请求的延迟，尤其是请求分布的尾部(95%和99%)。减少键值存储中尾部延迟的一个有效对策是提供高效的副本选择算法。然而，现有的解决方案是基于所有请求具有几乎相同的执行时间的假设。对于真实的工作负载来说，情况并非如此。这种不匹配导致执行时间短的请求的延迟增加，这些请求的调度落后于执行时间长的请求。我们提出了Héron，一种支持异构请求执行时间的工作负载的副本选择算法。我们在一个机器集群中使用一个受脸书数据集启发的合成数据集以及来自Flickr和WikiMedia的两个真实数据集来评估Héron。我们的结果表明，Héron的性能优于最先进的算法，将中值和尾部延迟都降低了41%。",
                    "title_zh": "Héron:在异构工作负载下驯服键值存储中的尾部延迟"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00031",
                    "title": "A Requirements-Driven Methodology for the Proper Selection and Configuration of Blockchains",
                    "authors": "Mirko Staderini, Enrico Schiavone, Andrea Bondavalli",
                    "abstract": "In recent years, the interest in blockchain has grown exponentially, and nowadays it is foreseen as a technology with the potential to revolutionize the way data is maintained and transferred around the globe. The reason of this excitement is ascribable to the ability of enabling new forms of transactions and interactions between mistrusting and decentralized entities. Indeed, it has attracted interests and huge investments from enterprises, and it is predictable that in a near future many industries will adopt it. However, it is not a panacea and in some cases may even become useless or not convenient. Moreover, even when it can really constitute an added value, selecting the proper blockchain and configuring it may not be trivial. Trying to go beyond the hype and to address this problem, this paper proposes a methodology addressing: i) whether, given a specific problem requirements, the blockchain is a proper solution for it ii) in such a case which is the blockchain category more suitable, and finally iii) guiding the designer throughout its configuration.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，人们对区块链的兴趣呈指数级增长，如今它被认为是一项有可能彻底改变全球数据维护和传输方式的技术。这种兴奋的原因可归因于在不信任和分散的实体之间实现新形式的交易和交互的能力。事实上，它已经吸引了企业的兴趣和巨额投资，可以预见，在不久的将来，许多行业将采用它。然而，它不是万灵药，在某些情况下甚至可能变得无用或不方便。此外，即使它真的能构成附加值，选择合适的区块链并对其进行配置也不是小事。为了超越宣传并解决这个问题，本文提出了一种方法来解决:I)对于给定的特定问题要求，区块链是否是一个合适的解决方案；ii)在这种情况下，哪个区块链类别更合适；以及iii)在整个配置过程中指导设计者。",
                    "title_zh": "正确选择和配置区块链的需求驱动方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00032",
                    "title": "Crash-Resilient Decentralized Synchronous Runtime Verification",
                    "authors": "Shokoufeh Kazemlou, Borzoo Bonakdarpour",
                    "abstract": "In this paper, we consider runtime verification of synchronous distributed systems, where a decentralized set of monitors that only have a partial view of the system are subject to crash failures. In this context, it is unavoidable that monitors may have different views of the underlying system, and, therefore, have different opinions about the correctness property. We propose an automata-based synchronous monitoring algorithm that copes with t crash monitor failures. Moreover, local monitors do not communicate their explicit reading of the underlying system. Rather, they emit a symbolic verdict that efficiently encodes their partial views. This significantly reduces the communication overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在本文中，我们考虑同步分布式系统的运行时验证，其中只有部分系统视图的一组分散的监视器容易发生崩溃故障。在这种情况下，不可避免的是，监视器可能对底层系统有不同的看法，因此对正确性属性有不同的意见。我们提出了一个基于自动机的同步监控算法来处理t崩溃监视器故障。此外，本地监视器不传达它们对底层系统的显式读取。相反，他们发出一个象征性的裁决，有效地编码了他们的部分观点。这大大减少了通信开销。",
                    "title_zh": "抗崩溃分散同步运行时验证"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00033",
                    "title": "Decentralized Release of Self-Emerging Data using Smart Contracts",
                    "authors": "Chao Li, Balaji Palanisamy",
                    "abstract": "In the age of Big Data, releasing protected sensitive data at a future point in time is critical for various applications. Such self-emerging data release requires the data to be protected until a prescribed data release time and be automatically released to the recipient at the release time, even if the data sender goes offline. While straight-forward centralized approaches provide a basic solution to the problem, unfortunately they are limited to a single point of trust and involve a single point of control. This paper presents decentralized techniques for supporting self-emerging data using smart contracts in Ethereum blockchain networks. We design a credible and enforceable smart contract for supporting self-emerging data release. The smart contract employs a set of Ethereum peers to jointly follow the proposed timed-release service protocol allowing the participating peers to earn the remuneration paid by the service users. We model the problem as an extensive-form game with imperfect information to protect against possible adversarial attacks including some peers destroying the private data (drop attack) or secretly releasing the private data before the release time (release-ahead attack). We demonstrate the efficacy and attack-resilience of the proposed techniques through rigorous analysis and experimental evaluation. Our implementation and experimental evaluation on the Ethereum official test network demonstrate the low monetary cost and the low time overhead associated with the proposed approach and validate its guaranteed security properties.",
                    "files": {
                        "openAccessPdf": "http://d-scholarship.pitt.edu/34983/1/srds-camera.pdf"
                    },
                    "abstract_zh": "在大数据时代，在未来某个时间点发布受保护的敏感数据对于各种应用程序来说至关重要。这种自出现的数据发布要求数据受到保护，直到规定的数据发布时间，并且在发布时间自动发布给接收者，即使数据发送者离线。虽然直接的集中式方法提供了该问题的基本解决方案，但不幸的是，它们局限于单点信任，并且涉及单点控制。本文提出了在以太坊区块链网络中使用智能合同支持自显现数据的分散技术。我们设计了一个可信的、可执行的智能合同来支持自浮现数据发布。智能合同采用一组以太坊节点来共同遵守提议的定时释放服务协议，允许参与节点获得服务用户支付的报酬。我们将问题建模为一个具有不完全信息的扩展形式的博弈，以防止可能的敌对攻击，包括一些节点破坏私有数据(丢弃攻击)或在发布时间之前秘密发布私有数据(提前发布攻击)。我们通过严格的分析和实验评估证明了所提出技术的有效性和抗攻击能力。我们在以太坊官方测试网络上的实现和实验评估证明了与所提出的方法相关的低货币成本和低时间开销，并验证了其有保证的安全性。",
                    "title_zh": "使用智能合约的自显现数据的分散发布"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00034",
                    "title": "Geographic State Machine Replication",
                    "authors": "Paulo R. Coelho, Fernando Pedone",
                    "abstract": "We present a new state transfer method for geographic State Machine Replication (SMR) that dynamically allocates the state to be transferred among replicas according to changes in communication bandwidths. SMR is a method that improves fault tolerance by replicating a service to multiple replicas. When a replica is newly added or is recovered from a failure, the other replicas transfer the current state of the service to it. However, in geographic SMR, the communication bandwidths of replicas are different and constantly changing. Therefore, existing state transfer methods cannot fully utilize the available bandwidth, and their state transfer time becomes long. To overcome this problem, our method divides the state into multiple chunks and assigns them to replicas based on each replica's bandwidth so that the broader a replica's bandwidth is, the more chunks it transfers. The number of assigned chunks is dynamically updated based on the currently estimated bandwidth. The performance evaluation on Amazon EC2 shows that the proposed method reduces the state transfer time by up to 47% compared with the existing one.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2110.04448"
                    },
                    "abstract_zh": "我们提出了一种新的地理状态机复制(SMR)的状态转移方法，该方法根据通信带宽的变化动态地在副本之间分配要转移的状态。SMR是一种通过将服务复制到多个副本来提高容错能力的方法。当新添加一个副本或从故障中恢复时，其他副本会将服务的当前状态传送给它。然而，在地理SMR中，副本的通信带宽是不同的，并且不断变化。因此，现有的状态转移方法不能充分利用可用带宽，并且它们的状态转移时间变长。为了克服这个问题，我们的方法将状态分成多个块，并根据每个副本的带宽将它们分配给副本，这样副本的带宽越宽，它传输的块就越多。基于当前估计的带宽，动态更新分配的块的数量。在Amazon EC2上的性能评估表明，与现有方法相比，该方法减少了47%的状态转移时间。",
                    "title_zh": "地理状态机复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00037",
                    "title": "Kernel Paxos",
                    "authors": "Emanuele Giuseppe Esposito, Paulo R. Coelho, Fernando Pedone",
                    "abstract": "State machine replication is a well-known technique to build fault-tolerant replicated systems. The technique guarantees that replicas of a service execute the same sequence of deterministic commands in the same total order. At the core of state machine replication is consensus, a distributed problem in which replicas agree on the next command to be executed. Among the various consensus algorithms proposed, Paxos stands out for its optimized resilience and communication. Much effort has been placed on implementing Paxos efficiently. Existing solutions make use of special network topologies, rely on specialized hardware, or exploit application semantics. Instead of proposing yet another variation of the original Paxos algorithm, this paper proposes a new strategy to increase performance of Paxos-based state machine replication. We introduce Kernel Paxos, an implementation of Paxos that significantly reduces communication overhead by avoiding system calls and TCP/IP stack. To reduce the number of context switches related to system calls, we provide Paxos as a kernel module. We present a detailed performance analysis of Kernel Paxos and compare it to a user-space equivalent implementation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "状态机复制是构建容错复制系统的一种众所周知的技术。该技术保证服务的复制品以相同的总顺序执行相同的确定性命令序列。状态机复制的核心是一致性，这是一个分布式问题，其中副本同意下一个要执行的命令。在提出的各种共识算法中，Paxos因其优化的弹性和通信而脱颖而出。在有效实施Paxos方面已经做了很多努力。现有的解决方案利用特殊的网络拓扑，依赖专门的硬件，或者利用应用程序语义。本文提出了一种新的策略来提高基于Paxos的状态机复制的性能，而不是提出原始Paxos算法的另一种变体。我们介绍了内核Paxos，它是Paxos的一种实现，通过避免系统调用和TCP/IP堆栈，大大减少了通信开销。为了减少与系统调用相关的上下文切换次数，我们提供了Paxos作为内核模块。我们对内核Paxos进行了详细的性能分析，并将其与用户空间的等效实现进行了比较。",
                    "title_zh": "内核Paxos"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00035",
                    "title": "MDC-Cast: A Total-Order Broadcast Protocol for Multi-Datacenter Environments",
                    "authors": "Mohamad-Jaafar Nehme, Nicolas Palix, Kamal Beydoun, Vivien Quéma",
                    "abstract": "The recent Total-Order Broadcast protocols that have been designed to sustain high throughput and low latency target fully switched environments, such as small datacenters and clusters. These protocols fail to achieve good performance in multi-datacenter environments, that are characterized by non-uniform network connectivity among a set of remote datacenters. More precisely, machines within a datacenter are connected using a fully switched network, whereas machines across datacenters use shared inter-datacenter network cables. This paper presents a novel Total-Order Broadcast protocol, called MDC-cast that specifically targets multi-datacenter environments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "最近的全序广播协议旨在维持高吞吐量和低延迟，目标是全交换环境，如小型数据中心和集群。这些协议无法在多数据中心环境中实现良好的性能，多数据中心环境的特征在于一组远程数据中心之间的非统一网络连接。更准确地说，数据中心内的机器使用全交换网络连接，而跨数据中心的机器使用共享的数据中心间网络电缆。本文提出了一种新的全序广播协议，称为MDC-cast，专门针对多数据中心环境。",
                    "title_zh": "MDC-Cast:多数据中心环境下的全序广播协议"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00036",
                    "title": "Byzantine Agreement with Interval Validity",
                    "authors": "Darya Melnyk, Roger Wattenhofer",
                    "abstract": "To solve Byzantine agreement, n nodes with real input values, among which t < n/3 are Byzantine, have to agree on a common consensus value. Previous research has mainly focused on determining a consensus value equal to an input value of some arbitrary node. In this work we instead assume that the values of the nodes are ordered and introduce a novel validity condition which accepts consensus values that are close to the k-th smallest value of the correct nodes. We propose a deterministic algorithm that approximates the k-th smallest value and show that this approximation is the best possible for the synchronous message passing model. Our approach is furthermore extended to multiple dimensions, where the order is not well-defined, and we show that our algorithm can be applied to determine a value that lies within a box around all correct input vectors.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了解决拜占庭协定，具有真实输入值的n个节点(其中t < n/3是拜占庭的)必须就一个共同的共识值达成一致。先前的研究主要集中在确定与某个任意节点的输入值相等的一致性值。在这项工作中，我们假设节点的值是有序的，并引入了一个新的有效性条件，该条件接受接近正确节点的第k个最小值的一致值。我们提出了一个确定性算法，该算法近似第k个最小值，并表明这种近似是同步消息传递模型的最佳可能。我们的方法进一步扩展到多维度，其中顺序没有很好地定义，并且我们表明我们的算法可以应用于确定位于所有正确输入向量周围的框内的值。",
                    "title_zh": "具有区间有效性的拜占庭协议"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00038",
                    "title": "Dynamic Checkpoint Architecture for Reliability Improvement on Distributed Frameworks",
                    "authors": "Paulo Vinicius Mendonca Cardoso, Patricia Pitthan de Araujo Barcelos",
                    "abstract": "Fault tolerant mechanisms are essential to provide reliable feature for distributed systems. Checkpoint and Recovery is a widely used technique that consists on saving data states for a fast recovery in case of failure. On Apache Hadoop and Apache Spark – distributed high performance frameworks –, checkpoint aims to help on recovery steps after failures. However, wrong configuration of checkpoint attributes can degrade system performance and reliability, thus losing checkpoint purpose. This work proposes a dynamic architecture for checkpoint based on system monitoring and alerts. In order to avoid checkpoint problems on Hadoop and Spark, one implementation of dynamic mechanism is defined for each framework.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "容错机制是为分布式系统提供可靠功能的基础。检查点和恢复是一种广泛使用的技术，它包括保存数据状态，以便在出现故障时快速恢复。在Apache Hadoop和Apache Spark(分布式高性能框架)上，checkpoint旨在帮助故障后的恢复步骤。但是，错误的检查点属性配置会降低系统性能和可靠性，从而失去检查点的用途。本文提出了一种基于系统监控和警报的动态检查点体系结构。为了避免Hadoop和Spark上的检查点问题，每个框架都定义了一个动态机制的实现。",
                    "title_zh": "提高分布式框架可靠性的动态检查点体系结构"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00042",
                    "title": "Security, Performance and Energy Implications of Hardware-Assisted Memory Protection Mechanisms on Event-Based Streaming Systems",
                    "authors": "Christian Göttel, Rafael Pires, Isabelly Rocha, Sébastien Vaucher, Pascal Felber, Marcelo Pasin, Valerio Schiavoni",
                    "abstract": "Major cloud providers such as Amazon [1], Google [2] and Microsoft [3] provide nowadays some form of infrastructure as a service (IaaS) which allows deploying services in the form of virtual machines [4], containers [5] or bare-metal [6] instances. Although software-based solutions like homomorphic encryption exit, privacy concerns [7] greatly hinder the deployment of such services over public clouds. It is particularly difficult for homomorphic encryption to match performance requirements of modern workloads [8]. Evaluating simple operations on basic data types with HElib [9], a homomorphic encryption library, against their unencrypted counter part reveals, that homomorphic encryption is still impractical under realistic workloads.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/2104.03731"
                    },
                    "abstract_zh": "亚马逊[1]、谷歌[2]和微软[3]等主要云提供商如今提供某种形式的基础设施即服务(IaaS)，允许以虚拟机[4]、容器[5]或裸机[6]实例的形式部署服务。尽管同态加密等基于软件的解决方案已经存在，但隐私问题[7]极大地阻碍了此类服务在公共云上的部署。同态加密很难满足现代工作负载的性能要求[8]。使用同态加密库HElib [9]对基本数据类型上的简单操作进行评估，对比其未加密的对应部分，发现同态加密在实际工作负载下仍然不切实际。",
                    "title_zh": "基于事件的流媒体系统中硬件辅助内存保护机制的安全性、性能和能耗"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00039",
                    "title": "Collective Attestation: for a Stronger Security in Embedded Networks",
                    "authors": "Ahmad Ibrahim",
                    "abstract": "Embedded devices are increasingly permeating our environment to collect data and act on the insight derived. Examples of such devices include smart environments and autonomous systems. The increasing ability to connect, communicate with, and remotely control such devices via the legacy internet has raised considerable security and privacy concerns. One key mechanism to protect the software integrity of these devices is attestation. In this dissertation, we devise attestation schemes that are scalable and applicable for large networks of embedded devices. In particular, we present attestation schemes that are capable of detecting remote malware infestation, physical, and run-time attacks in different settings including smart environments and autonomous systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "嵌入式设备越来越多地渗透到我们的环境中，以收集数据并根据所获得的信息采取行动。这种设备的例子包括智能环境和自治系统。通过传统互联网连接、通信和远程控制这些设备的能力日益增强，这引起了相当大的安全和隐私问题。保护这些设备的软件完整性的一个关键机制是证明。在本论文中，我们设计了适用于大型嵌入式设备网络的可扩展证明方案。特别地，我们提出了能够在包括智能环境和自治系统的不同设置中检测远程恶意软件感染、物理和运行时攻击的证明方案。",
                    "title_zh": "集体证明:增强嵌入式网络的安全性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00040",
                    "title": "Towards Real-Time-Aware Intrusion Tolerance",
                    "authors": "Christoph Lambert, Marcus Völp, Jeremie Decouchant, Paulo Jorge Esteves Veríssimo",
                    "abstract": "Technologies such as Industry 4.0 or assisted/autonomous driving are relying on highly customized cyber-physical realtime systems. Those systems are designed to match functional safety regulations and requirements such as EN ISO 13849, EN IEC 62061 or ISO 26262. However, as systems – especially vehicles – are becoming more connected and autonomous, they become more likely to suffer from new attack vectors. New features may meet the corresponding safety requirements but they do not consider adversaries intruding through security holes with the purpose of bringing vehicles into unsafe states. As research goal, we want to bridge the gap between security and safety in cyber-physical real-time systems by investigating real-time-aware intrusion-tolerant architectures for automotive use-cases.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "工业4.0或辅助/自动驾驶等技术依赖于高度定制的网络物理实时系统。这些系统的设计符合功能安全法规和要求，如ISO 13849、IEC 62061或ISO 26262。然而，随着系统——尤其是车辆——变得更加互联和自主，它们更有可能遭受新的攻击媒介。新功能可能满足相应的安全要求，但它们不考虑以将车辆带入不安全状态为目的通过安全漏洞入侵的对手。作为研究目标，我们希望通过研究汽车用例的实时感知入侵容忍体系结构，弥合信息物理实时系统中的安全性和安全性之间的差距。",
                    "title_zh": "面向实时感知的入侵容忍"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2018.00041",
                    "title": "Definition of an Architecture for Dynamic and Automatic Checkpoints on Apache Spark",
                    "authors": "Paulo Vinicius Cardoso, Patrícia Pitthan Barcelos",
                    "abstract": "Towards a scenario where failures on large-scale systems are inevitable, fault tolerant mechanisms must be efficiently applied. Checkpoint is a widely used technique that consists in saving data states for a fast recovery in case of failure. On Apache Spark – framework that uses in-memory data abstraction –, checkpoint serves to store datasets in a reliable source, so it helps on recovery process of complex datasets. However, once checkpoints must be defined by developer via source code, it may be a hard challenge to choose proper checkpoint scenarios. Therefore, this work proposes an automatic mechanism for checkpoint on Spark, which consists in monitoring system behavior and taking automatic checkpoint process according to defined policies.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对于大规模系统故障不可避免的情况，必须有效地应用容错机制。检查点是一种广泛使用的技术，它保存数据状态，以便在出现故障时快速恢复。在使用内存数据抽象的Apache Spark框架上，检查点用于将数据集存储在可靠的源中，因此它有助于复杂数据集的恢复过程。然而，一旦检查点必须由开发人员通过源代码定义，选择合适的检查点场景可能是一个严峻的挑战。因此，本文提出了一种Spark上的自动检查点机制，它包括监控系统行为和根据定义的策略进行自动检查点处理。",
                    "title_zh": "Apache Spark上动态和自动检查点架构的定义"
                }
            ]
        }
    ],
    "2016": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2016w.html",
            "conf_title": "35. SRDS 2016: Budapest, Hungary - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7593913/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.11",
                    "title": "sKnock: Port-Knocking for Masses",
                    "authors": "Daniel Sel, Sree Harsha Totakura, Georg Carle",
                    "abstract": "Port-knocking is the concept of hiding remote services behind a firewall which allows access to the services'listening ports only after the client has successfully authenticatedto the firewall. This helps in preventing scanners from learningwhat services are currently available on a host and also servesas a defense against zero-day attacks. Existing port-knockingimplementations are not scalable in service provider deploymentsdue to their usage of shared secrets. In this paper we introducean implementation of port-knocking based on x509 certificatesaimed towards being highly scalable.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "端口敲门是将远程服务隐藏在防火墙后的概念，只有在客户端成功通过防火墙的身份验证后，才允许访问服务的监听端口。这有助于防止扫描程序了解主机上当前可用的服务，还可以防御零日攻击。由于使用共享机密，现有的端口敲门信号实现在服务提供商部署中不可伸缩。在这篇文章中，我们介绍了一个基于x509证书的端口敲门的实现，目标是高度可扩展。",
                    "title_zh": "斯克诺克:为群众敲门"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.12",
                    "title": "Toward Access Control Model for Context-Aware Services Offloaded to Cloud Computing",
                    "authors": "Ichiro Satoh",
                    "abstract": "Off loading context-aware services with intensive tasks to cloud computing infrastructures is useful. However, we have a problem resulting from differences between context-centric access control models for pervasive computing and subject-based access control models for cloud computing. To solve this problem, this paper proposes a location model for spatially specifying containment relationships of persons, physical entities, spaces, and computers. The model also manages context-centric access control models, and introduces an interface between pervasive computing and cloud computing programs. The interfaces enable context-aware services executed forthe latter to access computational resources and information under an access control model for the former. This paper presents the basic notion of the model and its prototype implementation.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "将具有密集任务的上下文感知服务卸载到云计算基础设施是有用的。然而，我们有一个由普适计算的以上下文为中心的访问控制模型和云计算的基于主题的访问控制模型之间的差异引起的问题。为了解决这个问题，本文提出了一个位置模型，用于在空间上指定人、物理实体、空间和计算机的包含关系。该模型还管理以上下文为中心的访问控制模型，并在普适计算和云计算程序之间引入了一个接口。这些接口使得为后者执行的上下文感知服务能够在前者的访问控制模型下访问计算资源和信息。本文介绍了该模型的基本概念及其原型实现。",
                    "title_zh": "面向云计算环境感知服务的访问控制模型"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.13",
                    "title": "Comfort and Security Perception of Biometrics in Mobile Phones with Widespread Sensors",
                    "authors": "Javier Guerra Casanova, Belén Ríos-Sánchez, Miguel Viana-Matesanz, Gonzalo Bailador, Carmen Sanchez-Avila, Maria Jose Melcon De Giles",
                    "abstract": "Comfort and security perception are two key factorsto provide an adequate biometric solution. This article presentsthe results of an online survey about these characteristics in fourdifferent biometric modes implemented in mobile phones withwidespread sensors. Additionally, it presents the main concernsthat the use of these biometric modes generates in people, whichprovides a roadmap of additional issues that should be improvedto create satisfactory biometric techniques.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "舒适度和安全感是提供合适的生物识别解决方案的两个关键因素。这篇文章介绍了一项在线调查的结果，该调查是关于四种不同的生物识别模式的，这四种模式在带有广泛传感器的手机中实现。此外，它还提出了使用这些生物识别模式在人们身上产生的主要问题，这为创造令人满意的生物识别技术提供了一个应该改进的额外问题的路线图。",
                    "title_zh": "具有广泛传感器的移动电话中生物特征的舒适和安全感知"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.14",
                    "title": "A Configurable Multibiometric System for Authentication at Different Security Levels Using Mobile Devices",
                    "authors": "Belén Ríos-Sánchez, Miguel Viana-Matesanz, Carmen Sanchez-Avila, Maria Jose Melcon De Giles",
                    "abstract": "This work presents a configurable multibiometricsystem oriented to mobile devices which combines face, handand in-air signature biometrics to provide three different levelsof security. The number of traits involved in the authenticationincreases with the security strength, allowing the balance betweencomfort and accuracy according to the security requirements ofthe final application. In addition, the security of the system isenhanced by incorporating anti-coercion and aliveness detectionmechanisms. To decide which biometric mode should be requestedat each security level, an evaluation of the biometrics has beenperformed in terms of performance and users acceptability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "这项工作提出了一个面向移动设备的可配置多生物特征系统，它结合了人脸、手和空中签名生物特征来提供三个不同的安全级别。身份验证中涉及的特征数量随着安全强度的增加而增加，从而允许根据最终应用程序的安全要求在舒适性和准确性之间取得平衡。此外，通过加入反胁迫和活性检测机制，增强了系统的安全性。为了决定在每个安全级别应该请求哪种生物识别模式，已经从性能和用户可接受性方面对生物识别进行了评估。",
                    "title_zh": "使用移动设备在不同安全级别进行身份验证的可配置多生物测量系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.15",
                    "title": "BioALeg - Enabling Biometric Authentication in Legacy Web Sites",
                    "authors": "Sharareh Monfared, Daniel Andrade, Luís E. T. Rodrigues, João Nuno Silva",
                    "abstract": "The authentication of users in legacy web sites via mobile devices is still a challenging problem. Users are required to provide passwords, introducing several vulnerabilities: since strong passwords are hard to memorize, users often use weak passwords that are easy to break, and passwords can be intercepted by malware and stolen. In this paper we propose a novel architecture, named BioALeg, to support secure biometric authentication on legacy websites. Our approach leverages the potential of a Secured Personal Device (SPD), a hardware add-on for mobile phones that is being developed in the context of the PCAS European project. The device offers biometric authentication and secure storage services. BioALeg uses this infrastructure, and a companion web site plugin, to support biometric authentication in legacy web sites that currently use username/password authentication. In order to perform authentication, the smartphone requests a One Time Password (OTP) to the service provider when the user tries to access the service using the SPD. Due to the architecture and implementation of the SPD, the OTP transfer only occurs after the owner of the phone and SPD is correctly authenticated using biometrics. The PCAS infrastructure guarantees that, after the biometric authentication, the user identity is valid and accepted by all components. BioALeg has been implemented as an Android service and integrated with legacy web sites.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "通过移动设备对传统网站中的用户进行身份验证仍然是一个具有挑战性的问题。要求用户提供密码，介绍了几个漏洞:由于强密码难以记忆，用户往往使用容易破解的弱密码，密码会被恶意软件拦截并窃取。在本文中，我们提出了一种新的架构，命名为BioALeg，以支持传统网站上的安全生物认证。我们的方法利用了安全个人设备(SPD)的潜力，这是一种在PCAS欧洲项目背景下开发的移动电话硬件附件。该设备提供生物认证和安全存储服务。BioALeg使用这个基础设施和一个配套的网站插件来支持当前使用用户名/密码认证的传统网站中的生物认证。为了执行身份验证，当用户试图使用SPD访问服务时，智能手机会向服务提供商请求一次性密码(OTP)。由于SPD的架构和实现方式，OTP传输仅在手机和SPD的所有者使用生物特征被正确认证之后才发生。PCAS基础设施保证，在生物认证之后，用户身份是有效的，并且被所有组件接受。BioALeg已经作为Android服务实现，并与传统网站集成。",
                    "title_zh": "传统网站中支持生物认证的生物腿"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.16",
                    "title": "SafeRegions: Performance Evaluation of Multi-party Protocols on HBase",
                    "authors": "Rogerio Pontes, Francisco Maia, João Paulo, Ricardo Manuel Pereira Vilaça",
                    "abstract": "On-line applications and services are now a critical part of our everyday life. Using these services typically requires us to trust our personal or company's information to a large number of third-party entities. These entities enforce several security measures to avoid unauthorized accesses but data is still stored on common database systems that are designed without data privacy concerns in mind. As a result, data is vulnerable against anyone with direct access to the database, which may be external attackers, malicious insiders, spies or even subpoenas. Building strong data privacy mechanisms on top of common database systems is possible but has a significant impact on the system's resources, computational capabilities and performance. Notably, the amount of useful computation that may be done over strongly encrypted data is close to none, which defeats the purpose of offloading computation to third-party services. In this paper, we propose to shift the need to trust in the honesty and security of service providers to simply trust that they will not collude. This is reasonable as cloud providers, being competitors, do not share data among themselves. We focus on NoSQL databases and present SafeRegions, a novel prototype of a distributed and secure NoSQL database that is built on top of HBase and that guarantees strong data privacy while still providing most of HBase's query capabilities. Safe Regions relies on secret sharing and multi-party computation techniques to provide a NoSQL database built on top of multiple, non-colluding service providers that appear as a single one to the user. Strikingly, service providers, individually, cannot disclose any of the user's data but, together, are able to offer data storage and processing capabilities. Additionally, we evaluate SafeRegions exposing performance trade-offs imposed by security mechanisms and provide useful insights for future research on performance optimization.",
                    "files": {
                        "openAccessPdf": "https://repositorium.sdum.uminho.pt/bitstream/1822/66215/1/P-00M-521.pdf"
                    },
                    "abstract_zh": "在线应用和服务现在是我们日常生活的重要组成部分。使用这些服务通常需要我们将我们的个人或公司信息委托给大量第三方实体。这些实体执行若干安全措施来避免未经授权的访问，但是数据仍然存储在公共数据库系统中，这些系统在设计时没有考虑数据隐私问题。因此，数据容易受到直接访问数据库的任何人的攻击，这些人可能是外部攻击者、恶意的内部人员、间谍甚至是传票。在普通数据库系统之上构建强大的数据隐私机制是可能的，但会对系统的资源、计算能力和性能产生重大影响。值得注意的是，可以对高度加密的数据进行的有用计算量接近于零，这违背了将计算卸载到第三方服务的目的。在本文中，我们建议将信任服务提供商的诚实和安全性的需求转变为简单地信任他们不会串通。这是合理的，因为作为竞争对手，云提供商之间不共享数据。我们重点关注NoSQL数据库，并介绍SafeRegions，这是一个分布式安全NoSQL数据库的新颖原型，它构建在HBase之上，在提供大部分HBase查询功能的同时，保证了强大的数据隐私。安全区域依靠秘密共享和多方计算技术来提供NoSQL数据库，该数据库建立在多个非串通服务提供商之上，对用户来说表现为单个提供商。引人注目的是，服务提供商不能单独披露用户的任何数据，但联合起来，能够提供数据存储和处理能力。此外，我们评估了SafeRegions，揭示了安全机制带来的性能折衷，并为未来的性能优化研究提供了有用的见解。",
                    "title_zh": "安全区域:基于HBase的多方协议性能评估"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.17",
                    "title": "ARM TrustZone for Secure Image Processing on the Cloud",
                    "authors": "Tiago Brito, Nuno O. Duarte, Nuno Santos",
                    "abstract": "Nowadays, offloading storage and processing capacity to cloud servers is a growing trend. This happens because high storage capacity and powerful processors are expensive, whilst cloud services provide a cheaper, ongoing, and reliable solution. The problem with cloud-based solutions is that servers are highly accessible through the Internet and therefore considerably exposed to hackers and malware. In this paper, we design and implement Darkroom, a secure image processing service for the cloud leveraging ARM TrustZone technology. Our system enables users to securely process image data in a secure environment that prevents exposure of sensitive data to the operating system. We evaluate our system and observe that our solution adds a small overhead to image processing when compared to computer platforms that require the entire operating system to be trusted.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "如今，将存储和处理能力卸载到云服务器是一种日益增长的趋势。这是因为高存储容量和强大的处理器很昂贵，而云服务提供了一种更便宜、持续和可靠的解决方案。基于云的解决方案的问题是，服务器很容易通过互联网访问，因此很容易受到黑客和恶意软件的攻击。在本文中，我们利用ARM TrustZone技术设计并实现了一个面向云的安全图像处理服务Darkroom。我们的系统使用户能够在安全的环境中安全地处理图像数据，防止敏感数据暴露给操作系统。我们评估了我们的系统，发现与要求整个操作系统可信的计算机平台相比，我们的解决方案在图像处理方面增加了少量开销。",
                    "title_zh": "ARM TrustZone用于云上的安全图像处理"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.18",
                    "title": "Thwarting Data Exfiltration by Repackaged Applications",
                    "authors": "Daniel Andrade, Thor Kristoffersen, Ivar Rummelhoff, Alex Gerdov, João Nuno Silva",
                    "abstract": "Android applications are subject to repackaging attacks, where popular applications are modified, often by inserting malicious logic, re-signed, and then uploaded to an online store to be later on downloaded and installed by unsuspicious users. This paper presents a set of protocols for increasing trust in special-purpose Android applications, termed secured trusted applications, during communication with a trustworthy external hardware device for storing sensitive end user data, termed secured personal device. The proposed approach requires neither operating system modification nor root privileges. The evaluation of our solution shows that the authenticity and integrity of applications, and the confidentiality and integrity of communication, is ensured as long as Android operates correctly.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "Android应用程序会受到重新打包攻击，其中流行的应用程序会被修改，通常是通过插入恶意逻辑，重新签名，然后上传到在线商店，供不可疑的用户下载和安装。本文提出了一组协议，用于在与用于存储敏感终端用户数据的可信外部硬件设备(称为安全个人设备)通信期间，增加专用Android应用(称为安全可信应用)中的信任。所提出的方法既不需要修改操作系统，也不需要root权限。对我们的解决方案的评估表明，只要Android正确运行，应用的真实性和完整性以及通信的机密性和完整性就能得到保证。",
                    "title_zh": "通过重新打包的应用程序阻止数据泄露"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.19",
                    "title": "Emusphere: Evaluating Planetary-Scale Distributed Systems in Automated Emulation Environments",
                    "authors": "Johannes Köstler, Jan Seidemann, Hans P. Reiser",
                    "abstract": "This paper presents Emusphere, an integrated emulation platform for the efficient evaluation of planetary-scale distributed systems. It allows system developers and architects to assess their systems in an environment that is able to provision any desired computation infrastructure, mimic realistic environmental conditions, and carry out arbitrary usage scenarios. Unlike existing testbeds which suffer from technical complexity and high bootstrapping efforts, Emusphere is an easy-to-use and fully automated environment. This is achieved by reducing the complete configuration and execution efforts down to the definition of a single configuration file that defines the structure and course of the experiments. Those Experiment Descriptors are executed using Emusphere Executors which utilize resource providers to provision any specified virtual infrastructure, run the defined experiment steps, collect the results and finally tear down the whole environment. In this way experiments can be easily modified, reproduced, transferred and verified. We also provide an evaluation which shows that our approach surpasses existing solutions in terms of flexibility and usability while offering a high degree of scalability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了Emusphere，一个用于有效评估行星级分布式系统的集成仿真平台。它允许系统开发人员和架构师在能够提供任何所需计算基础设施、模拟真实环境条件和执行任意使用场景的环境中评估他们的系统。与现有的测试床不同，Emusphere是一个易于使用和完全自动化的环境，现有的测试床存在技术复杂性和高自举工作量的问题。这是通过将完整的配置和执行工作减少到单个配置文件的定义来实现的，该配置文件定义了实验的结构和过程。这些实验描述符使用Emusphere执行器执行，这些执行器利用资源提供者来提供任何指定的虚拟基础架构，运行定义的实验步骤，收集结果，并最终拆除整个环境。这样，实验可以很容易地修改，复制，转让和验证。我们还提供了一个评估，表明我们的方法在灵活性和可用性方面优于现有的解决方案，同时提供了高度的可扩展性。",
                    "title_zh": "Emusphere:在自动仿真环境中评估全球范围的分布式系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.20",
                    "title": "Have a Seat on the ErasureBench: Easy Evaluation of Erasure Coding Libraries for Distributed Storage Systems",
                    "authors": "Sébastien Vaucher, Hugues Mercier, Valerio Schiavoni",
                    "abstract": "We present ErasureBench, an open-source framework to test and benchmark erasure coding implementations for distributed storage systems under realistic conditions. ErasureBench automatically instantiates and scales a cluster of storage nodes, and can seamlessly leverage existing failure traces. As a first example, we use ErasureBench to compare three coding implementations: a (10,4) Reed-Solomon (RS) code, a (10,6,5) locally repairable code (LRC), and a partition of the data source in ten pieces without error-correction. Our experiments show that LRC and RS codes require the same repair throughput when used with small storage nodes, since cluster and network management traffic dominate at this regime. With large storage nodes, read and write traffic increases and our experiments confirm the theoretical and practical tradeoffs between the storage overhead and repair bandwidth of RS and LRC codes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们介绍ErasureBench，这是一个开源框架，用于在现实条件下测试和基准测试分布式存储系统的擦除编码实现。ErasureBench自动实例化和扩展存储节点集群，并可以无缝利用现有的故障跟踪。作为第一个例子，我们使用ErasureBench来比较三种编码实现:( 10，4) Reed-Solomon (RS)码,( 10，6，5)本地可修复码(LRC ),以及将数据源分成十块而不进行纠错。我们的实验表明，当用于小型存储节点时，LRC码和RS码需要相同的修复吞吐量，因为在这种情况下集群和网络管理流量占主导地位。对于大的存储节点，读取和写入流量增加，并且我们的实验证实了RS和LRC码的存储开销和修复带宽之间的理论和实际折衷。",
                    "title_zh": "请坐在擦除工作台上:轻松评估分布式存储系统的擦除编码库"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.21",
                    "title": "Adaptive IP Mutation: A Proactive Approach for Defending against Worm Propagation",
                    "authors": "Chang-Ting Lin, Chunming Wu, Min Huang, Zhenyu Wen, Qiumei Cheng",
                    "abstract": "IP address mutation is a proactive defense method that is used to reduce the risk of network attacks, especially to deal with the worm propagation attacks. However, previous work did not give much consideration to the negative effects that IP address mutation could bring to network performance. To be specific, there is a trade-off between network performance and security, which implies that when a security mechanism is reinforced, network performance would be impaired and vice versa. Therefore, in order to achieve the optimal balance between performance and security, an optimal solution should be provided. In this paper, we propose an adaptive IP mutation defense method which is based on temporal-dimension, to dynamically control the mutation interval according to real-time measurable metrics, assurance and avoidance. This method leverages a genetic algorithm to achieve the optimization of performance-security trade-off. We then evaluate our method in a simulated computer cluster environment, including 1024 hosts, and demonstrate that our method can successfully find the optimal solution according to the experimental results. For example, it can reduce the worm propagation significantly, while maintaining the network performance in a predefined level.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "IP地址变异是一种主动防御方法，用于降低网络攻击的风险，尤其是应对蠕虫传播攻击。然而，以前的工作没有考虑IP地址突变可能给网络性能带来的负面影响。具体来说，在网络性能和安全性之间有一个权衡，这意味着当安全机制被加强时，网络性能将被削弱，反之亦然。因此，为了实现性能和安全性之间的最佳平衡，应该提供最佳解决方案。本文提出了一种基于时间维度的自适应IP变异防御方法，根据实时可测量的度量、保证和避免来动态控制变异间隔。该方法利用遗传算法来实现性能-安全性折衷的优化。然后，我们在一个包括1024台主机的模拟计算机集群环境中对我们的方法进行了评估，并根据实验结果证明了我们的方法能够成功地找到最优解。例如，它可以显著减少蠕虫传播，同时将网络性能维持在预定义的水平。",
                    "title_zh": "自适应IP变异:一种主动防御蠕虫传播的方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2016.22",
                    "title": "The Convoy Effect in Atomic Multicast",
                    "authors": "Tarek Ahmed-Nacer, Pierre Sutra, Denis Conan",
                    "abstract": "Atomic multicast is a group communication primitive that allows disseminating messages to multiple distributed processes with strong ordering properties. As such, atomic multicast is a widely-employed tool to build large-scale systems, in particular when data is geo-distributed and/or replicated across multiple locations. However, all the most efficient atomic multicast algorithms suffer from a convoy effect that slows down the delivery of messages. In this paper, we study the impact of this phenomenon in detail. To this end, we first capture the convoy effect in the critical section problem with a timed automaton. We then extend this approach to the seminal atomic multicast solution of Skeen. Our analytical model shows that the convoy effect quickly degrades the latency of messages. We confirm this claim by fitting our model with empirical data from literature. To sidestep this performance degradation, we advocate the use of message semantics in atomic multicast. In particular, we present a simple protocol that reduces the convoy effect by a factor p, where p is the probability that two messages commute.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01582009/file/final.pdf"
                    },
                    "abstract_zh": "原子多播是一种组通信原语，它允许向多个具有强有序属性的分布式进程传播消息。因此，原子多播是构建大规模系统的广泛采用的工具，特别是当数据跨多个位置地理分布和/或复制时。然而，所有最有效的原子多播算法都受到护卫效应的影响，这会降低消息的传递速度。在本文中，我们详细研究了这一现象的影响。为此，我们首先用时间自动机捕捉临界区问题中的护航效应。然后，我们将这种方法扩展到Skeen开创性的原子多播解决方案。我们的分析模型表明，护送效应会迅速降低消息的延迟。我们通过用文献中的经验数据拟合我们的模型来证实这一说法。为了避免这种性能下降，我们提倡在原子多播中使用消息语义。特别地，我们提出了一个简单的协议，它通过因子p减少了护送效应，其中p是两个消息交换的概率。",
                    "title_zh": "原子多播中的护卫效应"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2016.html",
            "conf_title": "35. SRDS 2016: Budapest, Hungary",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7790033/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.012",
                    "title": "The Rowhammer Attack Injection Methodology",
                    "authors": "Keun Soo Yim",
                    "abstract": "This paper presents a systematic methodology to identify and validate security attacks that exploit user influenceable hardware faults (i.e., rowhammer errors). We break down rowhammer attack procedures into nine generalized steps where some steps are designed to increase the attack success probabilities. Our framework can perform those nine operations (e.g., pressuring system memory and spraying landing pages) as well as inject rowhammer errors which are basically modeled as ≥3-bit errors. When one of the injected errors is activated, such can cause control or data flow divergences which can then be caught by a prepared landing page and thus lead to a successful attack. Our experiments conducted against a guest operating system of a typical cloud hypervisor identified multiple reproducible targets for privilege escalation, shell injection, memory and disk corruption, and advanced denial-of-service attacks. Because the presented rowhammer attack injection (RAI) methodology uses error injection and thus statistical sampling, RAI can quantitatively evaluate the modeled rowhammer attack success probabilities of any given target software states.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文介绍了一种识别和验证利用用户可影响的硬件故障(即rowhammer错误)的安全攻击的系统方法。我们将rowhammer攻击过程分解为九个通用步骤，其中一些步骤旨在提高攻击成功的概率。我们的框架可以执行这九个操作(例如，对系统内存施压和喷射登录页面)以及注入基本上被建模为≥3位错误的rowhammer错误。当其中一个注入的错误被激活时，会导致控制或数据流偏离，然后被准备好的登录页面捕获，从而导致成功的攻击。我们针对典型云虚拟机管理程序的客户操作系统进行的实验确定了权限提升、外壳注入、内存和磁盘损坏以及高级拒绝服务攻击的多个可再现目标。因为所提出的行锤攻击注入(RAI)方法使用错误注入和统计采样，所以RAI可以定量评估任何给定目标软件状态的建模行锤攻击成功概率。",
                    "title_zh": "Rowhammer攻击注入方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.013",
                    "title": "ShareIff: A Sticky Policy Middleware for Self-Destructing Messages in Android Applications",
                    "authors": "Antonio Goulao, Nuno O. Duarte, Nuno Santos",
                    "abstract": "Self-destructing messaging applications have garnered immense popularity due to the arrival of Snapchat. However, Snapchat's history has shown that building such services on modern mobile platforms is very challenging. In fact, either caused by programming errors or due to the limitations of existing mobile operating systems, in Snapchat and other similar applications it is possible to recover supposedly deleted messages against the senders' expectations, therefore leaving millions of users potentially vulnerable to privacy breaches. This paper presents ShareIff, a middleware for Android that provides an API for secure sharing and display of self-destructing messages. Using this middleware, Snapchat or any similar application, is able to encrypt the message on the sender's endpoint and send it to the recipient such that the message can be decrypted and securely displayed only on the recipient's device for the amount of time specified by the sender. ShareIff provides this property by relying on specialized cryptographic protocols and operating system mechanisms. ShareIff offers application developers a simple programming abstraction and adds marginal overheads to system and app.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于Snapchat的到来，自毁式消息应用程序获得了巨大的人气。然而，Snapchat的历史表明，在现代移动平台上构建这样的服务非常具有挑战性。事实上，无论是由于编程错误还是由于现有移动操作系统的限制，在Snapchat和其他类似的应用程序中，都有可能违背发送者的期望恢复据称已删除的消息，从而使数百万用户的隐私可能受到侵犯。本文介绍了ShareIff，一个用于Android的中间件，它提供了一个用于安全共享和显示自毁消息的API。使用这种中间件，Snapchat或任何类似的应用程序能够在发送方的端点上加密消息，并将其发送给接收方，以便消息可以被解密，并仅在发送方指定的时间内在接收方的设备上安全地显示。ShareIff通过依赖专门的加密协议和操作系统机制来提供该属性。ShareIff为应用程序开发人员提供了简单的编程抽象，并增加了系统和应用程序的边际开销。",
                    "title_zh": "share IFF:Android应用程序中用于自毁消息的粘性策略中间件"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.014",
                    "title": "Lateral Movement Detection Using Distributed Data Fusion",
                    "authors": "Ahmed M. Fawaz, Atul Bohara, Carmen Cheh, William H. Sanders",
                    "abstract": "Attackers often attempt to move laterally from host to host, infecting them until an overall goal is achieved. One possible defense against this strategy is to detect such coordinated and sequential actions by fusing data from multiple sources. In this paper, we propose a framework for distributed data fusion that specifies the communication architecture and data transformation functions. Then, we use this framework to specify an approach for lateral movement detection that uses host-level process communication graphs to infer network connection causations. The connection causations are then aggregated into system-wide host-communication graphs that expose possible lateral movement in the system. In order to provide a balance between the resource usage and the robustness of the fusion architecture, we propose a multilevel fusion hierarchy that uses different clustering techniques. We evaluate the scalability of the hierarchical fusion scheme in terms of storage overhead, number of message updates sent, fairness of resource sharing among clusters, and quality of local graphs. Finally, we implement a host-level monitor prototype to collect connection causations, and evaluate its overhead. The results show that our approach provides an effective method to detect lateral movement between hosts, and can be implemented with acceptable overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "攻击者经常试图从一个宿主横向移动到另一个宿主，感染它们，直到达到一个总体目标。对这种策略的一种可能的防御是通过融合来自多个来源的数据来检测这种协调和连续的动作。在本文中，我们提出了一个分布式数据融合的框架，规定了通信架构和数据转换功能。然后，我们使用这个框架来指定横向移动检测的方法，该方法使用主机级进程通信图来推断网络连接原因。然后将连接原因汇总到系统范围的主机通信图中，以揭示系统中可能的横向移动。为了在融合架构的资源使用和鲁棒性之间提供平衡，我们提出了使用不同聚类技术的多级融合层次。我们从存储开销、发送的消息更新数量、集群间资源共享的公平性以及局部图的质量等方面评估了分层融合方案的可扩展性。最后，我们实现了一个主机级监视器原型来收集连接原因，并评估其开销。结果表明，我们的方法提供了一种有效的方法来检测主机之间的横向移动，并且可以以可接受的开销来实现。",
                    "title_zh": "使用分布式数据融合的横向运动检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.015",
                    "title": "Multi-round Master-Worker Computing: A Repeated Game Approach",
                    "authors": "Antonio Fernández Anta, Chryssis Georgiou, Miguel A. Mosteiro, Daniel Pareja",
                    "abstract": "We consider a computing system where a master processor assigns tasks for execution to worker processors through the Internet. We model the workers' decision of whether to comply (compute the task) or not (return a bogus result to save the computation cost) as a mixed extension of a strategic game among workers. That is, we assume that workers are rational in a game-theoretic sense, and that they randomize their strategic choice. Workers are assigned multiple tasks in subsequent rounds. We model the system as an infinitely repeated game of the mixed extension of the strategic game. In each round, the master decides stochastically whether to accept the answer of the majority or verify the answers received, at some cost. Incentives and/or penalties are applied to workers accordingly. Under the above framework, we study the conditions in which the master can reliably obtain tasks results, exploiting that the repeated game model captures the effect of long-term interaction. That is, workers take into account that their behavior in one computation will have an effect on the behavior of other workers in the future. Indeed, should a worker be found to deviate from some agreed strategic choice, the remaining workers would change their own strategy to penalize the deviator. Hence, being rational, workers do not deviate. We identify analytically the parameter conditions to induce a desired worker behavior, and we evaluate experimentally the mechanisms derived from such conditions. We also compare the performance of our mechanisms with a previously known multi-round mechanism based on reinforcement learning.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1508.05769"
                    },
                    "abstract_zh": "我们考虑一个计算系统，其中主处理器通过互联网将任务分配给工作处理器执行。我们将工人是否服从(计算任务)或不服从(返回虚假结果以节省计算成本)的决策建模为工人之间策略博弈的混合扩展。也就是说，我们假设工人在博弈论的意义上是理性的，他们随机选择他们的策略。工人在随后的几轮中被分配多项任务。我们将这个系统建模为一个无限重复的策略博弈的混合扩展博弈。在每一轮中，主人随机决定是否接受大多数人的答案或以一定的代价验证收到的答案。奖励和/或惩罚相应地适用于工人。在上述框架下，我们利用重复博弈模型捕捉到长期互动的效果，研究了主人能够可靠地获得任务结果的条件。也就是说，工作人员考虑到他们在一次计算中的行为会对将来其他工作人员的行为产生影响。事实上，如果一个工人被发现偏离了一些商定的战略选择，剩下的工人会改变他们自己的策略来惩罚偏离者。因此，理性的工人不会偏离。我们通过分析确定参数条件，以诱导期望的工人行为，我们通过实验评估从这些条件中得出的机制。我们还比较了我们的机制与先前已知的基于强化学习的多轮机制的性能。",
                    "title_zh": "多轮主-工计算:一种重复博弈方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.016",
                    "title": "Sirius: Neural Network Based Probabilistic Assertions for Detecting Silent Data Corruption in Parallel Programs",
                    "authors": "Tara E. Thomas, Anmol J. Bhattad, Subrata Mitra, Saurabh Bagchi",
                    "abstract": "The size and complexity of supercomputing clusters are rapidly increasing to cater to the needs of complex scientific applications. At the same time, the feature size and operating voltage level of the internal components are decreasing. This dual trend makes these machines extremely vulnerable to soft errors or random bit flips. For complex parallel applications, these soft errors can lead to silent data corruption which could lead to large inaccuracies in the final computational results. Hence, it is important to determine the presence and severity of such errors early on, so that proper counter measures can be taken. In this paper, we introduce a tool called Sirius, which can accurately identify silent data corruptions based on the simple insight that there exist spatial and temporal locality within most variables in such programs. Spatial locality means that values of the variable at nodes that are close by in a network sense, are also close numerically. Similarly, temporal locality means that the values change slowly and in a continuous manner with time. Sirius uses neural networks to learn such locality patterns, separately for each critical variable, and produces probabilistic assertions which can be embedded in the code of the parallel program to detect silent data corruptions. We have implemented this technique on parallel benchmark programs - LULESH and CoMD. Our evaluations show that Sirius can detect silent errors in the code with much higher accuracy compared to previously proposed methods. Sirius detected 98% of the silent data corruptions with a false positive rate of less than 0.02 as compared to the false positive rate 0.06 incurred by the state of the art acceleration based prediction (ABP) based technique.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "超级计算集群的规模和复杂性正在迅速增加，以满足复杂科学应用的需求。同时，内部元件的特征尺寸和工作电压水平也在降低。这种双重趋势使得这些机器极易出现软错误或随机比特翻转。对于复杂的并行应用程序，这些软错误可能会导致无声的数据损坏，从而导致最终计算结果的巨大误差。因此，尽早确定此类错误的存在和严重性非常重要，以便采取适当的应对措施。在本文中，我们介绍了一个叫做Sirius的工具，它可以准确地识别静默数据损坏，其基础是这类程序中的大多数变量都存在空间和时间局部性。空间局部性意味着在网络意义上邻近的节点上的变量值在数字上也是邻近的。类似地，时间局部性意味着这些值随着时间以连续的方式缓慢变化。Sirius使用神经网络分别为每个关键变量学习这种局部性模式，并生成概率性断言，这些断言可以嵌入并行程序的代码中，以检测静默数据损坏。我们已经在并行基准程序LULESH和CoMD上实现了这种技术。我们的评估表明，与以前提出的方法相比，Sirius可以更准确地检测代码中的无声错误。Sirius以小于0.02的假阳性率检测到98%的无声数据损坏，相比之下，由基于加速的预测(ABP)技术引起的假阳性率为0.06。",
                    "title_zh": "Sirius:基于神经网络的概率断言，用于检测并行程序中的静默数据损坏"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.017",
                    "title": "CRUDE: Combining Resource Usage Data and Error Logs for Accurate Error Detection in Large-Scale Distributed Systems",
                    "authors": "Nentawe Gurumdimma, Arshad Jhumka, Maria Liakata, Edward Chuah, James C. Browne",
                    "abstract": "The use of console logs for error detection in large scale distributed systems has proven to be useful to system administrators. However, such logs are typically redundant and incomplete, making accurate detection very difficult. In an attempt to increase this accuracy, we complement these incomplete console logs with resource usage data, which captures the resource utilisation of every job in the system. We then develop a novel error detection methodology, the CRUDE approach, that makes use of both the resource usage data and console logs. We thus make the following specific technical contributions: we develop (i) a clustering algorithm to group nodes with similar behaviour, (ii) an anomaly detection algorithm to identify jobs with anomalous resource usage, (iii) an algorithm that links jobs with anomalous resource usage with erroneous nodes. We then evaluate our approach using console logs and resource usage data from the Ranger Supercomputer. Our results are positive: (i) our approach detects errors with a true positive rate of about 80%, and (ii) when compared with the well-known Nodeinfo error detection algorithm, our algorithm provides an average improvement of around 85% over Nodeinfo, with a best-case improvement of 250%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在大规模分布式系统中使用控制台日志进行错误检测已被证明对系统管理员非常有用。然而，这样的日志通常是冗余的和不完整的，使得准确的检测非常困难。为了提高这种准确性，我们用资源使用数据来补充这些不完整的控制台日志，这些数据可以捕获系统中每个作业的资源利用率。然后，我们开发了一种新的错误检测方法，即粗糙方法，它利用了资源使用数据和控制台日志。因此，我们做出了以下具体的技术贡献:我们开发了(I)将具有相似行为的节点分组的聚类算法，(ii)识别具有异常资源使用的作业的异常检测算法，(iii)将具有异常资源使用的作业与错误节点链接的算法。然后，我们使用来自Ranger超级计算机的控制台日志和资源使用数据来评估我们的方法。我们的结果是肯定的:(I)我们的方法以大约80%的真实肯定率检测错误，以及(ii)当与众所周知的Nodeinfo错误检测算法相比时，我们的算法提供了比Nodeinfo大约85%的平均改善，最好的情况下改善了250%。",
                    "title_zh": "粗:结合资源使用数据和错误日志，在大规模分布式系统中进行准确的错误检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.018",
                    "title": "Achieving High Reliability via Expediting the Repair of Critical Blocks in Replicated Storage Systems",
                    "authors": "Juntao Fang, Shenggang Wan, Ping Huang, Xubin He, Changsheng Xie",
                    "abstract": "High reliability is critical to large data centers consisting of hundreds to thousands of storage nodes where node failures are not rare. Data replication is a typical technique deployed to achieve high reliability. When a node failure is detected, blocks with lost replicas are identified and recovered. Long timeouts are usually used for node failure detection. For blocks with one lost replica, the long timeouts can significantly reduce network traffic induced by data recovery. However, for blocks with two or more lost replicas, which can be caused by concurrent node failures that are not rare in large data centers, the long timeouts will result in a high risk of loss of these blocks. In this paper, we propose MFR to separate the identification of the blocks with two or more lost replicas from that of the blocks with one lost replica in a way that the identification of the blocks with two or more replicas can be accelerated while that of the blocks with one lost replica stays the same. Consequently, MFR can significantly improve data reliability while keeping the network traffic induced by data recovery stable. The results from our simulation and prototype implementation show that MFR improves the reliability of storage systems by a factor of up to 4.0 in terms of mean time to data loss. As blocks with two or more lost replicas are far fewer than blocks with one lost replica, the extra network traffic caused by MFR is less than 0.54% of total network traffic for data recovery.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高可靠性对于由数百到数千个存储节点组成的大型数据中心至关重要，在这些数据中心中，节点故障并不罕见。数据复制是实现高可靠性的典型技术。当检测到节点故障时，具有丢失副本的块被识别和恢复。长超时通常用于节点故障检测。对于具有一个丢失副本的块，长超时可以显著减少由数据恢复引起的网络流量。但是，对于具有两个或更多丢失副本的数据块(这可能是由大型数据中心中并不罕见的并发节点故障引起的)，长超时将导致这些数据块丢失的高风险。在本文中，我们提出了MFR来将具有两个或更多丢失副本的块的识别与具有一个丢失副本的块的识别分开，使得具有两个或更多副本的块的识别可以被加速，而具有一个丢失副本的块的识别保持不变。因此，MFR可以显著提高数据可靠性，同时保持由数据恢复引起的网络流量稳定。我们的模拟和原型实现的结果表明，就平均数据丢失时间而言，MFR将存储系统的可靠性提高了4.0倍。由于具有两个或更多丢失副本的块远远少于具有一个丢失副本的块，所以由MFR引起的额外网络流量小于用于数据恢复的总网络流量的0.54%。",
                    "title_zh": "通过加快复制存储系统中关键块的修复来实现高可靠性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.019",
                    "title": "Being Accurate Is Not Enough: New Metrics for Disk Failure Prediction",
                    "authors": "Jing Li, Rebecca J. Stones, Gang Wang, Zhongwei Li, Xiaoguang Liu, Kang Xiao",
                    "abstract": "Traditionally, disk failure prediction accuracy is used to evaluate disk failure prediction model. However, accuracy may not reflect their practical usage (protecting against failures, rather than only predicting failures) in cloud storage systems. In this paper, we propose two new metrics for disk failure prediction models: migration rate, which measures how much at-risk data is protected as a result of correct failure predictions, and mismigration rate, which measures how much data is migrated needlessly as a result of false failure predictions. To demonstrate their effectiveness, we compare disk failure prediction methods: (a) a classification tree (CT) model vs. a state-of-the-art recurrent neural network (RNN) model, and (b) a proposed residual life prediction model based on gradient boosted regression trees (GBRTs) vs. RNN. While prediction accuracy experiments favor the RNN model, migration rate experiments can favor the CT and GBRT models (depending on transfer rates). We conclude that prediction accuracy can be a misleading metric. Moreover, the proposed GBRT model offers a practical improvement in disk failure prediction in real-world data centers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传统上，磁盘故障预测精度是用来评价磁盘故障预测模型的。然而，准确性可能并不反映它们在云存储系统中的实际用途(防止故障，而不仅仅是预测故障)。在本文中，我们为磁盘故障预测模型提出了两个新的指标:迁移率，它衡量由于正确的故障预测而保护了多少有风险的数据；以及误迁移率，它衡量由于错误的故障预测而不必要地迁移了多少数据。为了证明其有效性，我们比较了磁盘故障预测方法:(a)分类树(CT)模型与最先进的递归神经网络(RNN)模型，以及(b)基于梯度增强回归树(GBRTs)的剩余寿命预测模型与RNN。虽然预测准确性实验有利于RNN模型，但迁移率实验可能有利于CT和GBRT模型(取决于迁移率)。我们的结论是，预测准确性可能是一个误导性的指标。此外，提出的GBRT模型在现实世界数据中心的磁盘故障预测方面提供了实际的改进。",
                    "title_zh": "准确是不够的:磁盘故障预测的新指标"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.020",
                    "title": "Norton Zone: Symantec's Secure Cloud Storage System",
                    "authors": "Walter Bogorad, Scott Schneider, Haibin Zhang",
                    "abstract": "Cloud storage services are the way of the future, if not the present, but broad adoption is limited by a stark trade-off between privacy and functionality. Many popular cloud services provide search capabilities, but make only nominal efforts to keep user data fully private. Alternatives that search private user data on an untrusted server sacrifice functionality and/or scalability. We describe Norton Zone, Symantec's secure and scalable public storage system based on our valet security model. Whereas most commercial cloud storage systems secure user data with access control and legal mechanisms, Zone's cryptographic techniques provide proven privacy guarantees. This gives users an extra layer of security without compromising functionality. Zone's performance is comparable to unencrypted cloud storage systems that support search and sharing. We report on the design of Zone and the lessons learned in developing and deploying it in commercial, distributed datacenters scalable to millions of users.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云存储服务是未来的方向，如果不是现在的话，但是隐私和功能之间的明显权衡限制了广泛采用。许多流行的云服务提供搜索功能，但只是名义上努力保持用户数据的完全隐私。在不受信任的服务器上搜索私人用户数据的替代方案牺牲了功能和/或可伸缩性。我们将介绍诺顿区，这是赛门铁克基于代客安全模型的安全且可扩展的公共存储系统。虽然大多数商业云存储系统通过访问控制和法律机制来保护用户数据，但Zone的加密技术提供了成熟的隐私保证。这为用户提供了额外的安全保障，同时又不影响功能。Zone的性能堪比支持搜索和共享的未加密云存储系统。我们报告了Zone的设计，以及在可扩展到数百万用户的商业分布式数据中心中开发和部署Zone的经验教训。",
                    "title_zh": "诺顿区:赛门铁克的安全云存储系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.021",
                    "title": "Tale of Tails: Anomaly Avoidance in Data Centers",
                    "authors": "Ji Xue, Robert Birke, Lydia Y. Chen, Evgenia Smirni",
                    "abstract": "It is a common practice that today's cloud data centers guard the performance by monitoring the resource usage, e.g., CPU and RAM, and issuing anomaly tickets whenever detecting usages exceeding predefined target values. Ensuring free of such usage anomaly can be extremely challenging, while catering to a large amount of virtual machines (VMs) showing bursty workloads on a limited amount of physical resource. Using resource usage data from production data centers that consist of more than 6K physical machines hosting more than 80K VMs, we identify statistic properties of anomaly instances (AIs) on physical servers, highlighting their burst duration and potential root causes. To strike a tradeoff between a strong performance guarantee and resource provisions, we propose a tail-driven anomaly avoidance policy for boxes, TailGuard, which allows a small fraction of AIs, e.g., 5% of usages can be above the target value, and still avoid severe performance degradation, typically caused by a burst of continuous AI. Specifically, TailGuard first introduces a novel usage tail prediction that explores the similarity patterns across a great number of boxes within a very recent history, and then redistributes the server load in an online fashion by proactive VM cloning and reactive load balancing. Evaluation results show that TailGuard can not only achieve an accuracy comparable with prediction methodology that relies on long history of usage data but also dramatically reduce the number of CPU AIs by 60%, with a tenfold reduction of their duration, from more than 25 time windows to only 2.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当今的云数据中心通常通过监控资源使用(例如CPU和RAM)来保护性能，并在检测到使用超过预定义的目标值时发出异常票据。确保没有这种使用异常是极具挑战性的，同时要在有限的物理资源上满足大量显示突发工作负载的虚拟机(VM)的需求。使用来自生产数据中心的资源使用数据，生产数据中心由托管80K多台虚拟机的6K多台物理机组成，我们确定了物理服务器上异常实例(ai)的统计属性，突出了它们的爆发持续时间和潜在的根本原因。为了在强大的性能保证和资源供应之间取得平衡，我们提出了一种尾部驱动的异常避免策略TailGuard，它允许一小部分AI，例如，5%的使用可以高于目标值，并且仍然避免严重的性能下降，通常由连续AI的突发引起。具体来说，TailGuard首先引入了一种新颖的使用尾部预测，该预测可以在最近的历史记录中跨大量机器探索相似性模式，然后通过主动虚拟机克隆和反应式负载平衡以在线方式重新分配服务器负载。评估结果表明，TailGuard不仅可以实现与依赖于长期使用数据历史的预测方法相当的准确性，还可以将CPU AIs的数量大幅减少60%，其持续时间减少10倍，从超过25个时间窗口减少到仅2个。",
                    "title_zh": "尾巴的故事:数据中心的异常规避"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.022",
                    "title": "vMocity: Traveling VMs Across Heterogeneous Clouds",
                    "authors": "Cheng Cheng, Zhui Deng, Zhongshu Gu, Dongyan Xu",
                    "abstract": "Current IaaS cloud providers typically adopt different underlying cloud infrastructures and are reluctant to provide consistent interfaces to facilitate cross-cloud interoperability. Such status quo significantly complicates inter-cloud virtual machine relocation and impedes the adoption of cloud services for more enterprises and individual users. In this paper, we propose vMocity, a middleware framework enabling VM relocation across heterogeneous IaaS clouds. vMocity extends the principles of cold migration and decouples VM's storage stack from their underlying virtualization platforms, which presents a homogeneous view of storage to cloud users. We deploy our prototype system across three representative commercial cloud platforms — Amazon EC2, Google Compute Engine, and VMware vSphere-based private cloud. Compared to existing approaches on both synthetic and real-world work-loads, vMocity can significantly reduce the disruption time, up to 27 times shorter, of relocated services and boost the recovery time, up to 1.8 times faster, to pre-relocation performance level. Our results demonstrate that vMocity is efficient and convenient for relocating VMs across clouds, offering freedom of choice to customers when facing a market of IaaS clouds to align with business objectives (cost, performance, service availability, etc.)",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "当前的IaaS云提供商通常采用不同的底层云基础设施，并且不愿意提供一致的接口来促进跨云互操作性。这种现状使跨云虚拟机迁移变得非常复杂，并阻碍了更多企业和个人用户采用云服务。在本文中，我们提出了vMocity，这是一个支持跨异构IaaS云的虚拟机重定位的中间件框架。vMocity扩展了冷迁移的原则，并将虚拟机的存储堆栈与其底层虚拟化平台分离，从而为云用户提供了一个同构的存储视图。我们在三个具有代表性的商业云平台上部署了我们的原型系统——Amazon EC2、Google Compute Engine和基于VMware vSphere的私有云。与针对合成和真实工作负载的现有方法相比，vMocity可以显著减少重新定位服务的中断时间(缩短27倍),并将恢复时间提高1.8倍，达到重新定位前的性能水平。我们的结果表明，vMocity能够高效、便捷地跨云重新部署虚拟机，在面对IaaS云市场时，为客户提供了自由选择的空间，以符合业务目标(成本、性能、服务可用性等)。)",
                    "title_zh": "vMocity:跨异构云迁移虚拟机"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.023",
                    "title": "Storekeeper: A Security-Enhanced Cloud Storage Aggregation Service",
                    "authors": "Sancha Pereira, André Alves, Nuno Santos, Ricardo Chaves",
                    "abstract": "Cloud storage services are currently a commodity that allows users to store data persistently, access the data from everywhere, and share it with friends or co-workers. However, due to the proliferation of cloud storage accounts and lack of interoperability between cloud services, managing and sharing cloud-hosted files is a nightmare for many users. To address this problem, specialized cloud aggregator systems emerged that provide users a global view of all files in their accounts and enable file sharing between users from different clouds. Such systems, however, have limited security: not only they fail to provide end-to-end privacy from cloud providers, but they require users to grant full access privileges to individual cloud storage accounts. In this paper, we present Storekeeper, a privacy-preserving cloud aggregation service that enables file sharing on multi-user multi-cloud storage platforms while preserving data confidentiality from cloud providers and from the cloud aggregator service. To provide this property, Storekeeper decentralizes most of the cloud aggregation logic to the client side enabling security sensitive functions to be performed only on the trusted client endpoints. This decentralization brings new challenges related with file update propagation, access control, user authentication, and key management that are addressed by Storekeeper. This is provided at a low cost (7% on average) when compared with the underlining cloud providers.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "云存储服务目前是一种商品，允许用户持久存储数据，从任何地方访问数据，并与朋友或同事分享数据。然而，由于云存储帐户的激增和云服务之间缺乏互操作性，管理和共享云托管的文件是许多用户的噩梦。为了解决这个问题，出现了专门的云聚合器系统，它为用户提供其帐户中所有文件的全局视图，并允许来自不同云的用户之间共享文件。然而，这样的系统具有有限的安全性:它们不仅不能提供来自云提供商的端到端隐私，而且它们需要用户授予个人云存储帐户的完全访问权限。在本文中，我们介绍了Storekeeper，这是一种保护隐私的云聚合服务，它支持多用户多云存储平台上的文件共享，同时保护云提供商和云聚合服务的数据机密性。为了提供这一特性，Storekeeper将大部分云聚合逻辑分散到客户端，使得安全敏感功能仅在可信客户端端点上执行。这种分散化带来了与文件更新传播、访问控制、用户认证和密钥管理相关的新挑战，这些挑战由Storekeeper解决。与主要的云提供商相比，这一成本较低(平均7%)。",
                    "title_zh": "Storekeeper:一种安全性增强的云存储聚合服务"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.024",
                    "title": "VMBeam: Zero-Copy Migration of Virtual Machines for Virtual IaaS Clouds",
                    "authors": "Kenichi Kourai, Hiroki Ooba",
                    "abstract": "Virtual Infrastructure-as-a-Service (IaaS) clouds are emerging for secondary cloud service providers to manage their own IaaS clouds on top of existing IaaS clouds. In virtual IaaS clouds, guest virtual machines (VMs) run inside cloud VMs provided by existing IaaS clouds. Unlike traditional IaaS clouds, they can be migrated between cloud VMs co-located at the same host. However, the performance of such VM migration is low due to slow virtual networks and doubled system loads. To optimize VM migration between co-located cloud VMs, we propose zero-copy migration for virtual IaaS clouds. Zero-copy migration just relocates the memory image of a guest VM without any copy. To enable live migration with negligible downtime, it first makes the memory of a guest VM share with the destination cloud VM and thereafter completes memory relocation. We have implemented a system called VMBeam for enabling zero-copy migration in Xen. According to our experimental results, zero-copy migration could achieve high migration performance and low system loads.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虚拟基础设施即服务(IaaS)云正在兴起，供二级云服务提供商在现有IaaS云的基础上管理自己的IaaS云。在虚拟IaaS云中，来宾虚拟机(VM)在由现有IaaS云提供的云VM内运行。与传统的IaaS云不同，它们可以在位于同一主机的云虚拟机之间迁移。然而，这种虚拟机迁移的性能很低，因为虚拟网络很慢，系统负载加倍。为了优化位于同一位置的云虚拟机之间的虚拟机迁移，我们提出了虚拟IaaS云的零拷贝迁移。零拷贝迁移只是重新定位来宾虚拟机的内存映像，而没有任何拷贝。为了在几乎不停机的情况下实现实时迁移，它首先让来宾虚拟机的内存与目标云虚拟机共享，然后完成内存重新分配。我们实现了一个名为VMBeam的系统，用于在Xen中实现零拷贝迁移。根据我们的实验结果，零拷贝迁移可以实现高迁移性能和低系统负载。",
                    "title_zh": "VMBeam:面向虚拟IaaS云的虚拟机零拷贝迁移"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.025",
                    "title": "Inside-Out: Reliable Performance Prediction for Distributed Storage Systems in the Cloud",
                    "authors": "Chin-Jung Hsu, Rajesh K. Panta, Moo-Ryong Ra, Vincent W. Freeh",
                    "abstract": "Many storage systems are undergoing a significant shift from dedicated appliance-based model to software-defined storage (SDS) because the latter is flexible, scalable and cost-effective for modern workloads. However, it is challenging to provide a reliable guarantee of end-to-end performance in SDS due to complex software stack, time-varying workload and performance interference among tenants. Therefore, modeling and monitoring the performance of storage systems is critical for ensuring reliable QoS guarantees. Existing approaches such as performance benchmarking and analytical modeling are inadequate because they are not efficient in exploring large configuration space, and cannot support elastic operations and diverse storage services in SDS. This paper presents Inside-Out, an automatic model building tool that creates accurate performance models for distributed storage services. Inside-Out is a black-box approach. It builds high-level performance models by applying machine learning techniques to low-level system performance metrics collected from individual components of the distributed SDS system. Inside-Out uses a two-level learning method that combines two machine learning models to automatically filter irrelevant features, boost prediction accuracy and yield consistent prediction. Our in-depth evaluation shows that Inside-Out is a robust solution that enables SDS to predict end-to-end performance even in challenging conditions, e.g., changes in workload, storage configuration, available cloud resources, size of the distributed storage service, and amount of interference due to multi-tenants. Our experiments show that Inside-Out can predict end-to-end performance with 91.1% accuracy on average. Its prediction accuracy is consistent across diverse storage environments.",
                    "files": {
                        "openAccessPdf": "https://repository.lib.ncsu.edu/bitstream/1840.20/33539/1/TR-2016-9.pdf"
                    },
                    "abstract_zh": "许多存储系统正在经历从基于专用设备的模式到软件定义的存储(SDS)的重大转变，因为后者对于现代工作负载来说灵活、可扩展且经济高效。然而，由于复杂的软件堆栈、时变的工作负载和租户间的性能干扰，在SDS中提供可靠的端到端性能保证具有挑战性。因此，建模和监控存储系统的性能对于确保可靠的QoS保证至关重要。现有的方法如性能基准测试和分析建模是不充分的，因为它们在探索大型配置空间方面效率不高，并且不能支持SDS中的弹性操作和多样化存储服务。本文介绍了Inside-Out，这是一种自动建模工具，可以为分布式存储服务创建精确的性能模型。由内向外是一种黑盒方法。它通过将机器学习技术应用于从分布式SDS系统的各个组件收集的低级系统性能度量来构建高级性能模型。Inside-Out使用两级学习方法，结合两个机器学习模型来自动过滤不相关的特征，提高预测准确性，并产生一致的预测。我们的深入评估表明，Inside-Out是一款强大的解决方案，即使在工作负载、存储配置、可用云资源、分布式存储服务的规模以及多租户造成的干扰量等挑战性条件下，SDS也能预测端到端性能。我们的实验表明，Inside-Out可以预测端到端性能，平均准确率为91.1%。它的预测准确性在不同的存储环境中保持一致。",
                    "title_zh": "由内而外:云中分布式存储系统的可靠性能预测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.026",
                    "title": "DTC: A Dynamic Transaction Chopping Technique for Geo-replicated Storage Systems",
                    "authors": "Ning Huang, Lihui Wu, Weigang Wu",
                    "abstract": "Large Web applications usually require replicating data across geo-distributed datacenters to achieve high locality, durability and availability. However, maintaining strong consistency in geo-replicated systems usually suffers from long latency due to costly coordination across datacenters. Among others, transaction chopping is an effective and efficient approach to cope with such a challenge. In this paper, we propose DTC (Dynamic Transaction Chopping), a novel technique that chops transactions and checks their conflicts in a dynamic and automatic way, during application execution. DTC mainly consists of two parts: a dynamic chopper that chops transaction dynamically according to data partition scheme, and a conflict detection algorithm for determining the safety of the dynamic chopping. Compared with existing transaction chopping technique for geo-replicated systems, DTC has several advantages, including transparency to programmers, flexibility in conflict analysis, high degree of piecewise execution, and adaptability to dynamic partition schemes. We implement our DTC technique and conduct experiments to examine the correctness of DTC and evaluate its performance. The experiment results show that our DTC technique can achieve much more piecewise execution than the existing chopping approach does, and reduce execution time obviously.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大型Web应用程序通常需要跨地理分布的数据中心复制数据，以实现高局部性、持久性和可用性。然而，由于跨数据中心的协调成本高昂，在地理复制系统中保持强一致性通常会遭遇长延迟。其中，事务截断是应对这种挑战的一种有效且高效的方法。在本文中，我们提出了DTC (Dynamic Transaction Chopping ),这是一种在应用程序执行期间，以动态和自动的方式分割事务并检查其冲突的新技术。DTC主要由两部分组成:一个根据数据划分方案动态切分事务的动态切分器，以及一个确定动态切分安全性的冲突检测算法。与现有的用于地理复制系统的事务截断技术相比，DTC具有几个优点，包括对程序员透明、冲突分析的灵活性、高度的分段执行以及对动态分区方案的适应性。我们实现了DTC技术，并进行了实验来检验DTC的正确性和评估其性能。实验结果表明，与现有的斩波方法相比，我们的DTC技术可以实现更多的分段执行，并明显减少执行时间。",
                    "title_zh": "DTC:一种用于地理复制存储系统的动态事务截断技术"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.027",
                    "title": "GlobalFS: A Strongly Consistent Multi-site File System",
                    "authors": "Leandro Pacheco, Raluca Halalai, Valerio Schiavoni, Fernando Pedone, Etienne Rivière, Pascal Felber",
                    "abstract": "This paper introduces GlobalFS, a POSIX-compliant geographically distributed file system. GlobalFS builds on two fundamental building blocks, an atomic multicast group communication abstraction and multiple instances of a single-site data store. We define four execution modes and show how all file system operations can be implemented with these modes while ensuring strong consistency and tolerating failures. We describe the GlobalFS prototype in detail and report on an extensive performance assessment. We have deployed GlobalFS across all EC2 regions and show that the system scales geographically, providing performance comparable to other state-of-the-art distributed file systems for local commands and allowing for strongly consistent operations over the whole system. The code of GlobalFS is available as open source.",
                    "files": {
                        "openAccessPdf": "https://dial.uclouvain.be/downloader/downloader.php?pid=boreal:213812&datastream=PDF_01&disclaimer=3e9c27f51e5ab53cb65e59b88842c56c27850bf73456bf73eae2d48bfc6ae7c8"
                    },
                    "abstract_zh": "本文介绍了GlobalFS，一个符合POSIX标准的地理分布式文件系统。GlobalFS构建在两个基本构建块上，一个原子多播组通信抽象和单站点数据存储的多个实例。我们定义了四种执行模式，并展示了如何使用这些模式实现所有文件系统操作，同时确保强一致性和容错。我们详细描述了GlobalFS原型，并报告了广泛的性能评估。我们已经在所有EC2区域部署了GlobalFS，并展示了该系统在地理上的可伸缩性，为本地命令提供了可与其他先进的分布式文件系统相媲美的性能，并允许在整个系统上进行高度一致的操作。GlobalFS的代码是开源的。",
                    "title_zh": "GlobalFS:一个强一致性的多站点文件系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.028",
                    "title": "On the Cost of Safe Storage for Public Clouds: An Experimental Evaluation",
                    "authors": "Dorian Burihabwa, Rogerio Pontes, Pascal Felber, Francisco Maia, Hugues Mercier, Rui Oliveira, João Paulo, Valerio Schiavoni",
                    "abstract": "Cloud-based storage services such as Dropbox, Google Drive and OneDrive are increasingly popular for storing enterprise data, and they have already become the de facto choice for cloud-based backup of hundreds of millions of regular users. Drawn by the wide range of services they provide, no upfront costs and 24/7 availability across all personal devices, customers are well-aware of the benefits that these solutions can bring. However, most users tend to forget—or worse ignore—some of the main drawbacks of such cloud-based services, namely in terms of privacy. Data entrusted to these providers can be leaked by hackers, disclosed upon request from a governmental agency's subpoena, or even accessed directly by the storage providers (e.g., for commercial benefits). While there exist solutions to prevent or alleviate these problems, they typically require direct intervention from the clients, like encrypting their data before storing it, and reduce the benefits provided such as easily sharing data between users. This practical experience report studies a wide range of security mechanisms that can be used atop standard cloud-based storage services. We present the details of our evaluation testbed and discuss the design choices that have driven its implementation. We evaluate several state-of-the-art techniques with varying security guarantees responding to user-assigned security and privacy criteria. Our results reveal the various trade-offs of the different techniques by means of representative workloads on top of industry-grade storage services.",
                    "files": {
                        "openAccessPdf": "http://repositorio.inesctec.pt/bitstreams/1890a6ba-5b4f-4349-8990-61952e6500f9/download"
                    },
                    "abstract_zh": "Dropbox、Google Drive和OneDrive等基于云的存储服务越来越受欢迎，它们已经成为数亿普通用户基于云备份的事实上的选择。客户被他们提供的广泛服务、无前期成本和所有个人设备的24/7可用性所吸引，非常清楚这些解决方案可以带来的好处。然而，大多数用户倾向于忘记——或者更糟的是忽略——这种基于云的服务的一些主要缺点，即在隐私方面。委托给这些提供商的数据可能会被黑客泄露，应政府机构的传票的请求而被披露，或者甚至被存储提供商直接访问(例如，为了商业利益)。虽然存在防止或减轻这些问题的解决方案，但是它们通常需要客户端的直接干预，例如在存储数据之前对其进行加密，并且降低了所提供的好处，例如在用户之间容易地共享数据。这份实践经验报告研究了可以在基于云的标准存储服务上使用的各种安全机制。我们将详细介绍我们的评估测试平台，并讨论推动其实施的设计选择。我们评估了几种最先进的技术，这些技术根据用户指定的安全和隐私标准提供不同的安全保证。我们的结果通过基于行业级存储服务的代表性工作负载揭示了不同技术的各种权衡。",
                    "title_zh": "公共云安全存储的成本:实验评估"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.029",
                    "title": "Who's On Board?: Probabilistic Membership for Real-Time Distributed Control Systems",
                    "authors": "Rachid Guerraoui, David Kozhaya, Manuel Oriol, Yvonne-Anne Pignolet",
                    "abstract": "To increase their dependability, distributed control systems (DCSs) need to agree in real time about which hosts have crashed, i.e., they need a real-time membership service. In this paper, we prove that such a service cannot be implemented deterministically if, besides host crashes, communication can also fail. We define implementable probabilistic variants of membership properties, which constitute what we call a synchronous membership service (SYMS). We present an algorithm, ViewSnoop, that implements SYMS with high-probability. We implement, deploy and evaluate ViewSnoop analytically as well as experimentally, within an industrial DCS framework. We show that ViewSnoop significantly improves the dependability of DCSs compared to membership schemes based on classic heartbeats, at low additional cost. Moreover, ViewSnoop distinguishes, with high probability, host crashes from message losses, enabling DCSs to counteract losses better than existing approaches.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "为了增加它们的可靠性，分布式控制系统(DCSs)需要实时地就哪些主机已经崩溃达成一致，也就是说，它们需要实时的成员资格服务。在本文中，我们证明，如果除了主机崩溃之外，通信也可能失败，那么这样的服务就不能确定地实现。我们定义了成员属性的可实现的概率变量，这构成了我们所说的同步成员服务(SYMS)。我们提出了一种高概率实现SYMS的算法ViewSnoop。我们在工业DCS框架内，通过分析和实验的方式实施、部署和评估ViewSnoop。我们发现，与基于经典心跳的成员方案相比，ViewSnoop以较低的额外成本显著提高了DCSs的可靠性。此外，ViewSnoop以很高的概率区分主机崩溃和消息丢失，使DCSs能够比现有方法更好地抵消丢失。",
                    "title_zh": "谁在船上？实时分布式控制系统的概率成员"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.030",
                    "title": "UDS: A Novel and Flexible Scheduling Algorithm for Deterministic Multithreading",
                    "authors": "Franz J. Hauck, Gerhard Habiger, Jörg Domaschka",
                    "abstract": "Active replication requires deterministic execution in each replica in order to keep them consistent. Debugging and testing need deterministic execution in order to avoid data races and \"Heisenbugs\". Beside input, multi-threading constitutes a major source of nondeterminism. Several deterministic scheduling algorithms exist that allow concurrent but deterministic executions. Yet, these algorithms seem to be very different. Some of them were even developed without knowing the others. In this paper, we present the novel and flexible Unified Deterministic Scheduling algorithm (UDS) for weakly and fully deterministic systems. Compared to existing algorithms, UDS has a broader parameter set, allowing for many configurations that can be used to adapt to a given work load. For the first time, UDS defines reconfiguration of a deterministic scheduler at run-time. Further, we informally show that existing algorithms can be imitated by a particular configuration of UDS, demonstrating its importance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "主动复制需要在每个副本中确定性地执行，以保持它们的一致性。调试和测试需要确定性的执行，以避免数据竞争和“海森伯格”。除了输入，多线程也是不确定性的主要来源。存在几种确定性调度算法，它们允许并发但确定性的执行。然而，这些算法似乎非常不同。其中一些甚至是在不了解其他人的情况下开发的。本文针对弱确定性系统和完全确定性系统，提出了一种新颖灵活的统一确定性调度算法。与现有算法相比，UDS具有更广泛的参数集，允许用于适应给定工作负载的许多配置。UDS首次定义了运行时确定性调度程序的重新配置。此外，我们非正式地表明，现有的算法可以被一个特定的配置的UDS模仿，证明了它的重要性。",
                    "title_zh": "UDS:一种新颖灵活的确定性多线程调度算法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.031",
                    "title": "Practical State Machine Replication with Confidentiality",
                    "authors": "Sisi Duan, Haibin Zhang",
                    "abstract": "We address the problem of how to store and process data privately in cloud environments that employ state machine replication. We show that the only known solution to the problem (Yin et al., SOSP '03) is potentially susceptible to attacks. We then present a new protocol that is secure in the stronger model we formalize. Our protocol uses only efficient symmetric cryptography, while Yin et al.'s uses costly threshold signatures. We implemented and evaluated our protocol. We show that our protocol is two to three orders of magnitude faster than Yin et al.'s, which is less secure than ours.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们解决了如何在采用状态机复制的云环境中存储和处理数据的问题。我们表明，唯一已知的解决问题的方法(尹等人，03)是潜在的易受攻击。然后，我们提出了一个新的协议，它在我们形式化的更强模型中是安全的。我们的协议只使用有效的对称密码，而尹等人的协议使用昂贵的门限签名。我们实施并评估了我们的方案。我们证明了我们的协议比尹等人的协议快两到三个数量级，而后者的安全性不如我们的协议。",
                    "title_zh": "具有保密性的实用状态机复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.032",
                    "title": "Speed for the Elite, Consistency for the Masses: Differentiating Eventual Consistency in Large-Scale Distributed Systems",
                    "authors": "Davide Frey, Achour Mostéfaoui, Matthieu Perrin, Pierre-Louis Roman, François Taïani",
                    "abstract": "Eventual consistency is a consistency model that emphasizes liveness over safety, it is often used for its ability to scale as distributed systems grow larger. Eventual consistency tends to be uniformly applied to an entire system, but we argue that there is a growing demand for differentiated eventual consistency requirements. We address this demand with UPS, a novel consistency mechanism that offers differentiated eventual consistency and delivery speed by working in pair with a two-phase epidemic broadcast protocol. We propose a closed-form analysis of our approach's delivery speed, and we evaluate our complete mechanism experimentally on a simulated network of one million nodes. To measure the consistency trade-off, we formally define a novel and scalable consistency metric that operates at runtime. In our simulations, UPS divides by more than 4 the inconsistencies experienced by a majority of the nodes, while reducing the average latency incurred by a small fraction of the nodes from 6 rounds down to 3 rounds.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01344138/file/ups_srds2016.pdf"
                    },
                    "abstract_zh": "最终一致性是一种强调活跃度而非安全性的一致性模型，它通常用于分布式系统变大时的伸缩能力。最终一致性倾向于统一地应用于整个系统，但是我们认为对有区别的最终一致性需求的需求在增长。我们通过UPS来满足这一需求，这是一种新型的一致性机制，通过与两阶段流行病广播协议配合工作，提供差异化的最终一致性和交付速度。我们提出了一个封闭形式的分析我们的方法的交付速度，我们评估了我们的完整机制的实验模拟网络上的一百万个节点。为了衡量一致性权衡，我们正式定义了一个新颖的、可扩展的、在运行时运行的一致性度量。在我们的模拟中，UPS将大多数节点经历的不一致性除以4，同时将一小部分节点引起的平均延迟从6轮减少到3轮。",
                    "title_zh": "精英的速度，大众的一致性:区分大规模分布式系统的最终一致性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.033",
                    "title": "Continuous Authentication and Non-repudiation for the Security of Critical Systems",
                    "authors": "Enrico Schiavone, Andrea Ceccarelli, Andrea Bondavalli",
                    "abstract": "User authentication is a key service, especially for systems that can be considered critical for the data stored and the functionalities offered. In those cases, traditional authentication mechanisms can be inadequate to face intrusions: they usually verify user's identity only at login, and even repeating this step, frequently asking for passwords or PIN would reduce system's usability. Biometric continuous authentication, instead, is emerging as viable alternative approach that can guarantee accurate and transparent verification for the entire session: the traits can be repeatedly acquired avoiding disturbing the user's activity. Another security service that these systems may need is nonrepudiation, which protect against the denial of having used the system or executed some commands with it. The paper focuses on biometric continuous authentication and nonrepudiation, and it briefly presents a preliminary solution based on a specific case study. This work presents the current research direction of the author and describes some challenges that the student aims to address in the next years.",
                    "files": {
                        "openAccessPdf": "https://flore.unifi.it/bitstream/2158/1049929/5/SRDS%2016%20Student%20Forum-%20Camera%20ready.pdf"
                    },
                    "abstract_zh": "用户身份验证是一项关键服务，尤其是对于被认为对存储的数据和提供的功能至关重要的系统。在这些情况下，传统的认证机制可能不足以应对入侵:它们通常只在登录时验证用户的身份，即使重复这一步骤，频繁地询问密码或PIN也会降低系统的可用性。相反，生物识别连续认证作为一种可行的替代方法出现，可以保证整个会话的准确和透明验证:可以重复获取特征，避免干扰用户的活动。这些系统可能需要的另一个安全服务是不可否认性，它可以防止否认使用过该系统或用它执行过一些命令。本文主要讨论生物特征的连续认证和不可否认性，并简要介绍了一个基于具体案例研究的初步解决方案。这项工作提出了作者目前的研究方向，并描述了学生在未来几年的目标解决的一些挑战。",
                    "title_zh": "关键系统安全性的连续认证和不可否认性"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.034",
                    "title": "Including Security Monitoring in Cloud Service Level Agreements",
                    "authors": "Amir Teshome, Louis Rilling, Christine Morin",
                    "abstract": "Service providers give assurance on some aspects of the service but, as of today, security monitoring is not one of them. In our work, we aim to allow providers to provide customers with guarantees on security monitoring of their outsourced information system.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01354975/file/2016-SRDS.pdf"
                    },
                    "abstract_zh": "服务提供商对服务的某些方面做出保证，但迄今为止，安全监控并不在其中。在我们的工作中，我们的目标是允许提供商为客户提供外包信息系统安全监控的保证。",
                    "title_zh": "在云服务级别协议中包含安全监控"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.035",
                    "title": "Visualizing and Controlling VMI-Based Malware Analysis in IaaS Cloud",
                    "authors": "Noëlle Rakotondravony, Hans P. Reiser",
                    "abstract": "Security in virtualized environment has known the support of different tools in the low-level detection and analysis of malware. The in-guest tracing mechanisms are now capable of operating at assembly language-, system call-, function call-and instruction-level to detect and classify malicious activities. Therefore, they are producing large amount of data about the state of a target system. However, the integrity of such data becomes questionable whenever the hosting target system is compromised. With virtual machine introspection (VMI), the monitoring tool runs outside the target monitored virtual machine (VM) [1]. Thus, the integrity of retrieved data is ensured even if the target system is compromised. Various works have brought VMI to Infrastructure-as-a-Service (Iaas) cloud environment, allowing the cloud user to run (simultaneous) forensics operations on his production VMs. The associated tracing mechanisms can collect larger amount of data in form of commented behavior traces or unstandardized log records. Thus, a human operator is needed to efficiently parse, represent, visualize and interpret the collected data, to benefit from their security relevance [2]. The use of visualization helps analysts investigate, compare and culster malware samples [3]. Existing visualization tools make use of recorded information to enhance the detection of intrusive behavior or the clustering of malware [4] from the observed system. However, at our knowledge, no existing tools establish a pre-to post-exploitation visualization graphs. We present an approach that enhances the detection and analysis of malware in the cloud by providing the cloud end-users the mean to efficiently visualize the different security relevant data collected through multiple VMI-based mechanisms.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "虚拟化环境中的安全性已知在恶意软件的低级检测和分析中不同工具的支持。客户内跟踪机制现在能够在汇编语言、系统调用、函数调用和指令级别运行，以检测和分类恶意活动。因此，他们会产生大量关于目标系统状态的数据。然而，每当宿主目标系统受到危害时，这种数据的完整性就变得有问题。借助虚拟机自检(VMI)，监控工具可以在被监控的目标虚拟机(VM)之外运行[1]。因此，即使目标系统受损，也能确保检索数据的完整性。各种工作已经将VMI引入基础架构即服务(Iaas)云环境，允许云用户在其生产虚拟机上运行(同时)取证操作。相关联的跟踪机制可以以注释行为跟踪或非标准化日志记录的形式收集更大量的数据。因此，需要人工操作员有效地解析、表示、可视化和解释收集的数据，以从它们的安全相关性中获益[2]。可视化的使用有助于分析师调查、比较和收集恶意软件样本[3]。现有的可视化工具利用记录的信息来增强对来自被观察系统的入侵行为或恶意软件群集的检测。然而，据我们所知，没有现有的工具建立开发前到开发后的可视化图形。我们提出了一种方法，通过为云最终用户提供有效可视化通过多个基于VMI的机制收集的不同安全相关数据的方式，来增强云中恶意软件的检测和分析。",
                    "title_zh": "在IaaS云中可视化和控制基于VMI的恶意软件分析"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.036",
                    "title": "Challenging Anomaly Detection in Complex Dynamic Systems",
                    "authors": "Tommaso Zoppi, Andrea Ceccarelli, Andrea Bondavalli",
                    "abstract": "Software infrastructures are becoming more and more complex, making performance and dependability monitoring in wide and dynamic contexts such as Distributed Systems, Systems of Systems (SoS) and Cloud environments an unachievable goal. Consequently, it is very difficult to know how all the specific parts, services and modules of these systems behave. This negatively impacts our ability in detecting anomalies, because the boundaries between normal and anomalous behaviors are not always known. The paper describes the context and the targeted problem highlighting the research directions that the student will follow in the next years. In particular, after introducing the relevance of this work with respect to the academic and the industrial state of the art, we carefully define the problem and summarize the main challenges that arise according to such problem definition.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "软件基础设施变得越来越复杂，使得在分布式系统、系统的系统(SoS)和云环境等广泛的动态环境中进行性能和可靠性监控成为一个无法实现的目标。因此，很难知道这些系统的所有特定部分、服务和模块是如何工作的。这对我们检测异常的能力有负面影响，因为正常和异常行为之间的界限并不总是已知的。论文描述了背景和目标问题，突出了学生在未来几年将遵循的研究方向。特别是，在介绍了这项工作与学术和工业现状的相关性之后，我们仔细地定义了问题，并总结了根据这样的问题定义而出现的主要挑战。",
                    "title_zh": "复杂动态系统中的挑战性异常检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.037",
                    "title": "PlayCloud: A Platform to Experiment with Coding Techniques for Storage in the Cloud",
                    "authors": "Dorian Burihabwa",
                    "abstract": "Cloud based storage services are increasingly popular for storing private and enterprise data. Differentiating themselves over a large range of features, storage providers can catter to the needs of any customer. But among the needs they must satisfy, safety from data loss or data corruption is the most important one. While data corruption stemming from faulty hardware or software is usually covered by those services, it is not the case when the erasure is due to malicious activities from the storage provider itself. Therefore the need for anti-tampering countermeasures needs to be addressed for the customer to feel comfortable enough to use the service. In the context of the SafeCloud project, our goal is to provide an extensible platform to implement and evaluate censorship resistant storage systems for long term storage. By combining classical techniques such as erasure coding and data dispersion with more novel ones like data block entanglement, we aim at giving good anti-tampering guarantees for cloud based storage services. In this paper, we will present some of the work that has been done so far to reach this objective, results and future developments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "基于云的存储服务越来越受欢迎，用于存储私有和企业数据。存储提供商可以通过大量的功能使自己与众不同，从而满足任何客户的需求。但是在他们必须满足的需求中，防止数据丢失或数据损坏是最重要的。虽然这些服务通常涵盖由故障硬件或软件引起的数据损坏，但如果擦除是由存储提供商本身的恶意活动引起的，则情况并非如此。因此，需要解决防篡改对策的需求，以使客户感觉足够舒适地使用服务。在SafeCloud项目中，我们的目标是提供一个可扩展的平台来实施和评估长期存储的防审查存储系统。通过将擦除编码和数据分散等经典技术与数据块纠缠等更新颖的技术相结合，我们旨在为基于云的存储服务提供良好的防篡改保证。在本文中，我们将介绍迄今为止为实现这一目标所做的一些工作、结果和未来的发展。",
                    "title_zh": "PlayCloud:一个试验云中存储编码技术的平台"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.038",
                    "title": "Reliable Event Dissemination in Dynamic Distributed Systems",
                    "authors": "Ugaitz Amozarrain, Mikel Larrea",
                    "abstract": "The proposed research addresses the problem of communicating events in a reliable and efficient manner between the producing and consuming devices. To do so, we will focus on the publish/subscribe paradigm. Commonly, this model has assumed a static topology of brokers that optimize event dissemination. The next step is to relax the conditions of the broker network in order to include fault tolerance and mobility in its elements, developing and validating new algorithms for highly dynamic publish/subscribe systems.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "提出的研究解决了在生产和消费设备之间以可靠和有效的方式传递事件的问题。为此，我们将关注发布/订阅范式。通常，这个模型假设了一个静态的代理拓扑结构来优化事件传播。下一步是放宽代理网络的条件，以便在其元素中包括容错和移动性，为高度动态的发布/订阅系统开发和验证新算法。",
                    "title_zh": "动态分布式系统中的可靠事件传播"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.039",
                    "title": "ProCode: A Proactive Erasure Coding Scheme for Cloud Storage Systems",
                    "authors": "Peng Li, Jing Li, Rebecca J. Stones, Gang Wang, Zhongwei Li, Xiaoguang Liu",
                    "abstract": "Common distributed storage systems use data replication to improve system reliability and maintain data availability, but at the cost of disk storage. In order to lower storage costs, data may instead be stored according to erasure codes, but this results in greater network and disk traffic when data blocks are reconstructed following an erasure. These methods are also passive, i.e., they only reconstruct data after failures occur. In this paper, we present a proactive erasure coding scheme (ProCode). We monitor the health of disks via drive failure prediction and automatically adjust the replication factor of data blocks on at-risk disks to ensure data safety. In this way, we achieve fast recovery after disk failures without significantly increasing the storage overhead. ProCode is implemented as an extension to HDFS-RAID used by Facebook. Compared with replication storage and erasure coding, ProCode improves system reliability and availability. Specifically, experimental results show 2 or more orders of magnitude reduction in the average number of data loss events over a 10- year period, a 63% or greater drop in degraded read latency, and a 78% drop in recovery time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "常见的分布式存储系统使用数据复制来提高系统可靠性和维护数据可用性，但这是以磁盘存储为代价的。为了降低存储成本，可以根据擦除代码来存储数据，但是当在擦除之后重建数据块时，这会导致更大的网络和磁盘流量。这些方法也是被动的，即它们仅在故障发生后重建数据。本文提出了一种主动擦除编码方案(ProCode)。我们通过驱动器故障预测来监控磁盘的运行状况，并自动调整有风险磁盘上数据块的复制因子，以确保数据安全。这样，我们在磁盘故障后实现了快速恢复，而不会显著增加存储开销。ProCode是脸书使用的HDFS RAID的扩展。与复制存储和擦除编码相比，ProCode提高了系统的可靠性和可用性。具体来说，实验结果显示，在10年的时间里，数据丢失事件的平均数量减少了2个或更多数量级，降级读取延迟下降了63%或更多，恢复时间下降了78%。",
                    "title_zh": "ProCode:一种面向云存储系统的主动擦除编码方案"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.040",
                    "title": "SwiftER: Elastic Erasure Coded Storage System",
                    "authors": "Anwitaman Datta, Wan-Hee Cho",
                    "abstract": "Over the life-cycle of a data object, it may be difficult to determine a priori how much redundancy to store it with. The desired degree of fault-tolerance may change over time, for instance, because the importance of the data changes, or the storage system environment changes. If the redundancy is achieved using replication, then changing the degree of fault-tolerance would mean adding (or removing) replicas - a reasonably straightforward operation. However, if erasure code is used instead (which is preferable, given the significantly lower storage overhead of erasure codes with respect to fully replicated systems), then, while shrinking redundancy can still be achieved similarly, expanding redundancy becomes non-trivial. A naive approach will require re-coding, which is both network resource and computation heavy. In this paper, we explore the possibility of using network coding techniques, to both distribute computational load, as well as reduce network usage, and in the process, speed-up the process of creating additional redundancy. The contributions of this paper are defining the problem and analyzing the theoretical limits by leveraging on and extending the existing literature on regenerating codes to realize erasure coded redundancy elasticity, propose a framework to realize code instances that are amenable to network coding based elastic expansion of redundancy, and integrate and benchmark one such code instance (which happens to be optimal with respect to the aforementioned established theoretical limit) with OpenStack Swift to demonstrate the practicality and advantages of the proposed approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在数据对象的整个生命周期中，可能很难预先确定用多少冗余来存储它。所需的容错程度可能会随着时间而改变，例如，因为数据的重要性改变，或者存储系统环境改变。如果冗余是通过复制实现的，那么改变容错程度就意味着添加(或删除)副本——这是一个相当简单的操作。然而，如果代之以使用擦除代码(这是优选的，考虑到擦除代码相对于完全复制系统的低得多的存储开销)，那么，虽然仍然可以类似地实现缩减冗余，但是扩展冗余变得不重要。一种简单的方法将需要重新编码，这既占用网络资源又计算量大。在本文中，我们探讨了使用网络编码技术的可能性，以分配计算负载，减少网络使用，并在此过程中，加速创建额外的冗余过程。本文的贡献是通过利用和扩展关于重新生成代码以实现擦除编码冗余弹性的现有文献来定义问题和分析理论限制，提出一个框架来实现服从基于网络编码的冗余弹性扩展的代码实例，并使用OpenStack Swift集成和基准测试一个这样的代码实例(相对于上述建立的理论限制而言，它恰好是最佳的),以展示所提出方法的实用性和优势。",
                    "title_zh": "更快:弹性擦除编码存储系统"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.041",
                    "title": "Encoding-Aware Data Placement for Efficient Degraded Reads in XOR-Coded Storage Systems",
                    "authors": "Zhirong Shen, Patrick P. C. Lee, Jiwu Shu, Wenzhong Guo",
                    "abstract": "Erasure coding has been increasingly used by distributed storage systems to maintain fault tolerance with low storage redundancy. However, how to enhance the performance of degraded reads in erasure-coded storage has been a critical issue. We revisit this problem from two different perspectives that are neglected by existing studies: data placement and encoding rules. To this end, we propose an encoding-aware data placement (EDP) approach that aims to reduce the number of I/Os in degraded reads during a single failure for general XOR-based erasure codes. EDP carefully places sequential data based on the encoding rules of the given erasure code. Trace-driven evaluation results show that compared to two baseline data placement methods, EDP reduces up to 37.4% of read data on the most loaded disk and shortens up to 15.4% of read time.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分布式存储系统越来越多地使用擦除编码来保持低存储冗余的容错性。然而，如何提高擦除编码存储中降级读取的性能一直是一个关键问题。我们从两个不同的角度重新审视这个问题，这两个角度被现有的研究忽略了:数据放置和编码规则。为此，我们提出了一种编码感知数据放置(EDP)方法，旨在减少一般基于XOR的擦除代码在单次故障期间降级读取的I/o数量。EDP根据给定擦除代码的编码规则仔细放置顺序数据。跟踪驱动的评估结果显示，与两种基准数据放置方法相比，EDP在负载最大的磁盘上减少了高达37.4%的读取数据，并缩短了高达15.4%的读取时间。",
                    "title_zh": "XOR编码存储系统中高效降级读取的编码感知数据放置"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.042",
                    "title": "Network Aware Reliability Analysis for Distributed Storage Systems",
                    "authors": "Amir Epstein, Elliot K. Kolodner, Dmitry Sotnikov",
                    "abstract": "It is hard to measure the reliability of a large distributed storage system, since it is influenced by low probability failure events that occur over time. Nevertheless, it is critical to be able to predict reliability in order to plan, deploy and operate the system. Existing approaches suffer from unrealistic assumptions regarding network bandwidth. This paper introduces a new framework that combines simulation and an analytic model to estimate durability for large distributed cloud storage systems. Our approach is the first that takes into account network bandwidth with a focus on the cumulative effect of simultaneous failures on repair time. Using our framework we evaluate the trade-offs between durability, network and storage costs for the OpenStack Swift object store, comparing various system configurations and resiliency schemes, including replication and erasure coding. In particular, we show that when accounting for the cumulative effect of simultaneous failures, the probability of data loss estimates can vary by two to four orders of magnitude.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大型分布式存储系统的可靠性很难测量，因为它受随时间推移发生的低概率故障事件的影响。然而，为了计划、部署和操作该系统，能够预测可靠性是至关重要的。现有方法受到关于网络带宽的不切实际的假设的困扰。本文介绍了一个新的框架，结合仿真和分析模型来评估大型分布式云存储系统的持久性。我们的方法是第一个考虑网络带宽的方法，重点是同时发生的故障对修复时间的累积影响。使用我们的框架，我们评估了OpenStack Swift对象存储的耐用性、网络和存储成本之间的权衡，比较了各种系统配置和弹性方案，包括复制和擦除编码。特别是，我们表明，当考虑到同时发生的故障的累积效应时，数据丢失估计的概率可能会有两到四个数量级的变化。",
                    "title_zh": "分布式存储系统的网络感知可靠性分析"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.043",
                    "title": "Collaborative Stabilization",
                    "authors": "Mohammad Roohitavaf, Sandeep S. Kulkarni",
                    "abstract": "Ag nanoclusters have received increasing attention due to their atomically precise and diverse structures and intriguing optical properties. Nevertheless, the inherent instability of Ag nanoclusters has seriously hindered their practical applications. In this work, for the first time, Ag cluster is collaboratively protected by hydrophobic Ti-oxo cluster and alkyne ligand. At the beginning, a pyramidal Ag5 cluster terminated with tBuC≡C- and CH3CN was inserted into the cavity of a Ti8-oxo nanoring to form Ag5@Ti8. To further overcome the instability of acetonitrile terminated silver site, such two Ag5@Ti8 clusters could sandwich an Ag4 unit to form Ag14-Nanorod@Ti16-oxo-Nanoring (Ag14@Ti16) in the absence of CH3CN, which is peripherally protected by fluorophenyl groups and alkyne caps. As a result, such threefold protected (hydrophobic fluorinated organic layer, Ti-O shell and terminal alkyne ligands) Ag14@Ti16 exhibits superhydrophobicity and excellent ambient stability, enabling it with solid-state optical limiting characteristics. The success of this work provides meaningful guidance for improving the stability of metallic clusters to extend their future practical applications.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "银纳米团簇由于其原子级的精确和多样的结构以及有趣的光学性质而受到越来越多的关注。然而，银纳米团簇固有的不稳定性严重阻碍了其实际应用。在这项工作中，银簇首次被疏水的钛氧簇和炔配体协同保护。开始时，以tBuC≡C-和CH3CN封端的金字塔形Ag5簇被插入Ti8-氧代纳米环的空腔中以形成Ag5@Ti8。为了进一步克服乙腈封端的银位点的不稳定性，在没有CH3CN的情况下，这两个Ag5@Ti8簇可以将Ag4单元夹在中间以形成Ag14-纳米棒@ Ti16-氧代-纳米环(Ag14@Ti16 ),其外围被氟苯基和炔烃帽保护。因此，这种三重保护(疏水氟化有机层、Ti-O壳和末端炔配体)的Ag14@Ti16表现出超疏水性和优异的环境稳定性，使其具有固态光限幅特性。这项工作的成功为提高金属团簇的稳定性以扩展其未来的实际应用提供了有意义的指导。",
                    "title_zh": "协同稳定"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.044",
                    "title": "Adaptive Location Privacy with ALP",
                    "authors": "Vincent Primault, Antoine Boutet, Sonia Ben Mokhtar, Lionel Brunie",
                    "abstract": "With the increasing amount of mobility data being collected on a daily basis by location-based services (LBSs) comes a new range of threats for users, related to the over-sharing of their location information. To deal with this issue, several location privacy protection mechanisms (LPPMs) have been proposed in the past years. However, each of these mechanisms comes with different configuration parameters that have a direct impact both on the privacy guarantees offered to the users and on the resulting utility of the protected data. In this context, it can be difficult for non-expert system designers to choose the appropriate configuration to use. Moreover, these mechanisms are generally configured once for all, which results in the same configuration for every protected piece of information. However, not all users have the same behaviour, and even the behaviour of a single user is likely to change over time. To address this issue, we present in this paper ALP (which stands for Adaptive Location Privacy), a new framework enabling the dynamic configuration of LPPMs. ALP can be used in two scenarios: (1) offline, where ALP enables a system designer to choose and automatically tune the most appropriate LPPM for the protection of a given dataset, (2) online, where ALP enables the user of a crowd sensing application to protect consecutive batches of her geolocated data by automatically tuning a given LPPM to fulfil a set of privacy and utility objectives. We evaluate ALP on both scenarios with two real-life mobility datasets and two state-of-the-art LPPMs. Our experiments show that the adaptive LPPM configurations found by ALP outperform static configurations in terms of trade-off between privacy and utility.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1609.07349"
                    },
                    "abstract_zh": "随着基于位置的服务(lbs)每天收集的移动数据量不断增加，用户面临一系列新的威胁，这些威胁与用户位置信息的过度共享有关。为了解决这个问题，在过去的几年中已经提出了几种位置隐私保护机制。然而，这些机制中的每一个都带有不同的配置参数，这些参数对提供给用户的隐私保证和受保护数据的最终效用都有直接影响。在这种情况下，非专家系统设计者可能很难选择合适的配置来使用。此外，这些机制通常只配置一次，这导致每条受保护的信息都有相同的配置。然而，并非所有用户都有相同的行为，甚至单个用户的行为也可能随着时间而改变。为了解决这个问题，我们在本文中提出了ALP(代表自适应位置隐私)，这是一个新的框架，能够动态配置LPPMs。ALP可以在两种情况下使用:(1)离线，其中ALP使系统设计者能够选择并自动调整最合适的LPPM来保护给定的数据集，(2)在线，其中ALP使人群感测应用的用户能够通过自动调整给定的LPPM来满足一组隐私和效用目标，从而保护其地理定位数据的连续批次。我们使用两个真实的移动数据集和两个最先进的LPPMs在两种场景下评估ALP。我们的实验表明，ALP发现的自适应LPPM配置在隐私和效用之间的权衡方面优于静态配置。",
                    "title_zh": "使用ALP的自适应位置隐私"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.045",
                    "title": "On Privacy-Preserving Cloud Auction",
                    "authors": "Zhili Chen, Lin Chen, Liusheng Huang, Hong Zhong",
                    "abstract": "Due to perceived fairness and allocation efficiency, cloud auctions for resource allocation and pricing have recently attracted significant attention. As an important economic property, truthfulness makes bidders reveal their true valuations for cloud resources to maximize their utilities. However, disclosure of one's true value causes numerous security vulnerabilities. Therefore, privacy-preserving cloud auctions are called for to prevent such information leakage. In this paper, we demonstrate how to perform privacy-preserving auctions in clouds that do not leak any information other than the auction results to anyone. Specifically, we design a privacy-preserving cloud auction framework that addresses the challenges posed by the cloud auction context by leveraging the techniques in garbled circuits and homomorphic encryption. As foundations of our privacy preserving cloud auction framework, we develop data-oblivious cloud auction algorithm and basic operations (e.g., comparison, swapping etc.), such that the execution path does not depend on the input. In practical systems with a large number of users and constrained resources, we develop an improved version with a computational complexity of O(n log2 n) in the number of bidders n. We further fully implement our framework and theoretically and experimentally show that it preserves privacy by incurring only limited computation and communication overhead.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于感知的公平性和分配效率，用于资源分配和定价的云拍卖最近引起了极大的关注。作为一个重要的经济属性，真实性使得投标者披露他们对云资源的真实估价，以最大化他们的效用。然而，披露一个人的真实价值会导致许多安全漏洞。因此，需要保护隐私的云拍卖来防止这种信息泄漏。在本文中，我们演示了如何在云中执行隐私保护拍卖，不会向任何人泄露除拍卖结果之外的任何信息。具体来说，我们设计了一个保护隐私的云拍卖框架，通过利用乱码电路和同态加密技术来解决云拍卖环境带来的挑战。作为隐私保护云拍卖框架的基础，我们开发了数据无关的云拍卖算法和基本操作(例如，比较、交换等)。)，这样执行路径就不依赖于输入了。在具有大量用户和有限资源的实际系统中，我们开发了一个改进的版本，其计算复杂度为O(n log2 n ),投标人数量为n。我们进一步完全实现了我们的框架，并从理论和实验上证明了它通过仅招致有限的计算和通信开销来保护隐私。",
                    "title_zh": "隐私保护的云拍卖研究"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.046",
                    "title": "Experiments with Self-Stabilizing Distributed Data Fusion",
                    "authors": "Bertrand Ducourthial, Véronique Cherfaoui",
                    "abstract": "The Theory of Belief Functions is a formal frame-work for reasoning with uncertainty that is well suited for rep-resenting unreliable information and weak states of knowledge. In a previous work, a distributed algorithm for computing data fusion on-the-fly has been introduced, avoiding gathering the data on a single node before computation. In this paper, we present an experimental study of its properties. This algorithm is self-stabilizing and runs on unreliable message passing networks. It converges in finite time whatever is the initialization of the system and for any unknown topology. First we explain the algorithm implementation on an unreliable message passing environment and we implement a simple use-case. Then, by experimenting with this distributed application on a realistic network emulator, we show its interest for enforcing local confidence using close nodes, saving bandwidth and warning dangers. Moreover, we focus on the interesting connections between the data fusion operator and the self-stabilizing properties and we highlight the importance of the discounting.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01378667/file/a-met-srds2016-final.pdf"
                    },
                    "abstract_zh": "信念函数理论是不确定性推理的形式框架，非常适合于表示不可靠信息和弱知识状态。在之前的工作中，已经引入了用于动态计算数据融合的分布式算法，避免了在计算之前在单个节点上收集数据。本文对其性质进行了实验研究。该算法是自稳定的，并且在不可靠的消息传递网络上运行。无论系统的初始化是什么，对于任何未知的拓扑，它都在有限时间内收敛。首先，我们解释了在不可靠的消息传递环境中的算法实现，并实现了一个简单的用例。然后，通过在一个真实的网络仿真器上对这个分布式应用程序进行实验，我们展示了它对使用邻近节点来加强本地信任、节省带宽和警告危险的兴趣。此外，我们关注数据融合算子和自稳定性质之间的有趣联系，并强调了折扣的重要性。",
                    "title_zh": "自稳定分布式数据融合实验"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.047",
                    "title": "TANGO: Toward a More Reliable Mobile Streaming through Cooperation between Cellular Network and Mobile Devices",
                    "authors": "Nawanol Theera-Ampornpunt, Tarun Mangla, Saurabh Bagchi, Rajesh Krishna Panta, Kaustubh R. Joshi, Mostafa H. Ammar, Ellen W. Zegura",
                    "abstract": "Multimedia streaming is a major mobile application, accounting for more than half of total mobile traffic. Streaming applications usually have a static buffering strategy. For example, buffer size is limited to x minutes of the stream, where x is optimized to provide the best trade-off between minimizing stalls and limiting waste of user's bandwidth and energy resulting from user abandonment. We show that such strategies based on information available on the mobile device alone do not work well when network conditions change dynamically, e.g., connectivity degrades due to congestion. We propose an alternative strategy using the framework called TANGO, based on a novel idea of cooperation between cellular network and mobile devices. By monitoring real-time network conditions and continuously predicting user location, our system is able to predict connectivity degradation in the near term. In such events, a notification is sent to the mobile device so that the streaming application can initiate a mitigation action, such as to pre-cache more content. In simulations based on real user traces, we found that TANGO reduces pause time by 13–72%, significantly outperforming DASH, which is the current state of the art.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "多媒体流是一种主要的移动应用，占总移动流量的一半以上。流式应用程序通常具有静态缓冲策略。例如，缓冲区大小被限制为流的x分钟，其中x被优化以在最小化停顿和限制由于用户放弃而导致的用户带宽和能量浪费之间提供最佳折衷。我们表明，当网络条件动态变化时，例如，由于拥塞导致连接性下降，这种基于移动设备上可用信息的策略不能很好地工作。基于蜂窝网络和移动设备之间合作的新思想，我们提出了一种使用称为TANGO的框架的替代策略。通过监控实时网络状况和持续预测用户位置，我们的系统能够预测近期的连接性下降。在这种情况下，向移动设备发送通知，使得流应用可以发起缓解动作，例如预缓存更多内容。在基于真实用户轨迹的模拟中，我们发现TANGO减少了13–72%的暂停时间，明显优于DASH，这是当前的技术水平。",
                    "title_zh": "TANGO:通过蜂窝网络和移动设备之间的合作实现更可靠的移动流媒体"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.048",
                    "title": "Model-Checking Assisted Protocol Design for Ultra-reliable Low-Latency Wireless Networks",
                    "authors": "Christian Dombrowski, Sebastian Junges, Joost-Pieter Katoen, James Gross",
                    "abstract": "Recently, the wireless networking community is getting more and more interested in novel protocol designs for safety-critical applications. These new applications come with unprecedented latency and reliability constraints which poses many open challenges. A particularly important one relates to the question how to develop such systems. Traditionally, development of wireless systems has mainly relied on simulations to identify viable architectures. However, in this case the drawbacks of simulations – in particular increasing run-times – rule out its application. Instead, in this paper we propose to use probabilistic model checking, a formal model-based verification technique, to evaluate different system variants during the design phase. Apart from allowing evaluations and therefore design iterations with much smaller periods, probabilistic model checking provides bounds on the reliability of the considered design choices. We demonstrate these salient features with respect to the novel EchoRing protocol, which is a token-based system designed for safety-critical industrial applications. Several mechanisms for dealing with a token loss are modeled and evaluated through probabilistic model checking, showing its potential as suitable evaluation tool for such novel wireless protocols. In particular, we show by probabilistic model checking that wireless token-passing systems can benefit tremendously from the considered fault-tolerant methods. The obtained performance guarantees for the different mechanisms even provide reasonable bounds for experimental results obtained from a real-world implementation.",
                    "files": {
                        "openAccessPdf": "http://kth.diva-portal.org/smash/get/diva2:953843/FULLTEXT01"
                    },
                    "abstract_zh": "最近，无线网络社区对安全关键应用的新型协议设计越来越感兴趣。这些新应用带来了前所未有的延迟和可靠性限制，这带来了许多公开的挑战。一个特别重要的问题是如何开发这样的系统。传统上，无线系统的开发主要依靠仿真来识别可行的架构。然而，在这种情况下，模拟的缺点——特别是运行时间的增加——排除了它的应用。相反，在本文中，我们建议使用概率模型检查，一种正式的基于模型的验证技术，在设计阶段评估不同的系统变量。除了允许评估，因此设计迭代周期更短，概率模型检查提供了考虑设计选择的可靠性界限。我们针对新型EchoRing协议展示了这些显著特征，echo ring协议是一种基于令牌的系统，专为安全关键型工业应用而设计。通过概率模型检查，对处理令牌丢失的几种机制进行建模和评估，显示了其作为这种新型无线协议的合适评估工具的潜力。特别地，我们通过概率模型检验表明，无线令牌传递系统可以从所考虑的容错方法中受益匪浅。所获得的不同机制的性能保证甚至为从真实世界实现中获得的实验结果提供了合理的界限。",
                    "title_zh": "超可靠低延迟无线网络的模型检测辅助协议设计"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.049",
                    "title": "Self-Stabilization - A Mechanism to Make Networked Embedded Systems More Reliable?",
                    "authors": "Stefan Lohs, Jörg Nolte, Gerry Siegemund, Volker Turau",
                    "abstract": "The erratic behavior of wireless channels is still a major hurdle in the implementation of robust applications in wireless networks. In the past it has been argued that self-stabilization is a remedy to provide the needed robustness. This assumption has not been verified to the extent necessary to convince engineers implementing such applications. A major reason is that the time in which a self-stabilizing system returns to a valid state is unpredictable and potentially unbound. Failure rates typically depend on physical phenomena and in self-stabilizing systems each node tries to react to failures in an inherently adaptive fashion by the cyclic observation of its neighbors' states. When the frequency of state changes is too high, the system may never reach a state sufficiently stable for a specific task. In this paper we substantiate the conditions under which self-stabilization leads to fault tolerance in wireless networks and look at the myths about the power of self-stabilization as a particular instance of self-organization. We investigate the influences of the error rate and the neighbor state exchange rate on the stability and the convergence time on topology information acquired in real network experiments.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "无线信道的不稳定行为仍然是在无线网络中实现健壮应用的主要障碍。过去，有人认为自稳定是提供所需坚固性的一种补救措施。这种假设还没有被验证到足以说服工程师实现这种应用的程度。一个主要原因是自稳定系统返回到有效状态的时间是不可预测的，并且可能是不受约束的。故障率通常取决于物理现象，在自稳定系统中，每个节点都试图通过循环观察其邻居的状态，以固有的自适应方式对故障做出反应。当状态改变的频率太高时，系统可能永远不会达到对于特定任务足够稳定的状态。在本文中，我们证实了自稳定导致无线网络容错的条件，并把自稳定的力量看作自组织的一个特殊例子。我们研究了误码率和邻居状态交换率对稳定性的影响，以及收敛时间对真实网络实验中获得的拓扑信息的影响。",
                    "title_zh": "自稳定-一种使网络化嵌入式系统更可靠的机制？"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.050",
                    "title": "RDE: Replay DEbugging for Diagnosing Production Site Failures",
                    "authors": "Peipei Wang, Hiep Nguyen, Xiaohui Gu, Shan Lu",
                    "abstract": "Online service failures in production computing environments are notoriously difficult to debug. One of the key challenges is to allow the developer to replay the failure execution within an interactive debugging tool such as GDB. Previous work has proposed in-situ approaches to inferring the production-run failure path within the production environment. However, those tools may sometimes suggest failure execution paths that are infeasible to reach by any program inputs. Moreover, production site often does not record or provide failure-triggering inputs due to the user privacy concern. In this paper, we present RDE, a Replay DEbug system that can replay a production-site failure at the development site within an interactive debugging environment without requiring user inputs. RDE takes an inferred production failure path as input and performs execution synthesis using a new guided symbolic execution technique. RDE can tolerate imprecise or inaccurate failure path information by navigating the symbolic execution along a set of selected paths. RDE synthesizes an input from the selected symbolic execution path which can be fed to a debugging tool to replay the failure. We have implemented an initial prototype of RDE and tested it with a set of coreutils bugs. The results show that RDE can successfully replay all the tested bugs within GDB.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "众所周知，生产计算环境中的在线服务故障很难调试。一个关键的挑战是允许开发人员在交互式调试工具(如GDB)中重放失败执行。先前的工作已经提出了在生产环境中推断生产运行故障路径的原位方法。然而，这些工具有时可能会建议任何程序输入都无法到达的失败执行路径。此外，出于对用户隐私的考虑，生产现场通常不记录或提供故障触发输入。在本文中，我们介绍了RDE，一个重放调试系统，它可以在交互式调试环境中在开发站点重放生产站点故障，而不需要用户输入。RDE将推断的生产故障路径作为输入，并使用新的引导符号执行技术执行执行综合。通过沿着一组选定的路径导航符号执行，RDE可以容忍不精确或不准确的故障路径信息。RDE合成来自所选符号执行路径的输入，该输入可以被馈送给调试工具以重放失败。我们已经实现了一个RDE的初始原型，并用一组coreutils错误对它进行了测试。结果表明，RDE可以成功地重放GDB境内所有被测试的错误。",
                    "title_zh": "RDE:重放调试以诊断生产站点故障"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2016.051",
                    "title": "A Component-Based Middleware for a Reliable Distributed and Reconfigurable Spacecraft Onboard Computer",
                    "authors": "Ting Peng, Kilian Hoflinger, Benjamin Weps, Olaf Maibaum, Kurt Schwenk, Daniel Lüdtke, Andreas Gerndt",
                    "abstract": "Emerging applications for space missions require increasing processing performance from the onboard computers. DLR's project \"Onboard Computer - Next Generation\" (OBC-NG) develops a distributed, reconfigurable computer architecture to provide increased performance while maintaining the high reliability of classical spacecraft computer architectures. Growing system complexity requires an advanced onboard middleware, handling distributed (real-time) applications and error mitigation by reconfiguration. The OBC-NG middleware follows the Component-Based Software Engineering (CBSE) approach. Using composite components, applications and management tasks can easily be distributed and relocated on the processing nodes of the network. Additionally, reuse of components for future missions is facilitated. This paper presents the flexible middleware architecture, the composite component framework, the middleware services and the model-driven Application Programming Interface (API) design of OBC-NG. Tests are conducted to validate the middleware concept and to investigate the reconfiguration efficiency as well as the reliability of the system. A relevant use case shows the advantages of CBSE for the development of distributed reconfigurable onboard software.",
                    "files": {
                        "openAccessPdf": "https://elib.dlr.de/106675/1/A%20Component-Based%20Middleware%20for%20a%20Reliable%20Distributed%20and%20Reconfigurable%20Spacecraft%20Onboard%20Computer.pdf"
                    },
                    "abstract_zh": "航天任务的新兴应用要求星载计算机具有更高的处理性能。德国航天中心的项目“星载计算机-下一代”(OBC-NG)开发了一种分布式、可重新配置的计算机体系结构，以提供更高的性能，同时保持经典航天器计算机体系结构的高可靠性。日益增长的系统复杂性需要先进的机载中间件，处理分布式(实时)应用程序，并通过重新配置来减少错误。OBC-NG中间件遵循基于组件的软件工程(CBSE)方法。使用复合组件，应用程序和管理任务可以很容易地在网络的处理节点上分布和重新定位。此外，为将来的任务重新使用部件提供了便利。本文介绍了OBC-NG的灵活中间件体系结构、组合组件框架、中间件服务和模型驱动的应用编程接口(API)设计。进行测试以验证中间件概念，并调查系统的重新配置效率以及可靠性。一个相关的用例展示了CBSE在分布式可重构星载软件开发中的优势。",
                    "title_zh": "一种基于组件的可靠分布式可重构航天器星载计算机中间件"
                }
            ]
        }
    ],
    "2015": [
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2015w.html",
            "conf_title": "34. SRDS 2015: Montreal, QC, Canada - Workshops",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7371401/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.17",
                    "title": "A Client-Based Replication Protocol for Multiversion Cloud File Storage",
                    "authors": "Mamoru Ohara, Satoshi Fukumoto",
                    "abstract": "In recent years, data replication have received attention in terms of tolerance for large-scale disasters. Also, file versioning features, by which more than one version of a file can be maintained, have been commercially available in some storage services. For providing file versioning with limited storage resources, it is essential to divide the resources among versions in accordance with the varied needs of numerous users. In this paper, we focus on applications in which newer versions of a file are more likely to be requested, which may be true in the case of many subscription services. We propose a new distributed data replication protocol supporting the file versioning feature. In order to eliminate a single point of failure, replica nodes themselves do not know about which nodes hold the newest version, instead, clients dynamically search the nodes having the required version in read/write operations. We also construct an analytical model that can derive an optimal allocation of the resources when the total number of replica nodes in a system and the distribution of the frequency of read requests for each version are given. In addition, we present some numerical examples obtained by simulations to show the good scalability and dependability of our system by assuming some realistic parameters.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，数据复制在对大规模灾难的容忍度方面受到了关注。此外，文件版本化功能(通过该功能可以维护文件的多个版本)已经在一些存储服务中商业化。为了用有限的存储资源提供文件版本控制，必须根据众多用户的不同需求在版本之间划分资源。在本文中，我们将重点放在更有可能请求文件的较新版本的应用程序上，这在许多订阅服务的情况下可能是真实的。我们提出了一种新的支持文件版本控制特性的分布式数据复制协议。为了消除单点故障，副本节点本身不知道哪些节点拥有最新版本，相反，客户端在读/写操作中动态搜索具有所需版本的节点。我们还构建了一个分析模型，当系统中副本节点的总数和每个版本的读请求频率分布已知时，该模型可以得出资源的最优分配。此外，我们给出了一些通过模拟得到的数值例子，通过假设一些实际的参数来说明我们的系统具有良好的可扩展性和可靠性。",
                    "title_zh": "基于客户端的多版本云文件存储复制协议"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.20",
                    "title": "Modeling the Autoscaling Operations in Cloud with Time Series Data",
                    "authors": "Mehran N. A. H. Khan, Yan Liu, Hanieh Alipour, Samneet Singh",
                    "abstract": "Autoscaling involves complex cloud operations that automate the provisioning and de-provisioning of cloud resources to support continuous development of customer services. Autoscaling depends on a number of decisions derived by aggregating metrics at the infrastructure and the platform level. In this paper, we review existing autoscaling techniques deployed in leading cloud providers. We identify core features and entities of the autoscaling operations as variables. We model these variables that quantify the interactions between these entities and incorporate workload time series data to calibrate the model. Hence the model allows proactive analysis of workload patterns and estimation of the responsiveness of the autoscaling operations. We demonstrate the use of this model with Google cluster trace data.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自动扩展涉及复杂的云操作，可自动调配和取消调配云资源，以支持客户服务的持续发展。自动扩展依赖于通过在基础架构和平台级别聚合指标得出的许多决策。在本文中，我们回顾了领先云提供商部署的现有自动扩展技术。我们将自动缩放操作的核心特征和实体识别为变量。我们对这些变量进行建模，量化这些实体之间的相互作用，并结合工作负载时间序列数据来校准模型。因此，该模型允许主动分析工作负载模式和估计自动扩展操作的响应性。我们用Google集群跟踪数据演示了这个模型的使用。",
                    "title_zh": "用时序数据模拟云中的自动缩放操作"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.15",
                    "title": "Hard Drive Failure Prediction Using Big Data",
                    "authors": "Wenjun Yang, Dianming Hu, Yuliang Liu, Shuhao Wang, Tianming Jiang",
                    "abstract": "We design a general framework named Hdoctor for hard drive failure prediction. Hdoctor leverages the power of big data to achieve a significant improvement comparing to all previous researches that used sophisticated machine learning algorithms. Hdoctor exhibits a series of engineering innovations: (1) constructing time dependent features to characterize the Self-Monitoring, Analysis and Reporting Technology (SMART) value transitions during disk failures, (2) combining features to enable the model to learn the correlation among different SMART attributes, (3) regarding circumstance data such as cluster workload, temperature, humidity, location as related features. Meanwhile, Hdoctor collects/labels samples and updates model automatically, and works well for all kinds of disk failure prediction in our intelligent data center. In this work, we use Hdoctor to collect 74,477,717 training records from our clusters involving 220,022 disks. By training a simple and scalable model, our system achieves a detection rate of 97.82%, with a false alarm rate (FAR) of 0.3%, which hugely outperforms all previous algorithms. In addition, Hdoctor is an excellent indicator for how to predict different hardware failures efficiently under various circumstances.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们设计了一个通用的硬盘故障预测框架Hdoctor。与之前所有使用复杂机器学习算法的研究相比，Hdoctor利用大数据的力量实现了重大改进。Hdoctor展示了一系列工程创新:(1)构建时间相关特征，以描述磁盘故障期间自我监控、分析和报告技术(SMART)值转变的特征，(2)组合特征，使模型能够学习不同SMART属性之间的相关性，(3)将集群工作负载、温度、湿度、位置等环境数据视为相关特征。同时，Hdoctor自动收集/标记样本并更新模型，在我们的智能数据中心中很好地用于各种磁盘故障预测。在这项工作中，我们使用Hdoctor从涉及220，022个磁盘的集群中收集了74，477，717条训练记录。通过训练一个简单且可扩展的模型，我们的系统实现了97.82%的检测率，0.3%的虚警率，这大大优于所有以前的算法。此外，对于如何在各种情况下高效预测不同的硬件故障，Hdoctor是一个优秀的指标。",
                    "title_zh": "使用大数据预测硬盘故障"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.12",
                    "title": "Building Secure Applications Using Pattern-Based Design Fragments",
                    "authors": "Paul Rimba, Liming Zhu, Xiwei Xu, Daniel Sun",
                    "abstract": "Developing and operating a complex secure application with high assurance is difficult and requires experts. Security patterns and best practices have been proposed to assist architects in designing secure applications. However, these are usually written independently of the underlying platforms and operating environment. This leads to a gap between patterns and the platforms, and does not directly support the design-level analysis and verification of systems to be built on those platforms. We propose an approach to incrementally build an application design using design fragments, which are specializations of patterns for target platforms. Design fragments can be composed and reused during design, and directly support design-level security analyses and operation level concerns. We apply this approach in a case study of the design and analysis of a smart electricity meter. We show how the approach can be used to iteratively address threats.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "开发和运行一个复杂的安全应用程序是很困难的，并且需要专家。已经提出了安全模式和最佳实践来帮助架构师设计安全的应用程序。然而，这些通常是独立于底层平台和操作环境编写的。这导致了模式和平台之间的差距，并且不直接支持在这些平台上构建的系统的设计级分析和验证。我们提出了一种使用设计片段逐步构建应用程序设计的方法，设计片段是目标平台模式的专门化。设计片段可以在设计期间组合和重用，并直接支持设计级安全分析和操作级关注。我们将这种方法应用于智能电表设计和分析的案例研究中。我们展示了如何使用这种方法迭代地解决威胁。",
                    "title_zh": "使用基于模式的设计片段构建安全的应用程序"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.14",
                    "title": "Architectural Support for DevOps in a Neo-Metropolis BDaaS Platform",
                    "authors": "Hong-Mei Chen, Rick Kazman, Serge Haziyev, Valentyn Kropov, Dmitri Chtchourov",
                    "abstract": "Big data as a Service (BDaaS) provides a viable strategy for organizations to implement scalable, tailorable big data infrastructure and applications built on this infrastructure. New trends in the BDaaS market are moving toward an open world model -- what we call the Neo-Metropolis model -- for developing BDaaS platforms. The key to the success of such large-scale technology-agnostic platforms, we posit, is an architectural strategy revolving around microservices and DevOps. This article presents the results of an action research with a Neo-Metropolis BDaaS vendor and illustrates how architectural support for DevOps is critical in achieving desired system qualities and enabling platform success. This research contributes to illuminate best practices of DevOps, and to validate and augment a set of DevOps tactics previously developed, while adding and recategorizing new instances of well-established architectural tactics.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "大数据即服务(BDaaS)为组织实施可扩展、可定制的大数据基础架构和基于该基础架构的应用程序提供了可行的策略。BDaaS市场的新趋势是朝着开发BDaaS平台的开放世界模型发展，我们称之为新大都市模型。我们认为，这种大规模技术无关平台成功的关键是围绕微服务和开发运维的架构策略。本文展示了对Neo-Metropolis BDaaS供应商的行动研究结果，并说明了DevOps的架构支持对于实现期望的系统质量和实现平台成功是多么重要。这项研究有助于阐明DevOps的最佳实践，并验证和扩充之前开发的一套DevOps策略，同时添加和重新分类成熟架构策略的新实例。",
                    "title_zh": "新大都市BDaaS平台中DevOps的架构支持"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.16",
                    "title": "A Distributed Monitoring and Reconfiguration Approach for Adaptive Network Computing",
                    "authors": "Bharat K. Bhargava, Pelin Angin, Rohit Ranchal, Sunil Lingayat",
                    "abstract": "The past decade has witnessed immense developments in the field of network computing thanks to the rise of the cloud computing paradigm, which enables shared access to a wealth of computing and storage resources without needing to own them. While cloud computing facilitates on-demand deployment, mobility and collaboration of services, mechanisms for enforcing security and performance constraints when accessing cloud services are still at an immature state. The highly dynamic nature of networks and clouds makes it difficult to guarantee any service level agreements. On the other hand, providing quality of service guarantees to users of mobile and cloud services that involve collaboration of multiple services is contingent on the existence of mechanisms that give accurate performance estimates and security features for each service involved in the composition. In this paper, we propose a distributed service monitoring and dynamic service composition model for network computing, which provides increased resiliency by adapting service configurations and service compositions to various types of changes in context. We also present a greedy dynamic service composition algorithm to reconfigure service orchestrations to meet user-specified performance and security requirements. Experiments with the proposed algorithm and the ease-of-deployment of the proposed model on standard cloud platforms show that it is a promising approach for agile and resilient network computing.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于云计算范式的兴起，过去十年见证了网络计算领域的巨大发展，云计算范式允许共享访问大量计算和存储资源，而无需拥有它们。虽然云计算有助于服务的按需部署、移动和协作，但在访问云服务时实施安全和性能约束的机制仍处于不成熟状态。网络和云的高度动态性使得很难保证任何服务水平协议。另一方面，向涉及多个服务协作的移动和云服务的用户提供服务质量保证，取决于是否存在为组合中涉及的每个服务提供准确的性能估计和安全特性的机制。在本文中，我们提出了一种网络计算的分布式服务监控和动态服务组合模型，该模型通过调整服务配置和服务组合来适应各种类型的上下文变化，从而提供增强的弹性。我们还提出了一个贪婪的动态服务组合算法来重新配置服务编排，以满足用户指定的性能和安全需求。实验表明，该算法和该模型在标准云平台上的易部署性，为敏捷和弹性网络计算提供了一种有前途的方法。",
                    "title_zh": "自适应网络计算的分布式监控和重构方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.21",
                    "title": "SMS Botnet Detection for Android Devices through Intent Capture and Modeling",
                    "authors": "Erik Johnson, Issa Traoré",
                    "abstract": "Mobile devices are subject to an increased attack surface vector as compared to desktop computing, due to the nature of sensors, radios, and increased peripherals. We investigate in this work mobile botnets with a specific focus on Android, which is the most widely adopted mobile platform, and a prime target for malicious software, 79% of reported malware threats to mobile operating systems are targeted at Android. Our analysis focuses on a short messaging service (SMS) botnet structure and investigates a new detection model using the concept of intents. We show that transparent control can be achieved by a remote endpoint, yet also detected by our proposed intent detection model. Intents are late run-time bindings mechanisms provided to applications in the Android operating system. Intents provide a clear and accurate picture of device behaviour with external sources, due to their design as a late run time binding mechanism in the Android Operating System. We propose an intent logging system to capture sample data, and use this as the basis to design and evaluate our proposed detection scheme.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "与桌面计算相比，由于传感器、无线电和越来越多的外围设备的性质，移动设备受到的攻击面越来越大。我们在这项工作中研究了移动僵尸网络，特别关注Android，这是最广泛采用的移动平台，也是恶意软件的主要目标，79%的报告的移动操作系统恶意软件威胁都是针对Android的。我们的分析侧重于短消息服务(SMS)僵尸网络结构，并研究了一种使用意图概念的新检测模型。我们证明了透明控制可以通过远程端点来实现，也可以通过我们提出的意图检测模型来检测。Intents是Android操作系统中提供给应用程序的后期运行时绑定机制。由于Intents被设计为Android操作系统中的后期运行时绑定机制，因此它可以清晰、准确地描述外部设备的行为。我们提出一个意图记录系统来捕获样本数据，并以此为基础来设计和评估我们提出的检测方案。",
                    "title_zh": "通过意图捕获和建模对Android设备进行短信僵尸网络检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.18",
                    "title": "On the Use of Mobile GPU for Accelerating Malware Detection Using Trace Analysis",
                    "authors": "Manel Abdellatif, Chamseddine Talhi, Abdelwahab Hamou-Lhadj, Michel R. Dagenais",
                    "abstract": "Malware detection on mobile phones involves analysing and matching large amount of data streams against a set of known malware signatures. Unfortunately, as the number of threats grows continuously, the number of malware signatures grows proportionally. This is time consuming and leads to expensive computation costs, especially for mobile devices where memory, power and computation capabilities are limited. As the security threat level is getting worse, parallel computation capabilities for mobile phones is getting better with the evolution of mobile graphical processing units (GPUs). In this paper, we discuss how we can benefit from the evolving parallel processing capabilities of mobile devices in order to accelerate malware detection on Android mobile phones. We have designed and implemented a parallel host-based anti-malware for mobile devices that exploits the computation capabilities of mobile GPUs. A series of computation and memory optimization techniques are proposed to increase the detection throughput. The results suggest that mobile graphic cards can be used effectively to accelerate malware detection for mobile phones.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "手机上的恶意软件检测包括分析大量数据流，并将其与一组已知的恶意软件签名进行匹配。不幸的是，随着威胁数量的持续增长，恶意软件签名的数量也成比例增长。这是耗时的，并且导致昂贵的计算成本，尤其是对于存储器、功率和计算能力有限的移动设备。随着安全威胁水平的恶化，随着移动图形处理单元(GPU)的发展，手机的并行计算能力越来越好。在本文中，我们讨论了如何从移动设备不断发展的并行处理能力中获益，以加速Android手机上的恶意软件检测。我们为移动设备设计并实现了一个基于并行主机的反恶意软件，它利用了移动GPU的计算能力。提出了一系列计算和存储优化技术来提高检测吞吐量。结果表明，移动图形卡可以有效地用于加速移动电话的恶意软件检测。",
                    "title_zh": "使用移动GPU通过跟踪分析加速恶意软件检测"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.22",
                    "title": "Secure Dissemination of Video Data in Vehicle-to-Vehicle Systems",
                    "authors": "Chenyang Qu, Denis A. Ulybyshev, Bharat K. Bhargava, Rohit Ranchal, Leszek T. Lilien",
                    "abstract": "Data exchange between vehicles and base stations may contain information on traffic accidents, traffic jams, road constructions etc. Risks to data privacy in vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) systems need be minimized. We present a policybased solution that provides controlled and privacypreserving dissemination of video data in V2V and V2I. This policy-based solution relies on Active Bundle (AB), which incorporates policy enforcement mechanism and policies that describe access to video data. The usage of ABs ensures privacy of actors during disclosure of captured video in untrusted environment. Face recognition algorithm is used to identify sensitive data in videos and it is used in policies. We use four algorithms to process images that are captured by a vehicle's camera.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "车辆和基站之间的数据交换可能包含关于交通事故、交通堵塞、道路建设等的信息。需要将车对车(V2V)和车对基础设施(V2I)系统中的数据隐私风险降至最低。我们提出了一个基于策略的解决方案，在V2V和V2I中提供受控和隐私保护的视频数据传播。这种基于策略的解决方案依赖于主动捆绑包(AB ),它整合了策略实施机制和描述视频数据访问的策略。ABs的使用确保了在不可信环境中公开捕获的视频期间演员的隐私。人脸识别算法用于识别视频中的敏感数据，并用于政策中。我们使用四种算法来处理车辆摄像头捕获的图像。",
                    "title_zh": "车对车系统中视频数据的安全传播"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.19",
                    "title": "Conflict Graph Based Channel Allocation in Cognitive Radio Networks",
                    "authors": "Vinesh Teotia, Vipin Kumar, Sonajharia Minz",
                    "abstract": "Cognitive radio technology provides a framework for flexible way to utilize the white spaces using the various spectrum sharing techniques. Interference plays an important role in communication when the channels are shared by the licensed and unlicensed users. Further, the signal to interference plus noise ratio also provide the bounds for the channel capacity. For this the authors introduce a conflict graph based approach for optimal channel allocation in cognitive radio networks named as Conflict Graph based Channel Allocation(CGCA) scheme. The proposed CGCA scheme was simulated and observed that the CGCA scheme outperformed Interference Aware Channel Assignment (IACA) scheme in terms of channel allocation. The channel allocation of the proposed CGCA was observed to have increased by 19 channels, when the unlicensed users shared the network as compared to the IACA technique.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "认知无线电技术使用各种频谱共享技术提供了灵活利用空白空间的框架。当信道由授权用户和未授权用户共享时，干扰在通信中起着重要的作用。此外，信号干扰噪声比也提供了信道容量的界限。为此，作者介绍了一种基于冲突图的认知无线电网络最优信道分配方法，称为基于冲突图的信道分配(CGCA)方案。对提出的CGCA方案进行了仿真，并观察到CGCA方案在信道分配方面优于干扰感知信道分配(IACA)方案。与IACA技术相比，当未授权用户共享网络时，观察到所提出的CGCA的信道分配增加了19个信道。",
                    "title_zh": "认知无线电网络中基于冲突图的信道分配"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.11",
                    "title": "Impact of Initial Target Position on Performance of UAV Surveillance Using Opportunistic Resource Utilization Networks",
                    "authors": "Leszek T. Lilien, Lotfi Ben Othmane, Pelin Angin, Bharat K. Bhargava, Raed M. Salih, Andrew DeCarlo",
                    "abstract": "We propose application of Opportunistic Resource Utilization Networks (Oppnets), a novel type of Mobile Ad Hoc NETworks (MANETs), for ad hoc networking of Unmanned Aerial Vehicles (UAVs) in surveillance missions. Oppnets provide effective resource virtualization and adaption to highly dynamic and unstable nature of MANETs. They can be viewed as middleware to facilitate building flexible and adaptive distributed systems that provide all kinds of resources or services to the requesting application via the so called helper mechanism. The simulation study focuses on the impact of an initial target position on the performance of Oppnet-based UAV surveillance systems. We find that detection success ratios and time to detect a target are negligibly affected by the initial target position in the surveillance area when UAVs expand up their Oppnet quickly, but strongly affected by the initial target position when UAVs are slow in building up their Oppnet.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们提出将机会资源利用网络(Oppnets)这种新型的移动自组织网络(MANETs)应用于监视任务中的无人机自组织网络。Oppnets提供了有效的资源虚拟化和对MANETs的高度动态和不稳定特性的适应。它们可以被视为中间件，有助于构建灵活、自适应的分布式系统，通过所谓的助手机制向请求应用程序提供各种资源或服务。仿真研究的重点是初始目标位置对基于Oppnet的无人机监视系统性能的影响。我们发现，当无人机快速扩大搜索范围时，探测成功率和探测时间受监视区域内初始目标位置的影响很小，而当无人机缓慢扩大搜索范围时，受初始目标位置的影响很大。",
                    "title_zh": "初始目标位置对机会资源利用网络无人机监视性能的影响"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.9",
                    "title": "Selective Hearing: An Approach to Distributed, Eventually Consistent Edge Computation",
                    "authors": "Christopher Meiklejohn, Peter Van Roy",
                    "abstract": "We present a new programming model for large-scale mobile and \"Internet of Things\" style distributed applications. The model consists of two layers: a language layer based on the Lasp language with a runtime layer based on epidemic broadcast. The Lasp layer provides deterministic coordination-free computation primitives based on conflict-free replicated data types (CRDTs). The epidemic broadcast layer is based on the Plumtree protocol. It provides a communication framework where clients may only have a partial view of membership and may not want to participate in or have knowledge of all active computations. We motivate the new model with a nontrivial mobile application, a distributed ad counter, and we give the model's formal semantics.",
                    "files": {
                        "openAccessPdf": "https://dial.uclouvain.be/downloader/downloader.php?pid=boreal:196239&datastream=PDF_01&disclaimer=600c6f3e21b12805a02a563b683da80a29004d80d01431614509519ddbd5e6f9"
                    },
                    "abstract_zh": "我们提出了一个新的大规模移动和“物联网”风格的分布式应用程序的编程模型。该模型由两层组成:基于Lasp语言的语言层和基于流行病广播的运行时层。Lasp层基于无冲突复制数据类型(CRDTs)提供确定性的无协调计算原语。流行病广播层基于Plumtree协议。它提供了一个通信框架，在该框架中，客户端可能只具有成员资格的部分视图，并且可能不想参与或了解所有活动的计算。我们用一个非平凡的移动应用程序，一个分布式广告计数器来激励这个新模型，并给出了这个模型的形式语义。",
                    "title_zh": "选择性听觉:一种分布式、最终一致的边缘计算方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.10",
                    "title": "Exactly-Once Quantity Transfer",
                    "authors": "Ali Shoker, Paulo Sérgio Almeida, Carlos Baquero",
                    "abstract": "Strongly consistent systems supporting distributed transactions can be prone to high latency and do not tolerate partitions. The present trend of using weaker forms of consistency, to achieve high availability, poses notable challenges in writing applications due to the lack of linearizability, e.g., to ensure global invariants, or perform mutator operations on a distributed datatype. This paper addresses a specific problem: the exactly-once transfer of a \"quantity\" from one node to another on an unreliable network (coping with message duplication, loss, or reordering) and without any form of global synchronization. This allows preserving a global property (the sum of quantities remains unchanged) without requiring global linearizability and only through using pairwise interactions between nodes, therefore allowing partitions in the system. We present the novel quantity-transfer algorithm while focusing on a specific use-case: a redistribution protocol to keep the quantities in a set of nodes balanced, in particular, averaging a shared real number across nodes. Since this is a work in progress, we briefly discuss the correctness of the protocol, and we leave potential extensions and empirical evaluations for future work.",
                    "files": {
                        "openAccessPdf": "https://repositorium.sdum.uminho.pt/bitstream/1822/51528/1/Exactly-Once-SRDSW2015.pdf"
                    },
                    "abstract_zh": "支持分布式事务的强一致性系统容易出现高延迟，并且不支持分区。使用较弱形式的一致性来实现高可用性的当前趋势，由于缺乏线性化，例如，为了确保全局不变量，或者在分布式数据类型上执行赋值操作，在编写应用程序时提出了显著的挑战。本文解决了一个具体的问题:在不可靠的网络上，在没有任何形式的全局同步的情况下，从一个节点到另一个节点的“量”的恰好一次传输(处理消息复制、丢失或重新排序)。这允许保持全局属性(数量的总和保持不变)而不需要全局线性化，并且仅通过使用节点之间的成对交互，因此允许系统中的分区。我们提出了新的数量转移算法，同时关注一个特定的用例:一个重新分配协议，以保持一组节点中的数量平衡，特别是，在节点之间平均一个共享的实数。由于这是一项正在进行的工作，我们简要讨论了协议的正确性，并为未来的工作留下了潜在的扩展和经验评估。",
                    "title_zh": "恰好一次数量转移"
                },
                {
                    "url": "https://doi.org/10.1109/SRDSW.2015.13",
                    "title": "Scaling Geo-replicated Databases to the MEC Environment",
                    "authors": "Alejandro Z. Tomsic, Tyler Crain, Marc Shapiro",
                    "abstract": "The Mobile-Edge Computing standard promises co-locating edge servers with mobile phone base stations. Web services running on this new ecosystem will have to address the challenges of this new model in order to see its benefits. In this work, we briefly discuss design guidelines for scaling strongly consistent geo-distributed databases to the MEC environment. Following these guidelines, we present the design of a MEC database tailored for a specific kind of web services and a protocol for ensuring transactional non-monotonic snapshot isolation (NMSI) at MEC scale.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "移动边缘计算标准承诺将边缘服务器与移动电话基站放在一起。运行在这个新生态系统上的Web服务必须解决这个新模型的挑战，才能看到它的好处。在本文中，我们简要讨论了将强一致性地理分布式数据库扩展到MEC环境的设计准则。遵循这些准则，我们提出了一个为特定类型的web服务定制的MEC数据库的设计，以及一个用于确保MEC规模的事务非单调快照隔离(NMSI)的协议。",
                    "title_zh": "将地理复制数据库扩展到MEC环境"
                }
            ]
        },
        {
            "dblp_url": "https://dblp.uni-trier.de/db/conf/srds/srds2015.html",
            "conf_title": "34. SRDS 2015: Montreal, QC, Canada",
            "conf_url": "https://ieeexplore.ieee.org/xpl/conhome/7371402/proceeding",
            "papers": [
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.22",
                    "title": "Probabilistic Byzantine Tolerance for Cloud Computing",
                    "authors": "Luciana Arantes, Roy Friedman, Olivier Marin, Pierre Sens",
                    "abstract": "Tolerating Byzantine failures in the context of cloud computing is costly. Traditional BFT protocols induce a fixed degree of replication for computations and are therefore wasteful. This paper explores probabilistic Byzantine tolerance, in which computation tasks are replicated on dynamic replication sets whose size is determined based on ensuring probabilistic thresholds of correctness. The probabilistic assessment of a trustworthy output by selecting reputable nodes allows a significant reduction in the number of nodes involved in each computation task. The paper further studies several reputation management policies, including the one used by BOINC as well as a couple of novel ones, in terms of their impact of the possible damage inflicted on the system by various Byzantine behavior strategies, and reports some encouraging insights.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在云计算环境中容忍拜占庭式的失败代价高昂。传统的BFT协议为计算引入了固定程度的复制，因此是浪费的。本文研究概率拜占庭容错，其中计算任务在动态复制集上复制，动态复制集的大小是基于确保概率正确性阈值而确定的。通过选择有信誉的节点对可信任的输出进行概率评估，可以显著减少每个计算任务中涉及的节点数量。本文进一步研究了几种声誉管理策略，包括BOINC使用的策略和几个新的策略，研究了它们对各种拜占庭行为策略可能对系统造成的损害的影响，并报告了一些令人鼓舞的见解。",
                    "title_zh": "云计算的概率拜占庭容错"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.27",
                    "title": "Privacy-Preserving Content-Based Image Retrieval in the Cloud",
                    "authors": "Bernardo Ferreira, João Rodrigues, João Leitão, Henrique João L. Domingos",
                    "abstract": "Storage requirements for visual data have been increasing in recent years, following the emergence of many new highly interactive multimedia services and applications for both personal and corporate use. This has been a key driving factor for the adoption of cloud-based data outsourcing solutions. However, outsourcing data storage to the Cloud also leads to new challenges that must be carefully addressed, especially regarding privacy. In this paper we propose a secure framework for outsourced privacy-preserving storage and retrieval in large image repositories. Our proposal is based on IES-CBIR, a novel Image Encryption Scheme that displays Content-Based Image Retrieval properties. Our solution enables both encrypted storage and searching using CBIR queries while preserving privacy. We have built a prototype of the proposed framework, formally analyzed and proven its security properties, and experimentally evaluated its performance and precision. Our results show that IES-CBIR is provably secure, allows more efficient operations than existing proposals, both in terms of time and space complexity, and enables more reliable practical application scenarios.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "近年来，随着许多新的高度交互式多媒体服务和应用的出现，用于个人和公司使用的视觉数据的存储需求一直在增加。这是采用基于云的数据外包解决方案的关键驱动因素。然而，将数据存储外包给云也带来了新的挑战，必须认真应对，尤其是在隐私方面。在本文中，我们提出了一个安全的框架，用于大型图像库中的外包隐私保护存储和检索。我们的建议是基于IES-CBIR，一个新颖的图像加密方案，显示基于内容的图像检索属性。我们的解决方案支持加密存储和使用CBIR查询进行搜索，同时保护隐私。我们构建了一个原型框架，形式化地分析和证明了它的安全特性，并实验性地评估了它的性能和精度。我们的结果表明，IES-CBIR是可证明安全的，在时间和空间复杂度方面，允许比现有方案更有效的操作，并且支持更可靠的实际应用场景。",
                    "title_zh": "云中保护隐私的基于内容的图像检索"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.23",
                    "title": "SafeSky: A Secure Cloud Storage Middleware for End-User Applications",
                    "authors": "Rui Zhao, Chuan Yue, Byung-Chul Tak, Chunqiang Tang",
                    "abstract": "As the popularity of cloud storage services grows rapidly, it is desirable and even essential for both legacy and new end-user applications to have the cloud storage capability to improve their functionality, usability, and accessibility. However, incorporating the cloud storage capability into applications must be done in a secure manner to ensure the confidentiality, integrity, and availability of users' data in the cloud. Unfortunately, it is non-trivial for ordinary application developers to either enhance legacy applications or build new applications to properly have the secure cloud storage capability, due to the development efforts involved as well as the security knowledge and skills required. In this paper, we propose SafeSky, a middleware that can immediately enable an application to use the cloud storage services securely and efficiently, without any code modification or recompilation. A SafeSky-enabled application does not need to save a user's data to the local disk, but instead securely saves them to different cloud storage services to significantly enhance the data security. We have implemented SafeSky as a shared library on Linux. SafeSky supports applications written in different languages, supports various popular cloud storage services, and supports common user authentication methods used by those services. Our evaluation and analysis of SafeSky with real-world applications demonstrate that SafeSky is a feasible and practical approach for equipping end-user applications with the secure cloud storage capability.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "随着云存储服务的普及，传统和新的最终用户应用程序都希望甚至必须拥有云存储功能，以提高其功能性、可用性和可访问性。然而，必须以安全的方式将云存储功能整合到应用程序中，以确保云中用户数据的机密性、完整性和可用性。不幸的是，由于所涉及的开发工作以及所需的安全知识和技能，对于普通应用程序开发人员来说，要么增强遗留应用程序，要么构建新应用程序，以适当地具有安全云存储能力，这不是小事。在本文中，我们提出了SafeSky，这是一个中间件，可以立即使应用程序安全高效地使用云存储服务，而无需任何代码修改或重新编译。启用SafeSky的应用程序不需要将用户的数据保存到本地磁盘，而是将它们安全地保存到不同的云存储服务，以显著增强数据安全性。我们已经在Linux上将SafeSky实现为一个共享库。SafeSky支持用不同语言编写的应用程序，支持各种流行的云存储服务，并支持这些服务使用的通用用户身份验证方法。我们对SafeSky和真实应用程序的评估和分析表明，SafeSky是为最终用户应用程序配备安全云存储功能的可行和实用的方法。",
                    "title_zh": "SafeSky:面向终端用户应用的安全云存储中间件"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.32",
                    "title": "Extending Eventually Consistent Cloud Databases for Enforcing Numeric Invariants",
                    "authors": "Valter Balegas, Diogo Serra, Sérgio Duarte, Carla Ferreira, Marc Shapiro, Rodrigo Rodrigues, Nuno M. Preguiça",
                    "abstract": "Geo-replicated databases often offer high availability and low latency by relying on weak consistency models. The inability to enforce invariants across all replicas remains a key shortcoming that prevents the adoption of such databases in several applications. In this paper we show how to extend an eventually consistent cloud database for enforcing numeric invariants. Our approach builds on ideas from escrow transactions, but our novel design overcomes the limitations of previous works. First, by relying on a new replicated data type, our design has no central authority and uses pairwise asynchronous communication only. Second, by layering our design on top of a fault-tolerant database, our approach exhibits better availability during network partitions and data center faults. The evaluation of our prototype, built on top of Riak, shows much lower latency and better scalability than the traditional approach of using strong consistency to enforce numeric invariants.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1503.09052"
                    },
                    "abstract_zh": "地理复制数据库通常依靠弱一致性模型来提供高可用性和低延迟。不能在所有复制品上实施不变量仍然是阻碍这种数据库在几个应用中采用的关键缺点。在本文中，我们展示了如何扩展一个最终一致的云数据库，以加强数值不变量。我们的方法建立在托管交易的基础上，但我们的新颖设计克服了以前作品的局限性。首先，通过依赖一种新的复制数据类型，我们的设计没有中央权威，只使用成对异步通信。第二，通过在容错数据库之上分层我们的设计，我们的方法在网络分区和数据中心故障期间表现出更好的可用性。对构建在Riak之上的原型的评估显示，与使用强一致性来实施数值不变量的传统方法相比，它具有更低的延迟和更好的可伸缩性。",
                    "title_zh": "扩展最终一致的云数据库以实现数值不变量"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.24",
                    "title": "Auditable Restoration of Distributed Programs",
                    "authors": "Reza Hajisheykhi, Mohammad Roohitavaf, Sandeep S. Kulkarni",
                    "abstract": "We focus on a protocol for auditable restoration of distributed systems. The need for such protocol arises due to conflicting requirements (e.g., access to the system should be restricted but emergency access should be provided). One can design such systems with a tamper detection approach (based on the intuition of \"break the glass door\"). However, in a distributed system, such tampering, which are denoted as auditable events, is visible only for a single node. This is unacceptable since the actions they take in these situations can be different than those in the normal mode. Moreover, eventually, the auditable event needs to be cleared so that system resumes the normal operation. With this motivation, in this paper, we present a protocol for auditable restoration, where any process can potentially identify an auditable event. Whenever a new auditable event occurs, the system must reach an \"auditable state\" where every process is aware of the auditable event. Only after the system reaches an auditable state, it can begin the operation of restoration. Although any process can observe an auditable event, we require that only \"authorized\" processes can begin the task of restoration. Moreover, these processes can begin the restoration only when the system is in an auditable state. Our protocol is self-stabilizing and can effectively handle the case where faults or auditable events occur during the restoration protocol. Moreover, it can be used to provide auditable restoration to other distributed protocol.",
                    "files": {
                        "openAccessPdf": "http://arxiv.org/pdf/1506.07957"
                    },
                    "abstract_zh": "我们关注于分布式系统的可审计恢复协议。对这种协议的需求是由于相互冲突的需求(例如，对系统的访问应该受到限制，但应该提供紧急访问)。人们可以用篡改检测方法(基于“打破玻璃门”的直觉)来设计这样的系统。然而，在分布式系统中，这种被表示为可审计事件的篡改仅对单个节点可见。这是不可接受的，因为它们在这些情况下采取的行动可能不同于正常模式下的行动。此外，最终，需要清除可审计事件，以便系统恢复正常操作。出于这种动机，在本文中，我们提出了一个可审计恢复协议，其中任何进程都可以潜在地识别可审计事件。每当新的可审核事件发生时，系统必须达到“可审核状态”,此时每个流程都知道该可审核事件。只有在系统达到可审计状态后，才能开始恢复操作。尽管任何流程都可以观察到可审核的事件，但我们要求只有“授权”的流程才能开始恢复任务。此外，只有当系统处于可审计状态时，这些过程才能开始恢复。我们的协议是自稳定的，并且可以有效地处理在恢复协议期间出现故障或可审计事件的情况。此外，它还可以为其他分布式协议提供可审计的恢复。",
                    "title_zh": "分布式程序的可审计恢复"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.39",
                    "title": "PSG-Codes: An Erasure Codes Family with High Fault Tolerance and Fast Recovery",
                    "authors": "Shiyi Li, Qiang Cao, Lei Tian, Shenggang Wan, Lu Qian, Changsheng Xie",
                    "abstract": "As hard disk failure rates are rarely improved and the reconstruction time for TB-level disks typically amounts to days, multiple concurrent disk/storage node failures in datacenter storage systems become common and frequent. As a result, the erasure coding schemes used in datacenters must meet the critical requirements of high fault tolerance, high storage efficiency, and fast fault recovery. In this paper, we introduce a new XOR-based non-MDS erasure code family with an ability of tolerating up to 12-disk/node failures, called PSG-Codes. The basic idea behind PSG-Codes is to partition disks into groups, and exploit short parity chains to generate parity units. Then, the parity chain is further shortened by varying the number of parity elements for each strip. We conduct a simulation-based study to search configuration parameter space of PSG-Codes, and prove that PSG-Codes can tolerate up to 12 disk/node failures. Compared with a well-known XOR-based non-MDS code, WEAVER codes, PSG-Codes have higher storage efficiency and lower reconstruction cost. Moreover, the storage efficiency and performance of PSG-Codes are also competitive with another stat-of-the-art GF-based non-MDS codes, LRC codes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "由于硬盘故障率很少得到改善，TB级磁盘的重建时间通常长达数天，数据中心存储系统中的多个并发磁盘/存储节点故障变得常见而频繁。因此，数据中心中使用的擦除编码方案必须满足高容错性、高存储效率和快速故障恢复的关键要求。在本文中，我们介绍了一种新的基于异或的非MDS擦除码家族，它能够容忍多达12个磁盘/节点的故障，称为PSG码。PSG代码背后的基本思想是将磁盘分成组，并利用短的奇偶校验链来生成奇偶校验单元。然后，通过改变每个条带的奇偶校验元素的数量来进一步缩短奇偶校验链。我们进行了一项基于仿真的研究来搜索PSG代码的配置参数空间，并证明PSG代码可以容忍多达12个磁盘/节点故障。与著名的基于异或的非MDS码WEAVER码相比，PSG码具有更高的存储效率和更低的重构成本。此外，PSG码的存储效率和性能也可与另一种基于GF的非MDS码——LRC码相媲美。",
                    "title_zh": "PSG码:一种高容错快速恢复的纠删码族"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.11",
                    "title": "Recurrence in Self-Stabilization",
                    "authors": "Oday Jubran, Oliver E. Theel",
                    "abstract": "Self-stabilization ensures that a system converges to a legitimate execution in finite time, where a legitimate execution comprises a sequence of configurations satisfying some safety condition. In this work, we investigate the notion of recurrence, which denotes how frequently a condition is satisfied in an execution of a system. We use this notion in self-stabilization to address the convergence of a system to a behavior that guarantees a minimum recurrence of some condition. We apply this notion to show how the design of distributed mutual exclusion algorithms can be altered to achieve a high service time under various convergence time and space complexities. As a particular contribution, we present a self-stabilizing mutual exclusion algorithm that has optimal service time together with optimal stabilization time complexity of (D/2 - 1) for synchronous executions and under any topology, where D is the diameter of the topology. In addition, we rectify an earlier proof stating that (D/2) is a lower bound, to conclude that (D/2 - 1) is optimal for synchronous executions.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "自稳定确保系统在有限时间内收敛到合法执行，其中合法执行包括满足某种安全条件的配置序列。在这项工作中，我们研究了递归的概念，它表示一个条件在一个系统的执行中被满足的频率。我们在自稳定中使用这个概念来解决一个系统收敛到一个行为的问题，这个行为保证某个条件的最小重现。我们应用这个概念来展示如何改变分布式互斥算法的设计，以在各种收敛时间和空间复杂性下实现高服务时间。作为一个特殊的贡献，我们提出了一个自稳定互斥算法，对于同步执行和在任何拓扑下，该算法具有最优服务时间和最优稳定时间复杂度(D/2 - 1 ),其中D是拓扑的直径。此外，我们纠正了早先的一个证明，即(D/2)是一个下界，从而得出结论(D/2 - 1)对于同步执行是最优的。",
                    "title_zh": "自稳定中的重现"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.37",
                    "title": "Multi-objective Optimisation of Rolling Upgrade Allowing for Failures in Clouds",
                    "authors": "Daniel Sun, Daniel Guimarans, Alan D. Fekete, Vincent Gramoli, Liming Zhu",
                    "abstract": "Rolling upgrade is a practical industry technique for online updating of software in distributed systems. This paper focuses on rolling upgrade of software versions in virtual machine instances on cloud computing platforms, when various failures may occur. An operator can choose the number of instances that are updated in one round and system environments to minimise completion time, availability degradation, and monetary cost for entire rolling upgrade, and hence this is a multi-objective optimisation problem. To predict completion time in the presence of failures, we offer a stochastic model that represents the dynamics of rolling upgrade. To reduce the computational effort of decision making for large scale complex systems, we propose a technique that can find a Pareto set quickly via an upper bound of the expected completion time. Then an optimum of the original problem can be chosen from this set of potential solutions. We validate our approach to minimise the objectives, through both experiments in Amazon Web Service (AWS) and simulations.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "滚动升级是分布式系统中软件在线更新的一种实用的行业技术。本文重点研究云计算平台上虚拟机实例中软件版本的滚动升级，在这种情况下可能会出现各种故障。运营商可以选择一轮更新的实例数量和系统环境，以最小化整个滚动升级的完成时间、可用性下降和货币成本，因此这是一个多目标优化问题。为了预测出现故障时的完成时间，我们提供了一个表示滚动升级动态的随机模型。为了减少大规模复杂系统决策的计算量，我们提出了一种通过期望完成时间的上界快速找到Pareto集的方法。然后，可以从这组潜在的解决方案中选择原始问题的最优方案。通过在Amazon Web Service (AWS)中的实验和模拟，我们验证了我们最小化目标的方法。",
                    "title_zh": "允许云中出现故障的滚动升级的多目标优化"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.14",
                    "title": "PASS: An Address Space Slicing Framework for P2P Eclipse Attack Mitigation",
                    "authors": "Daniel Germanus, Hatem Ismail, Neeraj Suri",
                    "abstract": "The decentralized design of Peer-to-Peer (P2P) protocols inherently provides for fault tolerance to non-malicious faults. However, the base P2P scalability and decentralization requirements often result in design choices that negatively impact their robustness to varied security threats. A prominent vulnerability are Eclipse attacks that aim at information hiding and consequently perturb a P2P overlay's reliable service delivery. Divergent lookups constitute an advocated mitigation technique but are size-limited to overlay networks with tens of thousands of peers. In this work, building upon divergent lookups, we propose a novel and scalable P2P address space slicing strategy (PASS) to efficiently mitigate attacks in overlays that host hundreds of thousands of peers. Moreover, we integrate and evaluate diversely designed lookup variants to assess their network overhead and mitigation rates. The proposed PASS approach shows mitigation rates reaching up to 100%.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对等(P2P)协议的分散设计固有地提供了对非恶意故障的容错。然而，基本的P2P可伸缩性和去中心化需求通常会导致设计选择对各种安全威胁的鲁棒性产生负面影响。一个突出的漏洞是Eclipse攻击，其目的是隐藏信息，从而干扰P2P覆盖的可靠服务交付。发散查找构成了一种被提倡的缓解技术，但是其大小受限于具有数万个对等体的覆盖网络。在这项工作中，我们提出了一种新的可扩展的P2P地址空间切片策略(PASS ),以有效地减轻托管数十万个对等点的覆盖网中的攻击。此外，我们整合并评估不同设计的查找变体，以评估它们的网络开销和缓解率。提议的PASS方法显示缓解率高达100%。",
                    "title_zh": "PASS:一个减轻P2P Eclipse攻击的地址空间切片框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.35",
                    "title": "ControlFreak: Signature Chaining to Counter Control Flow Attacks",
                    "authors": "Sergei Arnautov, Christof Fetzer",
                    "abstract": "Many modern embedded systems use networks to communicate. This increases the attack surface: the adversary does not need to have physical access to the system and can launch remote attacks. By exploiting software bugs, the attacker might be able to change the behavior of a program. Security violations in safety-critical systems are particularly dangerous since they might lead to catastrophic results. Hence, safety-critical software requires additional protection. We present an approach to detect and prevent control flow attacks. Such attacks maliciously modify program's control flow to achieve the desired behavior. We develop ControlFreak, a hardware watchdog to monitor program execution and to prevent illegal control flow transitions. The watchdog employs chained signatures to detect any modification of the instruction stream and any illegal jump in the program even if signatures are maliciously modified.",
                    "files": {
                        "openAccessPdf": "https://zenodo.org/record/211963/files/ControlFreak_Arnautov.pdf"
                    },
                    "abstract_zh": "许多现代嵌入式系统使用网络进行通信。这增加了攻击面:对手不需要物理访问系统，就可以发起远程攻击。通过利用软件漏洞，攻击者可能能够改变程序的行为。安全关键系统中的安全违规尤其危险，因为它们可能导致灾难性的结果。因此，安全关键软件需要额外的保护。我们提出了一种检测和防止控制流攻击的方法。这种攻击恶意修改程序的控制流，以达到预期的行为。我们开发了ControlFreak，它是一个硬件看门狗，用来监控程序的执行并防止非法的控制流转换。看门狗使用链式签名来检测指令流的任何修改和程序中的任何非法跳转，即使签名被恶意修改。",
                    "title_zh": "ControlFreak:对抗控制流攻击的签名链"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.31",
                    "title": "Denial of Service Elusion (DoSE): Keeping Clients Connected for Less",
                    "authors": "Paul Wood, Christopher N. Gutierrez, Saurabh Bagchi",
                    "abstract": "Denial of Service (DoS) attacks continue to grow in magnitude, duration, and frequency increasing the demand for techniques to protect services from disruption, especially at a low cost. We present Denial of Service Elusion (DoSE) as an inexpensive method for mitigating network layer attacks by utilizing cloud infrastructure and content delivery networks to protect services from disruption. DoSE uses these services to create a relay network between the client and the protected service that evades attack by selectively releasing IP address information. DoSE incorporates client reputation as a function of prior behavior to stop attackers along with a feedback controller to limit costs. We evaluate DoSE by modeling relays, clients, and attackers in an agent-based MATLAB simulator. The results show DoSE can mitigate a single-insider attack on 1,000 legitimate clients in 3.9 minutes while satisfying an average of 88.2% of requests during the attack.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "拒绝服务(DoS)攻击的规模、持续时间和频率持续增长，增加了对保护服务免受中断的技术的需求，尤其是在低成本的情况下。我们提出拒绝服务规避(DoSE)作为一种廉价的方法，通过利用云基础设施和内容交付网络来保护服务免受中断，从而减轻网络层攻击。DoSE使用这些服务在客户端和受保护的服务之间创建一个中继网络，通过选择性地释放IP地址信息来躲避攻击。DoSE将客户信誉作为先前行为的函数来阻止攻击者，并结合反馈控制器来限制成本。我们通过在基于代理的MATLAB模拟器中建模中继、客户端和攻击者来评估doe。结果显示DoSE可以在3.9分钟内缓解对1，000个合法客户端的单个内部攻击，同时满足攻击期间平均88.2%的请求。",
                    "title_zh": "拒绝服务规避(DoSE):以更低的成本保持客户端连接"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.42",
                    "title": "Temporality a NVRAM-based Virtualization Platform",
                    "authors": "Vasily A. Sartakov, Arthur Martens, Rüdiger Kapitza",
                    "abstract": "Power failures in data centers and Cloud Computing infrastructures can cause loss of data and impact revenue. Existing best practice such as persistent logging and checkpointing add overhead during operation and increase recovery time. Other solutions like the use of an uninterruptable power supply incur additional costs and are maintenance-intensive. Novel persistent main memory, i.e. memory that retains stored data without an external source of power, firstly prevents data loss in case of a power outage, secondly reduces the time for a system reboot and thirdly enables to continue operation at full-speed after a recovery. Yet new architectures and programming models are required to utilize persistent main memory. We present Temporality a virtualization layer that runs virtual machines in persistent memory and offers virtual persistent memory. It can be used as a basis for future Cloud platforms to allow applications the utilization of persistent memory without any changes. It provides safety of volatile data, significantly decreases overall recovery time and prevents subsequent performance degradation.",
                    "files": {
                        "openAccessPdf": "http://www.ibr.cs.tu-bs.de/users/sartakov/papers/sartakov15srds.pdf"
                    },
                    "abstract_zh": "数据中心和云计算基础设施中的电源故障会导致数据丢失并影响收入。现有的最佳实践(如持久日志记录和检查点)会增加操作过程中的开销并增加恢复时间。其他解决方案，如使用不间断电源，会产生额外的成本，并且需要大量维护。新颖的持久主存储器，即在没有外部电源的情况下保留存储数据的存储器，首先防止断电情况下的数据丢失，其次减少系统重启的时间，第三能够在恢复后继续全速运行。然而，需要新的体系结构和编程模型来利用永久主存储器。我们提出了临时虚拟化层，它在永久内存中运行虚拟机，并提供虚拟永久内存。它可以作为未来云平台的基础，允许应用程序在不做任何更改的情况下使用永久内存。它提供了易失数据的安全性，显著减少了总体恢复时间，并防止了随后的性能下降。",
                    "title_zh": "基于NVRAM的虚拟化平台"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.21",
                    "title": "A Secure Collusion-Aware and Probability-Aware Range Query Processing in Tiered Sensor Networks",
                    "authors": "Lei Dong, Xuan Chen, Jianxiang Zhu, Hong Chen, Ke Wang, Cuiping Li",
                    "abstract": "With high expansibility and efficient power usage, tiered wireless sensor networks are widely deployed in many fields as an important part of Internet of Things (IoTs). It is challenging to process range query while protecting sensitive data from adversaries. Moreover, most existing work focuses on privacy-preserving range query neglecting collusion attacks and probability attacks, which are more threatening to network security. In this paper, we first propose a secure range query protocol called secRQ, which not only protects data privacy, but also resists collusion attacks and probability attacks in tiered wireless sensor networks. Generalized inverse matrices and distance-based range query mechanism are used to guarantee security as well as high efficiency and accuracy. Besides, we propose the mutual verification scheme to verify the integrity of query results. Finally, both theoretical analysis and experimental results confirm the security, efficiency and accuracy of secRQ.",
                    "files": {
                        "openAccessPdf": "http://www.cs.sfu.ca/%7Ewangk/pub/SRDS2015-0720-camera.pdf"
                    },
                    "abstract_zh": "分层无线传感器网络作为物联网的重要组成部分，具有高扩展性和高效的能量利用，被广泛应用于许多领域。在处理范围查询的同时保护敏感数据免受对手攻击是一项挑战。此外，现有的大部分工作侧重于隐私保护范围查询，忽略了对网络安全威胁更大的共谋攻击和概率攻击。在本文中，我们首先提出了一种安全的范围查询协议secRQ，它不仅可以保护数据隐私，还可以抵抗分层无线传感器网络中的共谋攻击和概率攻击。采用广义逆矩阵和基于距离的范围查询机制，在保证安全性的同时提高了效率和准确性。此外，我们提出了相互验证方案来验证查询结果的完整性。最后，理论分析和实验结果都证实了secRQ的安全性、高效性和准确性。",
                    "title_zh": "分层传感器网络中安全的共谋感知和概率感知范围查询处理"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.41",
                    "title": "PmDroid: Permission Supervision for Android Advertising",
                    "authors": "Xing Gao, Dachuan Liu, Haining Wang, Kun Sun",
                    "abstract": "It is well-known that Android mobile advertising networks may abuse their host applications' permission to collect private information. Since the advertising library and host app are running in the same process, the current Android permission mechanism cannot prevent an ad network from collecting private data that is out of an ad network's permission range. In this paper, we propose PmDroid to protect the data that is not under the scope of the ad network's permission set. PmDroid can block the data from being sent to advertising servers at the occurrence of permission violation in ad networks. Moreover, we utilize PmDroid to assess how serious the permission violation problem is in the ad networks. We first implement 53 sample apps using a single ad network library. We grant all permissions of Android 4.3 to these apps and record the data sent to the Internet. Then, we further analyze 430 published market apps. In total, there are 76 ad networks identified in our experiments. We compare the permission of data received by these ad networks with their official documents. Our experimental results indicate that the permission violation is a real problem in existing ad network markets.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "众所周知，Android移动广告网络可能会滥用其主机应用程序的权限来收集私人信息。由于广告库和主机应用程序在同一进程中运行，当前的Android权限机制无法阻止广告网络收集广告网络权限范围之外的私人数据。在本文中，我们提出PmDroid来保护不在广告网络权限集范围内的数据。PmDroid可以在广告网络中出现权限违规时阻止数据发送到广告服务器。此外，我们利用PmDroid来评估广告网络中的权限违规问题有多严重。我们首先使用一个广告网络库实现了53个示例应用。我们将Android 4.3的所有权限授予这些应用，并记录发送到互联网的数据。然后，我们进一步分析了430个已发布的市场应用。在我们的实验中，总共识别出76个广告网络。我们将这些广告网络收到的数据的许可与它们的官方文件进行比较。我们的实验结果表明，在现有的广告网络市场中，许可违反是一个真实的问题。",
                    "title_zh": "pm droid:Android广告的权限监管"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.34",
                    "title": "Signature-Based Top-k Query Processing against Data Replacement Attacks in MANETs",
                    "authors": "Takuji Tsuda, Yuka Komai, Takahiro Hara, Shojiro Nishio",
                    "abstract": "In this paper, we propose a signature-based top-k query processing method against data replacement attacks in mobile ad hoc networks (MANETs). In order to rapidly identify a greater number of malicious nodes, nodes share information about identified malicious nodes with other nodes. If nodes share only this information, however, malicious nodes may successfully transmit false information identifying normal nodes as malicious. Therefore, in the proposed method, when nodes send reply messages during query processing, they attach encrypted information about the sent data items (i.e., digital signatures), providing the query-issuing node with critical information about the data items sent by nodes in the network, and thereby enabling it to identify malicious nodes, using the received signatures. After identifying the malicious nodes, it floods the network with a notification message including the signatures in which the identified malicious nodes have replaced higher-score data items to their own lower-score items.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "本文提出了一种基于签名的top-k查询处理方法来抵抗移动自组网中的数据替换攻击。为了快速识别更多的恶意节点，节点与其他节点共享关于所识别的恶意节点的信息。然而，如果节点仅共享该信息，则恶意节点可能成功地发送将正常节点识别为恶意的错误信息。因此，在所提出的方法中，当节点在查询处理期间发送回复消息时，它们附加关于所发送的数据项的加密信息(即，数字签名)，向发出查询的节点提供关于由网络中的节点发送的数据项的关键信息，从而使其能够使用所接收的签名来识别恶意节点。在识别恶意节点之后，它用包括签名的通知消息来淹没网络，在该签名中，所识别的恶意节点已经将较高分数的数据项替换为它们自己的较低分数的数据项。",
                    "title_zh": "移动自组网中抗数据替换攻击的基于签名的Top-k查询处理"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.12",
                    "title": "FTDE: Distributed Fault Tolerance for WSN Data Collection and Compression Schemes",
                    "authors": "Azad Ali, Abdelmajid Khelil, Neeraj Suri",
                    "abstract": "Wireless Sensor Networks (WSNs), being power and communication capacity constrained, often employ data compression schemes to reduce the data volumes. At the same time, various factors, such as low node reliability and communication faults, can compromise the core objective of accurate collection and delivery of the sensor data. However, contemporary compression schemes often fail to consider operational faults, and the resulting data errors arising from low node reliability (node crashes), and communication faults (data and links corruption) result in erroneous data being collected. This paper proposes a novel model-based fault-tolerance technique applicable to varied compression schemes. Being fully distributed, our scheme corrects data errors at the point of origin (faulty sensor nodes), and thus avoids costly transmissions of corrupt data, decreasing message cost, and enhances compression effectiveness by correcting the erroneous samples.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "受能量和通信容量限制，无线传感器网络通常采用数据压缩方案来减少数据量。与此同时，各种因素，如低节点可靠性和通信故障，可能会损害准确收集和传送传感器数据的核心目标。然而，当代的压缩方案经常不能考虑操作故障，并且由低节点可靠性(节点崩溃)和通信故障(数据和链路损坏)引起的结果数据错误导致收集到错误的数据。本文提出了一种新的基于模型的容错技术，适用于各种压缩方案。由于是完全分布式的，我们的方案在源点(有故障的传感器节点)纠正数据错误，从而避免了昂贵的损坏数据的传输，降低了消息成本，并通过纠正错误的样本增强了压缩效率。",
                    "title_zh": "FTDE:WSN数据收集和压缩方案的分布式容错"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.40",
                    "title": "Separating the WHEAT from the Chaff: An Empirical Design for Geo-Replicated State Machines",
                    "authors": "João Sousa, Alysson Bessani",
                    "abstract": "State machine replication is a fundamental technique for implementing consistent fault-tolerant services. In the last years, several protocols have been proposed for improving the latency of this technique when the replicas are deployed in geographically-dispersed locations. In this work we evaluate some representative optimizations proposed in the literature by implementing them on an open-source state machine replication library and running the experiments in geographically-diverse PlanetLab nodes and Amazon EC2 regions. Interestingly, our results show that some optimizations widely used for improving the latency of geo-replicated state machines do not bring significant benefits, while others - not yet considered in this context - are very effective. Based on this evaluation, we propose WHEAT, a configurable crash and Byzantine fault-tolerant state machine replication library that uses the optimizations we observed as most effective in reducing SMR latency. WHEAT employs novel voting assignment schemes that, by using few additional spare replicas, enables the system to make progress without needing to access a majority of replicas. Our evaluation shows that a WHEAT system deployed in several Amazon EC2 regions presents a median latency up to 56% lower than a \"normal\" SMR protocol.",
                    "files": {
                        "openAccessPdf": "http://www.di.fc.ul.pt/%7Ebessani/publications/srds15-wheat.pdf"
                    },
                    "abstract_zh": "状态机复制是实现一致容错服务的基本技术。在过去的几年中，当副本被部署在地理上分散的位置时，已经提出了几个协议来改善该技术的延迟。在这项工作中，我们评估了文献中提出的一些代表性优化，方法是在开源状态机复制库上实现它们，并在地理上不同的PlanetLab节点和Amazon EC2区域中运行实验。有趣的是，我们的结果表明，一些广泛用于改善地理复制状态机延迟的优化并没有带来显著的好处，而其他优化(在此上下文中尚未考虑)非常有效。基于这一评估，我们提出了WHEAT，一个可配置的崩溃和拜占庭容错状态机复制库，它使用了我们观察到的在减少SMR延迟方面最有效的优化。WHEAT采用新颖的投票分配方案，通过使用少量额外的备用副本，使系统能够在不需要访问大多数副本的情况下取得进展。我们的评估显示，部署在几个亚马逊EC2地区的小麦系统的平均延迟比“正常”SMR协议低56%。",
                    "title_zh": "从谷壳中分离小麦:地理复制状态机的经验设计"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.29",
                    "title": "Replacement: Decentralized Failure Handling for Replicated State Machines",
                    "authors": "Leander Jehl, Tormod Erevik Lea, Hein Meling",
                    "abstract": "We investigate methods for handling failures in a Paxos State Machine and introduce Replacement, a novel approach to handle failures. Replacement is fully decentralized and does not rely on consensus. This allows failed replicas to be replaced quickly, avoiding the bottleneck of a single leader. Instead of handling failures in the order proposed by a leader, concurrent replacements are combined to guarantee that all failed replicas are replaced. Replacement also allows the state machine to process client requests during failure handling, even while disagreeing on the current configuration. As our evaluation shows, this enables Replacement to quickly handle failures, with minimal disruption in the processing of client requests.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们研究了在Paxos状态机中处理故障的方法，并介绍了替换，一种处理故障的新方法。替代是完全去中心化的，不依赖共识。这允许快速替换失败的副本，避免了单个领导者的瓶颈。不是按照领导者提议的顺序处理故障，而是组合并发替换以保证所有失败的副本都被替换。替换还允许状态机在故障处理期间处理客户端请求，即使在不同意当前配置的情况下也是如此。正如我们的评估所显示的，这使得替换能够快速处理故障，同时将客户端请求处理中的中断降至最低。",
                    "title_zh": "替换:复制状态机的分散故障处理"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.30",
                    "title": "Approximate Hash-Based Set Reconciliation for Distributed Replica Repair",
                    "authors": "Nico Kruber, Maik Lange, Florian Schintke",
                    "abstract": "The objective comparison of hash-based set reconciliation algorithms for distributed replica repair is challenging. Each algorithm's behaviour can be tuned for a given use case, e.g. low bandwidth or computational overhead, using different sets of parameters. Changes on these parameters, however, often also influence the algorithm's accuracy in recognising differences between replicas and thus hinder objective comparisons. We develop models to deduce parameters for equally accurate set reconciliation algorithms for replica repair in a distributed system and compare equally accurate instances of two trivial hash-based algorithms, an algorithm using Bloom filters and a Merkle tree based algorithm. Instead of using a large fixed hash size for Merkle trees we propose to use dynamic hash sizes to align the transfer overhead with the desired accuracy. We evaluate (a) the transferred volume of data with respect to different entropy levels, data and failure distributions on the set of items, and (b) the scalability in the number of items. Our results allow to easily choose an efficient algorithm for practical set reconciliation tasks based on the required level of accuracy. Our way to find equally accurate configuration parameters for different algorithms can also be adopted to other set reconciliation algorithms and allows to rate their respective performance in an objective manner.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "分布式副本修复中基于哈希的集合协调算法的客观比较具有挑战性。每种算法的行为都可以针对给定的用例进行调整，例如，使用不同的参数集来调整低带宽或计算开销。然而，这些参数的变化通常也会影响算法识别复制品之间差异的准确性，从而阻碍客观比较。我们开发模型来推导用于分布式系统中的副本修复的同样精确的集合协调算法的参数，并且比较两个普通的基于散列的算法的同样精确的实例，一个算法使用布隆过滤器，并且一个算法基于Merkle树。我们建议使用动态散列大小来将传输开销与期望的准确度对齐，而不是对Merkle树使用大的固定散列大小。我们评估(a)根据不同的熵水平、项目集上的数据和故障分布传输的数据量，以及(b)项目数量的可伸缩性。我们的结果允许容易地选择一个有效的算法，为实际的集合协调任务的基础上，所需的准确性水平。我们为不同算法找到同样精确的配置参数的方法也可以用于其他集合协调算法，并允许以客观的方式评价它们各自的性能。",
                    "title_zh": "分布式副本修复中基于近似哈希的集合协调"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.38",
                    "title": "Securing Passive Replication through Verification",
                    "authors": "Bruno Vavala, Nuno Ferreira Neves, Peter Steenkiste",
                    "abstract": "We show how to leverage trusted computing technology to design an efficient fully-passive replicated system tolerant to arbitrary failures. The system dramatically reduces the complexity of a fault-tolerant service, in terms of protocols, messages, data processing and non-deterministic operations. Our replication protocol enables the execution of a single protected service, replicating only its state, while allowing the backup replicas to check the correctness of the results. We implemented our protocol on Trusted Computing (TC) technology and compared it with two recent replication systems.",
                    "files": {
                        "openAccessPdf": "http://www.di.fc.ul.pt/%7Enuno/PAPERS/SRDS15.pdf"
                    },
                    "abstract_zh": "我们展示了如何利用可信计算技术来设计一个高效的全被动复制系统，该系统能够容忍任意故障。该系统极大地降低了容错服务在协议、消息、数据处理和非确定性操作方面的复杂性。我们的复制协议支持执行单个受保护的服务，仅复制其状态，同时允许备份副本检查结果的正确性。我们在可信计算(TC)技术上实现了我们的协议，并将其与最近的两个复制系统进行了比较。",
                    "title_zh": "通过验证保护被动复制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.15",
                    "title": "PCM: A Parity-Check Matrix Based Approach to Improve Decoding Performance of XOR-based Erasure Codes",
                    "authors": "Yongzhe Zhang, Chentao Wu, Jie Li, Minyi Guo",
                    "abstract": "In large storage systems, erasure codes is a primary technique to provide high reliability with low monetary cost. Among various erasure codes, a major category called XORbased codes uses purely XOR operations to generate redundant data and offer low computational complexity. These codes are conventionally implemented via matrix based method or several specialized non-matrix based methods. However, these approaches are insufficient on decoding performance, which affects the reliability and availability of storage systems. To address the problem, in this paper, we propose a novel Parity-Check Matrix based (PCM) approach, which is a general-purpose method to implement XOR-based codes, and increases the decoding performance by using smaller and sparser matrices. To demonstrate the effectiveness of PCM, we conduct several experiments by using different XOR-based codes. The evaluation results show that, compared to typical matrix based decoding methods, PCM can improve the decoding speed by up to a factor of 1.5× when using EVENODD code (an erasure code for correcting double disk failures), and accelerate the decoding process of STAR code (an erasure code for correcting triple disk failures) by up to a factor of 2.4×.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "在大型存储系统中，擦除码是以低成本提供高可靠性的主要技术。在各种擦除码中，一个主要的类别称为XORbased码，它使用纯XOR运算来产生冗余数据并提供低计算复杂度。这些代码通常通过基于矩阵的方法或几种专门的非基于矩阵的方法来实现。然而，这些方法在解码性能上存在不足，影响了存储系统的可靠性和可用性。为了解决这个问题，本文提出了一种新的基于奇偶校验矩阵(PCM)的方法，这是一种通用的实现基于XOR码的方法，通过使用更小和更稀疏的矩阵来提高解码性能。为了证明PCM的有效性，我们通过使用不同的基于XOR的代码进行了几个实验。评估结果表明，与典型的基于矩阵的解码方法相比，当使用EVENODD码(用于纠正双磁盘故障的擦除码)时，PCM可以将解码速度提高1.5倍，并将STAR码(用于纠正三磁盘故障的擦除码)的解码过程加速2.4倍。",
                    "title_zh": "PCM:一种基于奇偶校验矩阵的XOR纠删码解码性能改进方法"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.25",
                    "title": "MICS: Mingling Chained Storage Combining Replication and Erasure Coding",
                    "authors": "Yan Tang, Jianwei Yin, Wei Lo, Ying Li, ShuiGuang Deng, Kexiong Dong, Calton Pu",
                    "abstract": "High reliability, low space cost, and efficient read/write performance are all desirable properties for cloud storage systems. Due to the inherent conflicts, however, simultaneously achieving optimality on these properties is unrealistic. Since reliable storage is indispensable prerequisite for services with high availability, tradeoff should therefore be made between space and read/write efficiency when storage scheme is designed. N-way Replication and Erasure Coding, two extensively-used storage schemes with high reliability, adopt opposite strategies on this tradeoff issue. However, unbalanced tradeoff designs of both schemes confine their effectiveness to limited types of workloads and system requirements. To mitigate such applicability penalty, we propose MICS, a MIngling Chained Storage scheme that combines structural and functional advantages from both N-way replication and erasure coding. Qualitatively, MICS provides efficient read/write performance and high reliability at reasonably low space cost. MICS stores each object in two forms: a full copy and certain amount of erasure-coded segments. We establish dedicated read/write protocols for MICS leveraging the unique structural advantages. Moreover, MICS provides high read/write efficiency with Pipeline Random-Access Memory consistency to guarantee reasonable semantics for services users. Evaluation results demonstrate that under same fault tolerance and consistency level, MICS outperforms N-way replication and pure erasure coding in I/O throughput by up to 34.1% and 51.3% respectively. Furthermore, MICS shows superior performance stability over diverse workload conditions, in which case the standard deviation of MICS is 70.1% and 29.3% smaller than those of other two schemes.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "高可靠性、低空间成本和高效的读/写性能都是云存储系统的期望属性。然而，由于固有的冲突，同时实现这些性能的最优化是不现实的。由于可靠的存储是高可用性服务不可或缺的前提，因此在设计存储方案时需要在空间和读写效率之间进行权衡。n路复制和擦除编码这两种广泛使用的高可靠性存储方案在这个折衷问题上采用了相反的策略。然而，这两种方案的不平衡折衷设计将它们的有效性限制在有限类型的工作负载和系统要求上。为了减轻这种适用性损失，我们提出了MICS，一种混合链式存储方案，结合了N路复制和擦除编码的结构和功能优势。从质量上来说，MICS以合理的低空间成本提供了高效的读/写性能和高可靠性。MICS以两种形式存储每个对象:一个完整副本和一定数量的擦除编码段。我们利用独特的结构优势，为MICS建立了专用的读/写协议。此外，MICS通过流水线随机存取存储器一致性提供了高读/写效率，以保证服务用户的合理语义。评估结果表明，在相同的容错和一致性水平下，MICS在I/O吞吐量方面分别比N路复制和纯擦除编码提高了34.1%和51.3%。此外，MICS在各种工作负载条件下表现出优异的性能稳定性，在这种情况下，MICS的标准偏差比其他两种方案分别小70.1%和29.3%。",
                    "title_zh": "MICS:混合链式存储结合复制和擦除编码"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.16",
                    "title": "Online Behavior Identification in Distributed Systems",
                    "authors": "Javier Álvarez Cid-Fuentes, Claudia Szabo, Katrina Falkner",
                    "abstract": "The diagnosis, prediction, and understanding of unexpected behavior is crucial for long running, large scale distributed systems. However, existing works focus on the identification of faults in specific time moments preceded by significantly abnormal metric readings, or require a previous analysis of historical failure data. In this work, we propose an online behavior classification system to identify a wide range of undesired behaviors, which may appear even in healthy systems, and their evolution over time. We employ a two-step process involving two online classifiers on periodically collected system metrics to identify at runtime normal and anomalous behaviors such as deadlock, starvation and livelock, without any previous analysis of historical failure data. Our approach achieves over 80% accuracy in detecting unexpected behaviors and over 90% accuracy in identifying their type with a short delay after the anomalies appear, and with minimal expert intervention. Our experimental analysis uses system execution traces obtained from a Google cluster and from our in-house distributed system with varied behaviors, and shows the benefits of our approach as well as future research challenges.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对于长时间运行的大规模分布式系统，对意外行为的诊断、预测和理解是至关重要的。然而，现有的工作集中于识别在显著异常的度量读数之前的特定时刻的故障，或者需要对历史故障数据的先前分析。在这项工作中，我们提出了一个在线行为分类系统，以识别各种各样的不良行为，这些行为甚至可能出现在健康的系统中，以及它们随时间的演变。我们采用两个步骤的过程，涉及两个在线分类器对定期收集的系统指标进行分类，以在运行时识别正常和异常行为，如死锁、饥饿和活锁，而无需对历史故障数据进行任何先前的分析。我们的方法实现了超过80%的意外行为检测准确率和超过90%的异常行为类型识别准确率，并在异常出现后有一个短暂的延迟，最少的专家干预。我们的实验分析使用了从Google集群和我们的内部分布式系统获得的具有不同行为的系统执行跟踪，并显示了我们的方法的好处以及未来的研究挑战。",
                    "title_zh": "分布式系统中的在线行为识别"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.18",
                    "title": "Z Codes: General Systematic Erasure Codes with Optimal Repair Bandwidth and Storage for Distributed Storage Systems",
                    "authors": "Qing Liu, Dan Feng, Hong Jiang, Yuchong Hu, Tianfeng Jiao",
                    "abstract": "Erasure codes are widely used in distributed storage systems to prevent data loss. Traditional erasure codes suffer from a typical repair-bandwidth problem in which the amount of data required to reconstruct the lost data, referred to as the repair bandwidth, is often far more than the theoretical minimum. While many novel erasure codes have been proposed in recent years to reduce the repair bandwidth, these codes either require extra storage capacity and computation overhead or are only applicable to some special cases. To address the weaknesses of the existing solutions to the repair-bandwidth problem, we propose Z Codes, a general family of codes capable of achieving the theoretical lower bound of repair bandwidth for a single data node failure. To the best of our knowledge, the Z codes are the first general systematic erasure codes that achieve optimal repair bandwidth under the minimum storage. Our in-memory performance evaluations of a 1-GB file indicate that Z codes have encoding and repairing speeds that are approximately equal to those of the Reed-Solomon (RS) codes, and their speed on the order of GB/s practically removes computation as a performance bottleneck.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "纠删码广泛应用于分布式存储系统中，以防止数据丢失。传统的擦除码存在典型的修复带宽问题，其中重建丢失数据所需的数据量(称为修复带宽)通常远远大于理论上的最小值。虽然近年来已经提出了许多新颖的擦除码来减少修复带宽，但是这些码要么需要额外的存储容量和计算开销，要么仅适用于一些特殊情况。为了解决修复带宽问题的现有解决方案的弱点，我们提出了Z码，这是一种能够实现单个数据节点故障的修复带宽的理论下限的通用码族。据我们所知，Z码是第一个在最小存储下实现最佳修复带宽的通用系统擦除码。我们对一个1gb文件的内存性能评估表明，Z码的编码和修复速度与Reed-Solomon (RS)码大致相当，其速度约为GB/s，实际上消除了计算这一性能瓶颈。",
                    "title_zh": "z码:分布式存储系统中具有最优修复带宽和存储的通用系统擦除码"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.33",
                    "title": "Distributed Attribute Based Access Control of Aggregated Data in Sensor Clouds",
                    "authors": "Vimal Kumar, Sanjay Madria",
                    "abstract": "Sensor clouds are large scale wireless sensor networks (WSNs), built by connecting a number of smaller WSNs together. Each of these smaller individual WSNs may be owned by different owners. Sensor clouds are dynamic in nature, where wireless sensors can be provisioned and de-provisioned for the users on demand. In such a multi-user, multi-owner system, user access control is a significant problem. Previous user access control schemes have been centralized and designed for standalone sensors or smaller networks and do not take large networks into consideration. In large networks, data is generally aggregated in-network during data collection. In this paper, we present a user access control scheme, which unlike other schemes, is distributed and works on aggregated data within a sensor network. Our scheme which is based on attribute based encryption is also able to differentiate between users who require data with the same set of attributes, which would be a necessity in a commercial sensor cloud system. Our scheme gives the flexibility to sensor network owners to control user access of data from their sensors. Finally, we compare our scheme with other closely related schemes in terms of attack resilience and computation and communication overhead to show its effectiveness.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "传感器云是大规模无线传感器网络(WSNs)，通过将许多较小的WSNs连接在一起而构建。这些较小的单个WSN中的每一个都可能由不同的所有者拥有。传感器云本质上是动态的，其中无线传感器可以按需为用户供应和取消供应。在这样的多用户、多所有者系统中，用户访问控制是一个重要的问题。以前的用户访问控制方案是集中式的，并且是为独立的传感器或较小的网络设计的，没有考虑到大型网络。在大型网络中，数据通常在数据收集过程中在网络中聚合。在本文中，我们提出了一个用户访问控制方案，不同于其他方案，它是分布式的，并对传感器网络中的聚集数据起作用。我们的方案基于基于属性的加密，也能够区分需要具有相同属性集的数据的用户，这在商业传感器云系统中是必要的。我们的方案为传感器网络所有者提供了控制用户访问传感器数据的灵活性。最后，我们从抗攻击能力、计算和通信开销等方面将我们的方案与其他相关方案进行了比较，以展示其有效性。",
                    "title_zh": "传感器云中基于分布式属性的聚合数据访问控制"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.20",
                    "title": "Seek-Efficient I/O Optimization in Single Failure Recovery for XOR-coded Storage Systems",
                    "authors": "Zhirong Shen, Jiwu Shu, Yingxun Fu",
                    "abstract": "Erasure coding provides an effective means for storage systems to protect against disk failures with low redundancy. One important objective for erasure-coded storage systems is to speed up single disk failure recovery. Previous approaches reduce the amount of read data for recovery by reading only a small subset of data. However, they often incur high disk seeks, which may negate the resulting recovery performance. We propose <italic>SIOR</italic>, a seek-efficient I/O recovery algorithm for improving the performance of single disk failure recovery. SIOR carefully balances the trade-off between the amount of read data and the number of disk seeks by considering the data layout at the multi-stripe level. It then greedily determines the data to read for recovery using Tabu search. Experiments show that SIOR achieves similar performance to the brute-force enumeration method while keeping high search efficiency. Also, SIOR reduces <inline-formula><tex-math notation=\"LaTeX\">$31.8\\sim 65.1$</tex-math><alternatives> <inline-graphic xlink:href=\"shen-ieq1-2591040.gif\"/></alternatives></inline-formula> percent of disk seeks during recovery and provides up to 150.0 percent recovery speed improvement, when compared to a state-of-the-art greedy recovery approach.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "擦除编码为存储系统提供了一种有效的手段来防止低冗余的磁盘故障。擦除编码存储系统的一个重要目标是加速单磁盘故障恢复。以前的方法通过仅读取一小部分数据来减少用于恢复的读取数据量。但是，它们通常会导致大量的磁盘寻道，这可能会降低最终的恢复性能。我们提出了< italic>SIOR</italic >，这是一种高效的I/O恢复算法，用于提高单磁盘故障恢复的性能。SIOR通过考虑多条带级别的数据布局，在读取数据量和磁盘寻道数量之间小心地进行权衡。然后，它使用禁忌搜索贪婪地确定要读取的恢复数据。实验表明，SIOR在保持较高搜索效率的同时，获得了与强力枚举法相近的性能。此外，与最先进的贪婪恢复方法相比，SIOR减少了恢复期间的< inline-formula > < tex-math notation = \" LaTeX \" > $ 31.8 \\ sim 65.1 $ </tex-math > < alternatives > < inline-graphic xlink:href = \" Shen-ie Q1-2591040 . gif \"/> </alternatives > </inline-formula >磁盘寻道百分比，并提供了高达150.0%的恢复速度提升。",
                    "title_zh": "XOR编码存储系统单故障恢复中的寻道高效I/O优化"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.10",
                    "title": "Communicating Reliably in Multihop Dynamic Networks Despite Byzantine Failures",
                    "authors": "Alexandre Maurer, Sébastien Tixeuil, Xavier Défago",
                    "abstract": "We consider the following problem: two nodes want to reliably communicate in a dynamic multihop network where some nodes have been compromised, and may have a totally arbitrary and unpredictable behavior. These nodes are called Byzantine. We consider the two cases where cryptography is available and not available. We prove the necessary and sufficient condition (that is, the weakest possible condition) to ensure reliable communication in this context. Our proof is constructive, as we provide Byzantine-resilient algorithms for reliable communication that are optimal with respect to our impossibility results. In a second part, we investigate the impact of our conditions in three case studies: participants interacting in a conference, robots moving on a grid and agents in the subway. Our simulations indicate a clear benefit of using our algorithms for reliable communication in those contexts.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "我们考虑下面的问题:两个节点想要在动态多跳网络中可靠地通信，其中一些节点已经受损，并且可能具有完全任意和不可预测的行为。这些节点被称为拜占庭。我们考虑加密技术可用和不可用的两种情况。我们证明了在这种情况下确保可靠通信的必要和充分条件(即最弱的可能条件)。我们的证明是建设性的，因为我们提供了可靠通信的拜占庭弹性算法，该算法相对于我们的不可能性结果是最优的。在第二部分，我们在三个案例研究中调查了我们的条件的影响:在会议中互动的参与者，在网格上移动的机器人和地铁中的代理。我们的模拟显示了在这些环境中使用我们的算法进行可靠通信的明显好处。",
                    "title_zh": "尽管有拜占庭故障，在多跳动态网络中仍能可靠通信"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.26",
                    "title": "To Transmit Now or Not to Transmit Now",
                    "authors": "Dacfey Dzung, Rachid Guerraoui, David Kozhaya, Yvonne-Anne Pignolet",
                    "abstract": "Given an unreliable communication link, this paper studies how to build, in an energy-efficient manner, a reliable communication service that is synchronous with high probability. We consider a Partially Observable Markov Decision Process (POMDP) setting in which a communication link's transmission quality: (i) changes according to a classic Markovian model and (ii) can be only partially observed, through feedback relative to previous transmissions. We perform a thorough analysis under several variations of Ack/Nack feedback mechanisms. Despite the general intractability of POMDPs, we prove that our communication service, under reliable feedback, can be inexpensively implemented. We obtain closed form solutions specifying when to transmit over the link, which allows to derive an energy-optimal implementation. We also analyse the impact of lossy feedback on implementing our communication service. Considering multiple lossy feedback mechanisms, we show that an easily implementable structure for our communication service can also be obtained, depending on the feedback mechanism itself.",
                    "files": {
                        "openAccessPdf": "http://infoscience.epfl.ch/record/210110/files/Technical%20Report.pdf?version%3D1"
                    },
                    "abstract_zh": "给定一个不可靠的通信链路，本文研究如何以一种能量有效的方式建立一个高概率同步的可靠通信服务。我们考虑一种部分可观测的马尔可夫决策过程(POMDP)设置，其中通信链路的传输质量:(I)根据经典的马尔可夫模型变化，以及(ii)通过相对于先前传输的反馈，只能部分观测。我们在Ack/Nack反馈机制的几种变化下执行彻底的分析。尽管POMDPs普遍难以处理，但我们证明，在可靠的反馈下，我们的通信服务可以廉价地实现。我们获得指定何时在链路上传输的封闭形式的解决方案，这允许导出能量最优的实现。我们还分析了有损反馈对实现我们的通信服务的影响。考虑到多种有损反馈机制，我们表明，根据反馈机制本身，我们的通信服务也可以获得一种易于实现的结构。",
                    "title_zh": "现在传输还是现在不传输"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.13",
                    "title": "Ridge: High-Throughput, Low-Latency Atomic Multicast",
                    "authors": "Carlos Eduardo Benevides Bezerra, Daniel Cason, Fernando Pedone",
                    "abstract": "It has been shown that the highest throughput for broadcasting messages in a point-to-point network is achieved with a ring topology. Although several ring-based group communication protocols have benefited from this observation, broadcasting messages along a ring overlay may lead to high latencies: In a system with n processes, at least n-1 communication steps are necessary for all processes to deliver a message. In this work, we argue that it is possible to reach optimal throughput without resorting to a ring topology (or to ip-multicast, typically unavailable in wide-area networks). This can be done by routing messages through different paths, while carefully using the available bandwidth at each process, resulting in a significantly lower latency for every message (potentially a single communication step). Based on this idea, we propose Ridge, a Paxos-based atomic multicast protocol where each message is initially forwarded to a single destination, the distributor, whose responsibility is to propagate the message to all other destinations. To utilize all bandwidth available in the system, processes alternate in the role of distributor. By doing this, the maximum system throughput matches that of ring-based protocols, with a latency that is not significantly dependent on the size of the system. Finally, we show that Ridge can also deliver messages optimistically, with even lower latency.",
                    "files": {
                        "openAccessPdf": "http://www.inf.usi.ch/faculty/pedone/Paper/2015/2015SRDSa.pdf"
                    },
                    "abstract_zh": "已经表明，在点对点网络中广播消息的最高吞吐量是通过环形拓扑实现的。尽管若干基于环的群组通信协议已经从这种观察中受益，但是沿着环覆盖广播消息可能导致高延迟:在具有n个进程的系统中，所有进程传递消息至少需要n-1个通信步骤。在这项工作中，我们认为不依靠环形拓扑(或ip多播，通常在广域网中不可用)也可以达到最佳吞吐量。这可以通过将消息通过不同的路径路由来实现，同时在每个过程中小心地使用可用带宽，从而显著降低每个消息的延迟(可能是一个通信步骤)。基于这一思想，我们提出了Ridge，一种基于Paxos的原子多播协议，其中每个消息最初被转发到单个目的地，即分发者，其责任是将消息传播到所有其他目的地。为了利用系统中所有可用的带宽，进程轮流扮演分发服务器的角色。通过这样做，最大系统吞吐量与基于环的协议相匹配，而延迟并不显著依赖于系统的大小。最后，我们展示了Ridge也可以乐观地传递消息，甚至具有更低的延迟。",
                    "title_zh": "Ridge:高吞吐量、低延迟的原子多播"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.19",
                    "title": "Identifying Global Icebergs in Distributed Streams",
                    "authors": "Emmanuelle Anceaume, Yann Busnel, Nicolo Rivetti, Bruno Sericola",
                    "abstract": "We consider the problem of identifying global iceberg attacks in massive and physically distributed streams. A global iceberg is a distributed denial of service attack, where some elements globally recur many times across the distributed streams, but locally, they do not appear as a deny of service. A natural solution to defend against global iceberg attacks is to rely on multiple routers that locally scan their network traffic, and regularly provide monitoring information to a server in charge of collecting and aggregating all the monitored information. Any relevant solution to this problem must minimise the communication between the routers and the coordinator, and the space required by each node to analyse its stream. We propose a distributed algorithm that tracks global icebergs on the fly with guaranteed error bounds, limited memory and processing requirements. We present a thorough analysis of our algorithm performance. In particular we derive a tight upper bound on the number of bits communicated between the multiple routers and the coordinator in presence of an oblivious adversary. Finally, we present the main results of the experiments we have run on a cluster of single-board computers. Those experiments confirm the efficiency and accuracy of our algorithm to track global icebergs hidden in very large input data streams exhibiting different shapes.",
                    "files": {
                        "openAccessPdf": "https://hal.archives-ouvertes.fr/hal-01194511/file/PID3812355.pdf"
                    },
                    "abstract_zh": "我们考虑在大规模和物理分布的流中识别全球冰山攻击的问题。全局冰山是一种分布式拒绝服务攻击，其中一些元素在分布式流中全局重复出现多次，但在本地，它们不会显示为拒绝服务。防御全球冰山攻击的自然解决方案是依靠多个路由器，这些路由器在本地扫描它们的网络流量，并定期向负责收集和汇总所有被监控信息的服务器提供监控信息。这个问题的任何相关解决方案必须最小化路由器和协调器之间的通信，以及每个节点分析其流所需的空间。我们提出了一种分布式算法，在保证误差范围、有限内存和处理要求的情况下，实时跟踪全球冰山。我们对我们的算法性能进行了全面的分析。特别地，我们推导出在存在不经意的对手的情况下，在多个路由器和协调器之间通信的比特数的严格上限。最后，我们给出了我们在单板计算机集群上运行的实验的主要结果。这些实验证实了我们的算法跟踪隐藏在呈现不同形状的非常大的输入数据流中的全球冰山的效率和准确性。",
                    "title_zh": "识别分布式河流中的全球冰山"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.36",
                    "title": "A Framework for the Design Configuration of Accountable Selfish-Resilient Peer-to-Peer Systems",
                    "authors": "Guido Lena Cota, Sonia Ben Mokhtar, Julia Lawall, Gilles Muller, Gabriele Gianini, Ernesto Damiani, Lionel Brunie",
                    "abstract": "A challenge in designing a peer-to-peer (P2P) system is to ensure that the system is able to tolerate selfish nodes that strategically deviate from their specification whenever doing so is convenient. In this paper, we propose RACOON, a framework for the design of P2P systems that are resilient to selfish behaviours. While most existing solutions target specific systems or types of selfishness, RACOON proposes a generic and semi-automatic approach that achieves robust and reusable results. Also, RACOON supports the system designer in the performance-oriented tuning of the system, by proposing a novel approach that combines Game Theory and simulations. We illustrate the benefits of using RACOON by designing two P2P systems: a live streaming and an anonymous communication system. In simulations and a real deployment of the two applications on a testbed comprising 100 nodes, the systems designed using RACOON achieve both resilience to selfish nodes and high performance.",
                    "files": {
                        "openAccessPdf": "https://hal.inria.fr/hal-01250717/file/racoon-master.pdf"
                    },
                    "abstract_zh": "设计对等(P2P)系统的一个挑战是确保系统能够容忍自私节点，只要这样做是方便的，这些自私节点在策略上偏离它们的规范。在本文中，我们提出了RACOON，这是一个用于设计对自私行为具有弹性的P2P系统的框架。虽然大多数现有的解决方案针对特定的系统或自私类型，但RACOON提出了一种通用的半自动方法，可以实现健壮和可重用的结果。此外，RACOON通过提出一种结合博弈论和模拟的新方法，支持系统设计者进行面向性能的系统调优。我们通过设计两个P2P系统来说明使用RACOON的好处:一个直播流和一个匿名通信系统。在包含100个节点的测试床上的模拟和实际部署中，使用RACOON设计的系统实现了对自私节点的弹性和高性能。",
                    "title_zh": "可问责的自私弹性对等系统的设计配置框架"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.28",
                    "title": "Chasing the Tail of Atomic Broadcast Protocols",
                    "authors": "Daniel Cason, Parisa Jalili Marandi, Luiz Eduardo Buzato, Fernando Pedone",
                    "abstract": "Many applications today rely on multiple services, whose results are combined to form the application's response. In such contexts, the most unreliable service and the slowest service determine the application's reliability and response time, respectively. State-machine replication and atomic broadcast are fundamental abstractions to build highly available services. In this paper, we consider the latency variability of atomic broadcast protocols. This is important because atomic broadcast has a direct impact on the response time of services. We study four high performance atomic broadcast protocols representative of different classes of protocol design and characterize their latency tail distribution under different workloads. Next, we assess how key design features of each protocol can possibly be related to the observed latency tail distributions. Our observations hint at request batching as a simple yet effective way to shorten the latency tails of some of the studied protocols, an improvement within the reach of application implementers. Indeed, our observation is not only verified experimentally, it allows us to assess which of the protocol's key design principles favor the construction of latency predictable protocols.",
                    "files": {
                        "openAccessPdf": "http://www.inf.usi.ch/faculty/pedone/Paper/2015/2015SRDSb.pdf"
                    },
                    "abstract_zh": "如今，许多应用程序依赖于多个服务，这些服务的结果被组合起来形成应用程序的响应。在这种情况下，最不可靠的服务和最慢的服务分别决定了应用程序的可靠性和响应时间。状态机复制和原子广播是构建高可用性服务的基本抽象。在本文中，我们考虑了原子广播协议的延迟可变性。这很重要，因为原子广播对服务的响应时间有直接影响。我们研究了代表不同协议设计类别的四种高性能原子广播协议，并描述了它们在不同工作负载下的延迟尾部分布。接下来，我们评估每个协议的关键设计特征如何可能与观察到的延迟尾部分布相关联。我们的观察表明，请求批处理是一种简单而有效的方法，可以缩短一些被研究的协议的延迟时间，这是应用程序实现者可以实现的改进。事实上，我们的观察不仅通过实验得到了验证，它还允许我们评估哪些协议的关键设计原则有利于构建延迟可预测的协议。",
                    "title_zh": "追逐原子广播协议的尾巴"
                },
                {
                    "url": "https://doi.org/10.1109/SRDS.2015.17",
                    "title": "A Practical Experience on Evaluating Intrusion Prevention System Event Data as Indicators of Security Issues",
                    "authors": "Rodrigo Sanches Miani, Bruno Bogaz Zarpelão, Bertrand Sobesto, Michel Cukier",
                    "abstract": "There are currently no generally accepted metrics for information security issues. One reason is the lack of validation using empirical data. In this practical experience report, we investigate whether metrics obtained from security devices used to monitor network traffic can be employed as indicators of security incidents. If so, security experts can use this information to better define priorities on security inspection and also to develop new rules for incident prevention. The metrics we investigate are derived from intrusion detection and prevention system (IDPS) alert events. We performed an empirical case study using IDPS data provided by a large organization of about 40,000 computers. The results indicate that characteristics of alerts can be used to depict trends in some security issues and consequently serve as indicators of security performance.",
                    "files": {
                        "openAccessPdf": ""
                    },
                    "abstract_zh": "对于信息安全问题，目前没有普遍接受的衡量标准。一个原因是缺乏使用经验数据的验证。在这份实践经验报告中，我们调查了从用于监控网络流量的安全设备获得的指标是否可以用作安全事件的指标。如果是这样，安全专家可以使用这些信息来更好地定义安全检查的优先级，并制定新的事故预防规则。我们调查的指标来自入侵检测和防御系统(IDPS)警报事件。我们使用由大约40，000台计算机的大型组织提供的IDPS数据进行了实证案例研究。结果表明，警报的特征可以用来描述某些安全问题的趋势，因此可以作为安全性能的指标。",
                    "title_zh": "评估入侵防御系统事件数据作为安全问题指标的实践经验"
                }
            ]
        }
    ]
}